<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>pytorch函数mm() mul() matmul()区别 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="pytorch函数mm() mul() matmul()区别" />
<meta property="og:description" content="文章目录 1、torch.mul()2、torch.mm()3、torch.matmul()3.1 输入都是二维3.2 输入都是三维3.3 输入的维度不同 1、torch.mul() torch.mul(a, b)是矩阵a和b对应位相乘torch.mul(a, b)中a和b的维度相等，但是，对应维度上的数字可以不同，可以用利用广播机制扩展到相同的形状，再进行点乘操作 # 比如a的维度是(1, 2)，b的维度是(1, 2)，返回的仍是(1, 2)的矩阵 &gt;&gt;&gt; a = torch.rand(1, 2) &gt;&gt;&gt; b = torch.rand(1, 2) &gt;&gt;&gt; torch.mul(a, b) # 返回 1*2 的tensor # 乘列向量 &gt;&gt;&gt; a = torch.ones(3,4) &gt;&gt;&gt; a tensor([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) &gt;&gt;&gt; b = torch.Tensor([1,2,3]).reshape((3,1)) &gt;&gt;&gt; b tensor([[1.], [2.], [3.]]) &gt;&gt;&gt; torch.mul(a, b) tensor([[1., 1., 1., 1.], [2., 2., 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/b0dcf06624f34b106079c71d24d861f4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-05-24T22:24:04+08:00" />
<meta property="article:modified_time" content="2021-05-24T22:24:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">pytorch函数mm() mul() matmul()区别</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#1torchmul_2" rel="nofollow">1、torch.mul()</a></li><li><a href="#2torchmm_30" rel="nofollow">2、torch.mm()</a></li><li><a href="#3torchmatmul_43" rel="nofollow">3、torch.matmul()</a></li><li><ul><li><a href="#31__50" rel="nofollow">3.1 输入都是二维</a></li><li><a href="#32__55" rel="nofollow">3.2 输入都是三维</a></li><li><a href="#33__62" rel="nofollow">3.3 输入的维度不同</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="1torchmul_2"></a>1、torch.mul()</h3> 
<ul><li><code>torch.mul(a, b)</code>是矩阵a和b<code>对应位相乘</code></li><li><code>torch.mul(a, b)中a和b的维度相等</code>，但是，对应维度上的数字可以不同，可以用利用广播机制扩展到相同的形状，再进行点乘操作</li></ul> 
<pre><code class="prism language-python"><span class="token comment"># 比如a的维度是(1, 2)，b的维度是(1, 2)，返回的仍是(1, 2)的矩阵</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>  <span class="token comment"># 返回 1*2 的tensor</span>

<span class="token comment"># 乘列向量</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span> 
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> a
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

</code></pre> 
<h3><a id="2torchmm_30"></a>2、torch.mm()</h3> 
<ul><li><code>torch.mm(a, b)</code>是矩阵a和b矩阵相乘，比如a的维度是(3, 4)，b的维度是(4, 2)，返回的就是(3, 2)的矩阵torch.mm(a, b)针对二维矩阵</li></ul> 
<pre><code class="prism language-python"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

</code></pre> 
<blockquote> 
 <p><code>mm()是mutmul()的简称？</code></p> 
</blockquote> 
<h3><a id="3torchmatmul_43"></a>3、torch.matmul()</h3> 
<ul><li><code>torch.matmul(a, b)</code>也是一种类似于矩阵相乘操作的tensor联乘操作，一般是高维矩阵a和b相乘，但是它可以利用python 中的广播机制，处理一些维度不同的tensor结构进行相乘操作。</li></ul> 
<h4><a id="31__50"></a>3.1 输入都是二维</h4> 
<ul><li>当输入都是二维时，就是普通的矩阵乘法，和tensor.mm()函数用法相同。<br> <img src="https://images2.imgbox.com/53/81/dGtrlfty_o.png" alt="在这里插入图片描述"></li></ul> 
<hr> 
<h4><a id="32__55"></a>3.2 输入都是三维</h4> 
<ul><li>下面看一个两个都是3维的例子：<br> <img src="https://images2.imgbox.com/51/b3/w6GVzKfS_o.png" alt="在这里插入图片描述"><br> 将b的第0维1broadcast成2提出来，后两维做矩阵乘法即可。</li></ul> 
<hr> 
<h4><a id="33__62"></a>3.3 输入的维度不同</h4> 
<ul><li>当输入有多维时，把多出的一维作为batch提出来，其他部分做矩阵乘法。<br> <img src="https://images2.imgbox.com/69/55/Ivu8BoW6_o.png" alt="在这里插入图片描述"></li><li>再看一个复杂一点的，是官网的例子：<br> <img src="https://images2.imgbox.com/1b/01/IoF27OFG_o.png" alt="在这里插入图片描述"><br> 首先把a的第0维2作为batch提出来，则a和b都可看作三维。再把a的1broadcat成5，提取公因式5。（这样说虽然不严谨，但是便于理解。）然后a剩下(3,4)，b剩下(4,2)，做矩阵乘法得到(3,2)。</li></ul> 
<blockquote> 
 <p>参考：https://www.jianshu.com/p/e277f7fc67b3<br> 参考：https://blog.csdn.net/qsmx666/article/details/105783610</p> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/df8fd2b1464013fdafae934897823bbd/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java #类的加载过程 #类加载子系统</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ff5af6801a3a0e0c1e742c9744e22b42/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">了解python之面向对象</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>