<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Pytorch：几行代码轻松实现Warm up &#43; Cosine Anneal LR - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Pytorch：几行代码轻松实现Warm up &#43; Cosine Anneal LR" />
<meta property="og:description" content="Warm up与Cosine Anneal 浅谈 warm up是深度学习炼丹时常用的一种手段，由于一开始参数不稳定，梯度较大，如果此时学习率设置过大可能导致数值不稳定。使用warm up有助于减缓模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳，其次也有助于保持模型深层的稳定性。
详见 https://www.zhihu.com/question/338066667/answer/771252708
余弦退火是常用的学习率调整策略，目前在Pytorch中已经集成了相应API，见官方文档。其原理如下式，其中 η m a x \eta_{max} ηmax​为学习率最大值， η m i n \eta_{min} ηmin​为最小值， T c u r T_{cur} Tcur​为当前轮次， T m a x T_{max} Tmax​为半个周期：
实例如下：
图来自：https://zhuanlan.zhihu.com/p/93624972
torch.optim.lr_scheduler.LambdaLR 虽然Pytorch已经提供了余弦退火的相应API，但是要结合Warm up和Cosine Anneal就没有了相应的操作。
pytorch给我们提供了很多调整学习率的策略(详见官方文档)，其中有一个LambdaLR策略，让我们自己能够很方便地制定规则来调整学习率。其中，最重要的参数就是 lr_lambda，传入自定义的函数或lambda表达式，可以对Optimizer中的不同的param_groups制定不同的调整规则。
简单地理解，传入的lr_lambda参数会在梯度下降时对optimizer对应参数组的学习率乘上一个权重系数。
warm up &#43; Cosine Anneal 代码实现 根据上小节介绍的LambdaLR，我们就可以很方便地实现warm up &#43; Cosine Anneal。
需要注意，传入的lr_lambda参数是在原先的学习率上乘以一个权重，因此在实现Cosine Anneal时需要注意在最后除以base_lr。其他细节见代码注释：
import math import torch from torchvision.models import resnet18 model = resnet18(pretrained=True)	# 加载模型 optimizer = torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/cbc3960cbbb5eaa2b6a0ed7b9da424bc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-23T23:13:05+08:00" />
<meta property="article:modified_time" content="2021-02-23T23:13:05+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Pytorch：几行代码轻松实现Warm up &#43; Cosine Anneal LR</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atelier-sulphurpool-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="Warm_upCosine_Anneal__0"></a>Warm up与Cosine Anneal 浅谈</h3> 
<p>warm up是深度学习炼丹时常用的一种手段，由于一开始参数不稳定，梯度较大，如果此时学习率设置过大可能导致数值不稳定。使用warm up有助于减缓模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳，其次也有助于保持模型深层的稳定性。</p> 
<blockquote> 
 <p>详见 https://www.zhihu.com/question/338066667/answer/771252708</p> 
</blockquote> 
<p>余弦退火是常用的学习率调整策略，目前在Pytorch中已经集成了相应API，见<a href="https://pytorch.org/docs/stable/optim.html?highlight=cosineanneal#torch.optim.lr_scheduler.CosineAnnealingLR" rel="nofollow">官方文档</a>。其原理如下式，其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          η 
         
         
         
           m 
          
         
           a 
          
         
           x 
          
         
        
       
      
        \eta_{max} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为学习率最大值，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          η 
         
         
         
           m 
          
         
           i 
          
         
           n 
          
         
        
       
      
        \eta_{min} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为最小值，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          T 
         
         
         
           c 
          
         
           u 
          
         
           r 
          
         
        
       
      
        T_{cur} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight" style="margin-right: 0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为当前轮次，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          T 
         
         
         
           m 
          
         
           a 
          
         
           x 
          
         
        
       
      
        T_{max} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为半个周期：</p> 
<center> 
 <img src="https://images2.imgbox.com/3f/62/6UwnyKCy_o.png"> 
</center> 
<p>实例如下：</p> 
<blockquote> 
 <p>图来自：https://zhuanlan.zhihu.com/p/93624972</p> 
</blockquote> 
<center> 
 <img src="https://images2.imgbox.com/a2/24/yA1XKeXT_o.png"> 
</center> 
<h3><a id="torchoptimlr_schedulerLambdaLR_17"></a>torch.optim.lr_scheduler.LambdaLR</h3> 
<blockquote> 
 <p>虽然Pytorch已经提供了余弦退火的相应API，但是要结合Warm up和Cosine Anneal就没有了相应的操作。</p> 
</blockquote> 
<p>pytorch给我们提供了很多调整学习率的策略(详见<a href="https://pytorch.org/docs/1.2.0/optim.html#how-to-adjust-learning-rate" rel="nofollow">官方文档</a>)，其中有一个<code>LambdaLR</code>策略，让我们自己能够很方便地制定规则来调整学习率。其中，最重要的参数就是 <code>lr_lambda</code>，传入<strong>自定义的函数</strong>或<strong>lambda表达式</strong>，可以对Optimizer中的不同的<code>param_groups</code>制定不同的调整规则。</p> 
<p><img src="https://images2.imgbox.com/cd/8c/sDDvjVTZ_o.png" alt="在这里插入图片描述"><br> 简单地理解，传入的<code>lr_lambda</code>参数会在梯度下降时对optimizer对应参数组的学习率乘上一个权重系数。</p> 
<h3><a id="warm_up__Cosine_Anneal__26"></a>warm up + Cosine Anneal 代码实现</h3> 
<p>根据上小节介绍的LambdaLR，我们就可以很方便地实现<code>warm up + Cosine Anneal</code>。</p> 
<p>需要注意，传入的<code>lr_lambda</code>参数是在原先的学习率上乘以一个权重，因此在实现<code>Cosine Anneal</code>时需要注意在最后除以<code>base_lr</code>。其他细节见代码注释：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> math
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">import</span> resnet18

model <span class="token operator">=</span> resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>	<span class="token comment"># 加载模型</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span><span class="token punctuation">[</span>	<span class="token comment"># 初始化优化器，并设置两个param_groups</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>layer2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>layer3<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span><span class="token number">0.2</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>	<span class="token comment"># base_lr = 0.1</span>

<span class="token comment"># 设置warm up的轮次为100次</span>
warm_up_iter <span class="token operator">=</span> <span class="token number">10</span>
T_max <span class="token operator">=</span> <span class="token number">50</span>	<span class="token comment"># 周期</span>
lr_max <span class="token operator">=</span> <span class="token number">0.1</span>	<span class="token comment"># 最大值</span>
lr_min <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span>	<span class="token comment"># 最小值</span>

<span class="token comment"># 为param_groups[0] (即model.layer2) 设置学习率调整规则 - Warm up + Cosine Anneal</span>
lambda0 <span class="token operator">=</span> <span class="token keyword">lambda</span> cur_iter<span class="token punctuation">:</span> cur_iter <span class="token operator">/</span> warm_up_iter <span class="token keyword">if</span>  cur_iter <span class="token operator">&lt;</span> warm_up_iter <span class="token keyword">else</span> \
        <span class="token punctuation">(</span>lr_min <span class="token operator">+</span> <span class="token number">0.5</span><span class="token operator">*</span><span class="token punctuation">(</span>lr_max<span class="token operator">-</span>lr_min<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1.0</span><span class="token operator">+</span>math<span class="token punctuation">.</span>cos<span class="token punctuation">(</span> <span class="token punctuation">(</span>cur_iter<span class="token operator">-</span>warm_up_iter<span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>T_max<span class="token operator">-</span>warm_up_iter<span class="token punctuation">)</span><span class="token operator">*</span>math<span class="token punctuation">.</span>pi<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">0.1</span>

<span class="token comment">#  param_groups[1] 不进行调整</span>
lambda1 <span class="token operator">=</span> <span class="token keyword">lambda</span> cur_iter<span class="token punctuation">:</span> <span class="token number">1</span>

<span class="token comment"># LambdaLR</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span><span class="token punctuation">[</span>lambda0<span class="token punctuation">,</span> lambda1<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>以上代码并无实际意义，仅展现warm up + Cosine Anneal的实现，若要应用到自己的code中，各参数视情况而定。</p> 
</blockquote> 
<p>代码输出结果：</p> 
<pre><code># warm up
0.0 0.2
0.010000000000000002 0.2
0.020000000000000004 0.2
0.03 0.2
0.04000000000000001 0.2
0.05 0.2
0.06 0.2
0.06999999999999999 0.2
0.08000000000000002 0.2
0.09000000000000001 0.2
0.1 0.2
# warm up结束，进行Cosine Anneal
0.09984588209998774 0.2
0.09938447858805392 0.2
0.09861863417028184 0.2
0.09755307053217621 0.2
0.09619435722790179 0.2
0.09455087117679745 0.2
0.09263274501688284 0.2
0.0904518046337755 0.2
0.08802149625017355 0.2
0.08535680352542145 0.2
0.08247415517626752 0.2
0.0793913236883622 0.2
0.07612731574297386 0.2
0.07270225503447865 0.2
0.06913725820109266 0.2
0.0654543046337755 0.2
0.061676100965976005 0.2
0.057825941079686353 0.2
0.05392756249091362 0.2
0.050005 0.2
0.04608243750908641 0.2
0.042184058920313655 0.2
0.03833389903402403 0.2
0.03455569536622451 0.2
0.03087274179890734 0.2
0.027307744965521366 0.2
0.02388268425702614 0.2
0.020618676311637812 0.2
0.017535844823732476 0.2
0.014653196474578559 0.2
0.011988503749826454 0.2
0.009558195366224508 0.2
0.007377254983117161 0.2
0.005459128823202553 0.2
0.0038156427720982197 0.2
0.0024569294678237993 0.2
0.0013913658297181606 0.2
0.0006255214119460928 0.2
0.00016411790001226746 0.2
</code></pre> 
<p><strong>分析：</strong></p> 
<p>可以看到对于参数组<code>[0]</code>进行了<code>warm up + cosine anneal</code>调整，而参数组<code>[1]</code>一直是预设的0.2没有改变。</p> 
<h3><a id="_125"></a>参考</h3> 
<p>[1] https://butui.me/post/lamdalr-in-pytorch/<br> [2] https://pytorch.org/docs/1.2.0/optim.html#how-to-adjust-learning-rate<br> [3] https://blog.csdn.net/zgcr654321/article/details/106765238</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/054fe8e6011192c82c406fef5ea91762/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">java变量圆_（4）根据下面的要求实现圆类Circle.Java① 圆类Circle的成员变量：radius表示圆的半径.　② 圆类Circle的方法成员：　　　Circle（）：构造方法,将半径置...</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6b6784c613f21138e803123acbe0fe71/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">java double 精度范围_float 和 double 范围和精度</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>