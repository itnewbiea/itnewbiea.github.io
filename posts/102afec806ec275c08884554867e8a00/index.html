<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Python】生成词云图太简单了|拿来就用能的词云图代码 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Python】生成词云图太简单了|拿来就用能的词云图代码" />
<meta property="og:description" content="1 词云简介 词云也叫文字云，是一种可视化的结果呈现，常用在爬虫数据分析中，原理就是统计文本中高频出现的词，过滤掉某些干扰词，将结果生成一张图片，直观的获取数据的重点信息。今天，我们一起来学习一下Python生成词云的常用库「wordcloud」。
wordcloud是第三方库，需要提前下载安装。
安装： pip install wordcloud
wordcloud 对象有很多参数设定，设定不同的参数，可以绘制不同形状、颜色和尺寸的词云图。
2 WordCloud对象常用参数 参数说明font_path设置字体，指定字体文件的路径width生成图片宽度，默认400像素height生成图片高度，默认200像素mask词云形状，默认使用矩形min_font_size词云中最小的字体字号，默认4号font_step字号步进间隔，默认1max_font_size词云中最大的字体字号，默认根据高度自动调节max_words词云显示的最大词数，默认200stopwords设置停用词（需要屏蔽的词），停用词不在词云中显示，默认使用内置的STOPWORDSbackground_color图片背景颜色，默认黑色 3 WordCloud常用方法 方法功能generate(text)加载词云文本to_file(filename)输出词云文件 wordcloud默认是为了英文文本来做词云的，如果需要制作中文文本词云，就需要先对中文进行分词。这里就需要用到中文分词库「jieba」。
4 jieba 分词库 jieba 是优秀的中文分词库，需要安装。它的原理是利用一个中文词库，确定中文字符之间的关联概率，汉字间概率大的组成词组，形成分词结果，除了分词，还可以添加自定义词组。
安装：pip install jieba
jieba有三种分词模式，这里我们只学习它的精确模式，把文本精确地切分开，不存在冗余单词。
使用jieba.lcut(s)，返回列表型分词结果。当然，也可以使用jieba.add_word(w)向jieba库中增加词语。
5 使用wordcloud生成词云的步骤 读取文件，分词整理，生成词云文本配置wordcloud对象参数，加载词云文本计算词频，输出词云文件 6 词云案例 --- 爬取最近很火的一部电影《芭比》的影评数据，生成词云图。 1）生成文本文件 获取豆瓣电影网站10页短评数据，保存到文本中。
代码如下：
import requests from lxml import etree import time import random # 通过观察url翻页的规律，使用for循环得到10个链接，保存到urls列表中 urls = [&#39;https://movie.douban.com/subject/4058939/comments?start={}&amp;limit=20&amp;status=P&amp;sort=new_score&#39;.format(str(i)) for i in range(0, 200, 20)] # print(urls) headers = { &#34;User-Agent&#34;: &#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/102afec806ec275c08884554867e8a00/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-28T23:44:27+08:00" />
<meta property="article:modified_time" content="2023-07-28T23:44:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Python】生成词云图太简单了|拿来就用能的词云图代码</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>1 词云简介</h3> 
<p>词云也叫文字云，是一种可视化的结果呈现，常用在爬虫数据分析中，原理就是统计文本中高频出现的词，过滤掉某些干扰词，将结果生成一张图片，直观的获取数据的重点信息。今天，我们一起来学习一下Python生成词云的常用库<strong>「wordcloud」</strong>。</p> 
<p>wordcloud是第三方库，需要提前下载安装。</p> 
<blockquote> 
 <p>安装： pip install wordcloud</p> 
</blockquote> 
<p> <strong>wordcloud </strong>对象有很多参数设定，设定不同的参数，可以绘制不同形状、颜色和尺寸的词云图。</p> 
<hr> 
<h3><strong>2 WordCloud对象常用参数</strong> </h3> 
<table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>font_path</td><td>设置字体，指定字体文件的路径</td></tr><tr><td>width</td><td>生成图片宽度，默认400像素</td></tr><tr><td>height</td><td>生成图片高度，默认200像素</td></tr><tr><td>mask</td><td>词云形状，默认使用矩形</td></tr><tr><td>min_font_size</td><td>词云中最小的字体字号，默认4号</td></tr><tr><td>font_step</td><td>字号步进间隔，默认1</td></tr><tr><td>max_font_size</td><td>词云中最大的字体字号，默认根据高度自动调节</td></tr><tr><td>max_words</td><td>词云显示的最大词数，默认200</td></tr><tr><td>stopwords</td><td>设置停用词（需要屏蔽的词），停用词不在词云中显示，默认使用内置的STOPWORDS</td></tr><tr><td>background_color</td><td>图片背景颜色，默认黑色</td></tr></tbody></table> 
<hr> 
<h3>3 WordCloud常用方法 </h3> 
<table><thead><tr><th>方法</th><th>功能</th></tr></thead><tbody><tr><td>generate(text)</td><td>加载词云文本</td></tr><tr><td>to_file(filename)</td><td>输出词云文件</td></tr></tbody></table> 
<p> wordcloud默认是为了英文文本来做词云的，如果需要制作中文文本词云，就需要先对中文进行分词。这里就需要用到中文分词库<strong>「jieba」</strong>。</p> 
<hr> 
<h3>4 jieba 分词库</h3> 
<p><strong>jieba </strong>是优秀的中文分词库，需要安装。它的原理是利用一个中文词库，确定中文字符之间的关联概率，汉字间概率大的组成词组，形成分词结果，除了分词，还可以添加自定义词组。</p> 
<blockquote> 
 <p>安装：<code>pip install jieba</code></p> 
</blockquote> 
<p>jieba有三种分词模式，这里我们只学习它的精确模式，把文本精确地切分开，不存在冗余单词。</p> 
<p>使用<code>jieba.lcut(s)</code>，返回列表型分词结果。当然，也可以使用jieba.add_word(w)向jieba库中增加词语。</p> 
<hr> 
<h3>5 使用wordcloud生成词云的步骤</h3> 
<ul><li><strong>读取文件，分词整理，生成词云文本</strong></li><li><strong>配置wordcloud对象参数，加载词云文本</strong></li><li><strong>计算词频，输出词云文件</strong></li></ul> 
<hr> 
<h3>6 词云案例</h3> 
<p>        --- 爬取最近很火的一部电影《芭比》的影评数据，生成词云图。 </p> 
<h4>1）生成文本文件 </h4> 
<p><strong>        获取豆瓣电影网站10页短评数据，保存到文本中。</strong></p> 
<p>代码如下：</p> 
<pre><code class="language-python">import requests
from lxml import etree
import time
import random

# 通过观察url翻页的规律，使用for循环得到10个链接，保存到urls列表中
urls = ['https://movie.douban.com/subject/4058939/comments?start={}&amp;limit=20&amp;status=P&amp;sort=new_score'.format(str(i)) for
        i in range(0, 200, 20)]
# print(urls)
headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36"
}
# 初始化用于保存短评的列表
comments_list = []
# 使用for循环遍历获取每个页面的数据，保存到comments_list列表中
for url in urls:
    resp = requests.get(url=url, headers=headers).text
    html = etree.HTML(resp)
    data_list = html.xpath('//div[@id="comments"]/div[@class="comment-item "]')
    # page_list用于保存同一页面内的所有评论
    page_list = []
    for data in data_list:
        comment = data.xpath('./div[2]/p/span/text()')[0]
        page_list.append(comment)
    # print(page_list)
    comments_list.extend(page_list)
    # 让程序随机睡眠0~3秒，避免速度过快被反爬
    time.sleep(random.randint(0, 3))
print("共获取电影《芭比》的短评条数：", len(comments_list))

with open('movie_comments.txt', 'w', encoding='utf-8') as f:
    # 将列表中的数据逐条写入到文本文件中
    for comment in comments_list:
        f.write(comment + "\n")</code></pre> 
<h4> 2）生成基本的词云</h4> 
<p>        读取第一步中的文本文件，生成词云图。</p> 
<p> 代码如下：</p> 
<pre><code class="language-python">import jieba
import wordcloud

# 读取文本
with open("movie_comments.txt", encoding="utf-8") as f:
    s = f.read()
# print(s)
# 生成分词列表
list_s = jieba.lcut(s)
# print(ls)
# 用空格连接成字符串文本
text = ' '.join(list_s)
# print(text)
# 将不需要显示的词整理好后，放入stopwords中
stopwords = ["是", "的", "了", "啊"]
# 创建词云对象
wc = wordcloud.WordCloud(font_path="msyh.ttc",
                         width=1000,
                         height=700,
                         background_color='white',
                         max_words=100,
                         stopwords=stopwords)
# msyh.ttc是电脑本地字体，也可以写成绝对路径，字体也可以根据需求换其他字体文件
wc.generate(text)   # 加载词云文本
wc.to_file("芭比comments.png")  # 保存词云图文件</code></pre> 
<p>词云图效果如下：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/34/b4/Ztqzfh6r_o.png"></p> 
<h4> 3）添加蒙版图片的词云图</h4> 
<p>可以将有白色背景的图片作为蒙版图片，而有图案的地方会被词云填充。</p> 
<p>添加蒙版图片需要使用PIL库和numpy库，需提前下载安装。</p> 
<p>本案例添加蒙版图片如下：</p> 
<p style="text-align:center;"> </p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/7a/e7/3h61Cknz_o.jpg"></p> 
<p> 代码如下：</p> 
<pre><code class="language-python">from wordcloud import WordCloud
from PIL import Image
import numpy as np
import jieba

# 打开文本
with open("movie_comments.txt", encoding="utf-8") as f:
    s = f.read()

# 中文分词
text = ' '.join(jieba.cut(s))

# 打开蒙版图片，生成Image对象
img = Image.open("img/chicken.jpg")  # 打开遮罩图片
# 生成蒙版
mask = np.array(img)   # 将图片转换为数组
# 整理不需要显示的词
stopwords = ["的", "是", "了", "在", "也", "和", "就", "都", "这", "你", "我", "她"]
# 生成WordCloud词云对象，并加载text字符串文本
wc = WordCloud(font_path="msyh.ttc",
               mask=mask,
               width=1000,
               height=800,
               background_color='white',
               max_words=200,
               stopwords=stopwords).generate(text)

# 保存词云图到文件
wc.to_file("芭比comments.png")
</code></pre> 
<p>词云图效果如下：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/f5/8e/NKCLd48H_o.png"> </p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7eb786296c8d12d9345b5cb7b14eb622/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Redis - Bitmap</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7430bc35a3eda230911e6045435afa29/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SQL练习题之求平均分低于80分的班级学生各科成绩并合计学生总分</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>