<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Swin Transformer详解 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Swin Transformer详解" />
<meta property="og:description" content="目录 1. Swin Transformer整体架构(a) Architecture(b) Two Successive Swin Transformer Blocks 2. Shifted Window based Self-Attention3. 实验结果 之前transformer主要用于NLP领域，现在也应用到了CV领域。
该文介绍了一种新的Transformer，称为Swin Transformer，它可以作为计算机视觉的通用backbone。
将Transformer从语言调整到视觉的挑战来自两个领域之间的差异：
1.视觉实体的大小差异很大，NLP对象的大小是标准固定的。
2.图像中的像素与文本中的单词相比具有很高的分辨率，而CV中使用Transformer的计算复杂度是图像尺度的平方，这会导致计算量过于庞大。
为了解决这两个问题，这篇文章提出了a hierarchical Transformer ，其表示是用滑窗操作计算的。滑窗操作方案通过将注意力计算限制到不重叠的局部窗口，同时还允许跨窗口连接，带来了更高的效率。（滑窗操作包括不重叠的local window，和重叠的cross-window。）
这种分层体系结构可以灵活地在各种尺度上建模，并且在图像大小方面具有线性计算复杂性。Swin Transformer的这些品质使其能够兼容广泛的视觉任务。
(a) 提出的Swin Transformer通过合并更深层的图像块(以灰色显示)来构建分层特征图，并且由于只在每个局部窗口(以红色显示)内计算注意力，因此对于输入图像大小具有线性计算复杂度。因此，它可以作为图像分类和密集识别任务的通用backbone。
(b) 相比之下，以前的Vison transformer产生单一低分辨率的特征图，并且由于计算全局的自我注意，对于输入图像大小具有二次计算复杂度。
———————————————————————————————————————
1. Swin Transformer整体架构 (a) Architecture 构建了4个stage，每个stage中都是类似的重复单元。
和ViT类似，通过patch partition将输入图片 HxWx3 划分为不重合的patch集合，其中每个patch尺寸为 4x4，那么每个patch的特征维度为 4x4x3=48 ，patch块的数量为H/4 x W/4；
stage1：先通过一个linear embedding将输划分后的patch特征维度变成C，然后送入Swin Transformer Block；
stage2-stage4操作相同，先通过一个patch merging，将输入按照2x2的相邻patches合并，这样子patch块的数量就变成了H/8 x W/8，特征维度就变成了4C，这个地方文章写的不清楚，猜测是跟stage1一样使用linear embedding将4C压缩成2C（通过一个全连接层再调整通道维度为原来的两倍），然后送入Swin Transformer Block。
stage1：【H/4 x W/4，C】
stage2：【H/8 x W/8，2C】
stage2：【H/16 x W/16，4C】" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/5acdf32344dbc4a0bb01aa1d956f0682/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-03T17:41:32+08:00" />
<meta property="article:modified_time" content="2022-04-03T17:41:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Swin Transformer详解</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><ul><li><a href="#1_Swin_Transformer_22" rel="nofollow">1. Swin Transformer整体架构</a></li><li><ul><li><a href="#a_Architecture_25" rel="nofollow">(a) Architecture</a></li><li><a href="#b_Two_Successive_Swin_Transformer_Blocks_41" rel="nofollow">(b) Two Successive Swin Transformer Blocks</a></li></ul> 
   </li><li><a href="#2_Shifted_Window_based_SelfAttention_47" rel="nofollow">2. Shifted Window based Self-Attention</a></li><li><a href="#3__77" rel="nofollow">3. 实验结果</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<p>之前transformer主要用于NLP领域，现在也应用到了CV领域。</p> 
<p>该文介绍了一种新的Transformer，称为Swin Transformer，它可以作为计算机视觉的通用backbone。<br> 将Transformer从语言调整到视觉的挑战来自两个领域之间的差异：</p> 
<p><strong>1.视觉实体的大小差异很大，NLP对象的大小是标准固定的。<br> 2.图像中的像素与文本中的单词相比具有很高的分辨率，而CV中使用Transformer的计算复杂度是图像尺度的平方，这会导致计算量过于庞大。</strong></p> 
<p>为了解决这两个问题，这篇文章提出了a hierarchical Transformer ，其表示是用滑窗操作计算的。滑窗操作方案通过将注意力计算限制到不重叠的局部窗口，同时还允许跨窗口连接，带来了更高的效率。（<strong>滑窗操作包括不重叠的local window，和重叠的cross-window。</strong>）<br> 这种分层体系结构可以灵活地在各种尺度上建模，并且<strong>在图像大小方面具有线性计算复杂性</strong>。Swin Transformer的这些品质使其能够兼容广泛的视觉任务。<br> <img src="https://images2.imgbox.com/8c/d3/LyM7uFyr_o.png" alt="在这里插入图片描述"><br> <strong>(a)</strong> 提出的Swin Transformer通过合并更深层的图像块(以灰色显示)来构建分层特征图，并且由于只在每个局部窗口(以红色显示)内计算注意力，因此对于输入图像大小具有线性计算复杂度。因此，它可以作为图像分类和密集识别任务的通用backbone。</p> 
<p><strong>(b)</strong> 相比之下，以前的Vison transformer产生单一低分辨率的特征图，并且由于计算全局的自我注意，对于输入图像大小具有二次计算复杂度。</p> 
<p>———————————————————————————————————————</p> 
<h3><a id="1_Swin_Transformer_22"></a>1. Swin Transformer整体架构</h3> 
<p><img src="https://images2.imgbox.com/82/11/Wvx6vJN4_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<h4><a id="a_Architecture_25"></a>(a) Architecture</h4> 
<p><img src="https://images2.imgbox.com/30/fe/mpYhGBsq_o.png" alt="在这里插入图片描述"><br> 构建了4个stage，每个stage中都是类似的重复单元。<br> 和ViT类似，通过patch partition将输入图片 <strong>HxWx3</strong> 划分为不重合的patch集合，其中每个patch尺寸为 <strong>4x4</strong>，那么每个patch的特征维度为 <strong>4x4x3=48</strong> ，<strong>patch块的数量为H/4 x W/4</strong>；<br> stage1：先通过一个linear embedding将输划分后的patch特征维度变成C，然后送入Swin Transformer Block；<br> stage2-stage4操作相同，先通过一个patch merging，将输入按照2x2的相邻patches合并，这样子patch块的数量就变成了H/8 x W/8，特征维度就变成了4C，这个地方文章写的不清楚，猜测是跟stage1一样使用linear embedding将4C压缩成2C（<strong>通过一个全连接层再调整通道维度为原来的两倍</strong>），然后送入Swin Transformer Block。<br> <img src="https://images2.imgbox.com/fd/f7/Jzr4tXJO_o.png" alt="在这里插入图片描述"><br> <strong>stage1：【H/4 x W/4，C】<br> stage2：【H/8 x W/8，2C】<br> stage2：【H/16 x W/16，4C】<br> stage2：【H/32 x W/32，8C】</strong></p> 
<p>Swin Transformer和ViT划分patch的方式类似，Swin Transformer也是先确定每个patch的大小，然后计算确定patch数量。不同的是，<strong>随着网络深度加深ViT的patch数量不会变化</strong>，而<strong>Swin Transformer随着网络深度的加深数量会逐渐减少并且每个patch的感知范围会扩大</strong>，这个设计是为了方便Swin Transformer的层级构建，并且能够适应视觉任务的多尺度。</p> 
<hr> 
<h4><a id="b_Two_Successive_Swin_Transformer_Blocks_41"></a>(b) Two Successive Swin Transformer Blocks</h4> 
<p><img src="https://images2.imgbox.com/ba/55/D3Fs3Ej3_o.png" alt="在这里插入图片描述"><br> 这是两个连续的Swin Transformer Block。一个Swin Transformer Block由一个带两层MLP的shifted window based MSA组成。在每个MSA模块和每个MLP之前使用LayerNorm(LN)层，并在每个MSA和MLP之后使用残差连接。</p> 
<hr> 
<h3><a id="2_Shifted_Window_based_SelfAttention_47"></a>2. Shifted Window based Self-Attention</h3> 
<p><img src="https://images2.imgbox.com/c1/16/S81gMEU8_o.png" alt="在这里插入图片描述"><br> 在所提出的Swin transformer体系结构中计算注意力的滑窗操作的示例。在l层(左)中，采用规则的窗口划分方案，在每个窗口内计算自注意。在下一层l + 1(右)中，窗口分区被移动，产生了新的窗口。新窗口中的自注意计算跨越了层l中以前窗口的边界，提供了它们之间的连接。</p> 
<p><strong>普通的MSA和W-MSA的计算量对比：</strong><br> <img src="https://images2.imgbox.com/2d/4b/s9FXyPNR_o.png" alt="在这里插入图片描述"><br> W-MSA虽然降低了计算复杂度，但是不重合的window之间缺乏信息交流，于是作者进一步引入shifted window partition来解决不同window的信息交流问题，该方法在连续的Swin Transformer块中的两个Swin Transformer Block之间交替进行。</p> 
<p><strong>第一个模块W-MSA:</strong> 使用从左上角像素开始的常规窗口划分策略，将8 × 8特征图均匀划分为大小为4×4 (M = 4)的2×2窗口。</p> 
<p><strong>下一个模块SW-MSA:</strong> 采用与前一层不同的窗口配置，通过将窗口从规则划分的窗口中移位(M/2，M/2)个像素。</p> 
<p><img src="https://images2.imgbox.com/e1/12/1V0vQrAJ_o.png" alt="在这里插入图片描述"><br> <em>将前一层Swin Transformer Block的8x8尺寸feature map划分成2x2个patch，每个patch尺寸为4x4，然后将下一层Swin Transformer Block的window位置进行移动，得到3x3个不重合的patch。移动window的划分方式使上一层相邻的不重合window之间引入连接，大大的增加了感受野。可以看到移位后的窗口包含了原本相邻窗口的元素。但这也引入了一个新问题，即window的个数翻倍了，由原本四个窗口变成了9个窗口。</em></p> 
<p>在实际代码里，我们是通过对<strong>特征图移位</strong>，并<strong>给Attention设置mask</strong>来间接实现的。能在保持原有的window个数下，最后的计算结果等价。</p> 
<p><strong>特征图移位操作</strong><br> <img src="https://images2.imgbox.com/5d/0f/v4qy3bTc_o.png" alt="在这里插入图片描述"><br> <strong>Attention Mask</strong><br> 先特征图移位<br> <img src="https://images2.imgbox.com/c7/4d/y6h6qibH_o.png" alt="在这里插入图片描述"><br> 让具有相同index QK进行计算，而忽略不同index QK计算结果。<br> <img src="https://images2.imgbox.com/f7/55/b1hefr9x_o.png" alt="在这里插入图片描述"><br> <a href="https://zhuanlan.zhihu.com/p/367111046" rel="nofollow">特征图移位操作来源：https://zhuanlan.zhihu.com/p/367111046</a></p> 
<p><strong>Relative position bias</strong><br> 增加了个相对位置偏差B<br> <img src="https://images2.imgbox.com/7b/ac/EfSsskfV_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="3__77"></a>3. 实验结果</h3> 
<p><img src="https://images2.imgbox.com/3d/ce/ti2t5KDh_o.png" alt="在这里插入图片描述"><br> 可以看出，在Imagenet数据集上比它之前的ViT效果要好。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3f52da9e35d190a202202ddc48a8bfb6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">学术经验（一）Endnote的安装与使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ffd479661120644a115582cd99868d23/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Proactor模型</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>