<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python词云图词频统计 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python词云图词频统计" />
<meta property="og:description" content="目录
一：安装必要的库
二：数据分析 条形图可视化
三：数据分析 词频统计 词云图可视化
一：安装必要的库 导入必要的库
import collections # 词频统计库 import os import re # 正则表达式库 import urllib.error # 指定url，获取网页数据 import urllib.request import jieba # 结巴分词 import matplotlib.pyplot as plt # 图像展示库 import numpy as np # numpy数据处理库 import pandas as pd import wordcloud # 词云展示库 import xlwt # 进行excel操作 from PIL import Image # 图像处理库 from bs4 import BeautifulSoup # 网页解析，获取数据 from pyecharts.charts import Bar # 画柱形图 导入的库，如果出现报错，自己安装即可 如下安装示例1" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/b4763ac3081fc09c428666704d9d1e8d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-25T16:36:54+08:00" />
<meta property="article:modified_time" content="2022-12-25T16:36:54+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python词云图词频统计</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%EF%BC%9A%E5%AE%89%E8%A3%85%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93-toc" style="margin-left:0px;"><a href="#%E4%B8%80%EF%BC%9A%E5%AE%89%E8%A3%85%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93" rel="nofollow">一：安装必要的库</a></p> 
<p id="%E4%BA%8C%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20%E6%9D%A1%E5%BD%A2%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20%E6%9D%A1%E5%BD%A2%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96" rel="nofollow">二：数据分析 条形图可视化</a></p> 
<p id="%E4%B8%89%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%20%E8%AF%8D%E4%BA%91%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96-toc" style="margin-left:0px;"><a href="#%E4%B8%89%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%20%E8%AF%8D%E4%BA%91%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96" rel="nofollow">三：数据分析 词频统计 词云图可视化</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%B8%80%EF%BC%9A%E5%AE%89%E8%A3%85%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93">一：安装必要的库</h2> 
<blockquote> 
 <p><strong>导入必要的库</strong></p> 
</blockquote> 
<pre><code class="language-python">import collections  # 词频统计库
import os
import re  # 正则表达式库
import urllib.error  # 指定url，获取网页数据
import urllib.request
import jieba  # 结巴分词
import matplotlib.pyplot as plt  # 图像展示库
import numpy as np  # numpy数据处理库
import pandas as pd
import wordcloud  # 词云展示库
import xlwt  # 进行excel操作
from PIL import Image  # 图像处理库
from bs4 import BeautifulSoup  # 网页解析，获取数据
from pyecharts.charts import Bar  # 画柱形图</code></pre> 
<blockquote> 
 <p><strong>导入的库，如果出现报错，自己安装即可</strong> </p> 
</blockquote> 
<blockquote> 
 <p><strong>如下安装示例1</strong></p> 
</blockquote> 
<pre><code class="language-bash">pip install xlrd  -i https://pypi.tuna.tsinghua.edu.cn/simple</code></pre> 
<p><img alt="" height="170" src="https://images2.imgbox.com/98/a6/o7gqLlWw_o.png" width="1200"></p> 
<blockquote> 
 <p><strong>如下安装示例2</strong></p> 
</blockquote> 
<blockquote> 
 <p><strong>词云库下载，需要注意查看自己版本，下载对应版本安装</strong></p> 
 <p><strong><a class="link-info" href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud" rel="nofollow" title="https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud">https://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud</a></strong> </p> 
</blockquote> 
<p><img alt="" height="424" src="https://images2.imgbox.com/78/4e/6ZzxcbRg_o.png" width="664"> </p> 
<blockquote> 
 <p><strong>如博主使用的是python3.7，64位，【可以调出cmd 输入python回车即可查看】 </strong> </p> 
</blockquote> 
<p><img alt="" height="34" src="https://images2.imgbox.com/4f/e0/1lNjLqyV_o.png" width="549"> </p> 
<blockquote> 
 <p><strong>总之，安装必要的库，比较简单，这边不过多阐述 </strong></p> 
</blockquote> 
<h2 id="%E4%BA%8C%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20%E6%9D%A1%E5%BD%A2%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96">二：数据分析 条形图可视化</h2> 
<blockquote> 
 <p><strong>电影评分前25名，条形图展示</strong></p> 
</blockquote> 
<pre><code class="language-python">    # 可视化
    data = pd.read_excel('豆瓣电影Top250.xls')
    df = data.sort_values('评分', ascending=False).head(25)
    v = df['影片中文名'].values.tolist()  # tolist()将数据转换为列表形式
    d = df['评分'].values.tolist()
    # 设置颜色
    color_series = ['#2C6BA0', '#2B55A1', '#2D3D8E', '#44388E', '#6A368B'
                                                                '#7D3990', '#A63F98', '#C31C88', '#D52178', '#D5225B']
    print("-----" * 15)
    bar = (
        Bar()
            .add_xaxis([i for i in df['影片中文名'].values.tolist()])
            .add_yaxis('评分前25名', df['评价数'].values.tolist())
    )
    bar.render("./条形图.html")
    print("柱形图保存成功！")</code></pre> 
<blockquote> 
 <p><strong>生成html网页可以查看条形图 电影评分前25名</strong></p> 
</blockquote> 
<p><img alt="" height="650" src="https://images2.imgbox.com/5f/cb/48YpxU1M_o.png" width="1134"></p> 
<h2 id="%E4%B8%89%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%20%E8%AF%8D%E4%BA%91%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96">三：数据分析 词频统计 词云图可视化</h2> 
<pre><code class="language-bash"># 读取文件
fn = open('top250.txt', 'r', encoding='utf-8')
string_data = fn.read()
fn.close()</code></pre> 
<blockquote> 
 <p><strong>需要特别注意的是，文件格式为utf8，可对txt另存为，再设置编码格式，如下</strong></p> 
</blockquote> 
<p><img alt="" height="174" src="https://images2.imgbox.com/a2/b0/8tznhbJh_o.png" width="782"></p> 
<blockquote> 
 <p><strong>词频统计 词云图生成 ：</strong></p> 
</blockquote> 
<pre><code class="language-python">    # 读取文件
    fn = open('top250.txt', 'r', encoding='utf-8')
    string_data = fn.read()
    fn.close()
    # 文本预处理
    pattern = re.compile(u'\t|\n|\.|-|:|;|\)|\(|\?|"')  # 定义正则表达式匹配模式
    string_data = re.sub(pattern, '', string_data)  # 将符合模式的字符去除
    # 文本分词
    seg_list_exact = jieba.cut(string_data, cut_all=False)  # 精确模式分词
    object_list = []
    remove_words = [u'19', u'，', u'20', u'德国', u'导演', u'日本', u'法国', u'等', u'能', u'都', u'。', u' ', u'、', u'中', u'在',
                    u'了',
                    u'20', u'大陆', u'我们', u'美国']  # 自定义去除词库

    for word in seg_list_exact:  # 循环读出每个分词
        if word not in remove_words:  # 如果不在去除词库中
            object_list.append(word)  # 分词追加到列表

    # 词频统计
    word_counts = collections.Counter(object_list)
    word_counts_top10 = word_counts.most_common(10)
    print(word_counts_top10)  # 输出检查
    word_counts_top10 = str(word_counts_top10)

    # 词频展示
    mask = np.array(Image.open('image.jpg'))
    wc = wordcloud.WordCloud(
        font_path='simfang.ttf',
        mask=mask,
        max_words=100,  # 最多显示词数
        max_font_size=150,  # 字体最大值
        background_color='white',
        width=800, height=600,
    )

    wc.generate_from_frequencies(word_counts)
    plt.imshow(wc)
    plt.axis('off')
    plt.show()
    wc.to_file('wordcloud.png')</code></pre> 
<blockquote> 
 <p><strong>运行测试，实现词频统计 </strong></p> 
</blockquote> 
<p><img alt="" height="596" src="https://images2.imgbox.com/e2/20/3CeuLIC8_o.png" width="778"></p> 
<p><img alt="" height="119" src="https://images2.imgbox.com/2a/04/mMFWDMgY_o.png" width="1200"></p> 
<blockquote> 
 <p><strong>同时生成词云图 保存本地可查看 </strong></p> 
</blockquote> 
<p><img alt="" height="663" src="https://images2.imgbox.com/a5/95/BOsryCIR_o.png" width="1200"></p> 
<blockquote> 
 <p><strong>完整源码分享，需要自取</strong></p> 
</blockquote> 
<pre><code class="language-python">import collections  # 词频统计库
import os
import re  # 正则表达式库
import urllib.error  # 指定url，获取网页数据
import urllib.request
import jieba  # 结巴分词
import matplotlib.pyplot as plt  # 图像展示库
import numpy as np  # numpy数据处理库
import pandas as pd
import wordcloud  # 词云展示库
import xlwt  # 进行excel操作
from PIL import Image  # 图像处理库
from bs4 import BeautifulSoup  # 网页解析，获取数据
from pyecharts.charts import Bar  # 画柱形图


def main():
    baseurl = "https://movie.douban.com/top250?start="
    # 获取网页
    datalist = getDate(baseurl)
    savepath = ".\\豆瓣电影Top250.xls"
    # 保存数据
    saveData(datalist, savepath)


head = {
    "User-Agent": "Mozilla / 5.0(Windows NT 10.0;WOW64) AppleWebKit / 537.36(KHTML, likeGecko) Chrome / 85.0.4183.121Safari / 537.36"
}

# 影片详情链接规则
findLink = re.compile(r'&lt;a href="(.*?)"&gt;')  # 创建正则表达式对象
# 影片图片的链接
findImgSrc = re.compile(r'&lt;img.*src="(.*?)"', re.S)
# 影片片名
findTitle = re.compile(r'&lt;span class="title"&gt;(.*)&lt;/span&gt;')
# 影片评分
findRating = re.compile(r'&lt;span class="rating_num" property="v:average"&gt;(.*)&lt;/span&gt;')
# 评价人数
findJudge = re.compile(r'&lt;span&gt;(\d*)人评价&lt;/span&gt;')
# 概况
findInq = re.compile(r'&lt;span class="inq"&gt;(.*)&lt;/span&gt;')
# 找到影片的相关内容
findBd = re.compile(r'&lt;p class=""&gt;(.*?)&lt;/p&gt;', re.S)


# 爬取网页
def getDate(baseurl):
    datalist = []
    x = 1
    # 调用获取页面信息的函数(10次)
    for i in range(0, 10):
        url = baseurl + str(i * 25)
        html = askURL(url)  # 保存获取到的网页源码
        # 逐一解析数据
        soup = BeautifulSoup(html, "html.parser")
        for item in soup.find_all('div', class_="item"):
            data = []  # 保存一部电影的所有信息
            item = str(item)  # 将item转换为字符串
            # 影片详情链接
            link = re.findall(findLink, item)[0]
            # 追加内容到列表
            data.append(link)

            imgSrc = re.findall(findImgSrc, item)[0]
            data.append(imgSrc)

            titles = re.findall(findTitle, item)
            if (len(titles) == 2):
                ctitle = titles[0]
                data.append(ctitle)  # 添加中文名
                otitle = titles[1].replace("/", "")
                data.append(otitle)  # 添加外国名
            else:
                data.append(titles[0])
                data.append(' ')  # 外国名如果没有则留空

            rating = re.findall(findRating, item)[0]
            data.append(rating)

            judgeNum = re.findall(findJudge, item)[0]
            data.append(judgeNum)

            inq = re.findall(findInq, item)
            if len(inq) != 0:
                inq = inq[0].replace("。", "")
                data.append(inq)
            else:
                data.append(' ')

            bd = re.findall(findBd, item)[0]
            bd = re.sub('&lt;br(\s+)?/&gt;(\s+)?', " ", bd)
            bd = re.sub('/', " ", bd)
            data.append(bd.strip())

            datalist.append(data)  # 把处理好的一部电影信息放入datalist
            # print(link)

            # 下载图片到本地
            root = "D://moviePic//"
            path = root + str(x) + '.jpg'
            try:
                if not os.path.exists(root):
                    os.mkdir(root)
                if not os.path.exists(path):
                    # r = requests.get(imgSrc, headers=head)
                    urllib.request.urlretrieve(imgSrc, path)
                    # with open(path, 'wb') as f:
                    #   f.write(r.content)
                    #   f.close()
                    print("下载第%d部电影封面" % (x))
                    x += 1
                else:
                    print("文件保存成功")
            except:
                print("下载失败")
    return datalist


# 得到指定一个url的网页内容
def askURL(url):
    request = urllib.request.Request(url, headers=head)
    html = ""
    try:
        response = urllib.request.urlopen(request)
        html = response.read().decode("utf-8")
    except urllib.error.URLError as e:
        if hasattr(e, "code"):
            print(e.code)  # 打印错误信息
        if hasattr(e, "reason"):
            print(e.reason)  # 打印错误原因
    return html


# 保存数据
def saveData(datalist, savepath):
    book = xlwt.Workbook(encoding="utf-8", style_compression=0)  # 创建workbook对象
    sheet = book.add_sheet("豆瓣电影Top250", cell_overwrite_ok=True)  # 创建工作表
    col = ('电影详情链接', "图片链接", "影片中文名", "影片外国名", "评分", "评价数", "概况", "相关信息")
    try:
        for i in range(0, 8):
            sheet.write(0, i, col[i])  # 输入列名
        for i in range(0, 250):
            print("第%d条" % (i + 1))
            data = datalist[i]
            for j in range(0, 8):
                sheet.write(i + 1, j, data[j])
        book.save(savepath)
    except:
        print("爬取异常")


if __name__ == '__main__':
    main()
    print("爬取完毕")
    # 可视化
    data = pd.read_excel('豆瓣电影Top250.xls')
    df = data.sort_values('评分', ascending=False).head(25)
    v = df['影片中文名'].values.tolist()  # tolist()将数据转换为列表形式
    d = df['评分'].values.tolist()
    # 设置颜色
    color_series = ['#2C6BA0', '#2B55A1', '#2D3D8E', '#44388E', '#6A368B'
                                                                '#7D3990', '#A63F98', '#C31C88', '#D52178', '#D5225B']
    print("-----" * 15)
    bar = (
        Bar()
            .add_xaxis([i for i in df['影片中文名'].values.tolist()])
            .add_yaxis('评分前25名', df['评价数'].values.tolist())
    )
    bar.render("./条形图.html")
    print("柱形图保存成功！")
    # 读取文件
    fn = open('top250.txt', 'r', encoding='utf-8')
    string_data = fn.read()
    fn.close()
    # 文本预处理
    pattern = re.compile(u'\t|\n|\.|-|:|;|\)|\(|\?|"')  # 定义正则表达式匹配模式
    string_data = re.sub(pattern, '', string_data)  # 将符合模式的字符去除
    # 文本分词
    seg_list_exact = jieba.cut(string_data, cut_all=False)  # 精确模式分词
    object_list = []
    remove_words = [u'19', u'，', u'20', u'德国', u'导演', u'日本', u'法国', u'等', u'能', u'都', u'。', u' ', u'、', u'中', u'在',
                    u'了',
                    u'20', u'大陆', u'我们', u'美国']  # 自定义去除词库

    for word in seg_list_exact:  # 循环读出每个分词
        if word not in remove_words:  # 如果不在去除词库中
            object_list.append(word)  # 分词追加到列表

    # 词频统计
    word_counts = collections.Counter(object_list)
    word_counts_top10 = word_counts.most_common(10)
    print(word_counts_top10)  # 输出检查
    word_counts_top10 = str(word_counts_top10)

    # 词频展示
    mask = np.array(Image.open('image.jpg'))
    wc = wordcloud.WordCloud(
        font_path='simfang.ttf',
        mask=mask,
        max_words=100,  # 最多显示词数
        max_font_size=150,  # 字体最大值
        background_color='white',
        width=800, height=600,
    )

    wc.generate_from_frequencies(word_counts)
    plt.imshow(wc)
    plt.axis('off')
    plt.show()
    wc.to_file('wordcloud.png')</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d6717266c8471ad1f68802a2177b0c61/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Linux】基础IO——系统文件IO&amp;fd&amp;重定向&amp;理解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5bdc7d61590a4a3ea875584491813b3a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">新特性，推荐一款超强接口管理神器 Apifox</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>