<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>模型微调技术 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="模型微调技术" />
<meta property="og:description" content="模型微调 一、迁移学习中的常见技巧:微调（fine-tuning）1.1 概念1.2 步骤1.3 训练1.4 实现 一、迁移学习中的常见技巧:微调（fine-tuning） 1.1 概念 将在大数据集上训练得到的weights作为特定任务（小数据集）的初始化权重，重新训练该网络（根据需要，修改全连接层输出）；至于训练的方式可以是：
1.微调所有层；
2.固定网络前面几层权重，只微调网络的后面几层，这样做有两个原因：A. 避免因数据量小造成过拟合现象；B.CNN前几层的特征中包含更多的一般特征（比如，边缘信息，色彩信息等），这对许多任务来说是非常通用的，但是CNN后面几层的特征学习注重高层特征，也就是语义特征，这是针对于数据集而言的，不同的数据集后面几层学习的语义特征也是完全不同的； 1.2 步骤 在源数据集上训练神经网络模型或将已经在大数据集上训练好的模型保存的模型，即源模型；创建新的神经网络模型，即目标模型。这将复制源模型上的所有模型设计（即模型层数设计）及其参数（输出层除外）。假定模型参数包含从源数据集中学到的知识，这些知识也将适用于目标数据集；想目标模型中添加输出层，其输出类别数目是目标数据集中的类别数， 然后随机初始化该层的模型参数；在目标数据集上训练目标模型，输出层从头开始训练，其他所有层的参数将根据源模型的参数进行微调。 1.3 训练 源数据集远复杂于目标数据，通常微调效果更好；通常使用更小的学习率和更少的数据迭代； 1.4 实现 #热狗识别 #导入所需包 from d2l import torch as d2l from torch import nn import torchvision import torch import os %matplotlib inline #获取数据集 &#34;&#34;&#34; 我们使用的热狗数据集来源于网络。 该数据集包含1400张热狗的“正类”图像，以及包含尽可能多的其他食物的“负类”图像。 含着两个类别的1000张图片用于训练，其余的则用于测试。 &#34;&#34;&#34; d2l.DATA_HUB[&#39;hotdog&#39;] = (d2l.DATA_URL &#43; &#39;hotdog.zip&#39;, &#39;fba480ffa8aa7e0febbb511d181409f899b9baa5&#39;) data_dir = d2l.download_extract(&#39;hotdog&#39;) print(data_dir) #输出..\data\hotdog train_imgs=torchvision.datasets.ImageFolder(os.path.join(data_dir,&#39;train&#39;)) test_imgs=torchvision.datasets.ImageFolder(os.path.join(data_dir,&#39;test&#39;)) hotdogs=[train_imgs[i][0] for i in range(8)] not_hotdogs=[train_imgs[-i-1][0] for i in range(8)] d2l." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/fee18784fe7ff08644135a71efb55d00/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-02-21T17:30:59+08:00" />
<meta property="article:modified_time" content="2022-02-21T17:30:59+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">模型微调技术</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>模型微调</h4> 
 <ul><li><a href="#finetuning_1" rel="nofollow">一、迁移学习中的常见技巧:微调（fine-tuning）</a></li><li><ul><li><a href="#11__2" rel="nofollow">1.1 概念</a></li><li><a href="#12__6" rel="nofollow">1.2 步骤</a></li><li><a href="#13__13" rel="nofollow">1.3 训练</a></li><li><a href="#14__16" rel="nofollow">1.4 实现</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="finetuning_1"></a>一、迁移学习中的常见技巧:微调（fine-tuning）</h2> 
<h3><a id="11__2"></a>1.1 概念</h3> 
<ol><li>将在大数据集上训练得到的weights作为特定任务（小数据集）的初始化权重，重新训练该网络（根据需要，修改全连接层输出）；至于训练的方式可以是：<br> <mark>1</mark>.微调所有层；<br> <mark>2</mark>.固定网络前面几层权重，只微调网络的后面几层，这样做有两个原因：A. 避免因数据量小造成过拟合现象；B.CNN前几层的特征中包含更多的一般特征（比如，边缘信息，色彩信息等），这对许多任务来说是非常通用的，但是CNN后面几层的特征学习注重高层特征，也就是语义特征，这是针对于数据集而言的，不同的数据集后面几层学习的语义特征也是完全不同的；</li></ol> 
<h3><a id="12__6"></a>1.2 步骤</h3> 
<ol><li>在源数据集上训练神经网络模型或将已经在大数据集上训练好的模型保存的模型，即源模型；</li><li>创建新的神经网络模型，即目标模型。这将复制源模型上的所有模型设计（即模型层数设计）及其参数（输出层除外）。假定模型参数包含从源数据集中学到的知识，这些知识也将适用于目标数据集；</li><li>想目标模型中添加输出层，其输出类别数目是目标数据集中的类别数， 然后随机初始化该层的模型参数；</li><li>在目标数据集上训练目标模型，输出层从头开始训练，其他所有层的参数将根据源模型的参数进行微调。</li></ol> 
<p><img src="https://images2.imgbox.com/42/49/3GpHE5RW_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="13__13"></a>1.3 训练</h3> 
<ul><li>源数据集远复杂于目标数据，通常微调效果更好；</li><li>通常使用更小的学习率和更少的数据迭代；</li></ul> 
<h3><a id="14__16"></a>1.4 实现</h3> 
<pre><code class="prism language-python"><span class="token comment">#热狗识别</span>
<span class="token comment">#导入所需包</span>
<span class="token keyword">from</span> d2l <span class="token keyword">import</span> torch <span class="token keyword">as</span> d2l
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> os
<span class="token operator">%</span>matplotlib inline
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#获取数据集</span>
<span class="token triple-quoted-string string">"""
我们使用的热狗数据集来源于网络。 
该数据集包含1400张热狗的“正类”图像，以及包含尽可能多的其他食物的“负类”图像。
含着两个类别的1000张图片用于训练，其余的则用于测试。
"""</span>
d2l<span class="token punctuation">.</span>DATA_HUB<span class="token punctuation">[</span><span class="token string">'hotdog'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>DATA_URL <span class="token operator">+</span> <span class="token string">'hotdog.zip'</span><span class="token punctuation">,</span>
                         <span class="token string">'fba480ffa8aa7e0febbb511d181409f899b9baa5'</span><span class="token punctuation">)</span>

data_dir <span class="token operator">=</span> d2l<span class="token punctuation">.</span>download_extract<span class="token punctuation">(</span><span class="token string">'hotdog'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>
<span class="token comment">#输出..\data\hotdog</span>
</code></pre> 
<pre><code class="prism language-python">train_imgs<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_imgs<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'test'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hotdogs<span class="token operator">=</span><span class="token punctuation">[</span>train_imgs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
not_hotdogs<span class="token operator">=</span><span class="token punctuation">[</span>train_imgs<span class="token punctuation">[</span><span class="token operator">-</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
d2l<span class="token punctuation">.</span>show_images<span class="token punctuation">(</span>hotdogs<span class="token operator">+</span>not_hotdogs<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span>scale<span class="token operator">=</span><span class="token number">1.4</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/32/7f/Vtwch2A7_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token comment"># 使用RGB通道的均值和标准差，以标准化每个通道</span>
<span class="token triple-quoted-string string">"""
在训练期间，我们首先从图像中裁切随机大小和随机长宽比的区域，然后将该区域缩放为\(224*224\)输入图像。 
在测试过程中，我们将图像的高度和宽度都缩放到256像素，然后裁剪中央\(224*224\)区域作为输入。
此外，对于RGB（红、绿和蓝）颜色通道，我们分别标准化每个通道。 
具体而言，该通道的每个值减去该通道的平均值，然后将结果除以该通道的标准差。
"""</span>
normalize<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span><span class="token number">0.456</span><span class="token punctuation">,</span><span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                           <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span><span class="token number">0.224</span><span class="token punctuation">,</span><span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
train_augs<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#随机裁剪，并resize成224</span>
                                          torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                          torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                          normalize<span class="token punctuation">]</span><span class="token punctuation">)</span>
test_augs<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                          torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#将图片从中心裁剪成224*224</span>
                                          torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                          normalize<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#我们使用在ImageNet数据集上预训练的ResNet-18作为源模型。 在这里，我们指定pretrained=True以自动下载预训练的模型参数。 </span>
<span class="token comment">#如果你首次使用此模型，则需要连接互联网才能下载。</span>
pretrained_net<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""
预训练的源模型实例包含许多特征层和一个输出层fc(全连接层)。 
此划分的主要目的是促进对除输出层以外所有层的模型参数进行微调。 
下面给出了源模型的成员变量fc。
"""</span>
pretrained_net<span class="token punctuation">.</span>fc
<span class="token comment">#输出</span>
<span class="token comment">#Linear(in_features=512, out_features=1000, bias=True)</span>
</code></pre> 
<pre><code class="prism language-python">finetune_net<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
finetune_net<span class="token punctuation">.</span>fc<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>finetune_net<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>in_features<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment">#全连接层的输入神经元数量是特征数量，因为是2分类，所以输出是2</span>
nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>finetune_net<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token comment">#随机初始化全连接层权重</span>
<span class="token comment">#Parameter containing:</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0378</span><span class="token punctuation">,</span>  <span class="token number">0.0630</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0080</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0220</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0511</span><span class="token punctuation">,</span>  <span class="token number">0.0959</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span> <span class="token number">0.0556</span><span class="token punctuation">,</span>  <span class="token number">0.0227</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0262</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1059</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0171</span><span class="token punctuation">,</span>  <span class="token number">0.0051</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#微调模型</span>
<span class="token comment"># 如果param_group=True，输出层中的模型参数将使用十倍的学习率</span>
<span class="token keyword">def</span> <span class="token function">train_fine_tuning</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> learning_rate<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
                      param_group<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>
        os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>train_augs<span class="token punctuation">)</span><span class="token punctuation">,</span>
        batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>
        os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>test_augs<span class="token punctuation">)</span><span class="token punctuation">,</span>
        batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
    devices <span class="token operator">=</span> d2l<span class="token punctuation">.</span>try_all_gpus<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> param_group<span class="token punctuation">:</span>
        params_1x <span class="token operator">=</span> <span class="token punctuation">[</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
             <span class="token keyword">if</span> name <span class="token keyword">not</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"fc.weight"</span><span class="token punctuation">,</span> <span class="token string">"fc.bias"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
        trainer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">'params'</span><span class="token punctuation">:</span> params_1x<span class="token punctuation">}</span><span class="token punctuation">,</span>
                                   <span class="token punctuation">{<!-- --></span><span class="token string">'params'</span><span class="token punctuation">:</span> net<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                    <span class="token string">'lr'</span><span class="token punctuation">:</span> learning_rate <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        trainer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span>
                                  weight_decay<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>train_ch13<span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> test_iter<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> trainer<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span>
                   devices<span class="token punctuation">)</span>
train_fine_tuning<span class="token punctuation">(</span>finetune_net<span class="token punctuation">,</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>                  
</code></pre> 
<p><img src="https://images2.imgbox.com/6c/04/vfUfgQ8x_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token comment">#为了进行比较，我们定义了一个相同的模型，但是将其所有模型参数初始化为随机值。 </span>
<span class="token comment">#由于整个模型需要从头开始训练，因此我们需要使用更大的学习率。</span>
scratch_net <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span><span class="token punctuation">)</span>
scratch_net<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>scratch_net<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>in_features<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
train_fine_tuning<span class="token punctuation">(</span>scratch_net<span class="token punctuation">,</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> param_group<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/d1/18/hhnyhZ47_o.png" alt="在这里插入图片描述"></p> 
<ul><li>参考网址：<a href="https://zh-v2.d2l.ai/chapter_computer-vision/fine-tuning.html" rel="nofollow">https://zh-v2.d2l.ai/chapter_computer-vision/fine-tuning.html</a></li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/03fe771cd5ac3dc3409cf93ea9bf4250/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue 前端 增加取色器/拾色器</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/efc18f45b489ac289c286185722a51b4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">CommonJS、AMD、CMD、ES Module</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>