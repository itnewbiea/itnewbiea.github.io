<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>论文阅读 | Bringing a Blurry Frame Alive at High Frame-Rate with an Event Camera - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="论文阅读 | Bringing a Blurry Frame Alive at High Frame-Rate with an Event Camera" />
<meta property="og:description" content="前言：这是一篇事件相机面向去糊方向的文章。发表在了CVPR2019 oral，之后也改进出了一篇PAMI。内容主要是对事件相机的成像原理和图片的模糊原理进行建模，整理出公式并给出了优化函数，通过不断调整阈值C似的图像变得锐利清晰。
论文：【here】
代码：code
Bringing a Blurry Frame Alive at High Frame-Rate with an Event Camera 目的 根据事件相机拍到的一张模糊图片（或是低帧率视频）和一系列事件点，还原出高帧率的锐利且清晰的视频。
不同于一些传统方法的去糊工作，即一张模糊图片还原出一张清晰图片。
主要思想 先构建一个潜在帧的概念。
潜在帧即假设可以用事件相机记录下来的高帧率帧，然而事件相机记录的是事件点，理论上我们可以通过事件点还原出每个潜在帧。
假设强度帧intensity frame不是模糊的，我们可以构建f时刻的锐利帧和事件点之间的关系，即我们可以直接用事件积分来表示不同时刻图像之间的残差。
即对应T时刻的图像I_t
I t = I f &#43; E ( t ) = I f &#43; ∫ t f e ( s ) d s . I_t=I_f&#43; E(t)=I_f&#43; \int_t^f\ e(s)ds\,. It​=If​&#43;E(t)=If​&#43;∫tf​ e(s)ds.
然而这只是一个理想的情况，因为它只对于边缘锋利的清晰帧可行。
对于模糊帧，我们先要找到模糊帧与锐利帧之间的关系，再根据上式某时刻锐利帧和事件之间的关系，我们即可以恢复出每个时刻的锐利帧。
模糊帧和锐利帧之间的关系如下：
在第f时刻的模糊帧，其实是这一段T时刻的锐利帧的积分取平均（这里假设锐利帧和模糊帧的帧率差距很大）
结合模糊帧和锐利帧之间的关系和锐利帧和事件点的关系，可以构造出一个双积分模型：
外面的积分是模糊帧的积分，里面的积分是事件点叠加的积分。就这样，可以利用已有的一张模糊帧和一系列事件点，生成一系列锐利帧。
优化函数 以上的公式中有一个变量未知，即事件相机出发事件的阈值C。我们可以通过不断调整阈值C，来获得一个最满意的去糊结果。因此，本文还构建了一个优化函数，通过不断调整C，使得公式中的优化损失最小。
优化思想是：用事件积分得到的模型会更不容易受到噪声影响。因此得到两幅图，事件积分的图片和生成的锐利帧，对两幅图取sobel算子得到边缘，边缘应该足够接近。这里的接近程度用互相关表示。
其次，我们也希望生成的锐利帧的噪声小，保持边缘，因此需要惩罚空间波动。
于是最终的优化函数就变成了：
这里作者放了一些中间结果图来阐释优化的作用：
总结 这篇文章作者主要从成像原理的角度对事件相机的两类成像进行了建模，并用Matlab进行了实验，这对很多之后的深度学习方法很有启发，之后的一些卷积神经网络架构即建立在本文的原理上。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/ee41a12cdde3c2d965e526a3afbaf26f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-29T11:16:54+08:00" />
<meta property="article:modified_time" content="2022-08-29T11:16:54+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">论文阅读 | Bringing a Blurry Frame Alive at High Frame-Rate with an Event Camera</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>前言：这是一篇事件相机面向去糊方向的文章。发表在了CVPR2019 oral，之后也改进出了一篇PAMI。内容主要是对事件相机的成像原理和图片的模糊原理进行建模，整理出公式并给出了优化函数，通过不断调整阈值C似的图像变得锐利清晰。<br> 论文：<a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Bringing_a_Blurry_Frame_Alive_at_High_Frame-Rate_With_an_CVPR_2019_paper.html" rel="nofollow">【here】</a><br> 代码：<a href="https://github.com/panpanfei/Bringing-a-Blurry-Frame-Alive-at-High-Frame-Rate-with-an-Event-Camera">code</a></p> 
<h2><a id="Bringing_a_Blurry_Frame_Alive_at_High_FrameRate_with_an_Event_Camera_4"></a>Bringing a Blurry Frame Alive at High Frame-Rate with an Event Camera</h2> 
<h3><a id="_5"></a>目的</h3> 
<p>根据事件相机拍到的一张模糊图片（或是低帧率视频）和一系列事件点，还原出高帧率的锐利且清晰的视频。<br> 不同于一些传统方法的去糊工作，即一张模糊图片还原出一张清晰图片。</p> 
<h3><a id="_9"></a>主要思想</h3> 
<p>先构建一个潜在帧的概念。<br> 潜在帧即假设可以用事件相机记录下来的高帧率帧，然而事件相机记录的是事件点，理论上我们可以通过事件点还原出每个潜在帧。<br> 假设强度帧intensity frame不是模糊的，我们可以构建f时刻的<strong>锐利帧和事件点之间的关系</strong>，即我们可以直接用事件积分来表示不同时刻图像之间的残差。<br> <img src="https://images2.imgbox.com/5a/47/or4axj4B_o.png" alt="在这里插入图片描述"><br> 即对应T时刻的图像I_t<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           I 
          
         
           t 
          
         
        
          = 
         
         
         
           I 
          
         
           f 
          
         
        
          + 
         
        
          E 
         
        
          ( 
         
        
          t 
         
        
          ) 
         
        
          = 
         
         
         
           I 
          
         
           f 
          
         
        
          + 
         
         
         
           ∫ 
          
         
           t 
          
         
           f 
          
         
        
            
         
        
          e 
         
        
          ( 
         
        
          s 
         
        
          ) 
         
        
          d 
         
        
          s 
          
        
          . 
         
        
       
         I_t=I_f+ E(t)=I_f+ \int_t^f\ e(s)ds\,. 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 2.511em; vertical-align: -0.9119em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right: 0.4445em; position: relative; top: -0.0011em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.599em;"><span class="" style="top: -1.7881em; margin-left: -0.4445em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span class="" style="top: -3.8129em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.9119em;"><span class=""></span></span></span></span></span></span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">.</span></span></span></span></span></span></p> 
<p>然而这只是一个理想的情况，因为它只对于边缘锋利的清晰帧可行。<br> 对于模糊帧，我们先要找到模糊帧与锐利帧之间的关系，再根据上式某时刻锐利帧和事件之间的关系，我们即可以恢复出每个时刻的锐利帧。</p> 
<p><strong>模糊帧和锐利帧之间的关系</strong>如下：<br> <img src="https://images2.imgbox.com/97/0d/6GGNsQvV_o.png" alt="在这里插入图片描述"><br> 在第f时刻的模糊帧，其实是这一段T时刻的锐利帧的积分取平均（这里假设锐利帧和模糊帧的帧率差距很大）</p> 
<p>结合<strong>模糊帧和锐利帧之间的关系</strong>和<strong>锐利帧和事件点的关系</strong>，可以构造出一个双积分模型：<br> <img src="https://images2.imgbox.com/1d/85/ajzcS86U_o.png" alt="在这里插入图片描述"><br> 外面的积分是模糊帧的积分，里面的积分是事件点叠加的积分。就这样，可以利用已有的一张模糊帧和一系列事件点，生成一系列锐利帧。<br> <img src="https://images2.imgbox.com/b6/64/0Ryqzt4b_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_32"></a>优化函数</h3> 
<p>以上的公式中有一个变量未知，即事件相机出发事件的阈值C。我们可以通过不断调整阈值C，来获得一个最满意的去糊结果。因此，本文还构建了一个优化函数，通过不断调整C，使得公式中的优化损失最小。<br> 优化思想是：用事件积分得到的模型会更不容易受到噪声影响。因此得到两幅图，事件积分的图片和生成的锐利帧，对两幅图取sobel算子得到边缘，边缘应该足够接近。这里的接近程度用互相关表示。<br> <img src="https://images2.imgbox.com/88/90/XL2l5YuE_o.png" alt="在这里插入图片描述"><br> 其次，我们也希望生成的锐利帧的噪声小，保持边缘，因此需要惩罚空间波动。<br> <img src="https://images2.imgbox.com/18/31/NljEbUm5_o.png" alt="在这里插入图片描述"><br> 于是最终的优化函数就变成了：<br> <img src="https://images2.imgbox.com/fd/86/VCbFjJDm_o.png" alt="在这里插入图片描述"><br> 这里作者放了一些中间结果图来阐释优化的作用：<br> <img src="https://images2.imgbox.com/4c/93/zHJHc1jZ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_42"></a>总结</h3> 
<p>这篇文章作者主要从成像原理的角度对事件相机的两类成像进行了建模，并用Matlab进行了实验，这对很多之后的深度学习方法很有启发，之后的一些卷积神经网络架构即建立在本文的原理上。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/89ded649313d8c19eb2b4546f288f888/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">晶体与晶振知识详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a1ed25d0d3932aaa1a9432cc2454fe0f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">JS学习：条件语句--奇偶性判断</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>