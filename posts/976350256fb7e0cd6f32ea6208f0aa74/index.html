<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>flink加载kafka数据源存储至hbase - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="flink加载kafka数据源存储至hbase" />
<meta property="og:description" content="1、添加框架依赖
implementation &#39;org.apache.flink:flink-java:1.16.0&#39; implementation &#39;org.apache.flink:flink-streaming-java:1.16.0&#39; implementation &#39;org.apache.flink:flink-connector-kafka:1.16.0&#39; implementation &#39;org.apache.flink:flink-clients:1.16.0&#39; implementation &#39;org.apache.flink:flink-json:1.16.0&#39; implementation &#39;org.apache.flink:flink-table-api-scala-bridge_2.12:1.16.0&#39; implementation &#39;com.alibaba:fastjson:2.0.19.graal&#39; implementation &#39;org.apache.hadoop:hadoop-client:3.2.2&#39; implementation &#39;org.apache.flink:flink-connector-jdbc:1.16.0&#39; implementation &#39;org.apache.phoenix:phoenix-client-hbase-2.4:5.1.2&#39; 2、flink读取kafka数据
kafka数据源数据格式
{&#34;common&#34;:{&#34;ar&#34;:&#34;110000&#34;,&#34;ba&#34;:&#34;iPhone&#34;,&#34;ch&#34;:&#34;Appstore&#34;,&#34;is_new&#34;:&#34;1&#34;,&#34;md&#34;:&#34;iPhone 8&#34;,&#34;mid&#34;:&#34;mid_368770&#34;,&#34;os&#34;:&#34;iOS 13.3.1&#34;,&#34;uid&#34;:&#34;63&#34;,&#34;vc&#34;:&#34;v2.1.132&#34;},&#34;displays&#34;:[{&#34;display_type&#34;:&#34;activity&#34;,&#34;item&#34;:&#34;1&#34;,&#34;item_type&#34;:&#34;activity_id&#34;,&#34;order&#34;:1,&#34;pos_id&#34;:3}],&#34;page&#34;:{&#34;during_time&#34;:19393,&#34;page_id&#34;:&#34;home&#34;},&#34;ts&#34;:1605368266000} 编写flink读取kafka数据源
public class ReadKafkaToFlinkFunction { public static StreamExecutionEnvironment getEnv() { StreamExecutionEnvironment.createRemoteEnvironment(String host, int port, String... jarFiles); StreamExecutionEnvironment executionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment(); executionEnvironment.setParallelism(1); executionEnvironment.enableCheckpointing(5 * 60000L, CheckpointingMode.EXACTLY_ONCE); executionEnvironment.getCheckpointConfig().setCheckpointTimeout(10 * 60000L); executionEnvironment.getCheckpointConfig().setMaxConcurrentCheckpoints(2); executionEnvironment.setRestartStrategy(RestartStrategies.fixedDelayRestart(3, 5000L)); executionEnvironment.setStateBackend(new HashMapStateBackend()); executionEnvironment.getCheckpointConfig().setCheckpointStorage(&#34;hdfs://server115:9000/flink/ck&#34;); System.setProperty(&#34;HADOOP_USER_NAME&#34;, &#34;wucf&#34;); return executionEnvironment; } /** * ID | CH | MD | MID | OS | DURING_TIME | PAGE_ID | TS * 将kafka的数据读取到flink */ public static void kafkaNewFlinkStream() { try { StreamExecutionEnvironment env = getEnv(); // 将kafka数据作为source KafkaSource&lt;String&gt; kafkaConsumer = KafkaUtils." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/976350256fb7e0cd6f32ea6208f0aa74/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-21T23:10:30+08:00" />
<meta property="article:modified_time" content="2022-11-21T23:10:30+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">flink加载kafka数据源存储至hbase</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>1、添加框架依赖</p> 
<pre><code class="hljs">    implementation 'org.apache.flink:flink-java:1.16.0'
    implementation 'org.apache.flink:flink-streaming-java:1.16.0'
    implementation 'org.apache.flink:flink-connector-kafka:1.16.0'
    implementation 'org.apache.flink:flink-clients:1.16.0'
    implementation 'org.apache.flink:flink-json:1.16.0'
    implementation 'org.apache.flink:flink-table-api-scala-bridge_2.12:1.16.0'
    implementation 'com.alibaba:fastjson:2.0.19.graal'
    implementation 'org.apache.hadoop:hadoop-client:3.2.2'
    implementation 'org.apache.flink:flink-connector-jdbc:1.16.0'
    implementation 'org.apache.phoenix:phoenix-client-hbase-2.4:5.1.2'</code></pre> 
<p>2、flink读取kafka数据</p> 
<p>    kafka数据源数据格式</p> 
<pre><code class="language-XML">{"common":{"ar":"110000","ba":"iPhone","ch":"Appstore","is_new":"1","md":"iPhone 8","mid":"mid_368770","os":"iOS 13.3.1","uid":"63","vc":"v2.1.132"},"displays":[{"display_type":"activity","item":"1","item_type":"activity_id","order":1,"pos_id":3}],"page":{"during_time":19393,"page_id":"home"},"ts":1605368266000}</code></pre> 
<p>   编写flink读取kafka数据源</p> 
<pre><code class="language-XML">
public class ReadKafkaToFlinkFunction {

    public static StreamExecutionEnvironment getEnv() {
        StreamExecutionEnvironment.createRemoteEnvironment(String host, int port, String... jarFiles);
        StreamExecutionEnvironment executionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();
        executionEnvironment.setParallelism(1);
        executionEnvironment.enableCheckpointing(5 * 60000L, CheckpointingMode.EXACTLY_ONCE);
        executionEnvironment.getCheckpointConfig().setCheckpointTimeout(10 * 60000L);
        executionEnvironment.getCheckpointConfig().setMaxConcurrentCheckpoints(2);
        executionEnvironment.setRestartStrategy(RestartStrategies.fixedDelayRestart(3, 5000L));
        executionEnvironment.setStateBackend(new HashMapStateBackend());
        executionEnvironment.getCheckpointConfig().setCheckpointStorage("hdfs://server115:9000/flink/ck");
        System.setProperty("HADOOP_USER_NAME", "wucf");
        return executionEnvironment;
    }


    /**
     * ID | CH | MD | MID | OS | DURING_TIME | PAGE_ID | TS
     * 将kafka的数据读取到flink
     */
    public static void kafkaNewFlinkStream() {
        try {
            StreamExecutionEnvironment env = getEnv();
             // 将kafka数据作为source
            KafkaSource&lt;String&gt; kafkaConsumer = KafkaUtils.getKafkaConsumer("topic-log");
            DataStreamSource&lt;String&gt; dataStreamSource = env.fromSource(kafkaConsumer, WatermarkStrategy.noWatermarks(), "KafkaSource");
            ///dataStreamSource.map((MapFunction&lt;String, Object&gt;) value -&gt; StringUtils.isNoneBlank(value) ? JSONObject.parseObject(value, LogBean.class).getCommon().getUid() : "001").print();
            ///dataStreamSource.filter((FilterFunction&lt;String&gt;) value -&gt; "6".equals(StringUtils.isNoneBlank(value)?JSONObject.parseObject(value, LogBean.class).getCommon().getUid():"")).print("1");
            SinkFunction sink= new  FlinkToPhoenixHbaseFunction();
            dataStreamSource
                    .map((MapFunction&lt;String, LogBean&gt;) value -&gt; StringUtils.isNoneBlank(value) ? JSONObject.parseObject(value, LogBean.class) : new LogBean())
                    .filter((FilterFunction&lt;LogBean&gt;) value -&gt; !Objects.isNull(value.getPage()))
                    .keyBy((KeySelector&lt;LogBean, Object&gt;) value -&gt; value.getCommon().getUid())
                    .max("page.during_time")
                    .addSink(sink);
            env.execute();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }


}</code></pre> 
<p>     json数据转实体类</p> 
<pre><code class="language-XML">@Data
public class LogBean {
    private CommonBean common;
    private PageBean page;
    private long ts;
    private List&lt;DisplaysBean&gt; displays;

    @Data
    public static class CommonBean {
        private String ar;
        private String ba;
        private String ch;
        private String is_new;
        private String md;
        private String mid;
        private String os;
        private String uid;
        private String vc;
    }

    @Data
    public static class PageBean {
        private int during_time;
        private String page_id;
    }

    @Data
    public static class DisplaysBean {
        private String display_type;
        private String item;
        private String item_type;
        private int order;
        private int pos_id;
    }
}
</code></pre> 
<p>   kafka的工具类</p> 
<pre><code class="language-XML">
public class KafkaUtils {
    public  static KafkaSource&lt;String&gt; getKafkaConsumer(String  topic){
        KafkaSource&lt;String&gt; source = KafkaSource.&lt;String&gt;builder()
                .setBootstrapServers("server200:9092,server200:9093")
                .setTopics(Arrays.asList(topic))
            .setDeserializer(KafkaRecordDeserializationSchema.valueOnly(StringDeserializer.class))
                .setUnbounded(OffsetsInitializer.latest())
                .build();
        return  source;
    }

}</code></pre> 
<p>3、编写flink的sink 代码</p> 
<pre><code class="language-XML">public class FlinkToPhoenixHbaseFunction extends RichSinkFunction&lt;Object&gt; {

    private final  static Logger LOGGER = LoggerFactory.getLogger(FlinkToPhoenixHbaseFunction.class);

    private final  static  String   PHOENIX_DRIVER_NAME="org.apache.phoenix.jdbc.PhoenixDriver";

    private final  static   String  PHOENIX_URL = "jdbc:phoenix:server200:2181";

    private    static   DruidPooledConnection connection;

    static {
        try {
            DruidDataSource  dataSource = new DruidDataSource();
            dataSource.setDriverClassName(PHOENIX_DRIVER_NAME);
            dataSource.setUrl(PHOENIX_URL);
            dataSource.setTestOnBorrow(false);
            dataSource.setTestOnReturn(false);
            dataSource.setTestWhileIdle(true);
            dataSource.setTimeBetweenEvictionRunsMillis(60000);
            dataSource.setMaxActive(20);
            dataSource.setInitialSize(5);
            connection= dataSource.getConnection();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    @Override
    public void open(Configuration parameters) throws Exception {
         createLogTb();
    }
    
    @Override
    public void invoke(Object value, Context context) throws Exception {
        upsertLogData((LogBean) value);
    }
    
    
    /**
     * 创建表   
     * create  table  if  not  exists  "wmy_db.tb_log"(id varchar primary key,common.ch varchar,common.md varchar,common.mid varchar,common.os varchar,page.during_time varchar,page.page_id varchar,displays varchar,ts varchar);
     */
    private  void  createLogTb(){
        try {
            StringBuilder  sql  = new StringBuilder();
            sql.append(" create  table  if  not  exists ");
            sql.append("wmydb.").append("tb_log");
            sql.append("(");
            sql.append("id varchar primary key," +
                    "common.ch varchar," +
                    "common.md varchar," +
                    "common.mid varchar," +
                    "common.os varchar," +
                    "page.during_time varchar," +
                    "page.page_id varchar," +
                    "displays varchar," +
                    "ts varchar");
            sql.append(")");
            PreparedStatement preparedStatement = connection.prepareStatement(sql.toString());
            preparedStatement.execute();
            preparedStatement.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
    
    private  void  upsertLogData(LogBean logBean){
        try {
            StringBuilder  sql =new StringBuilder();
            sql.append("  upsert into \"wmydb.tb_log\"  values(");
            sql.append("'").append(System.currentTimeMillis()).append("'").append(",");
            sql.append("'").append(logBean.getCommon().getCh()).append("'").append(",");
            sql.append("'").append(logBean.getCommon().getMd()).append("'").append(",");
            sql.append("'").append(logBean.getCommon().getMd()).append("'").append(",");
            sql.append("'").append(logBean.getCommon().getOs()).append("'").append(",");
            sql.append("'").append(logBean.getPage().getDuring_time()).append("'").append(",");
            sql.append("'").append(logBean.getPage().getPage_id()).append("'").append(",");
            sql.append("'").append(logBean.getDisplays()).append("'").append(",");
            sql.append("'").append(logBean.getTs()).append("'");
            sql.append(")");
            PreparedStatement preparedStatement  = connection.prepareStatement(sql.toString());
            preparedStatement.execute();
            connection.commit();
            preparedStatement.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
}
</code></pre> 
<p>4、测试</p> 
<pre><code class="language-XML">public class FlinkApp {
    public static void main(String[] args) {
        System.out.println("hello word");
        ReadKafkaToFlinkFunction.kafkaNewFlinkStream();
    }
}</code></pre> 
<p><img alt="" height="432" src="https://images2.imgbox.com/10/7d/TzXJKw2s_o.png" width="1200"></p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/67391687d427e770a63b32281f1190d8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">mesa 概述</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8710d56667a4f0946715675f3f6ba91a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">[Android Material Design]组件16 - NavigationView</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>