<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python没有错误但是不显示结果_【Python错误总结】 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python没有错误但是不显示结果_【Python错误总结】" />
<meta property="og:description" content="from import : 从车里把矿泉水拿出来，给我
import : 把车给我
import datetime
print(datetime.datetime.now())
是引入整个datetime包
from datetime import datetime
print(datetime.now())
是只引入datetime包里的datetime类
所以import之后前者是datetime这个包可见 后者是datetime.datetime这个类可见
2. ImportError: No module named &#39;cookielib&#39;1
Python3中，改成 import http.cookiejar,然后方法里也改成 http.cookiejar，查找替换就行
3. NameError: name &#39;raw_input&#39; is not defined
在版本3中已经用input()替换
4. Import error: No module name urllib
from urllib.request import urlopen
5. ImportError: No module named urllib2
Python 3中urllib2用urllib.request替代
6、TypeError: write() argument must be str, not bytes
文件打开的方式有问题。
之前文件打开的语句是：
f=open(&#34;list.pkl&#34;,&#34;w&#43;&#34;)
然后使用二进制方式打开就没有这个问题：
f=open(&#34;list_account.pkl&#34;,&#34;wb&#43;&#34;)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/b3a0c7675e5e3d9c533cb29e55a33e62/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-23T17:14:25+08:00" />
<meta property="article:modified_time" content="2020-11-23T17:14:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python没有错误但是不显示结果_【Python错误总结】</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>from import : 从车里把矿泉水拿出来，给我</p> 
<p>import : 把车给我</p> 
<p>import datetime</p> 
<p>print(datetime.datetime.now())</p> 
<p>是引入整个datetime包</p> 
<p>from datetime import datetime</p> 
<p>print(datetime.now())</p> 
<p>是只引入datetime包里的datetime类</p> 
<p>所以import之后前者是datetime这个包可见 后者是datetime.datetime这个类可见</p> 
<p>2. ImportError: No module named 'cookielib'1</p> 
<p>Python3中，改成 import  http.cookiejar,然后方法里也改成 http.cookiejar，查找替换就行</p> 
<p>3. NameError: name 'raw_input' is not defined</p> 
<p>在版本3中已经用input()替换</p> 
<p>4. Import error: No module name urllib</p> 
<p>from urllib.request import urlopen</p> 
<p>5. ImportError: No module named urllib2</p> 
<p>Python 3中urllib2用urllib.request替代</p> 
<p>6、TypeError: write() argument must be str, not bytes</p> 
<p>文件打开的方式有问题。</p> 
<p>之前文件打开的语句是：</p> 
<p>f=open("list.pkl","w+")</p> 
<p>然后使用二进制方式打开就没有这个问题：</p> 
<p>f=open("list_account.pkl","wb+")</p> 
<p>产生问题的原因是因为pickle存储方式默认是二进制方式</p> 
<p>写文件处 open(filename, 'w').write 应该写为 open(filename, 'wb').write</p> 
<p>8、TabError: Inconsistent use of tabs and spaces in indentation</p> 
<p>这个错误是说你用了tab键作缩进了</p> 
<p>在python里不用大括号来区分程序块，用缩进</p> 
<p>所以缩进很重要</p> 
<p>你把tab都换成空格就好了</p> 
<p>3.0现在的参数更改了,现在读取的是bytes-like的,但参数要求是chart-like的,找了一下,加了个编码:</p> 
<p>data = data.decode('GBK')</p> 
<p>在与正则使用前,就可以正常使用了..</p> 
<p>去找找你所调用的函数的返回的值的类型，是否和返回值所赋值的变量的类型，两者是否匹配。</p> 
<p>11、module 'urllib' has no attribute 'urlencode'</p> 
<p>Python3的话，包内部的代码结构貌似变化了，要用urllib.parse.urlencode()来调用才对。</p> 
<p>12、python3.x执行post请求时报错“POST data should be bytes or an iterable of bytes...”的解决方法</p> 
<p>在urlencode语句后加encode(encoding='UTF8')</p> 
<p>eg:</p> 
<p>params = urllib.parse.urlencode({'userid':'381fccbd776c4deb'}).encode(encoding='UTF8')</p> 
<p>问题解决</p> 
<p>首行增加，已测试可用。</p> 
<p># coding=gbk</p> 
<p>程序中出现中文，运行的时候出现如下错误：</p> 
<p>SyntaxError: Non-UTF-8 code starting with 'xc1' in file C:...xxx.py on line 8, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details</p> 
<p>导致出错的根源就是编码问题。</p> 
<p>解决方案是：</p> 
<p>在程序最上面加上：</p> 
<p># coding=gbk搜索</p> 
<p>这样程序就可以正常运行了。</p> 
<p>14、使用 Sublime 工具时报Decode error - output not utf-8解决办法</p> 
<p>打开Python.sublime-build文件,并添加"encoding":"cp936"这一行,保存即可</p> 
<p>{<!-- --></p> 
<p>"cmd": ["python", "-u", "$file"],</p> 
<p>"file_regex": "^[ ]*File \"(...*?)\", line ([0-9]*)",</p> 
<p>"selector": "source.python",</p> 
<p>"encoding":"cp936"</p> 
<p>}</p> 
<p>Python.sublime-build文件存放地址:</p> 
<p>C:\Users\用户名\AppData\Roaming\Sublime Text 2\Packages\Python</p> 
<p>实在找不到的话可以这样来查找:</p> 
<p>tools-&gt;build system -&gt; New Build System</p> 
<p>此时会打开一个新文件,不用输入内容,直接保存,看看保存到哪里去了吧.</p> 
<p>15、安装scrapy时报错：[twisted] CRITICAL: Unhandled error in Deferred:</p> 
<p align="center"><img src="https://images2.imgbox.com/e4/ae/xADVLJwO_o.png" alt="c1f8aafe-c2af-3d31-88be-4acc88839137.png"></p> 
<p>16、爬取链接时，urlopen().read()后，返回的是b'\x1f\x8b\x08\x00\x00\x00\x00\。。。</p> 
<p>解决思路：</p> 
<p>1、刚开始尝试了bytes转Str类型的各种方法，都不起作用，报错</p> 
<p>UnicodeDecodeError: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte</p> 
<p>2、突然发现python有个第三方包叫chardet，它可以自动帮你识别出网页的编码</p> 
<p>import chardet</p> 
<p>import urllib2</p> 
<p>#可根据需要，选择不同的数据</p> 
<p>TestData = urllib2.urlopen('http://www.baidu.com/').read()</p> 
<p>print chardet.detect(TestData)</p> 
<p align="center"><img src="https://images2.imgbox.com/09/25/zmHQr9eP_o.png" alt="d51925bf-573e-3a4c-8004-d9c52262a6c8.png">准确的判断编码方式是utf-8.</p> 
<p>3、我测试后，返回的编码却为这种None：</p> 
<p>{'encoding': None, 'confidence': 0.0}</p> 
<p>原来是这个页面的编码问题，该页面返回的是gzip编码，实际上每次应该判断页面信息的'Content-Encoding'是否为'gzip'。</p> 
<p>urllib支持gzip页面自动解压而urllib2不支持。 所以对于这种页面， 先解压再read：</p> 
<p>try:</p> 
<p>response = urllib2.urlopen(self.url, timeout = self.timeout)</p> 
<p>if response.info().get('Content-Encoding', "") == 'gzip':</p> 
<p>buf = StringIO.StringIO(response.read())</p> 
<p>f = gzip.GzipFile(fileobj=buf)</p> 
<p>content = f.read()</p> 
<p>else:</p> 
<p>content = response.read()</p> 
<p>content = self.enc_dec(content)</p> 
<p>return content</p> 
<p>except socket.timeout:</p> 
<p>log.warn("Timeout in fetching %s" % self.url)</p> 
<p>方法2：</p> 
<p>def getUrlContent(url):</p> 
<p>#返回页面内容</p> 
<p>doc = urllib.request.urlopen(url).read()</p> 
<p>#解码</p> 
<p>try:</p> 
<p>html=gzip.decompress(doc).decode("utf-8")</p> 
<p>except:</p> 
<p>html=doc.decode("utf-8")</p> 
<p>return html</p> 
<p>自己的解决方法是在请求时，将header中的</p> 
<p>'Accept-Encoding':'gzip, deflate, sdch', 注释掉即可获取到正常的bytes数据</p> 
<p>然后自己再次识别编码，结果为：{'encoding': 'utf-8', 'confidence': 0.99}</p> 
<p>最后再bytes转换为 str,即可获得完整可识别的HTML代码。</p> 
<p>==============================================================================</p> 
<p>解压：</p> 
<p>def ungzip(data):</p> 
<p>try:</p> 
<p>print('正在解压.....')</p> 
<p>print(data)</p> 
<p>data = gzip.decompress(data)</p> 
<p>print('解压完毕!')</p> 
<p>except:</p> 
<p>print('未经压缩, 无需解压')</p> 
<p>return data</p> 
<p>结果：</p> 
<p>正在解压.....</p> 
<p>b"\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\x03\x14\xcaM\x0e@0\x10\x06\xd0\xbb|kii\x98xc7!\x82\x7fU\x00\x00\x00"</p> 
<p>解压完毕!</p> 
<p>b'{"status":"loginok","msg":"\\u767b\\u9646\\u6210\\u529f"}'</p> 
<p>18、python getaddrinfo failed</p> 
<p>HOST="" 中间没有空格</p> 
<p>19、数据转换：</p> 
<p>将b'{"status":"ok","total":"36","data":[{"id":"115878","uid":"3364","type":"9","pay":"\\u7b7e\\u5230\\u7ea2\\u5305"...}]}'</p> 
<p>转为{"status":"ok","total":"36","data":[{"id":"115878","uid":"3364","type":"9","pay":"\u7b7e\u5230\u7ea2\u5305"...}]}</p> 
<p>op = signsession.get(url)</p> 
<p>#print(op.content)</p> 
<p>data = op.content.decode()</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f62e912a1878ed75a6285f199d35df23/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">MySQL 计算字符串字段中逗号分隔计数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/93c27fe4b1a45fca678faa96b4efb0be/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Flink SQL深度篇</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>