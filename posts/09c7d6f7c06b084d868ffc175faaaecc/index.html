<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>一份全面的大模型「幻觉」综述 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="一份全面的大模型「幻觉」综述" />
<meta property="og:description" content="文章目录 一份全面的大模型「幻觉」综述1. 幻觉的分类2. 幻觉的来源2.1 幻觉来自数据2.2 幻觉来自训练2.3 幻觉来自生成/推理 3. 幻觉的检测3.1 事实性幻觉的检测3.2 忠实性幻觉的检测 4. 幻觉的评估5. 幻觉的解决 一份全面的大模型「幻觉」综述 相信大家在使用ChatGPT或者其他大模型时会遇到这样的情况，模型答非所问甚至自相矛盾。
虽然大语言模型（LLMs）在各种下游任务中展示出了卓越的能力，在多个领域有广泛应用，但存在着幻觉的问题：即生成与用户输入不符、与先前生成的内容矛盾或与已知世界知识不符的内容。
这种现象对LLMs在现实世界场景中的可靠性构成了重大挑战。在准确率要求非常高的场景下幻觉是不可接受的，比如医疗领域、金融领域等。
目前在LLM幻觉问题上已经有无数的研究，比如关于幻觉的检测、幻觉的评估基准分类、缓解幻觉的方法等。
今天我会结合几篇有关LLM幻觉问题的综述论文，来聊聊LLM幻觉的分类、检测方法、评估和基准、减轻方法等。
传送门：《一文读懂：大语言模型LLM的幻觉问题》
最近的一篇是来自哈尔滨工业大学和华为的研究团队，长达49页，对有关LLM幻觉问题的最新进展来了一个全面而深入的概述。
这篇综述（下文简称：综述1）从LLM幻觉的创新分类方法出发，深入探究了可能导致幻觉的因素，并对检测幻觉的方法和基准进行了概述。
论文链接：https://arxiv.org/abs/2311.05232
另外还有一篇综述（下文简称：综述2），来自腾讯AI实验室和一些国内大学的研究团队，综述提出了LLM幻觉现象的分类法和评估基准，分析旨在减轻LLM幻觉的现有方法，并确定未来研究的潜在方向。
论文链接：https://arxiv.org/pdf/2309.01219.pdf
还有一篇有关幻觉的论文（下文简称：论文1），对各种文本生成任务中的幻觉现象进行了新的分类，从而提供了理论分析、检测方法和改进方法。
论文链接：https://arxiv.org/pdf/2309.06794v1.pdf
1. 幻觉的分类 在综述2中，将LLMs幻觉分为三种：输入冲突幻觉、上下文冲突幻觉和事实冲突幻觉。
输入冲突幻觉：是指生成的内容与用户提供的输入不符；上下文冲突幻觉：是指生成的内容与之前生成的信息相矛盾；事实冲突幻觉：是指生成的内容与已知的世界知识不符。 图注：3种幻觉的定义
而在最新的综述1中，将LLM幻觉分为两种：事实型幻觉和忠实度幻觉。
如上图所示，左边是事实型幻觉：当LLM被问到谁是第一个在月球上漫步的人时，LLM编了个人物出来，甚至还说得有模有样。右边是忠实度幻觉：LLM在看到这段新闻后，直接把年份概括错了。
下图是一张更为详细的LLM幻觉种类图，包括更为细致的分类：事实型幻觉包括事实不一致、事实捏造；忠实度幻觉又包括：指令-答案的不一致、文本不一致，以及逻辑不一致。
总的来说，结合事实、上下文、输入的不一致，幻觉的定义和分类上是相似的。
结合常见的下游任务，比如机器翻译、问答系统、对话系统、文本摘要、LLM知识图谱和视觉问答系统，论文1总结了典型的幻觉现象，如下表所示：
2. 幻觉的来源 综述2认为产生幻觉的主要原因有预训练数据收集、知识GAP和大模型优化过程三个方面。
最新的综述1也深入探讨LLM产生幻觉的根本原因，主要分为三个关键方面：数据、训练和推理。
结合起来，我们具体来看下幻觉的来源：
2.1 幻觉来自数据 预训练数据：大模型的知识和能力主要来自与预训练数据，如果预训练数据使用了不完整或者过期的数据，那么就很可能导致知识的错误，从而引起幻觉现象。数据利用：LLMs 往往会捕捉到虚假的相关性，在回忆知识（尤其是长尾信息）和复杂推理场景中表现出困难，从而进一步加剧幻觉。 2.2 幻觉来自训练 预训练阶段：LLMs在这一阶段学习通用表征并捕捉广泛的知识，通常采用基于transformer的架构，在庞大的语料库中进行因果语言建模。但是，固有的架构设计和研究人员所采用的特定训练策略，可能会产生与幻觉相关的问题。对齐阶段：一般涉及两个主要过程，即监督微调和从人类反馈中强化学习（RLHF）。虽然对齐能显著提高 LLM 响应的质量，但也会带来产生幻觉的风险，主要分为两方面：能力不对齐（Capability Misalignment）和信念不对齐（Belief Misalignment）。 2.3 幻觉来自生成/推理 经过预训练和对齐后，解码在体现 LLM 能力方面发挥着重要作用。然而，解码策略的某些缺陷可能导致 LLM 出现幻觉。综述1深入探讨源于解码过程的潜在原因，并强调两个关键因素：
解码策略固有的随机性（Inherent Sampling Randomness）：比如采用采样生成策略（如top-p和top-k）引入的随机性也可能导致幻觉的产生。不完善的解码表示（Imperfect Decoding Representation）：在解码阶段，LLM 使用顶层表示法预测下一个标记。然而，顶层表示法也有其局限性，主要表现在两个方面： 上下文关注不足（Insufficient Context Attention）和Softmax瓶颈（Softmax Bottleneck）。 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/09c7d6f7c06b084d868ffc175faaaecc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-05T09:23:01+08:00" />
<meta property="article:modified_time" content="2023-12-05T09:23:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">一份全面的大模型「幻觉」综述</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">一份全面的大模型「幻觉」综述</a></li><li><ul><li><a href="#1__42" rel="nofollow">1. 幻觉的分类</a></li><li><a href="#2__83" rel="nofollow">2. 幻觉的来源</a></li><li><ul><li><a href="#21__91" rel="nofollow">2.1 幻觉来自数据</a></li><li><a href="#22__96" rel="nofollow">2.2 幻觉来自训练</a></li><li><a href="#23__101" rel="nofollow">2.3 幻觉来自生成/推理</a></li></ul> 
   </li><li><a href="#3__108" rel="nofollow">3. 幻觉的检测</a></li><li><ul><li><a href="#31__116" rel="nofollow">3.1 事实性幻觉的检测</a></li><li><a href="#32__136" rel="nofollow">3.2 忠实性幻觉的检测</a></li></ul> 
   </li><li><a href="#4__150" rel="nofollow">4. 幻觉的评估</a></li><li><a href="#5__173" rel="nofollow">5. 幻觉的解决</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>一份全面的大模型「幻觉」综述</h2> 
<p>相信大家在使用ChatGPT或者其他大模型时会遇到这样的情况，模型答非所问甚至自相矛盾。</p> 
<p>虽然大语言模型（LLMs）在各种下游任务中展示出了卓越的能力，在多个领域有广泛应用，但存在着<strong>幻觉</strong>的问题：即生成与用户输入不符、与先前生成的内容矛盾或与已知世界知识不符的内容。</p> 
<p>这种现象对LLMs在现实世界场景中的可靠性构成了重大挑战。在准确率要求非常高的场景下幻觉是不可接受的，比如医疗领域、金融领域等。</p> 
<p>目前在LLM幻觉问题上已经有无数的研究，比如关于幻觉的检测、幻觉的评估基准分类、缓解幻觉的方法等。</p> 
<p>今天我会结合几篇有关LLM幻觉问题的综述论文，来聊聊LLM幻觉的分类、检测方法、评估和基准、减轻方法等。</p> 
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg5MzczMjc3Nw==&amp;mid=2247489364&amp;idx=1&amp;sn=22721b120e7e4137baf26b922f3dbb55&amp;chksm=c02b0592f75c8c84c793252a80e6a131c45daa6b239af669f92d0ba66ee3960838ed91ecad2d&amp;token=582854639&amp;lang=zh_CN#rd" rel="nofollow">传送门：《一文读懂：大语言模型LLM的幻觉问题》</a></p> 
<p>最近的一篇是来自哈尔滨工业大学和华为的研究团队，长达49页，对有关LLM幻觉问题的最新进展来了一个全面而深入的概述。</p> 
<p>这篇综述（下文简称：<a href="https://arxiv.org/abs/2311.05232" rel="nofollow">综述1</a>）从LLM幻觉的创新分类方法出发，深入探究了可能导致幻觉的因素，并对检测幻觉的方法和基准进行了概述。</p> 
<p><img src="https://images2.imgbox.com/d4/ac/6gDBOIAz_o.png" alt="在这里插入图片描述"></p> 
<p>论文链接：<a href="https://arxiv.org/abs/2311.05232" rel="nofollow">https://arxiv.org/abs/2311.05232</a></p> 
<p><img src="https://images2.imgbox.com/3a/71/YCh8xsgt_o.png" alt="在这里插入图片描述"></p> 
<p>另外还有一篇综述（下文简称：<a href="https://arxiv.org/pdf/2309.01219.pdf" rel="nofollow">综述2</a>），来自腾讯AI实验室和一些国内大学的研究团队，综述提出了LLM幻觉现象的分类法和评估基准，分析旨在减轻LLM幻觉的现有方法，并确定未来研究的潜在方向。</p> 
<p><img src="https://images2.imgbox.com/2b/aa/TNImAcDD_o.png" alt="在这里插入图片描述"></p> 
<p>论文链接：<a href="https://arxiv.org/pdf/2309.01219.pdf" rel="nofollow">https://arxiv.org/pdf/2309.01219.pdf</a></p> 
<p>还有一篇有关幻觉的论文（下文简称：<a href="https://arxiv.org/pdf/2309.06794v1.pdf" rel="nofollow">论文1</a>），对各种文本生成任务中的幻觉现象进行了新的分类，从而提供了理论分析、检测方法和改进方法。</p> 
<p><img src="https://images2.imgbox.com/c8/65/XHT5HeT2_o.png" alt="在这里插入图片描述"></p> 
<p>论文链接：<a href="https://arxiv.org/pdf/2309.06794v1.pdf" rel="nofollow">https://arxiv.org/pdf/2309.06794v1.pdf</a></p> 
<h3><a id="1__42"></a>1. 幻觉的分类</h3> 
<p>在<a href="https://arxiv.org/pdf/2309.01219.pdf" rel="nofollow">综述2</a>中，将LLMs幻觉分为三种：<strong>输入冲突幻觉</strong>、<strong>上下文冲突幻觉</strong>和<strong>事实冲突幻觉</strong>。</p> 
<ul><li><strong>输入冲突幻觉</strong>：是指生成的内容与用户提供的输入不符；</li><li><strong>上下文冲突幻觉</strong>：是指生成的内容与之前生成的信息相矛盾；</li><li><strong>事实冲突幻觉</strong>：是指生成的内容与已知的世界知识不符。</li></ul> 
<p><img src="https://images2.imgbox.com/9b/47/CT4oMkOq_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/37/cc/E3uFGlT0_o.png" alt="在这里插入图片描述"></p> 
<p>图注：3种幻觉的定义</p> 
<p>而在最新的<a href="https://arxiv.org/abs/2311.05232" rel="nofollow">综述1</a>中，将LLM幻觉分为两种：事实型幻觉和忠实度幻觉。</p> 
<p><img src="https://images2.imgbox.com/1b/45/3yoeUI8l_o.png" alt="在这里插入图片描述"></p> 
<p>如上图所示，左边是事实型幻觉：当LLM被问到谁是第一个在月球上漫步的人时，LLM编了个人物出来，甚至还说得有模有样。右边是忠实度幻觉：LLM在看到这段新闻后，直接把年份概括错了。</p> 
<p>下图是一张更为详细的LLM幻觉种类图，包括更为细致的分类：事实型幻觉包括事实不一致、事实捏造；忠实度幻觉又包括：指令-答案的不一致、文本不一致，以及逻辑不一致。</p> 
<p><img src="https://images2.imgbox.com/07/66/DNKHhYHA_o.png" alt="在这里插入图片描述"></p> 
<p>总的来说，结合事实、上下文、输入的不一致，幻觉的定义和分类上是相似的。</p> 
<p>结合常见的下游任务，比如机器翻译、问答系统、对话系统、文本摘要、LLM知识图谱和视觉问答系统，<a href="https://arxiv.org/pdf/2309.06794v1.pdf" rel="nofollow">论文1</a>总结了典型的幻觉现象，如下表所示：</p> 
<p><img src="https://images2.imgbox.com/3c/26/fwybHGS0_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2__83"></a>2. 幻觉的来源</h3> 
<p><a href="https://arxiv.org/pdf/2309.01219.pdf" rel="nofollow">综述2</a>认为产生幻觉的主要原因有<strong>预训练数据收集</strong>、<strong>知识GAP</strong>和<strong>大模型优化过程</strong>三个方面。</p> 
<p>最新的<a href="https://arxiv.org/abs/2311.05232" rel="nofollow">综述1</a>也深入探讨LLM产生幻觉的根本原因，主要分为三个关键方面：<strong>数据</strong>、<strong>训练</strong>和<strong>推理</strong>。</p> 
<p>结合起来，我们具体来看下幻觉的来源：</p> 
<h4><a id="21__91"></a>2.1 幻觉来自数据</h4> 
<ul><li><strong>预训练数据</strong>：大模型的知识和能力主要来自与预训练数据，如果预训练数据使用了不完整或者过期的数据，那么就很可能导致知识的错误，从而引起幻觉现象。</li><li><strong>数据利用</strong>：LLMs 往往会捕捉到虚假的相关性，在回忆知识（尤其是长尾信息）和复杂推理场景中表现出困难，从而进一步加剧幻觉。</li></ul> 
<h4><a id="22__96"></a>2.2 幻觉来自训练</h4> 
<ul><li><strong>预训练阶段</strong>：LLMs在这一阶段学习通用表征并捕捉广泛的知识，通常采用基于transformer的架构，在庞大的语料库中进行因果语言建模。但是，固有的架构设计和研究人员所采用的特定训练策略，可能会产生与幻觉相关的问题。</li><li><strong>对齐阶段</strong>：一般涉及两个主要过程，即监督微调和从人类反馈中强化学习（RLHF）。虽然对齐能显著提高 LLM 响应的质量，但也会带来产生幻觉的风险，主要分为两方面：能力不对齐（Capability Misalignment）和信念不对齐（Belief Misalignment）。</li></ul> 
<h4><a id="23__101"></a>2.3 幻觉来自生成/推理</h4> 
<p>经过预训练和对齐后，解码在体现 LLM 能力方面发挥着重要作用。然而，解码策略的某些缺陷可能导致 LLM 出现幻觉。综述1深入探讨源于解码过程的潜在原因，并强调两个关键因素：</p> 
<ul><li><strong>解码策略固有的随机性</strong>（Inherent Sampling Randomness）：比如采用采样生成策略（如top-p和top-k）引入的随机性也可能导致幻觉的产生。</li><li><strong>不完善的解码表示</strong>（Imperfect Decoding Representation）：在解码阶段，LLM 使用顶层表示法预测下一个标记。然而，顶层表示法也有其局限性，主要表现在两个方面： 上下文关注不足（Insufficient Context Attention）和Softmax瓶颈（Softmax Bottleneck）。</li></ul> 
<h3><a id="3__108"></a>3. 幻觉的检测</h3> 
<p>检测 LLM 中的幻觉对于确保生成内容的可靠性和可信度至关重要。传统的衡量标准主要依赖于词语重叠，无法区分可信内容和幻觉内容之间的细微差别。这样的挑战凸显了为 LLM 幻觉量身定制更复杂的检测方法的必要性。</p> 
<p>鉴于这些幻觉的多样性，检测方法也相应地有所不同。</p> 
<p>在<a href="https://arxiv.org/abs/2311.05232" rel="nofollow">综述1</a>中，全面介绍了针对<strong>事实性幻觉</strong>和<strong>忠实性幻觉</strong>的主要幻觉检测策略。</p> 
<h4><a id="31__116"></a>3.1 事实性幻觉的检测</h4> 
<p>事实性幻觉的检测方法：通常分为 “<strong>检索外部事实</strong>”（Retrieve External Facts）和 “<strong>不确定性估计</strong>”（Uncertainty Estimation）。</p> 
<p><strong>检索外部事实</strong>：为了有效地指出 LLM 输出中的事实不准确之处，一种直观的策略是将模型生成的内容与可靠的知识来源进行比较，如下图 3 所示。<br> <img src="https://images2.imgbox.com/67/01/REQSYuzW_o.png" alt="在这里插入图片描述"></p> 
<p>虽然许多幻觉检测方法都依赖外部知识源进行事实检查，但有几种方法可以在零资源环境下解决这一问题，从而无需检索。</p> 
<p>这些策略背后的基本前提是，LLM 幻觉的起源本质上与模型的不确定性有关。</p> 
<p>因此，通过对模型生成的事实内容的不确定性进行估计，就可以检测出幻觉。</p> 
<p><strong>不确定性估计</strong>的方法大致可分为两种：<strong>基于内部状态</strong>和** LLM 行为**，如图 4 所示。前者的前提是可以访问模型的内部状态，而后者则适用于更受限制的环境，仅利用模型的可观测行为来推断其潜在的不确定性。</p> 
<p><img src="https://images2.imgbox.com/a1/8f/ux6QcWVd_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="32__136"></a>3.2 忠实性幻觉的检测</h4> 
<p><strong>忠实性幻觉</strong>的检测方法：主要侧重于确保生成的内容与给定上下文保持一致，从而避免无关或矛盾输出的潜在隐患。如下图5探讨在 LLM 生成中检测不忠实的方法。</p> 
<ul><li><strong>基于事实度量</strong>：通过检测生成内容与源内容之间的事实重叠度来评估忠实度。</li><li><strong>基于分类器的度量</strong>：利用经过训练的分类器来区分生成内容与源内容之间的关联程度。</li><li><strong>基于QA的度量方法</strong>：利用问题解答系统来验证源内容与生成内容之间的信息一致性。</li><li><strong>不确定性估计</strong>：通过测量模型对其生成输出的置信度来评估忠实度。</li><li><strong>基于prompt的度量方法</strong>：让LLM充当评估者，通过特定的prompt策略来评估生成内容的忠实度。</li></ul> 
<p><img src="https://images2.imgbox.com/c3/2b/87g4VC1q_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="4__150"></a>4. 幻觉的评估</h3> 
<p>针对不同类型的幻觉，采用的评估方式不一样。</p> 
<p>现有针对幻觉的工作，提出了各种基准来评估LLM中的幻觉，如下表5所示：</p> 
<p><img src="https://images2.imgbox.com/9c/23/uVaMVEeM_o.png" alt="在这里插入图片描述"></p> 
<p>现有的基准主要根据LLMs的两种不同能力来评估幻觉：<strong>生成</strong>事实陈述或<strong>判别</strong>事实陈述与非事实陈述的能力。下表说明了这两种评估形式的区别。</p> 
<p><img src="https://images2.imgbox.com/df/00/IMq6zp5g_o.png" alt="在这里插入图片描述"></p> 
<ul><li> <p><strong>Generation 生成式基准</strong>：将幻觉看作一种生成特征，类似于流畅度和连贯性，并对LLM生成的文本进行评估。例如，<strong>TruthfulQA</strong>用于评估大型模型对问题的回答的真实性，而<strong>FactScore</strong>则用于评估大型模型生成的个人传记的事实准确性。</p> </li><li> <p><strong>Discrimination 判别式基准</strong>：考察大型模型区分真实陈述和幻觉陈述的能力。具体来说，<strong>HaluEval</strong>要求模型确定状态信息是否包含幻觉信息，而F<strong>ACTOR</strong>则研究LLM是否更可能生成事实陈述而非非事实陈述。</p> </li></ul> 
<p>在这些基准中，<strong>TruthfulQA</strong>是一种特殊的基准，兼具生成式和判别式两种基准，提供了一个多项选择的替代方案，以测试模型区分真实陈述的能力。</p> 
<h3><a id="5__173"></a>5. 幻觉的解决</h3> 
<p><a href="https://arxiv.org/pdf/2309.06794v1.pdf" rel="nofollow">论文1</a>总结了五种解决幻觉的方法，具体如下图所示：</p> 
<p><img src="https://images2.imgbox.com/8f/2a/8dpo713J_o.png" alt="在这里插入图片描述"></p> 
<p>不同下游任务解决幻觉的方法不同，具体如下图所示：</p> 
<p><img src="https://images2.imgbox.com/7c/69/wa9BnSaN_o.png" alt="在这里插入图片描述"></p> 
<p>在哈工大的<a href="https://arxiv.org/abs/2311.05232" rel="nofollow">综述1</a>中，全面回顾了当前减轻幻觉的方法，并根据幻觉成因对这些方法进行了系统分类。</p> 
<p>具体来说，<a href="https://arxiv.org/abs/2311.05232" rel="nofollow">综述1</a>将重点放在解决与数据相关的幻觉、与训练相关的幻觉和与推理相关的幻觉的方法上，每种方法都提供了量身定制的解决方案，以应对各自原因所固有的特定挑战。</p> 
<p>参考：<br> https://zhuanlan.zhihu.com/p/666278645<br> https://arxiv.org/abs/2311.05232<br> https://arxiv.org/abs/2309.01219<br> https://arxiv.org/abs/2309.06794v1</p> 
<p>欢迎各位关注我的个人微信公众号：<strong>HsuDan</strong>，我将分享更多自己的学习心得、避坑总结、面试经验、AI最新技术资讯。</p> 
<div align="center"> 
 <img src="https://images2.imgbox.com/b1/0d/zVss6GUn_o.png" width="50%"> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/326335ba581fb8ce44d2150fb87c42ff/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">2023 年诺贝尔奖花落谁家？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/cb9e7192a26897ff5be1b3ce73f75aa0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">浪潮信息 KeyarchOS 安全可信攻防体验</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>