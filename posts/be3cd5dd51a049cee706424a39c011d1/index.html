<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用proxy_pool来为爬虫程序自动更换代理IP - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="使用proxy_pool来为爬虫程序自动更换代理IP" />
<meta property="og:description" content="文章目录 1. 前言2. 教程3. 官网 4. 在线demo 4.1. 本地部署4.2. 安装4.2.1. Python源码构建安装4.2.1.1. 安装redis数据库4.2.1.1.1. 下载redis源码4.2.1.1.2. 启动redis服务4.2.1.1.3. 安装redis服务4.2.1.1.4. 再次通过命令启动redis服务4.2.1.1.5. 测试redis服务是否可用 4.2.1.2. 下载proxy_pool源码4.2.1.3. 安装依赖4.2.1.4. 更新配置4.2.1.4.1. 配置参数4.2.1.4.2. 配置参数案例 4.2.1.5. 启动项目4.2.1.6. 测试API的调用4.2.1.6.1. 直接打开网页版4.2.1.6.2. 代码测试 4.2.2. docker安装4.2.3. API调用 5. 报错 1. 前言 之前做爬虫的时候，经常会遇到对于一个网页，使用同一个IP多次会被禁掉IP的问题，我们可以自己手动更换代理IP再继续这个问题但多少会有点麻烦，我对于一个懒人来说，手动更换IP太麻烦，而且也不符合程序员懒惰的美德，于是便有了下面的故事。proxy_pool 是一个开源的代理池，聚合了各大免费的 ip 代理池。当自己的爬虫因为爬的太快了 ip 被封了的时候，代理池就可以派上用场啦爬虫代理IP池项目,主要功能为定时采集网上发布的免费代理验证入库，定时验证入库的代理保证代理的可用性，提供API和CLI两种使用方式。同时你也可以扩展代理源以增加代理池IP的质量和数量。 2. 教程 部署自己的代理池 - idealclover 3. 官网 GitHub - jhao104/proxy_pool: Python爬虫代理IP池(proxy pool) 4. 在线demo demo.spiderpy.cn/ 4.1. 本地部署 4.2. 安装 python爬虫添加代理ip池ProxyPool (Windows) - 灰信网（软件开发博客聚合） 4.2.1. Python源码构建安装 4.2.1.1. 安装redis数据库 4.2.1.1.1. 下载redis源码 Windows下安装Redis图文教程_喵代王-香菜的博客-CSDN博客_windows安装rediswindows首先下载安装Redis安装包，并解压到合适位置(放哪都行) 4." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/be3cd5dd51a049cee706424a39c011d1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-24T23:43:32+08:00" />
<meta property="article:modified_time" content="2022-12-24T23:43:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用proxy_pool来为爬虫程序自动更换代理IP</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1__1" rel="nofollow">1. 前言</a></li><li><a href="#2__7" rel="nofollow">2. 教程</a></li><li><a href="#3__11" rel="nofollow">3. 官网</a></li><li><ul><li><a href="#_14" rel="nofollow"></a></li></ul> 
  </li><li><a href="#4_demo_16" rel="nofollow">4. 在线demo</a></li><li><ul><li><ul><li><a href="#_20" rel="nofollow"></a></li></ul> 
   </li><li><a href="#41__22" rel="nofollow">4.1. 本地部署</a></li><li><a href="#42__24" rel="nofollow">4.2. 安装</a></li><li><ul><li><a href="#421_Python_28" rel="nofollow">4.2.1. Python源码构建安装</a></li><li><ul><li><a href="#4211__redis_30" rel="nofollow">4.2.1.1. 安装redis数据库</a></li><li><ul><li><a href="#42111_redis_32" rel="nofollow">4.2.1.1.1. 下载redis源码</a></li><li><a href="#42112_redis_38" rel="nofollow">4.2.1.1.2. 启动redis服务</a></li><li><a href="#42113_redis_44" rel="nofollow">4.2.1.1.3. 安装redis服务</a></li><li><a href="#42114_redis_56" rel="nofollow">4.2.1.1.4. 再次通过命令启动redis服务</a></li><li><a href="#42115_redis_65" rel="nofollow">4.2.1.1.5. 测试redis服务是否可用</a></li></ul> 
     </li><li><a href="#4212_proxy_pool_72" rel="nofollow">4.2.1.2. 下载proxy_pool源码</a></li><li><a href="#4213__83" rel="nofollow">4.2.1.3. 安装依赖</a></li><li><a href="#4214__89" rel="nofollow">4.2.1.4. 更新配置</a></li><li><ul><li><a href="#42141__93" rel="nofollow">4.2.1.4.1. 配置参数</a></li><li><a href="#42142__153" rel="nofollow">4.2.1.4.2. 配置参数案例</a></li></ul> 
     </li><li><a href="#4215__178" rel="nofollow">4.2.1.5. 启动项目</a></li><li><a href="#4216_API_199" rel="nofollow">4.2.1.6. 测试API的调用</a></li><li><ul><li><a href="#42161__201" rel="nofollow">4.2.1.6.1. 直接打开网页版</a></li><li><a href="#42162__213" rel="nofollow">4.2.1.6.2. 代码测试</a></li></ul> 
    </li></ul> 
    </li><li><a href="#422_docker_248" rel="nofollow">4.2.2. docker安装</a></li><li><a href="#423_API_265" rel="nofollow">4.2.3. API调用</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_271" rel="nofollow"></a></li><li><a href="#5__273" rel="nofollow">5. 报错</a></li><li><ul><li><ul><li><a href="#_278" rel="nofollow"></a></li><li><a href="#_281" rel="nofollow"></a></li><li><a href="#_283" rel="nofollow"></a></li></ul> 
   </li><li><a href="#_324" rel="nofollow"></a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="1__1"></a>1. 前言</h2> 
<ul><li>之前做爬虫的时候，经常会遇到对于一个网页，使用同一个IP多次会被禁掉IP的问题，我们可以自己手动更换代理IP再继续这个问题但多少会有点麻烦，我对于一个懒人来说，手动更换IP太麻烦，而且也不符合程序员懒惰的美德，于是便有了下面的故事。</li><li>proxy_pool 是一个<strong>开源的代理池</strong>，聚合了<strong>各大免费</strong>的 <strong>ip 代理池</strong>。当自己的爬虫因为爬的太快了 ip 被封了的时候，代理池就可以派上用场啦</li><li>爬虫代理IP池项目,主要功能为定时采集网上发布的免费代理验证入库，定时验证入库的代理保证代理的可用性，提供API和CLI两种使用方式。同时你也可以扩展代理源以增加代理池IP的质量和数量。</li></ul> 
<h2><a id="2__7"></a>2. 教程</h2> 
<ul><li><a href="https://idealclover.top/archives/544/" rel="nofollow">部署自己的代理池 - idealclover</a></li></ul> 
<h2><a id="3__11"></a>3. 官网</h2> 
<ul><li><a href="https://github.com/jhao104/proxy_pool">GitHub - jhao104/proxy_pool: Python爬虫代理IP池(proxy pool)</a><h3><a id="_14"></a></h3> </li></ul> 
<h2><a id="4_demo_16"></a>4. 在线demo</h2> 
<ul><li><a href="http://demo.spiderpy.cn/" rel="nofollow">demo.spiderpy.cn/</a></li><li><img src="https://images2.imgbox.com/3e/84/EyZS81eQ_o.png" alt=""><h4><a id="_20"></a></h4> </li></ul> 
<h3><a id="41__22"></a>4.1. 本地部署</h3> 
<h3><a id="42__24"></a>4.2. 安装</h3> 
<ul><li><a href="https://www.freesion.com/article/44981507298/" rel="nofollow">python爬虫添加代理ip池ProxyPool (Windows) - 灰信网（软件开发博客聚合）</a></li></ul> 
<h4><a id="421_Python_28"></a>4.2.1. Python源码构建安装</h4> 
<h5><a id="4211__redis_30"></a>4.2.1.1. 安装redis数据库</h5> 
<h6><a id="42111_redis_32"></a>4.2.1.1.1. 下载redis源码</h6> 
<ul><li><a href="https://blog.csdn.net/chen15369337607/article/details/119334531">Windows下安装Redis图文教程_喵代王-香菜的博客-CSDN博客_windows安装redis</a></li><li>windows首先下载安装Redis安装包，并解压到合适位置(放哪都行)</li><li><img src="https://images2.imgbox.com/bf/0c/C9OOiTFJ_o.png" alt=""></li></ul> 
<h6><a id="42112_redis_38"></a>4.2.1.1.2. 启动redis服务</h6> 
<ul><li>cmd进入文件位置</li><li>redis-server.exe redis.windows.conf</li><li><img src="https://images2.imgbox.com/22/79/yib0xqQ4_o.png" alt=""></li></ul> 
<h6><a id="42113_redis_44"></a>4.2.1.1.3. 安装redis服务</h6> 
<ul><li>再打开一个cmd窗口，输入下面的命令，将Redis安装到Windows服务中</li><li>redis-server --service-install redis.windows.conf</li><li><img src="https://images2.imgbox.com/bb/58/6UpTWFrM_o.png" alt=""></li><li>查看是否添加进去了服务</li><li>services.msc</li><li><img src="https://images2.imgbox.com/15/db/d1jFmNwn_o.png" alt=""></li><li><img src="https://images2.imgbox.com/8a/ad/yDXLxVuJ_o.png" alt=""></li><li><li></ul> 
<h6><a id="42114_redis_56"></a>4.2.1.1.4. 再次通过命令启动redis服务</h6> 
<ul><li>关闭第一个“启动服务”cmd窗口，另开一个cmd窗口，启动服务</li><li>redis-server --service-start</li><li><img src="https://images2.imgbox.com/d9/72/rYFXv7YI_o.png" alt=""></li><li>关闭服务命令</li><li>redis-server --service-stop</li><li></ul> 
<h6><a id="42115_redis_65"></a>4.2.1.1.5. 测试redis服务是否可用</h6> 
<ul><li>redis-cli.exe -h 127.0.0.1 -p 6379</li><li>如果没报错，并且显示下面的界面的话，就表示这个redis服务现在可用</li><li><img src="https://images2.imgbox.com/c6/9c/2ldVwQ5q_o.png" alt=""></li><li></ul> 
<h5><a id="4212_proxy_pool_72"></a>4.2.1.2. 下载proxy_pool源码</h5> 
<pre><code>git clone git@github.com:jhao104/proxy_pool.git
</code></pre> 
<ul><li>如果无法通过这种方法克隆的话，就手动下载吧</li><li>或者直接下载特定的release版本</li><li><a href="https://github.com/jhao104/proxy_pool/releases">Releases · jhao104/proxy_pool · GitHub</a></li><li><img src="https://images2.imgbox.com/b8/25/2aI2MmO1_o.png" alt=""></li></ul> 
<h5><a id="4213__83"></a>4.2.1.3. 安装依赖</h5> 
<pre><code>pip install -r requirements.txt
</code></pre> 
<h5><a id="4214__89"></a>4.2.1.4. 更新配置</h5> 
<ul><li>配置文件 setting.py 位于项目的主目录下:</li></ul> 
<h6><a id="42141__93"></a>4.2.1.4.1. 配置参数</h6> 
<ul><li><a href="https://proxy-pool.readthedocs.io/zh/latest/user/how_to_config.html" rel="nofollow">配置参考 — ProxyPool 2.1.0 文档</a></li><li>配置参数说明</li><li>服务配置</li><li>HOST</li><li>API服务监听的IP, <strong>本机访问</strong>设置为 127.0.0.1, 开启远程访问设置为: 0.0.0.0</li><li>PORT</li><li>API服务监听的端口.</li><li>数据库配置</li><li>DB_CONN</li><li>用户存放代理IP的数据库URI, 配置格式为: <code> db_type://[[user]:[pwd]]@ip:port/[db] </code></li><li>目前支持的db_type有: ssdb 、 redis.</li><li>DB_CONN配置示例</li></ul> 
<pre><code># SSDB IP: 127.0.0.1  Port: 8888 
DB_CONN = 'ssdb://@127.0.0.1:8888' 
# SSDB IP: 127.0.0.1  Port: 8899  Password:  123456 
DB_CONN = 'ssdb://:123456@127.0.0.1:8888' 
 
# Redis IP: 127.0.0.1  Port: 6379 
DB_CONN = 'redis://@127.0.0.1:6379' 
# Redis IP: 127.0.0.1  Port: 6379  Password:  123456 
DB_CONN = 'redis://:123456@127.0.0.1:6379' 
# Redis IP: 127.0.0.1  Port: 6379  Password:  123456  DB: 15 
DB_CONN = 'redis://:123456@127.0.0.1:6379/15'
</code></pre> 
<pre><code>         - 我这里没有密码，所以直接就设置成了
         - DB_CONN = 'redis://@127.0.0.1:6379/0'
         - ![](https://img-blog.csdnimg.cn/img_convert/1f5a0a730e71f0290c6a6f68f1f9b37e.png) 
         - 
</code></pre> 
<ul><li>TABLE_NAME</li><li>存放代理的<strong>数据载体名称</strong>, ssdb和redis的存放结构为<strong>hash</strong>.</li><li>采集配置</li><li>PROXY_FETCHER</li><li>启用的代理采集方法名, 代理采集方法位于 fetcher/proxyFetcher.py 类中.</li><li>由于各个代理源的稳定性不容易掌握, 当某个代理采集方法失效时, 可以该配置中注释掉其名称.</li><li>如果有增加某些代理采集方法, 也请在该配置中添加其方法名, 具体请参考 /dev/extend_fetcher.</li><li>调度程序每次执行采集任务时都会再次加载该配置, 保证每次运行的采集方法都是有效的.</li><li>这里需要实时进行更新 
  <ul><li><img src="https://images2.imgbox.com/ef/18/d6WNA9nZ_o.png" alt=""></li></ul> </li><li><li>校验配置</li><li>HTTP_URL</li><li>用于检验代理是否可用的地址, 默认为<code> http://httpbin.org</code> ,可根据使用场景修改为其他地址.</li><li><img src="https://images2.imgbox.com/7c/eb/UQ7EqQMw_o.png" alt=""></li><li><li>HTTPS_URL</li><li>用于检验代理是否支持HTTPS的地址, 默认为<code> https://www.qq.com</code> ,可根据使用场景修改为其他地址.</li><li>VERIFY_TIMEOUT</li><li>检验代理的超时时间, 默认为 10 , 单位秒. 使用代理访问 HTTP(S)_URL 耗时超过 VERIFY_TIMEOUT 时, 视为代理不可用.</li><li>MAX_FAIL_COUNT</li><li>检验代理允许最大失败次数, 默认为 0, 即出错一次即删除.</li><li>POOL_SIZE_MIN</li><li>代理检测定时任务运行前若代理数量小于 POOL_SIZE_MIN, 则先运行抓取程序.</li><li></ul> 
<h6><a id="42142__153"></a>4.2.1.4.2. 配置参数案例</h6> 
<pre><code># Config.ini 为项目配置文件 
# 配置DB 
type = SSDB       # 如果使用SSDB或redis数据库，均配置为SSDB 
host = localhost  # db host 
port = 6379       # db port 
name = proxy      # 默认配置 
 
# 配置 ProxyGetter 
freeProxyFirst  = 1  # 这里是启动的抓取函数，可在ProxyGetter/getFreeProxy.py 扩展 
freeProxySecond = 1 
.... 
 
# 配置 HOST (api服务) 
ip = 127.0.0.1       # 监听ip,0.0.0.0开启外网访问 
port = 5010          # 监听端口 
# 上面配置启动后，代理api地址为 http://127.0.0.1:5010
</code></pre> 
<ul><li>第一个port是你<strong>数据库</strong>的<strong>端口号</strong>, 第二个是<strong>api</strong>的<strong>端口号</strong></li><li><a href="https://github.com/jhao104/proxy_pool/issues/118">目标计算机积极拒绝 · Issue #118 · jhao104/proxy_pool · GitHub</a></li><li><img src="https://images2.imgbox.com/c2/6d/RJdECRIW_o.png" alt=""></li></ul> 
<h5><a id="4215__178"></a>4.2.1.5. 启动项目</h5> 
<ul><li>如果已配置好运行环境, 具备运行条件, 可以通过 proxyPool.py 启动. proxyPool.py 是项目的<strong>CLI入口</strong>. 完整程序包含两部份: <strong>schedule 调度程序</strong>和 <strong>server API服务</strong>, 调度程序负责<strong>采集</strong>和<strong>验证</strong>代理, API服务提供代理服务<strong>HTTP接口.</strong></li><li>通过命令行程序<strong>分别启动 调度程序</strong>和<strong>API服务</strong>:</li><li>启动调度程序：python proxyPool.py schedule</li><li><img src="https://images2.imgbox.com/77/6c/xPgLjyHV_o.png" alt=""></li><li>可以看到，正在采集对于IP，有的成功，有的失败</li><li><img src="https://images2.imgbox.com/2d/73/Pv80AhFc_o.png" alt=""></li><li>最终稳定下来</li><li><img src="https://images2.imgbox.com/ee/5c/IS8otYZC_o.png" alt=""></li><li><li>再开一个命令号，启动webApi服务：python proxyPool.py server</li></ul> 
<pre><code>python proxyPool.py schedule
python proxyPool.py server
</code></pre> 
<ul><li><li><img src="https://images2.imgbox.com/ac/52/UP9EDoKM_o.png" alt=""></li></ul> 
<h5><a id="4216_API_199"></a>4.2.1.6. 测试API的调用</h5> 
<h6><a id="42161__201"></a>4.2.1.6.1. 直接打开网页版</h6> 
<ul><li><a href="http://127.0.0.1:5010/get/" rel="nofollow">127.0.0.1:5010/get/</a></li><li><code> http://127.0.0.1:5010/get/</code></li><li>这里需要注意的是，网址端口应该改成自己之前定义的端口</li><li><img src="https://images2.imgbox.com/1a/84/HwLIIPqH_o.png" alt=""></li><li><img src="https://images2.imgbox.com/34/e6/RwepQHtf_o.png" alt=""></li><li><li>每一次刷新上面的代理IP地址都会发生改变</li><li><img src="https://images2.imgbox.com/5b/54/tixhIpPg_o.png" alt=""></li><li></ul> 
<h6><a id="42162__213"></a>4.2.1.6.2. 代码测试</h6> 
<pre><code>import requests 
  
def get_proxy(): 
    #5000：settings中设置的监听端口，不是Redis服务的端口 
    return requests.get("http://127.0.0.1:5000/get/").json() 
  
def delete_proxy(proxy): 
    requests.get("http://127.0.0.1:5000/delete/?proxy={}".format(proxy)) 
  
# 主代码 
def getHtml(): 
    retry_count = 5 
    proxy = get_proxy().get("proxy") 
    print(proxy) 
    while retry_count &gt; 0: 
        try: 
            html = requests.get('http://www.baidu.com', proxies={"http": "http://{}".format(proxy)}) 
            print(html.text) 
            break 
        except Exception: 
            retry_count -= 1 
    # 删除代理池中代理 
    delete_proxy(proxy) 
    return None 
  
getHtml()
</code></pre> 
<ul><li><li><img src="https://images2.imgbox.com/ef/1c/N40F0k8M_o.png" alt=""></li><li></ul> 
<h4><a id="422_docker_248"></a>4.2.2. docker安装</h4> 
<p>安装</p> 
<pre><code>docker pull jhao104/proxy_pool 
 
docker run --env DB_CONN=redis://:password@ip:port/0 -p 5010:5010 jhao104/proxy_pool:latest
</code></pre> 
<ul><li><li>运行</li></ul> 
<pre><code>docker-compose up -d
</code></pre> 
<h4><a id="423_API_265"></a>4.2.3. API调用</h4> 
<p>启动web服务后, 默认配置下会开启<a href="http://127.0.0.1:5010/" rel="nofollow">127.0.0.1:5010/</a> 的api接口服务:<br> 参数</p> 
<ul><li><img src="https://images2.imgbox.com/41/8c/NwCcrmMl_o.png" alt=""></li><li> <h2><a id="_271"></a></h2> </li></ul> 
<h2><a id="5__273"></a>5. 报错</h2> 
<ul><li> <p>ValueError: invalid literal for int() with base 10: ‘port’</p> </li><li> <p><img src="https://images2.imgbox.com/58/d1/AD4olMYl_o.png" alt=""></p> </li><li> <p>可能是一个端口不可用吧，在GUI界面中修改一下端口号就好了</p> <h4><a id="_278"></a></h4> </li><li> <p>redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:<strong>6379</strong>. 由于目标计算机积极拒绝，无法连接。.2022-12-24 20:52:10,677 launcher.py[line:39] INFO exit!</p> </li><li> <p><img src="https://images2.imgbox.com/aa/a9/IZknwkDG_o.png" alt=""></p> <h4><a id="_281"></a></h4> </li><li> <p>可能只是自己参数设置的不对吧</p> <h4><a id="_283"></a></h4> </li><li> <p>redis.exceptions.AuthenticationError: <strong>Client sent AUTH</strong>, but <strong>no password is set</strong> 2022-12-24 21:56:48,828 launcher.py[line:39] INFO exit!</p> </li><li> <p><img src="https://images2.imgbox.com/5e/43/vZXhVvcb_o.png" alt=""></p> </li><li> <p>redis的账号密码设置的不对<br> <a href="../%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7/proxy_pool/%E4%BD%BF%E7%94%A8/%E5%AE%89%E8%A3%85/Python%E6%BA%90%E7%A0%81%E6%9E%84%E5%BB%BA/%E6%9B%B4%E6%96%B0%E9%85%8D%E7%BD%AE/%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE/DB_CONN/DB_CONN%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B.md" rel="nofollow">DB_CONN配置示例</a></p> </li><li> <p>ImportError: cannot import name ‘Markup’ from ‘jinja2’ (D:\Program\Anaconda3\lib\site-packages\jinja2_<em>init</em>_.py)</p> </li><li> <p><img src="https://images2.imgbox.com/73/51/4C7bh7JR_o.png" alt=""></p> </li><li> <p>python版本太高了，目前支持到3.6. 3.6以上的版本把requirements.txt里面的版本号删掉 重新pip install 一下</p> </li></ul> 
<pre><code>### APScheduler
werkzeug
Flask
requests
click
gunicorn
lxml
redis
</code></pre> 
<ul><li> <p>pip uninstall -r requirements.txt</p> </li><li> <p>pip install -r requirements.txt</p> </li><li> <p><img src="https://images2.imgbox.com/f7/75/arm22MaB_o.png" alt=""></p> </li><li> <p><a href="https://github.com/jhao104/proxy_pool/issues/663">运行出错！ · Issue #663 · jhao104/proxy_pool · GitHub</a></p> </li></ul> 
<p>之后就正常了</p> 
<ul><li> <p><img src="https://images2.imgbox.com/dc/47/icW40Ptf_o.png" alt=""></p> </li><li> <p>requests.exceptions.ConnectionError: <strong>HTTPConnectionPool</strong>(host=‘127.0.0.1’, port=<strong>5000</strong>): Max retries exceeded with url: /get/ (Caused by NewConnectionError(‘&lt;urllib3.connection.HTTPConnection object at 0x000001AF5F88EAD0 Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。’))</p> </li><li> <p>很简单，端口不匹配，更改即可<br> <img src="https://images2.imgbox.com/66/75/dX8jkRyB_o.png" alt=""></p> </li></ul> 
<p>ctionPool**(host=‘127.0.0.1’, port=<strong>5000</strong>): Max retries exceeded with url: /get/ (Caused by NewConnectionError(‘&lt;urllib3.connection.HTTPConnection object at 0x000001AF5F88EAD0 Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。’))</p> 
<ul><li>很简单，端口不匹配，更改即可<br> [外链图片转存中…(img-nAUDtJec-1671896468370)]</li></ul> 
<h3><a id="_324"></a></h3>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/72770c854626cfb5764999b32a748807/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">使用Docker搭建Nacos的持久化和集群部署</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0bc8e50a97e131bc0f1096a3c38954e8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python爬虫爬取网页上的天气数据</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>