<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>多光谱行人检测（一）Multispectral Pedestrian Detection：Benchmark Dataset and Baseline - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="多光谱行人检测（一）Multispectral Pedestrian Detection：Benchmark Dataset and Baseline" />
<meta property="og:description" content="这篇文章最主要的是制作了KIAST数据集，直到现在仍有许多人使用这个数据集进行多光谱行人检测。虽然提出ACF方法在后续文章作为对比算法，但是因为深度学习的快速发展，后续工作很少基于ACF进行改进。
这篇文章提出了一个多光谱行人数据集，该数据集由基于分束器的特殊硬件捕获，提供良好的颜色-热图像对。颜色热数据集和以前基于颜色的数据集一样大，并提供了密集的注释，包括时间对应。利用该数据集，同时引入了多光谱ACF，它是聚合通道特征(ACF)的扩展，可以同时处理彩色-热图像对。多谱ACF使得ACF的平均漏检率降低了15%，实现了行人检测任务的又一突破。
文章目录 1. 主要贡献2. 数据采集3. 数据集介绍3.1 数据规模3.2 行人遮挡3.3 行人位置3.4 行人外观变化 4. 行人检测基线4.1 标准 ACF4.2 多光谱 ACF 的多光谱行人数据集的例子。它将从白天/晚上的交通场景中捕获的彩色(左列)和热(右列)图像对齐。数据集提供的绿色、黄色和红色框分别表示无遮挡、部分遮挡和重度遮挡。
1. 主要贡献 引入了多光谱行人数据集，提供了对齐的颜色和热图像对。的数据集的图像帧数和广泛使用的行人数据集一样多[10,15]。该数据集还包含以前的数据集中很少提供或讨论的夜间流量序列。分析了颜色通道和热通道的互补关系，提出了如何结合两种通道的优点，而不是单独使用颜色通道或热通道。提出了几种带有热通道的扩展ACF的组合。扩展在提出的多光谱行人数据集上减少了15%的平均漏报率。与以往大多数数据集利用彩色热立体设置相比，使用基于分束器的硬件来物理对齐两个图像域。第一个在白天和晚上提供对齐的彩色和热图像对的数据集。 2. 数据采集 硬件规格如上图所示，开发了由彩色摄像机、热摄像机、分束器和三轴摄像机夹具组成的成像硬件。
彩色相机640×480像素的空间分辨率与103.6◦垂直视野。热相机有320 × 256像素的空间分辨率与39◦垂直视野。请注意，彩色相机的视场比热成像相机大。通过牺牲彩色图像的边缘区域来使用原始热图像在对齐图像域。两个摄像头的帧率等于20fps。
相机标定。硬件的概念是由Bienkowski等人引入的，用于无损评估目的。由于[3]中没有提到对两个图像域的校准方法，所以在这里简要介绍的校准方法。首先，利用立体摄像机标定计算安装在硬件上的两个摄像机之间的平移。在这里，可以认为两个相机的光轴超过分束器是平行的，由于硬连线的安排。因此，两个图像域之间只存在平移，只使用三轴夹具调整摄像机位置，直到平移为零。调整后，两个图像域被矫正为具有相同的虚拟焦距。经过这些步骤，两个图像域具有相同的焦距和相同的主点，并且没有基线。虚拟对齐的图像域有640×512像素的空间分辨率，并有39°垂直视野，这是类似于人类的视觉。由于传统的棋盘图案在热成像相机中是无法观察到的，使用了一个特殊的标定板[16,17]，它有一些孔。当它被加热时，在板和孔之间有一个温度差，因此可以在热成像相机中观察到。图3所示为孔模式图像的示例。
硬件安装在车顶上，用于捕捉以自我为中心的交通场景图像。特别的是，在白天和晚上捕捉了各种场景，以考虑光照条件的变化。在捕获的帧中，95328对彩色热对图像进行手工标注，总共有103128个密集标注和1182个独特的行人。为了标注地面的真实情况，使用了Piotr的计算机视觉工具箱[8]，但它被修改为同时显示彩色和热图像。修改有助于注释，因为在夜间，在颜色通道中很难看到远处的行人。还修改了工具箱，为每个边界框提供遮挡标记，而不是遮挡区域。类似于Dollár等[10]，该对象有四个标签中的一个。很明显，一个行人被标记为“人”。无法区分的个体被贴上了人的标签。骑两轮交通工具的人被称为骑自行车的人。在高度混乱的场景中，即使是人类注释者有时也不能清楚地确定一个人形物体是否是行人。这个物体被标记为人?它在计算中被忽略了。在注释之后，边界框还具有指示帧上的人员索引的时间对应。在的数据集中，一个人平均出现74.80帧(相当于3.74秒)。
3. 数据集介绍 3.1 数据规模 规模。由于行人检测的关键应用是避免事故，根据车辆制动距离对标注的边界盒大小进行分类。在行人经常出现的市区，认为一般车速为30至55公里/小时。在这种驾驶条件下，预期的制动距离为11 ~ 28米(包括驾驶员反应造成的制动延迟)[7]。如果行人的高度约为1.7米，那么在对齐的图像域中，这对应于45 ~ 115像素的高度。将这些大小的注释分类为介质。如图5(a)所示，也确定了远近，即小于或大于中等。图5(b)显示了以像素为单位的行人高度与其对应的距离(以米为单位)的关系。
3.2 行人遮挡 如果一个行人突然被场景中的其他行人或物体遮挡，用三个遮挡标签中的一个来标注。没有被遮挡的行人被标记为没有遮挡;那些在一定程度上闭塞了一半以上的被标记为部分闭塞;轮廓大部分被遮挡的被标记为重遮挡。在所有标注中，75%以上的行人被标注为未遮挡(78.6%)，其余为部分遮挡(12.6%)和重度遮挡(8.8%)。
3.3 行人位置 图6 (a)是用混合高斯模型的分布表示的标注行人的中心。的硬件被设置为覆盖一般驱动程序的视图。这个设置限制了行人在特定区域的外观。因此，行人分布在图像中心的一个窄带内。行人多出现在图像的右侧，因为汽车是在右向交通条件下行驶。还在图6 (b)中以对数标准化的比例显示了每帧的行人数量。
3.4 行人外观变化 图7显示了白天和晚上行人的几个例子。由于强烈的阳光，白天的彩色图像显示出独特的人体形状。另一方面，由于黑暗的环境，夜间彩色图像中的形状无法区分。然而，热图像在夜间显示出明显的形状，因为当空气温度较低时，温差更大，所以可以清楚地捕捉到固定温度的行人在夜间。在白天，强烈的太阳辐射造成背景杂波。基于这些原因，可以期望通过全天使用彩色和热图像的优点来获得更好的性能。
4. 行人检测基线 为了有效地处理颜色和热通道，基线算法建立在聚合通道特征(ACF)行人检测器[9]的基础上。这是一种自然的选择，因为算法可以容纳显示不同模式的多个通道。例如，它使用单色图像的彩色和渐变通道。这样，热通道可以看作是该算法中另一个增强的通道。在这里，受益于的捕获硬件，因为颜色和热通道之间的对齐问题被删除。此外，ACF行人检测器被广泛用作并行最先进的行人检测器的基算法。有了这个想法，首先回顾了为彩色图像设计的标准ACF，并介绍了的扩展来额外处理热通道。
4.1 标准 ACF 对于彩色图像输入，标准ACF[9]有10个增强通道(LUV&#43;M&#43;O): LUV表示颜色空间的3个通道，M表示1个梯度幅值通道，O表示6个梯度直方图通道，是定向梯度直方图(HOG)[4]的简化版本。在ACF[9]中，他们利用了引导过程，从大量的底片中挖掘硬底片，并多次重新训练AdaBoost分类器[1]。最后，他们应用了一种称为软级联的有效抑制方法来提高检测时间。通过这种方法，构建了一个功能强大的行人检测框架。
4.2 多光谱 ACF 利用ACF行人检测器作为的基线，并将其扩展为热强度通道编码。对于扩展，建议三个基线:(1)ACF&#43;T (2) ACF&#43;T&#43;TM&#43;TO (3) ACF&#43;T&#43;THOG。ACF是前面提到的为颜色通道定义的特性。T、T&#43;TM&#43;TO和T&#43;THOG表示热通道增加的额外通道特性。
T 该通道特性直接利用热强度。为了提高检测性能，使用直方图均衡化增强了图像的对比度。T &#43; TM &#43;TO。这个扩展包括三个渠道:T, TM和TO。T为上述热通道，TM为热图像的归一化梯度幅值，TO为热图像的定向梯度直方图。TM和TO采用与标准ACF相同的方法获得。T &#43; THOG。该扩展使用热图像的T和HOG特征(表示为THOG)。与计算6个直方图方向相比，THOG计算更多的梯度方向，并且在局部直方图上有额外的归一化步骤。 这三个扩展利用了热通道的强度和梯度信息。利用热图像的梯度作为一个重要的线索。在不同的条件下对这些扩展进行了自我评估:不同的尺度、遮挡标记和捕获时间(白天或夜晚)。图10的结果表明，三种扩展的性能都优于ACF，其中ACF&#43;T&#43;THOG的性能最好。这是因为ACF&#43;T&#43;THOG有最详尽的人形表示。基于这一观察结果，选择了ACF&#43;T&#43;THOG作为理想的信道特性组合，并对其进行了分析。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/d7311a3f05d8cabcf5a59e245671a6d0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-07-05T16:19:32+08:00" />
<meta property="article:modified_time" content="2021-07-05T16:19:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">多光谱行人检测（一）Multispectral Pedestrian Detection：Benchmark Dataset and Baseline</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>这篇文章最主要的是制作了KIAST数据集，直到现在仍有许多人使用这个数据集进行多光谱行人检测。虽然提出ACF方法在后续文章作为对比算法，但是因为深度学习的快速发展，后续工作很少基于ACF进行改进。</p> 
</blockquote> 
<p>这篇文章提出了一个多光谱行人数据集，该数据集由基于分束器的特殊硬件捕获，提供良好的颜色-热图像对。颜色热数据集和以前基于颜色的数据集一样大，并提供了密集的注释，包括时间对应。利用该数据集，同时引入了多光谱ACF，它是聚合通道特征(ACF)的扩展，可以同时处理彩色-热图像对。多谱ACF使得ACF的平均漏检率降低了15%，实现了行人检测任务的又一突破。<br> </p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#1__10" rel="nofollow">1. 主要贡献</a></li><li><a href="#2__15" rel="nofollow">2. 数据采集</a></li><li><a href="#3__28" rel="nofollow">3. 数据集介绍</a></li><li><ul><li><a href="#31__29" rel="nofollow">3.1 数据规模</a></li><li><a href="#32__33" rel="nofollow">3.2 行人遮挡</a></li><li><a href="#33__35" rel="nofollow">3.3 行人位置</a></li><li><a href="#34__38" rel="nofollow">3.4 行人外观变化</a></li></ul> 
   </li><li><a href="#4__42" rel="nofollow">4. 行人检测基线</a></li><li><ul><li><a href="#41__ACF_45" rel="nofollow">4.1 标准 ACF</a></li><li><a href="#42__ACF_47" rel="nofollow">4.2 多光谱 ACF</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<p><img src="https://images2.imgbox.com/f4/f2/ORNNEz4n_o.png" alt="在这里插入图片描述"><br> 的多光谱行人数据集的例子。它将从白天/晚上的交通场景中捕获的彩色(左列)和热(右列)图像对齐。数据集提供的绿色、黄色和红色框分别表示无遮挡、部分遮挡和重度遮挡。</p> 
<h3><a id="1__10"></a>1. 主要贡献</h3> 
<ol><li>引入了多光谱行人数据集，提供了对齐的颜色和热图像对。的数据集的图像帧数和广泛使用的行人数据集一样多[10,15]。该数据集还包含以前的数据集中很少提供或讨论的夜间流量序列。</li><li>分析了颜色通道和热通道的互补关系，提出了如何结合两种通道的优点，而不是单独使用颜色通道或热通道。</li><li>提出了几种带有热通道的扩展ACF的组合。扩展在提出的多光谱行人数据集上减少了15%的平均漏报率。与以往大多数数据集利用彩色热立体设置相比，使用基于分束器的硬件来物理对齐两个图像域。第一个在白天和晚上提供对齐的彩色和热图像对的数据集。</li></ol> 
<h3><a id="2__15"></a>2. 数据采集</h3> 
<p><img src="https://images2.imgbox.com/14/e4/vgJbStQG_o.png" alt="在这里插入图片描述"></p> 
<p>硬件规格如上图所示，开发了由彩色摄像机、热摄像机、分束器和三轴摄像机夹具组成的成像硬件。<br> 彩色相机640×480像素的空间分辨率与103.6◦垂直视野。热相机有320 × 256像素的空间分辨率与39◦垂直视野。请注意，彩色相机的视场比热成像相机大。通过牺牲彩色图像的边缘区域来使用原始热图像在对齐图像域。两个摄像头的帧率等于20fps。</p> 
<p>相机标定。硬件的概念是由Bienkowski等人引入的，用于无损评估目的。由于[3]中没有提到对两个图像域的校准方法，所以在这里简要介绍的校准方法。首先，利用立体摄像机标定计算安装在硬件上的两个摄像机之间的平移。在这里，可以认为两个相机的光轴超过分束器是平行的，由于硬连线的安排。因此，两个图像域之间只存在平移，只使用三轴夹具调整摄像机位置，直到平移为零。调整后，两个图像域被矫正为具有相同的虚拟焦距。经过这些步骤，两个图像域具有相同的焦距和相同的主点，并且没有基线。虚拟对齐的图像域有640×512像素的空间分辨率，并有39°垂直视野，这是类似于人类的视觉。由于传统的棋盘图案在热成像相机中是无法观察到的，使用了一个特殊的标定板[16,17]，它有一些孔。当它被加热时，在板和孔之间有一个温度差，因此可以在热成像相机中观察到。图3所示为孔模式图像的示例。<br> <img src="https://images2.imgbox.com/33/20/HMOODvcO_o.png" alt="在这里插入图片描述"></p> 
<p>硬件安装在车顶上，用于捕捉以自我为中心的交通场景图像。特别的是，在白天和晚上捕捉了各种场景，以考虑光照条件的变化。在捕获的帧中，95328对彩色热对图像进行手工标注，总共有103128个密集标注和1182个独特的行人。为了标注地面的真实情况，使用了Piotr的计算机视觉工具箱[8]，但它被修改为同时显示彩色和热图像。修改有助于注释，因为在夜间，在颜色通道中很难看到远处的行人。还修改了工具箱，为每个边界框提供遮挡标记，而不是遮挡区域。类似于Dollár等[10]，该对象有四个标签中的一个。很明显，一个行人被标记为“人”。无法区分的个体被贴上了人的标签。骑两轮交通工具的人被称为骑自行车的人。在高度混乱的场景中，即使是人类注释者有时也不能清楚地确定一个人形物体是否是行人。这个物体被标记为人?它在计算中被忽略了。在注释之后，边界框还具有指示帧上的人员索引的时间对应。在的数据集中，一个人平均出现74.80帧(相当于3.74秒)。</p> 
<h3><a id="3__28"></a>3. 数据集介绍</h3> 
<h4><a id="31__29"></a>3.1 数据规模</h4> 
<p><img src="https://images2.imgbox.com/a3/12/EvnKQSPf_o.png" alt="在这里插入图片描述"><br> 规模。由于行人检测的关键应用是避免事故，根据车辆制动距离对标注的边界盒大小进行分类。在行人经常出现的市区，认为一般车速为30至55公里/小时。在这种驾驶条件下，预期的制动距离为11 ~ 28米(包括驾驶员反应造成的制动延迟)[7]。如果行人的高度约为1.7米，那么在对齐的图像域中，这对应于45 ~ 115像素的高度。将这些大小的注释分类为介质。如图5(a)所示，也确定了远近，即小于或大于中等。图5(b)显示了以像素为单位的行人高度与其对应的距离(以米为单位)的关系。</p> 
<h4><a id="32__33"></a>3.2 行人遮挡</h4> 
<p>如果一个行人突然被场景中的其他行人或物体遮挡，用三个遮挡标签中的一个来标注。没有被遮挡的行人被标记为没有遮挡;那些在一定程度上闭塞了一半以上的被标记为部分闭塞;轮廓大部分被遮挡的被标记为重遮挡。在所有标注中，75%以上的行人被标注为未遮挡(78.6%)，其余为部分遮挡(12.6%)和重度遮挡(8.8%)。</p> 
<h4><a id="33__35"></a>3.3 行人位置</h4> 
<p><img src="https://images2.imgbox.com/84/cc/azsk0kl3_o.png" alt="在这里插入图片描述"><br> 图6 (a)是用混合高斯模型的分布表示的标注行人的中心。的硬件被设置为覆盖一般驱动程序的视图。这个设置限制了行人在特定区域的外观。因此，行人分布在图像中心的一个窄带内。行人多出现在图像的右侧，因为汽车是在右向交通条件下行驶。还在图6 (b)中以对数标准化的比例显示了每帧的行人数量。</p> 
<h4><a id="34__38"></a>3.4 行人外观变化</h4> 
<p><img src="https://images2.imgbox.com/4b/7f/JjR07tpO_o.png" alt="在这里插入图片描述"></p> 
<p>图7显示了白天和晚上行人的几个例子。由于强烈的阳光，白天的彩色图像显示出独特的人体形状。另一方面，由于黑暗的环境，夜间彩色图像中的形状无法区分。然而，热图像在夜间显示出明显的形状，因为当空气温度较低时，温差更大，所以可以清楚地捕捉到固定温度的行人在夜间。在白天，强烈的太阳辐射造成背景杂波。基于这些原因，可以期望通过全天使用彩色和热图像的优点来获得更好的性能。</p> 
<h3><a id="4__42"></a>4. 行人检测基线</h3> 
<p>为了有效地处理颜色和热通道，基线算法建立在聚合通道特征(ACF)行人检测器[9]的基础上。这是一种自然的选择，因为算法可以容纳显示不同模式的多个通道。例如，它使用单色图像的彩色和渐变通道。这样，热通道可以看作是该算法中另一个增强的通道。在这里，受益于的捕获硬件，因为颜色和热通道之间的对齐问题被删除。此外，ACF行人检测器被广泛用作并行最先进的行人检测器的基算法。有了这个想法，首先回顾了为彩色图像设计的标准ACF，并介绍了的扩展来额外处理热通道。</p> 
<h4><a id="41__ACF_45"></a>4.1 标准 ACF</h4> 
<p>对于彩色图像输入，标准ACF[9]有10个增强通道(LUV+M+O): LUV表示颜色空间的3个通道，M表示1个梯度幅值通道，O表示6个梯度直方图通道，是定向梯度直方图(HOG)[4]的简化版本。在ACF[9]中，他们利用了引导过程，从大量的底片中挖掘硬底片，并多次重新训练AdaBoost分类器[1]。最后，他们应用了一种称为软级联的有效抑制方法来提高检测时间。通过这种方法，构建了一个功能强大的行人检测框架。</p> 
<h4><a id="42__ACF_47"></a>4.2 多光谱 ACF</h4> 
<p>利用ACF行人检测器作为的基线，并将其扩展为热强度通道编码。对于扩展，建议三个基线:(1)ACF+T (2) ACF+T+TM+TO (3) ACF+T+THOG。ACF是前面提到的为颜色通道定义的特性。T、T+TM+TO和T+THOG表示热通道增加的额外通道特性。</p> 
<ul><li>T 该通道特性直接利用热强度。为了提高检测性能，使用直方图均衡化增强了图像的对比度。</li><li>T + TM +TO。这个扩展包括三个渠道:T, TM和TO。T为上述热通道，TM为热图像的归一化梯度幅值，TO为热图像的定向梯度直方图。TM和TO采用与标准ACF相同的方法获得。</li><li>T + THOG。该扩展使用热图像的T和HOG特征(表示为THOG)。与计算6个直方图方向相比，THOG计算更多的梯度方向，并且在局部直方图上有额外的归一化步骤。</li></ul> 
<p><img src="https://images2.imgbox.com/4c/b1/Mhynbfta_o.png" alt="在这里插入图片描述"><br> 这三个扩展利用了热通道的强度和梯度信息。利用热图像的梯度作为一个重要的线索。在不同的条件下对这些扩展进行了自我评估:不同的尺度、遮挡标记和捕获时间(白天或夜晚)。图10的结果表明，三种扩展的性能都优于ACF，其中ACF+T+THOG的性能最好。这是因为ACF+T+THOG有最详尽的人形表示。基于这一观察结果，选择了ACF+T+THOG作为理想的信道特性组合，并对其进行了分析。<br> <img src="https://images2.imgbox.com/12/51/xbsmaHIY_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8dc8e7877d092a5ba4e1180dd3560ab2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">CSS flex 盒子在 Chrome 和 Safari 中的行为差异</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/31b55304d92a69a2a8b09bbd20ea68c2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">net::ERR_ABORTED 404 (Not Found)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>