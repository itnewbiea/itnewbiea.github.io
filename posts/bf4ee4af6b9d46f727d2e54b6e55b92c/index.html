<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>C&#43;&#43; 离群点检测 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="C&#43;&#43; 离群点检测" />
<meta property="og:description" content="ai.hpp
#ifndef ENGINE_AI_N_H #define ENGINE_AI_N_H #pragma once #endif #include &lt;vector&gt; #include &lt;cmath&gt; #include &lt;string&gt; #include &lt;list&gt; #include &lt;unordered_map&gt; #include &lt;tuple&gt; #include &lt;algorithm&gt; #include &lt;memory&gt; #include &lt;fstream&gt; #include &lt;sstream&gt; #include &lt;chrono&gt; using namespace std; typedef std::vector&lt;float&gt; Vector; template &lt;typename T&gt; struct Cvt; template &lt;&gt; struct Cvt&lt;std::string&gt; { static const std::string&amp; to_utf8(const std::string&amp; s) { return s; } static const std::string&amp; from_utf8(const std::string&amp; s) { return s; } }; namespace v { struct LightVector: public std::pair&lt;float *, float *&gt; { using Parent = std::pair&lt;float *, float *&gt;; template &lt;typename." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/bf4ee4af6b9d46f727d2e54b6e55b92c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-06T10:31:12+08:00" />
<meta property="article:modified_time" content="2023-09-06T10:31:12+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">C&#43;&#43; 离群点检测</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>ai.hpp</p> 
<pre><code class="prism language-C++">#ifndef ENGINE_AI_N_H
#define ENGINE_AI_N_H
#pragma once
#endif

#include &lt;vector&gt;
#include &lt;cmath&gt;
#include &lt;string&gt;
#include &lt;list&gt;
#include &lt;unordered_map&gt;
#include &lt;tuple&gt;
#include &lt;algorithm&gt;
#include &lt;memory&gt;
#include &lt;fstream&gt;
#include &lt;sstream&gt;
#include &lt;chrono&gt;

using namespace std;

typedef std::vector&lt;float&gt; Vector;

template &lt;typename T&gt; struct Cvt;

template &lt;&gt; struct Cvt&lt;std::string&gt; {
    static const std::string&amp; to_utf8(const std::string&amp; s) { return s; }
    static const std::string&amp; from_utf8(const std::string&amp; s) { return s; }
};

namespace v {
	struct LightVector: public std::pair&lt;float *, float *&gt;
	{
	  using Parent = std::pair&lt;float *, float *&gt;;
	  template &lt;typename... Arg&gt; LightVector(Arg&amp;&amp; ... arg): Parent(std::forward&lt;Arg&gt;(arg) ...) {}

	  float *data() const { return first; }
	  size_t size() const { return std::distance(first, second); }
	  bool empty() const  { return first == second; }

	  float&amp; operator[](size_t i) { return *(first + i); }
	  float operator[](size_t i) const { return *(first + i); }
	};

	template &lt;class Vector1, class Vector2&gt; inline float dot(const Vector1&amp;x, const Vector2&amp; y) { 
		int m = x.size(); const float *xd = x.data(), *yd = y.data();
		float sum = 0.0;
		while (--m &gt;= 0) sum += (*xd++) * (*yd++);
		return sum;
	}

	// saxpy: x = x + g * y; x = a * x + g * y
	inline void saxpy(Vector&amp; x, float g, const Vector&amp; y) {
		int m = x.size(); float *xd = x.data(); const float *yd = y.data();
		while (--m &gt;= 0) (*xd++) += g * (*yd++);
	}
	
	inline void unit(Vector&amp; x) {
		float len = std::sqrt(dot(x, x));
		if (len == 0) return;

		int m = x.size(); float *xd = x.data();
		while (--m &gt;= 0) (*xd++) /= len;
	}
}

namespace ai
{
    template &lt;class String = std::string&gt;
    struct Word2Vec
    {
        struct Word
        {
            int32_t index_;
            String text_;
            uint32_t count_;
            Word *left_, *right_;
        
            std::vector&lt;uint8_t&gt; codes_;
            std::vector&lt;uint32_t&gt; points_;
        
            Word(int32_t index, String text, uint32_t count, Word *left = 0, Word *right = 0) : index_(index), text_(text), count_(count), left_(left), right_(right) {}
            Word(const Word&amp;) = delete;
            const Word&amp; operator = (const Word&amp;) = delete;
        };
        typedef std::shared_ptr&lt;Word&gt; WordP;
        
        struct Sentence
        {
            std::vector&lt;Word *&gt; words_;	
            std::vector&lt;String&gt; tokens_;
        };
        typedef std::shared_ptr&lt;Sentence&gt; SentenceP;

        std::vector&lt;Vector&gt; syn0_, syn1_;
        std::vector&lt;Vector&gt; syn0norm_;

        std::unordered_map&lt;String, WordP&gt; vocab_;
        std::vector&lt;Word *&gt; words_;

        int layer1_size_;
        int window_;

        //subsampling
        float sample_;

        int min_count_;

        float alpha_, min_alpha_;

        bool phrase_;
        float phrase_threshold_;

        Word2Vec(int size = 100, int window = 5, float sample = 0.001, int min_count = 5, int negative = 0, float alpha = 0.025, float min_alpha = 0.0001) 
            :layer1_size_(size), window_(window), sample_(sample), min_count_(min_count), alpha_(alpha), min_alpha_(min_alpha), phrase_(false), phrase_threshold_(50)
        {}

        bool has(const String&amp; w) const { return vocab_.find(w) != vocab_.end(); }

        int build_vocab(std::vector&lt;SentenceP&gt;&amp; sentences) {
            size_t count = 0;
            std::unordered_map&lt;String, int&gt; vocab;

            for (auto&amp; sentence: sentences) {
                ++count;

                String last_token;
                for (auto&amp; token: sentence-&gt;tokens_) {
                    vocab[token] += 1;
                    // add bigram phrases
                    if (phrase_) {
                        if(!last_token.empty()) vocab[last_token + Cvt&lt;String&gt;::from_utf8("_") + token] += 1;
                        last_token = token;
                    }
                }
            }

            if (phrase_) {
                count = 0;
                int total_words = std::accumulate(vocab.begin(), vocab.end(), 0, [](int x, const std::pair&lt;String, int&gt;&amp; v) { return x + v.second; });

                std::unordered_map&lt;String, int&gt; phrase_vocab;

                for (auto&amp; sentence: sentences) {
                    ++count;
                    
                    std::vector&lt;String&gt; phrase_tokens;
                    String last_token;
                    uint32_t pa = 0, pb = 0, pab = 0;
                    for (auto&amp; token: sentence-&gt;tokens_) {
                        pb = vocab[token];
                        if (!last_token.empty()) {
                            String phrase = last_token + Cvt&lt;String&gt;::from_utf8("_") + token;	
                            pab = vocab[phrase];
                            float score = 0;
                            if (pa &gt;= min_count_ &amp;&amp; pb &gt;= min_count_ &amp;&amp; pab &gt;= min_count_)
                                score = (pab - min_count_ ) / (float(pa) * pb) * total_words;
                            if (score &gt; phrase_threshold_) {
                                phrase_tokens.emplace_back(phrase);
                                token.clear();
                                phrase_vocab[phrase] += 1;
                            }
                            else {
                                phrase_tokens.emplace_back(last_token);
                                phrase_vocab[last_token] += 1;
                            }
                        }
                        last_token = token;
                        pa = pb;
                    }

                    if (!last_token.empty()) {
                        phrase_tokens.emplace_back(last_token);
                        phrase_vocab[last_token] += 1;
                    }
                    sentence-&gt;tokens_.swap(phrase_tokens);
                }
                
                vocab.swap(phrase_vocab);
            }

            int n_words = vocab.size();
            if (n_words &lt;= 1) return -1;

            words_.reserve(n_words);
            auto comp = [](Word *w1, Word *w2) { return w1-&gt;count_ &gt; w2-&gt;count_; };

            for (auto&amp; p: vocab) {
                uint32_t count = p.second;
                if (count &lt;= min_count_) continue;

                auto r = vocab_.emplace(p.first, WordP(new Word{0, p.first, count}));

                auto it = std::find(words_.begin(), words_.end(), r.first-&gt;second.get());
                if (it != words_.end()) {
                    continue;
                } else {
                    words_.emplace_back((r.first-&gt;second.get()));
                }
            }
            std::sort(words_.begin(), words_.end(), comp);

            int index = 0;
            for (auto&amp; w: words_) w-&gt;index_ = index++;

            n_words = words_.size();
            
            std::vector&lt;Word *&gt; heap = words_;
            std::make_heap(heap.begin(), heap.end(), comp);

            std::vector&lt;WordP&gt; tmp;
            for (int i=0; i&lt;n_words-1; ++i) {
                std::pop_heap(heap.begin(), heap.end(), comp);
                auto min1 = heap.back(); heap.pop_back();
                std::pop_heap(heap.begin(), heap.end(), comp);
                auto min2 = heap.back(); heap.pop_back();
                tmp.emplace_back(WordP(new Word{i + n_words, Cvt&lt;String&gt;::from_utf8(""), min1-&gt;count_ + min2-&gt;count_, min1, min2}));

                heap.emplace_back(tmp.back().get());
                std::push_heap(heap.begin(), heap.end(), comp);
            }

            int max_depth = 0;
            std::list&lt;std::tuple&lt;Word *, std::vector&lt;uint32_t&gt;, std::vector&lt;uint8_t&gt;&gt;&gt; stack;
            stack.emplace_back(std::make_tuple(heap[0], std::vector&lt;uint32_t&gt;(), std::vector&lt;uint8_t&gt;()));
            count = 0;
            while (!stack.empty()) {
                auto t = stack.back();
                stack.pop_back();

                Word *word = std::get&lt;0&gt;(t);
                if (word-&gt;index_ &lt; n_words) {
                    word-&gt;points_ = std::get&lt;1&gt;(t);
                    word-&gt;codes_ = std::get&lt;2&gt;(t);
                    max_depth = std::max((int)word-&gt;codes_.size(), max_depth);
                }
                else {
                    auto points = std::get&lt;1&gt;(t);
                    points.emplace_back(word-&gt;index_ - n_words);
                    auto codes1 = std::get&lt;2&gt;(t);
                    auto codes2 = codes1;
                    codes1.emplace_back(0); codes2.emplace_back(1);
                    stack.emplace_back(std::make_tuple(word-&gt;left_, points, codes1));
                    stack.emplace_back(std::make_tuple(word-&gt;right_, points, codes2));
                }
            }

            syn0_.resize(n_words);
            syn1_.resize(n_words);

            std::default_random_engine eng(::time(NULL));
            std::uniform_real_distribution&lt;float&gt; rng(0.0, 1.0);
            for (auto&amp; s: syn0_) { 
                s.resize(layer1_size_);
                for (auto&amp; x: s) x = (rng(eng) - 0.5) / layer1_size_;
            }
            for (auto&amp; s: syn1_) s.resize(layer1_size_);

            return 0;
        }

        int train(std::vector&lt;SentenceP&gt;&amp; sentences) {
            int total_words = std::accumulate(vocab_.begin(), vocab_.end(), 0, 
                [](int x, const std::pair&lt;String, WordP&gt;&amp; p) { return (int)(x + p.second-&gt;count_); });
            int current_words = 0;
            float alpha0 = alpha_, min_alpha = min_alpha_;

            std::default_random_engine eng(::time(NULL));
            std::uniform_real_distribution&lt;float&gt; rng(0.0, 1.0);

            size_t n_sentences = sentences.size();

            size_t last_words = 0;
            auto cstart = std::chrono::high_resolution_clock::now();

            #pragma omp parallel for
            for (size_t i=0; i &lt; n_sentences; ++i) {
                auto sentence = sentences[i].get();
                if (sentence-&gt;tokens_.empty()) 
                    continue;
                size_t len = sentence-&gt;tokens_.size();
                for (size_t i=0; i&lt;len; ++i) {
                    auto it = vocab_.find(sentence-&gt;tokens_[i]);
                    if (it == vocab_.end()) continue; 
                    Word *word = it-&gt;second.get();
                    // subsampling
                    if (sample_ &gt; 0) {
                        float rnd = (sqrt(word-&gt;count_ / (sample_ * total_words)) + 1) * (sample_ * total_words) / word-&gt;count_;
                        if (rnd &lt; rng(eng)) continue;
                    }
                    sentence-&gt;words_.emplace_back(it-&gt;second.get());
                }

                float alpha = std::max(min_alpha, float(alpha0 * (1.0 - 1.0 * current_words / total_words)));
                Vector work(layer1_size_);
                size_t words = train_sentence(*sentence, alpha, work);

                #pragma omp atomic
                current_words += words;

                if (current_words - last_words &gt; 1024 * 100 || i == n_sentences - 1) {
                    auto cend = std::chrono::high_resolution_clock::now();
                    auto duration = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(cend - cstart).count();
                    // printf("training alpha: %.4f progress: %.2f%% words per sec: %.3fK\n", alpha, current_words * 100.0/total_words, (current_words - last_words) * 1000.0 / duration);
                    last_words = current_words;
                    cstart = cend;
                }
            }

            syn0norm_ = syn0_;
            for (auto&amp; v: syn0norm_) v::unit(v);

            return 0;
        }

        int save(const std::string&amp; file) const {
            std::ofstream out(file, std::ofstream::out);
            out &lt;&lt; syn0_.size() &lt;&lt; " " &lt;&lt; syn0_[0].size() &lt;&lt; std::endl;
            
            std::vector&lt;Word *&gt; words = words_;
            std::sort(words.begin(), words.end(), [](Word *w1, Word *w2) { return w1-&gt;count_ &gt; w2-&gt;count_; });

            for (auto w: words) {
                out &lt;&lt; Cvt&lt;String&gt;::to_utf8(w-&gt;text_);
                for (auto i: syn0_[w-&gt;index_]) out &lt;&lt; " " &lt;&lt; i;
                out &lt;&lt; std::endl;
            }

            return 0;
        }

        int load(const std::string&amp; file) {
            std::ifstream in(file);
            std::string line;
            if (! std::getline(in, line)) return -1;

            int n_words = 0, layer1_size = 0;
            std::istringstream iss(line);
            iss &gt;&gt; n_words &gt;&gt; layer1_size;

            syn0_.clear(); vocab_.clear(); words_.clear();
            syn0_.resize(n_words);
            for (int i=0; i&lt;n_words; ++i) {
                if (! std::getline(in, line)) return -1;

                std::istringstream iss(line);
                std::string text;
                iss &gt;&gt; text;

                auto p = vocab_.emplace(Cvt&lt;String&gt;::from_utf8(text), WordP(new Word{i, Cvt&lt;String&gt;::from_utf8(text), 0}));
                words_.emplace_back(p.first-&gt;second.get());
                syn0_[i].resize(layer1_size);
                for(int j=0; j&lt;layer1_size; ++j) {
                    iss &gt;&gt; syn0_[i][j];
                }
            }
            
            layer1_size_ = layer1_size;

            syn0norm_ = syn0_;
            for (auto&amp; v: syn0norm_) v::unit(v);
            
            return 0;	
        }
        
        std::vector&lt;std::pair&lt;String,float&gt;&gt; most_similar(std::vector&lt;String&gt; positive, std::vector&lt;String&gt; negative, int topn) {
            if ((positive.empty() &amp;&amp; negative.empty()) || syn0norm_.empty()) return std::vector&lt;std::pair&lt;String,float&gt;&gt;{};

            Vector mean(layer1_size_);
            std::vector&lt;int&gt; all_words;
            auto add_word = [&amp;mean, &amp;all_words, this](const String&amp; w, float weight) {
                auto it = vocab_.find(w);		
                if (it == vocab_.end()) return;

                Word&amp; word = *it-&gt;second;
                v::saxpy(mean, weight, syn0norm_[word.index_]);

                all_words.push_back(word.index_);
            };

            for (auto&amp; w: positive) add_word(w, 1.0);
            for (auto&amp; w: negative) add_word(w, -1.0);

            v::unit(mean);

            Vector dists;
            std::vector&lt;int&gt; indexes;
            int i=0;

            dists.reserve(syn0norm_.size());
            indexes.reserve(syn0norm_.size());
            for (auto &amp;x: syn0norm_) {
                dists.push_back(v::dot(x, mean));		
                indexes.push_back(i++);
            }

            auto comp = [&amp;dists](int i, int j) { return dists[i] &gt; dists[j]; };
    
            int k = std::min(int(topn+all_words.size()), int(indexes.size())-1);
            auto first = indexes.begin(), last = indexes.begin() + k, end = indexes.end();
            std::make_heap(first, last + 1, comp);
            std::pop_heap(first, last + 1, comp);
            for (auto it = last + 1; it != end; ++it) {
                if (! comp(*it, *first)) continue;
                    *last = *it;
                    std::pop_heap(first, last + 1, comp);
            }
            
            std::sort_heap(first, last, comp);

            std::vector&lt;std::pair&lt;String,float&gt;&gt; results;
            for(int i=0, j=0; i&lt;k; ++i) {
                if (std::find(all_words.begin(), all_words.end(), indexes[i]) != all_words.end())
                    continue;
                results.push_back(std::make_pair(words_[indexes[i]]-&gt;text_, dists[indexes[i]]));
                if (++j &gt;= topn) break;
            }

            return results;
        }

        const Vector&amp; word_vector(const String&amp; w) const {
            static Vector nil;
            auto it = vocab_.find(w);
            if (it == vocab_.end()) return nil;
            
            return syn0_[it-&gt;second-&gt;index_];
        }

        size_t word_vector_size() const { return layer1_size_; }

        const Vector calculate_words_average(const Vector&amp; word_vec1, const Vector&amp; word_vec2) {
            int size = word_vec1.size();

            if (size != word_vec2.size()) {
                if (word_vec1.empty()) return word_vec2;
                return word_vec1;
            }

            Vector result(size);
            for (size_t i = 0; i &lt; size; ++i) result[i] = (word_vec1[i] + word_vec2[i]) / 2.0;

            return result;
        }

    private:
        int train_sentence(Sentence&amp; sentence, float alpha, Vector&amp; work) {
            const int max_size = 1000;
            const float max_exp = 6.0;
            const static std::vector&lt;float&gt; table = [&amp;](){
                    std::vector&lt;float&gt; x(max_size);
                    for (size_t i=0; i&lt;max_size; ++i) { float f = exp( (i / float(max_size) * 2 -1) * max_exp); x[i] = f / (f + 1); }
                    return x;
                }();

            int count = 0;
            int len = sentence.words_.size();
            int reduced_window = rand() % window_;
            for (int i=0; i&lt;len; ++i) {
                const Word&amp; current = *sentence.words_[i];
                size_t codelen = current.codes_.size();

                int j = std::max(0, i - window_ + reduced_window);
                int k = std::min(len, i + window_ + 1 - reduced_window);
                for (; j &lt; k; ++j) {
                    const Word *word = sentence.words_[j];
                    if (j == i || word-&gt;codes_.empty()) 
                        continue;
                    int word_index = word-&gt;index_;
                    auto&amp; l1 = syn0_[word_index];

                    std::fill(work.begin(), work.end(), 0);
                    for (size_t b=0; b&lt;codelen; ++b) {
                        int idx = current.points_[b];
                        auto&amp; l2 = syn1_[idx];
                    
                        float f = v::dot(l1, l2);
                        if (f &lt;= -max_exp || f &gt;= max_exp) 
                            continue;
            
                        int fi = int((f + max_exp) * (max_size / max_exp / 2.0));
                        
                        f = table[fi];
                        float g = (1 - current.codes_[b] - f) * alpha;

                        v::saxpy(work, g, l2);
                        v::saxpy(l2, g, l1);
                    }
                    v::saxpy(l1, 1.0, work);
                }
                ++count;
            }

            return count;
        }

        float similarity(const String&amp; w1, const String&amp; w2) const {
            auto it1 = vocab_.find(w1), it2 = vocab_.find(w2);
            if (it1 != vocab_.end() &amp;&amp; it2 != vocab_.end())
                return v::dot(syn0_[it1-&gt;second-&gt;index_], syn0_[it2-&gt;second-&gt;index_]);

            return 0;
        }
    };

    template &lt;class Double = std::double_t&gt;
    struct DBSCAN
    {
        struct Model {
            Vector features;   // 特征向量
            int label;         // 类别标签
        };

        Double epsilon;
        size_t minPts;

        DBSCAN(Double epsilon = 0.6, size_t minPts = 1, size_t knn_k = 4) :epsilon(epsilon), minPts(minPts) {}

        std::vector&lt;int&gt; dbscan(const std::vector&lt;Vector&gt;&amp; sentences) {
            int n = sentences.size();
            std::vector&lt;int&gt; labels(n, -1);
            int cluster = 0;

            for (int i = 0; i &lt; n; ++i) {
                if (labels[i] != -1) continue;

                std::vector&lt;int&gt; neighbors;
                for (int j = i + 1; j &lt; n; ++j) {
                    Double distance = calculate_distance(sentences[i], sentences[j]);
                    if (distance &lt;= epsilon) neighbors.emplace_back(j);
                }
                int size = neighbors.size();
                if (size &lt; minPts) {
                    labels[i] = 0;
                } else {
                    ++cluster;
                    labels[i] = cluster;

                    for (int j = 0; j &lt; size; ++j) {
                        int neighborIndex = neighbors[j];
                        if (labels[neighborIndex] == 0) {
                            labels[neighborIndex] = cluster;
                        }

                        if (labels[neighborIndex] != -1) continue;

                        labels[neighborIndex] = cluster;

                        std::vector&lt;int&gt; newNeighbors;
                        for (int k = neighborIndex + 1; k &lt; n; ++k) {
                            double distance = calculate_distance(sentences[neighborIndex], sentences[k]);
                            if (distance &lt;= epsilon) newNeighbors.emplace_back(k);
                        }

                        if (newNeighbors.size() &gt;= minPts) neighbors.insert(neighbors.end(), newNeighbors.begin(), newNeighbors.end());
                    }
                }
            }

            return labels;
        }

        int predict(const std::vector&lt;Model&gt;&amp; model, const Vector&amp; sentence) {
            int n = model.size();

            for (int i = 0; i &lt; n; ++i) {
                double distance = calculate_distance(model[i].features, sentence);
                if (distance &lt;= epsilon-2) {
                    if (model[i].label != 0) {
                        return model[i].label;
                    }
                }
            }

            return 0;
        }

        std::vector&lt;Model&gt; create_model(const std::vector&lt;Vector&gt;&amp; baseline, const std::vector&lt;int&gt;&amp; labels) {
            std::vector&lt;Model&gt; model;
            size_t numSamples = std::min(baseline.size(), labels.size());

            for (size_t i = 0; i &lt; numSamples; ++i) {
                Model m;
                m.features = baseline[i];
                m.label = labels[i];
                model.emplace_back(m);
            }

            return model;
        }

        ~DBSCAN() {}

    private:
        Double calculate_distance(const Vector&amp; v1, const Vector&amp; v2) {
            Double distance = 0.0;

            int size = v1.size();
            for (int i = 0; i &lt; size; ++i) {
                Double diff = v1[i] - v2[i];
                distance += std::abs(diff);  
            }

            return distance;
        }
    };
} // namespace ai
</code></pre> 
<p>main.cpp</p> 
<pre><code class="prism language-C++">// OpenMP is required..
// g++-4.8 -ow2v -fopenmp -std=c++0x -Ofast -march=native -funroll-loops  main.cpp  -lpthread

#include "ai.hpp"
#include &lt;fstream&gt;
#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;list&gt;
#include &lt;set&gt;

#define MODEL_SIZE 1000

std::vector&lt;ai::Word2Vec&lt;std::string&gt;::SentenceP&gt; get_sentences (const std::string&amp; filename) {
	using Sentence = ai::Word2Vec&lt;std::string&gt;::Sentence;
	using SentenceP = ai::Word2Vec&lt;std::string&gt;::SentenceP;
	
	SentenceP sentence(new Sentence);

	std::ifstream ifs;
	ifs.open(filename, std::ios::in);
	std::string line;
	std::list&lt;SentenceP&gt; sentence_list;

	while (std::getline(ifs, line)) {
		std::string token;
		std::string before_token;
		std::istringstream iss(line);

		while (iss &gt;&gt; token) {
			sentence-&gt;tokens_.push_back(std::move(token));
		}

		sentence_list.push_back(std::move(sentence));
		sentence.reset(new Sentence);
	}

	if (!sentence-&gt;tokens_.empty()) sentence_list.push_back(std::move(sentence));

	std::vector&lt;SentenceP&gt; sentences(sentence_list.begin(), sentence_list.end());

	return sentences;
}

int train_w2v(ai::Word2Vec&lt;std::string&gt; &amp;w2v, std::vector&lt;ai::Word2Vec&lt;std::string&gt;::SentenceP&gt;&amp; sentences) {
	if (w2v.build_vocab(sentences) != 0) return -1;
	if (w2v.train(sentences) != 0) return -1;
	if (w2v.save("word2vec") != 0) return -1;

	return 0;
}

std::vector&lt;Vector&gt; get_sentences_vector(ai::Word2Vec&lt;std::string&gt; &amp;w2v, std::vector&lt;ai::Word2Vec&lt;std::string&gt;::SentenceP&gt;&amp; sentences) {
	std::vector&lt;Vector&gt; sentences_vector;
	for (auto sentence = sentences.begin(); sentence != sentences.end(); ++sentence) {
		Vector sentence_vector;
		sentence_vector.reserve((*sentence)-&gt;tokens_.size());
		for (auto token = (*sentence)-&gt;tokens_.begin(); token != (*sentence)-&gt;tokens_.end(); ++token) 
			if (w2v.has(*token)) sentence_vector = w2v.calculate_words_average(sentence_vector, w2v.word_vector(*token));
		
		if (!sentence_vector.empty()) sentences_vector.push_back(std::move(sentence_vector));
	}

	return sentences_vector;
}

int main(int argc, const char *argv[])
{
	std::shared_ptr&lt;ai::Word2Vec&lt;std::string&gt;&gt; w2v = std::make_shared&lt;ai::Word2Vec&lt;std::string&gt;&gt;(32);
	w2v-&gt;sample_ = 0;
	w2v-&gt;min_count_= 1;
	// w2v-&gt;window_ = 10;

	std::vector&lt;ai::Word2Vec&lt;std::string&gt;::SentenceP&gt; sentences = get_sentences("sentences.txt");
	if (train_w2v((*w2v), sentences) != 0) return -1;

	std::vector&lt;Vector&gt; sentences2vector = get_sentences_vector((*w2v), sentences);
	std::cout &lt;&lt; "sentence vector size:" &lt;&lt; sentences2vector.size() &lt;&lt; std::endl;

    ai::DBSCAN&lt;std::double_t&gt; dbscan;
	dbscan.epsilon = 5.03;
	dbscan.minPts = 3;

	std::vector&lt;Vector&gt; second_data;
	using second_Sentence = ai::Word2Vec&lt;std::string&gt;::Sentence;
	using second_SentenceP = ai::Word2Vec&lt;std::string&gt;::SentenceP;
	
	second_SentenceP sentence(new second_Sentence);
	std::vector&lt;second_SentenceP&gt; second_sentences_;

	int num = 0;
	size_t size1 = sentences2vector.size();
	for (int i = 0;i &lt; 50; i+=2) {
		std::vector&lt;Vector&gt; baseline(sentences2vector.begin() + i*MODEL_SIZE, sentences2vector.begin() + (i+1)*MODEL_SIZE);
		std::vector&lt;int&gt; labels = dbscan.dbscan(baseline);

		std::set&lt;int&gt; labels_set(labels.begin(), labels.end());
		std::vector&lt;Vector&gt; average_baseline;

		std::unordered_map&lt;int, Vector&gt; baseline_map;

		for (size_t i = 0; i &lt; labels.size(); i++) {
			baseline_map[labels[i]] = w2v-&gt;calculate_words_average(baseline_map[labels[i]], baseline[i]);
		}

		std::vector&lt;int&gt; new_labels;
		std::vector&lt;Vector&gt; new_baseline;

		for (const auto&amp; pair : baseline_map) {
			new_labels.push_back(pair.first);
			new_baseline.push_back(pair.second);
		}

		std::vector&lt;ai::DBSCAN&lt;std::double_t&gt;::Model&gt; model = dbscan.create_model(baseline, labels);
		// std::vector&lt;ai::DBSCAN&lt;std::double_t&gt;::Model&gt; model = dbscan.create_model(new_baseline, new_labels);
		Vector before_log;

		for (int j = 0; j &lt; MODEL_SIZE; j++) {
			if (j+(i+1)*MODEL_SIZE == size1) goto over;
 			Vector log = sentences2vector.at(j+(i+1)*MODEL_SIZE);

			if (!dbscan.predict(model, log)) {
				second_data.push_back(log);
				second_sentences_.push_back(sentences[j+(i+1)*MODEL_SIZE]);
				num++;
				std::cout &lt;&lt; "第一次检测的离群点: ";
				const ai::Word2Vec&lt;std::string&gt;::SentenceP&amp; sentence = sentences[j+(i+1)*MODEL_SIZE];
				const ai::Word2Vec&lt;std::string&gt;::Sentence&amp; tokens = *sentence;
				for (const std::string&amp; token : tokens.tokens_) std::cout &lt;&lt; token &lt;&lt; " ";
				std::cout &lt;&lt; std::endl;
			}
		}
		std::cout &lt;&lt; std::endl;
	}

over:
	std::cout &lt;&lt; "num:" &lt;&lt; num &lt;&lt; std::endl;

	std::vector&lt;ai::Word2Vec&lt;std::string&gt;::SentenceP&gt; second_sentences(second_sentences_.begin(), second_sentences_.end());
	num = 0;
	std::vector&lt;int&gt; labels = dbscan.dbscan(second_data);
	for(int i = 0; i &lt; labels.size(); i++) {
		if (labels[i] == 0) {
			num++;
			std::cout &lt;&lt; "第二次检测的离群点: ";
			const ai::Word2Vec&lt;std::string&gt;::SentenceP&amp; sentence = second_sentences[i];
			const ai::Word2Vec&lt;std::string&gt;::Sentence&amp; tokens = *sentence;
			for (const std::string&amp; token : tokens.tokens_) std::cout &lt;&lt; token &lt;&lt; " ";
			std::cout &lt;&lt; std::endl;
		}
	}
	std::cout &lt;&lt; "num:" &lt;&lt; num &lt;&lt; std::endl;
}
</code></pre> 
<p>sentences.txt</p> 
<pre><code class="prism language-txt">abc def ghi sdff ghrio oongs
sdgg sdgf jong wongg lllg
jjogg weg egege geron osdg lsdg
...
</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6fb033347f75b82d2ed0f9d3b2b2e855/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Nginx如何安装SSL证书，在编辑nginx.conf，替换一下代码</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bfd98e5edda42b6a952e8c0eebcb130b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SpringBoot自定义注解&#43;AOP&#43;自定义异常</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>