<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>吃瓜教程 —— 第三章 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="吃瓜教程 —— 第三章" />
<meta property="og:description" content="三. 线性模型 1. 基本形式 给定由d个属性描述的示例 x = (x_1;x_2;…;x_d)，其中x_i在第i个属性上的取值，线性模型表示为
一般情况下用向量的形式，则表示成
只要能够确定出 w 和 b 的值就可以确定这个线性模型了
2. 线性回归 线性回归是什么？
线性回归是通过学习一个线性模型，来预测出其对应的连续值，通过对预测值和真实值之间，尽可能缩小其欧氏距离，即使得 f (x_i ) ≈ y_i
2.1 最小二乘法 使用均方误差最小化来进行模型求解的，形如
2.2 极大似然估计 假设线性回归模型如下所示，
其中 ϵ 符合
然后将 ϵ 用 y-(wx&#43;b) 进行代替后，得到的式子为
代入极大似然估计后，得到如下所示，
由于极大似然函数不好求，因此对上述的式子进行取对数，最终得出
其中使用了 ln(ab)=lna&#43;lnb 的性质
2.3 求解 w 和 b 的值 加上 argmin 后就变成
其中 argmin 表示当这个式子取最小的时候，w 和 b的取值是多少
由于上述的式子中存在着两个参数一个是 w ，一个是 b，因此对上述的式子，根据数分的知识，要求出其值，则分别对两个参数求偏导，令导数为0，即可求出连个参数的值
最终得出
w 的求解公式为
b 的求解公式是
2.4 Hessian矩阵 用于判断这个函数是否为一个凸函数的办法，Hessian矩阵形如下所示，
Hessian矩阵是针对于一个函数对其求二阶偏导，得出的一个矩阵，当这个矩阵为半正定的时候便可以说明这个函数为凸函数" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/f858871554b77330354c5474ccb574cc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-23T17:47:44+08:00" />
<meta property="article:modified_time" content="2022-05-23T17:47:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">吃瓜教程 —— 第三章</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="__0"></a>三. 线性模型</h2> 
<h3><a id="1__1"></a>1. 基本形式</h3> 
<p>给定由d个属性描述的示例 x = (x_1;x_2;…;x_d)，其中x_i在第i个属性上的取值，线性模型表示为<br> <img src="https://images2.imgbox.com/3f/98/lffTFOfW_o.png" alt="在这里插入图片描述"><br> 一般情况下用<strong>向量</strong>的形式，则表示成<br> <img src="https://images2.imgbox.com/50/16/ybMBYtr2_o.png" alt="在这里插入图片描述"><br> 只要能够确定出 w 和 b 的值就可以确定这个线性模型了</p> 
<h3><a id="2__7"></a>2. 线性回归</h3> 
<blockquote> 
 <p>线性回归是什么？<br> 线性回归是通过<strong>学习一个线性模型</strong>，来<strong>预测出其对应的连续值</strong>，通过对预测值和真实值之间，尽可能缩小其欧氏距离，即使得 f (x_i ) ≈ y_i</p> 
</blockquote> 
<h4><a id="21__12"></a>2.1 最小二乘法</h4> 
<p>使用<strong>均方误差最小化</strong>来进行模型求解的，形如<br> <img src="https://images2.imgbox.com/a6/83/kPKinVs1_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="22__15"></a>2.2 极大似然估计</h4> 
<p>假设线性回归模型如下所示，<br> <img src="https://images2.imgbox.com/47/c7/SHriCbCG_o.png" alt="在这里插入图片描述"><br> 其中 ϵ 符合<br> <img src="https://images2.imgbox.com/1e/56/z0DzIhI8_o.png" alt="在这里插入图片描述"><br> 然后将 ϵ 用 y-(wx+b) 进行代替后，得到的式子为<br> <img src="https://images2.imgbox.com/eb/3b/TJDu0yvX_o.png" alt="在这里插入图片描述"><br> 代入极大似然估计后，得到如下所示，<br> <img src="https://images2.imgbox.com/49/e7/vg03zhdg_o.png" alt="在这里插入图片描述"><br> 由于极大似然函数不好求，因此对上述的式子进行<strong>取对数</strong>，最终得出<br> <img src="https://images2.imgbox.com/c2/b4/pHTEG1mr_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>其中使用了 ln(ab)=lna+lnb 的性质</p> 
</blockquote> 
<h4><a id="23__w__b__29"></a>2.3 求解 w 和 b 的值</h4> 
<p>加上 argmin 后就变成<br> <img src="https://images2.imgbox.com/6e/f8/HxU6cfVZ_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>其中 argmin 表示当这个式子取最小的时候，w 和 b的取值是多少</p> 
</blockquote> 
<p>由于上述的式子中存在着两个参数一个是 w ，一个是 b，因此对上述的式子，根据数分的知识，要求出其值，则分别对两个参数求偏导，令导数为0，即可求出连个参数的值<br> 最终得出<br> w 的求解公式为<br> <img src="https://images2.imgbox.com/e0/0b/D4XtfYWD_o.png" alt="在这里插入图片描述"><br> b 的求解公式是<br> <img src="https://images2.imgbox.com/3e/9c/Kc4GGAxx_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="24_Hessian_41"></a>2.4 Hessian矩阵</h4> 
<p>用于<strong>判断这个函数是否为一个凸函数的办法</strong>，Hessian矩阵形如下所示，<br> <img src="https://images2.imgbox.com/f1/8c/lRxWvmss_o.png" alt="在这里插入图片描述"><br> Hessian矩阵是针对于一个函数对其<strong>求二阶偏导</strong>，得出的一个矩阵，<strong>当这个矩阵为半正定的时候便可以说明这个函数为凸函数</strong></p> 
<h4><a id="25__46"></a>2.5 多元线性回归</h4> 
<p>从一般的线性回归模型，到映射在n维空间上的多元线性回归，可以通过矩阵的形式表示出来，即<br> <img src="https://images2.imgbox.com/3f/14/NKmY0YJe_o.png" alt="在这里插入图片描述"><br> 其中 w = (w_1,w_2,…w_n), x = (x_ 1,x _2 ,…x _n)，当然从满足矩阵运算的角度来说，对哪一个进行转置都是可以的，只不过是满足一列乘以一行的规律<br> 根据均方差误差最小化原则有<br> <img src="https://images2.imgbox.com/61/47/vz7CdPcv_o.png" alt="在这里插入图片描述"><br> 对 w 进行求导<br> <img src="https://images2.imgbox.com/a6/21/46x0g6VP_o.png" alt="在这里插入图片描述"><br> 令导数为0，就可以求出来 w 的解</p> 
<h3><a id="3__55"></a>3. 对数几率回归</h3> 
<p>对数几率回归，又叫做逻辑回归，比如说将二分类的问题的结果转化为0-1上的值的输出，而最理想的单位阶跃函数是<br> <img src="https://images2.imgbox.com/eb/88/NMpoezRC_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a9/4e/pakHEKqp_o.png" alt="在这里插入图片描述"><br> 针对于上述的图，有一个函数可以代替图，其便是 sigmoid 函数<br> <img src="https://images2.imgbox.com/77/95/HonwV8gj_o.png" alt="在这里插入图片描述"><br> 将线性模型 y=w^T_x+b 带入 sigmoid 函数中, 可以得到<br> <img src="https://images2.imgbox.com/db/f1/P4Ec8w6q_o.png" alt="在这里插入图片描述"><br> 取对数后得到的操作如下所示<br> <img src="https://images2.imgbox.com/e1/2e/mNrAO76O_o.png" alt="在这里插入图片描述"><br> 采用极大似然去求解，将模型改写如下<br> <img src="https://images2.imgbox.com/93/d3/XuSOBAUT_o.png" alt="在这里插入图片描述"><br> 得到极大似然函数，并对极大似然函数进行求对数<br> <img src="https://images2.imgbox.com/7a/37/N4kgyP5q_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="4_LDA_69"></a>4. 线性判别分析(LDA)</h3> 
<p>LDA 的思想很朴素，通过给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近，异类样例的投影点尽可能远离.<br> <img src="https://images2.imgbox.com/a9/7c/7nfN11Sf_o.png" alt="在这里插入图片描述"><br> 其中正例的投影为 w^Tu_0 ,<br> 其协方差为 w^TΣ_0w,<br> 负例的投影为 w ^Tu_1,<br> 协方差为 w^TΣ_1w<br> 使得同类样例的投影点尽可能接近，则可以让下面的等式尽可能小<br> <img src="https://images2.imgbox.com/1e/59/9IEHVIkM_o.png" alt="在这里插入图片描述"><br> 使得异类样例的投影点尽可能远离，则可以让下面的等式尽可能大<br> <img src="https://images2.imgbox.com/4d/d8/fTQiTfz0_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>二范式，就是通常意义上的模。<br> 传送门：<a href="https://blog.csdn.net/zjpp2580369/article/details/83478204">范式理解</a></p> 
</blockquote> 
<p>因此得到一个目标函数 J<br> <img src="https://images2.imgbox.com/9a/ce/Y6ar3vjc_o.png" alt="在这里插入图片描述"><br> 定义类内散度矩阵<br> <img src="https://images2.imgbox.com/ce/9e/MA5YGMgi_o.png" alt="在这里插入图片描述"><br> 以及类间散度矩阵<br> <img src="https://images2.imgbox.com/4b/98/syCUdOtc_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/94/44/PEFVCuBX_o.png" alt="在这里插入图片描述"><br> 所以目标函数 J 可以改写成<br> <img src="https://images2.imgbox.com/99/90/3gC2M49E_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <ul><li>如何确定 W ？<br> <strong>拉格朗日乘子法</strong><br> 传送门：<a href="https://zhuanlan.zhihu.com/p/154517678" rel="nofollow">优化-拉格朗日乘子法</a></li></ul> 
</blockquote> 
<h3><a id="5__98"></a>5. 多分类学习</h3> 
<ul><li>一对一(OvO)<br> 假如某个分类中有N个类别，我们将这N个类别进行两两配对（两两配对后转化为二分类问题）。那么我们可以得到个二分类器。（简单解释一下，相当于在N个类别里面抽2个）<br> 之后，在测试阶段，我们把新样本交给这个二分类器。于是我们可以得到个分类结果。把预测的最多的类别作为预测的结果。</li><li>一对多(OvR)<br> 一对其余其实更加好理解，每次将一个类别作为正类，其余类别作为负类。此时共有（N个分类器）。在测试的时候若仅有一个分类器预测为正类，则对应的类别标记为最终的分类结果。</li><li>多对多(MvM)</li></ul> 
<p>传送门：<a href="https://blog.csdn.net/qq_40710190/article/details/105546802">多分类学习</a></p> 
<h3><a id="6__108"></a>6. 类别不平衡问题</h3> 
<p>当数据集中，正例和负例的不多的时候，需要对其进行重新采样，再<strong>缩放</strong>思想<br> 解决类别不平衡的三类做法</p> 
<ol><li>直接对训练集里的反类样例进行"欠采样"，即去除一些反例使得正反例数目接近</li><li>对训练集里的正类样例进行"过采样"，即增加一些正例使得正反例数目接近，然后再学习</li><li>直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，称为"阈值移动"</li></ol>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f5a378bf210725feade3e6560d6bc68e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">docker-compose部署elasticsearch-exporter和kafka-exporter</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c1e9dfb757353c3d03aaa551fad56598/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【React项目】使用npm install出现npm ERR cb() never called 报错</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>