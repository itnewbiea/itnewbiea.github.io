<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ã€ŠåŠ¨æ‰‹æ·±åº¦å­¦ä¹ ã€‹çº¿æ€§å›å½’ç®€æ´å®ç°å®ä¾‹ - ITå­¦ä¹ è€…åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ã€ŠåŠ¨æ‰‹æ·±åº¦å­¦ä¹ ã€‹çº¿æ€§å›å½’ç®€æ´å®ç°å®ä¾‹" />
<meta property="og:description" content="ğŸˆ ä½œè€…ï¼šLinuxçŒ¿
ğŸˆ ç®€ä»‹ï¼šCSDNåšå®¢ä¸“å®¶ğŸ†ï¼Œåä¸ºäº‘äº«ä¸“å®¶ğŸ†ï¼ŒLinuxã€C/C&#43;&#43;ã€äº‘è®¡ç®—ã€ç‰©è”ç½‘ã€é¢è¯•ã€åˆ·é¢˜ã€ç®—æ³•å°½ç®¡å’¨è¯¢æˆ‘ï¼Œå…³æ³¨æˆ‘ï¼Œæœ‰é—®é¢˜ç§èŠï¼
ğŸˆ æ¬¢è¿å°ä¼™ä¼´ä»¬ç‚¹èµğŸ‘ã€æ”¶è—â­ã€ç•™è¨€ğŸ’¬
æœ¬æ–‡æ˜¯ã€ŠåŠ¨æ‰‹æ·±åº¦å­¦ä¹ ã€‹çº¿æ€§å›å½’ç®€æ´å®ç°å®ä¾‹çš„å®ç°å’Œåˆ†æï¼Œä¸»è¦å¯¹ä»£ç è¿›è¡Œè¯¦ç»†è®²è§£ï¼Œæœ‰é—®é¢˜æ¬¢è¿åœ¨è¯„è®ºåŒºè®¨è®ºäº¤æµã€‚
ä¸€ã€ä»£ç å®ç° å®ç°ä»£ç å¦‚ä¸‹æ‰€ç¤ºã€‚
import torch from torch.utils import data # d2låŒ…æ˜¯ææ²è€å¸ˆç­‰äººå¼€å‘çš„åŠ¨æ‰‹æ·±åº¦å­¦ä¹ é…å¥—çš„åŒ…, # é‡Œé¢å°è£…äº†å¾ˆå¤šæœ‰å…³ä¸æ•°æ®é›†å®šä¹‰ï¼Œæ•°æ®é¢„å¤„ç†ï¼Œä¼˜åŒ–æŸå¤±å‡½æ•°çš„åŒ… from d2l import torch as d2l # nn æ˜¯ç¥ç»ç½‘ç»œ Neural Network çš„ç¼©å†™ï¼Œæä¾›äº†ä¸€ç³»åˆ—çš„æ¨¡å—å’Œç±»ï¼Œå®ç°åˆ›å»ºã€è®­ç»ƒã€ä¿å­˜ã€æ¢å¤ç¥ç»ç½‘ç»œ from torch import nn &#39;&#39;&#39; 1. ç”Ÿæˆæ•°æ®é›†ï¼Œå…± 1000 æ¡ true_w å’Œ true_b æ˜¯ä¸´æ—¶å˜é‡ç”¨äºç”Ÿæˆæ•°æ®é›† ç”Ÿæˆ X, y ï¼šæ»¡è¶³å…³ç³» y = Xw &#43; b &#43; noise &#39;&#39;&#39; true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = d2l.synthetic_data(true_w, true_b, 1000) &#39;&#39;&#39; 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/07d4a43a84d4aeba104f42310886679e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-31T08:00:00+08:00" />
<meta property="article:modified_time" content="2023-10-31T08:00:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ITå­¦ä¹ è€…åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ITå­¦ä¹ è€…åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ã€ŠåŠ¨æ‰‹æ·±åº¦å­¦ä¹ ã€‹çº¿æ€§å›å½’ç®€æ´å®ç°å®ä¾‹</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <hr> 
<p><strong>ğŸˆ ä½œè€…ï¼š</strong><a href="https://blog.csdn.net/nyist_zxp" title="LinuxçŒ¿">LinuxçŒ¿</a></p> 
<p><strong>ğŸˆ ç®€ä»‹ï¼š</strong>CSDNåšå®¢ä¸“å®¶ğŸ†ï¼Œåä¸ºäº‘äº«ä¸“å®¶ğŸ†ï¼ŒLinuxã€C/C++ã€äº‘è®¡ç®—ã€ç‰©è”ç½‘ã€é¢è¯•ã€åˆ·é¢˜ã€ç®—æ³•å°½ç®¡å’¨è¯¢æˆ‘ï¼Œå…³æ³¨æˆ‘ï¼Œæœ‰é—®é¢˜ç§èŠï¼</p> 
<p><strong>ğŸˆ </strong>æ¬¢è¿å°ä¼™ä¼´ä»¬ç‚¹èµğŸ‘ã€æ”¶è—â­ã€ç•™è¨€ğŸ’¬</p> 
<hr> 
<p>æœ¬æ–‡æ˜¯ã€ŠåŠ¨æ‰‹æ·±åº¦å­¦ä¹ ã€‹çº¿æ€§å›å½’ç®€æ´å®ç°å®ä¾‹çš„å®ç°å’Œåˆ†æï¼Œä¸»è¦å¯¹ä»£ç è¿›è¡Œè¯¦ç»†è®²è§£ï¼Œæœ‰é—®é¢˜æ¬¢è¿åœ¨è¯„è®ºåŒºè®¨è®ºäº¤æµã€‚</p> 
<h2>ä¸€ã€ä»£ç å®ç°</h2> 
<p>å®ç°ä»£ç å¦‚ä¸‹æ‰€ç¤ºã€‚</p> 
<pre><code class="language-python">import torch
from torch.utils import data
# d2låŒ…æ˜¯ææ²è€å¸ˆç­‰äººå¼€å‘çš„åŠ¨æ‰‹æ·±åº¦å­¦ä¹ é…å¥—çš„åŒ…,
# é‡Œé¢å°è£…äº†å¾ˆå¤šæœ‰å…³ä¸æ•°æ®é›†å®šä¹‰ï¼Œæ•°æ®é¢„å¤„ç†ï¼Œä¼˜åŒ–æŸå¤±å‡½æ•°çš„åŒ…
from d2l import torch as d2l
# nn æ˜¯ç¥ç»ç½‘ç»œ Neural Network çš„ç¼©å†™ï¼Œæä¾›äº†ä¸€ç³»åˆ—çš„æ¨¡å—å’Œç±»ï¼Œå®ç°åˆ›å»ºã€è®­ç»ƒã€ä¿å­˜ã€æ¢å¤ç¥ç»ç½‘ç»œ
from torch import nn

'''
1. ç”Ÿæˆæ•°æ®é›†ï¼Œå…± 1000 æ¡
true_w å’Œ true_b æ˜¯ä¸´æ—¶å˜é‡ç”¨äºç”Ÿæˆæ•°æ®é›†
ç”Ÿæˆ X, y ï¼šæ»¡è¶³å…³ç³» y = Xw + b + noise
'''
true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = d2l.synthetic_data(true_w, true_b, 1000)

'''
2. æ„é€ å¾ªç¯è¯»å–æ•°æ®é›†çš„è¿­ä»£å™¨
'''
def load_array(data_arrays, batch_size, is_train=True):  #@save
    # æ„é€ ä¸€ä¸ª PyTorch æ•°æ®è¿­ä»£å™¨ï¼Œå¯¹ tensor è¿›è¡Œæ‰“åŒ…ï¼ŒåŒ…è£…æˆ datasetã€‚
    dataset = data.TensorDataset(*data_arrays)
    # æ ¹æ®æ•°æ®é›†æ„é€ ä¸€ä¸ªè¿­ä»£å™¨
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

# å°æ‰¹é‡æ•°æ®
batch_size = 10
# è®¾ç½®äº†ä¸€ä¸ªæ•°æ®è¯»å–çš„è¿­ä»£å™¨ï¼Œæ¯æ¬¡è¯»å– batch_size(10) æ¡
data_iter = load_array((features, labels), batch_size)

'''
3. è®¾ç½®å…¨è¿æ¥å±‚
'''
'''
# nn.Linear(in_features, out_features, bias=True)
# in_features : è¾“å…¥å‘é‡çš„åˆ—æ•°
# out_features : è¾“å‡ºå‘é‡çš„åˆ—æ•°
# bias = True æ˜¯å¦åŒ…å«åç½®
æ‰§è¡Œçº¿æ€§å˜æ¢ï¼šYn*o = Xn*i Wi*o + b
å…¶ä¸­ï¼šW å’Œ b æ¨¡å‹éœ€è¦å­¦ä¹ çš„å‚æ•°
åœ¨æœ¬ä¾‹ä¸­ï¼šn = 10ï¼Œi = 2, o = 1
'''
net = nn.Sequential(nn.Linear(2, 1))
# è®¾ç½®æƒé‡ w å’Œ åç½® b
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)

'''
4. å®šä¹‰æŸå¤±å‡½æ•°
'''
# å‡æ–¹è¯¯å·®ï¼Œæ˜¯é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹å·®çš„å¹³æ–¹å’Œçš„å¹³å‡å€¼
loss = nn.MSELoss()
# lr å­¦ä¹ ç‡ learning rate
trainer = torch.optim.SGD(net.parameters(), lr=0.03)

'''
4. è®­ç»ƒæ•°æ®
'''
# è¶…å‚æ•° è®¾ç½®æ‰¹æ¬¡
num_epochs = 3
for epoch in range(num_epochs): # è¿›è¡Œ num_epochs ä¸ªè¿­ä»£å‘¨æœŸ
    for X, y in data_iter:
        l = loss(net(X) ,y) # è®¡ç®—æŸå¤±ï¼Œnet(X) è®¡ç®—é¢„æµ‹å€¼ y1ï¼Œloss(y1, y) è®¡ç®—é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·
        trainer.zero_grad() # å°†æ‰€æœ‰æ¨¡å‹å‚æ•°çš„æ¢¯åº¦ç½®ä¸º 0
        l.backward() # æ±‚æ¢¯åº¦ï¼Œä¸ä½¿ç”¨ä»é›¶å®ç°ä¸­ l.sum.backward çš„åŸå› æ˜¯æŸå¤±è®¡ç®—ä¸­ä½¿ç”¨äº†å¹³å‡çš„ gard
        trainer.step() # ä¼˜åŒ–å‚æ•° w å’Œ b
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {l:f}')

w = net[0].weight.data
print('wçš„ä¼°è®¡è¯¯å·®ï¼š', true_w - w.reshape(true_w.shape))
b = net[0].bias.data
print('bçš„ä¼°è®¡è¯¯å·®ï¼š', true_b - b)</code></pre> 
<p></p> 
<h2>äºŒã€å®ç°è§£æ</h2> 
<p>é’ˆå¯¹å®ä¾‹ä¸­é‡è¦çš„å‡½æ•°è§£æå¦‚ä¸‹ã€‚</p> 
<h3>2.1 Linear å‡½æ•°</h3> 
<p>nn.Linear(in_features, out_features, bias=True)</p> 
<p>ç¥ç»ç½‘ç»œçš„çº¿æ€§å±‚ï¼Œä¹Ÿæˆä¸ºå…¨è¿æ¥å±‚ï¼Œè¿›è¡Œ Y = XW + b çš„çº¿æ€§å˜æ¢ã€‚</p> 
<p><strong>å‚æ•°ï¼š</strong></p> 
<p><strong>in_features : </strong>è¾“å…¥å‘é‡çš„åˆ—æ•°</p> 
<p><strong>out_features :</strong> è¾“å‡ºå‘é‡çš„åˆ—æ•°</p> 
<p><strong>bias = True</strong> æ˜¯å¦åŒ…å«åç½®</p> 
<p>in_features å’ŒÂ out_features æ˜¯ W çš„è¡Œå’Œåˆ—ã€‚</p> 
<p>æ‰§è¡Œçº¿æ€§å˜æ¢ï¼šYn*o = Xn*i Wi*o + b</p> 
<p>å…¶ä¸­ï¼šW å’Œ b æ¨¡å‹éœ€è¦å­¦ä¹ çš„å‚æ•°</p> 
<p>åœ¨æœ¬ä¾‹ä¸­ï¼šn = 10ï¼Œi = 2, o = 1ã€‚</p> 
<h3>2.2Â Sequential å‡½æ•°</h3> 
<p>ä¸€ä¸ªåºåˆ—å®¹å™¨ï¼Œç”¨äºæ­å»ºç¥ç»ç½‘ç»œçš„æ¨¡å—ï¼ŒæŒ‰ç…§ä¼ å…¥æ„é€ å™¨çš„é¡ºåºæ·»åŠ åˆ° nn.Sequential() å®¹å™¨ä¸­ã€‚æŒ‰ç…§å†…éƒ¨æ¨¡å—çš„é¡ºåºè‡ªåŠ¨ä¾æ¬¡è®¡ç®—å¹¶è¾“å‡ºç»“æœã€‚</p> 
<p></p> 
<h3>2.3Â MSELoss å‡½æ•°</h3> 
<p>å‡æ–¹è¯¯å·®ï¼Œæ˜¯é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹å·®çš„å¹³æ–¹å’Œçš„å¹³å‡å€¼ï¼Œå³ï¼š</p> 
<p class="img-center"><img alt="" height="94" src="https://images2.imgbox.com/20/56/32rEb5Le_o.png" width="268"></p> 
<h3>2.4 TensorDataset å‡½æ•°</h3> 
<p>ç”¨æ¥å¯¹ tensor è¿›è¡Œæ‰“åŒ…ï¼Œå°±å¥½åƒ python ä¸­çš„ zip åŠŸèƒ½ã€‚è¯¥ç±»é€šè¿‡æ¯ä¸€ä¸ª tensor çš„ç¬¬ä¸€ä¸ªç»´åº¦è¿›è¡Œç´¢å¼•ã€‚å› æ­¤ï¼Œè¯¥ç±»ä¸­çš„ tensor ç¬¬ä¸€ç»´åº¦å¿…é¡»ç›¸ç­‰. å¦å¤–ï¼šTensorDataset ä¸­çš„å‚æ•°å¿…é¡»æ˜¯ tensorã€‚å¯ä»¥å‚è€ƒå¦‚ä¸‹ä¾‹å­ï¼š</p> 
<pre><code class="language-python">import torch
from torch.utils.data import TensorDataset
from torch.utils.data import DataLoader

# len = 12
a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [1, 2, 3], [4, 5, 6], [7, 8, 9], [1, 2, 3], [4, 5, 6], [7, 8, 9], [1, 2, 3], [4, 5, 6], [7, 8, 9]])
# len = 12
b = torch.tensor([44, 55, 66, 44, 55, 66, 44, 55, 66, 44, 55, 66])
# å°† tensor a å’Œ b å‹ç¼©åœ¨ä¸€èµ·
train_ids = TensorDataset(a, b)
# è¾“å‡º
for x, y in train_ids:
    print(x, y)</code></pre> 
<p>è¾“å‡ºå¦‚ä¸‹ï¼š</p> 
<pre><code class="language-python">tensor([1, 2, 3]) tensor(44)
tensor([4, 5, 6]) tensor(55)
tensor([7, 8, 9]) tensor(66)
tensor([1, 2, 3]) tensor(44)
tensor([4, 5, 6]) tensor(55)
tensor([7, 8, 9]) tensor(66)
tensor([1, 2, 3]) tensor(44)
tensor([4, 5, 6]) tensor(55)
tensor([7, 8, 9]) tensor(66)
tensor([1, 2, 3]) tensor(44)
tensor([4, 5, 6]) tensor(55)
tensor([7, 8, 9]) tensor(66)</code></pre> 
<p></p> 
<h3>2.5Â DataLoader å‡½æ•°</h3> 
<p>DataLoader æ˜¯ç”¨æ¥åŒ…è£…æ‰€ä½¿ç”¨çš„æ•°æ®ï¼Œæ¯æ¬¡æŠ›å‡ºä¸€æ‰¹æ•°æ®ï¼Œä¸‹é¢æ¥çœ‹ä¸€ä¸ªä¾‹å­ã€‚</p> 
<pre><code class="language-python">import torch
from torch.utils import data

# len = 12
a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [1, 2, 3], [4, 5, 6], [7, 8, 9], [1, 2, 3], [4, 5, 6], [7, 8, 9], [1, 2, 3], [4, 5, 6], [7, 8, 9]])
# len = 12
b = torch.tensor([44, 55, 66, 44, 55, 66, 44, 55, 66, 44, 55, 66])
# å°† tensor a å’Œ b å‹ç¼©åœ¨ä¸€èµ·
train_ids = data.TensorDataset(a, b)
# è¾“å‡º
#for x, y in train_ids:
#    print(x, y)

BATCH_SIZE = 4
loader = data.DataLoader(dataset=train_ids,
                         batch_size=BATCH_SIZE, # æ¯æ¬¡å– BATCH_SIZE=4 ä¸ªæ•°æ®
                         shuffle=False, # ä¸æ‰“ä¹±é¡ºåº,ä¾¿äºæŸ¥çœ‹
                         num_workers=0)

for x, y in loader:
    print(x, y)
    break</code></pre> 
<p>è¾“å‡ºå¦‚ä¸‹ï¼š</p> 
<pre><code class="language-python">tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9],
        [1, 2, 3]]) tensor([44, 55, 66, 44])</code></pre> 
<p>Â å¦‚ä¸Šæ‰€ç¤ºï¼Œè¾“å‡ºç¬¬ä¸€ä¸ª BATCH_SIZE=4ã€‚</p> 
<p></p> 
<h3>2.6 zero_grad å‡½æ•°</h3> 
<p>trainer.zero_grad() æ˜¯ç”¨æ¥æ¸…ç©ºæ¨¡å‹å‚æ•°æ¢¯åº¦çš„å‡½æ•°ï¼Œå®ƒå°†æ¨¡å‹å‚æ•°çš„æ¢¯åº¦ç¼“å­˜è®¾ç½®ä¸º 0ã€‚åœ¨è¿›è¡Œåå‘ä¼ æ’­æ—¶ï¼Œæ¢¯åº¦ä¼šç´¯åŠ ï¼Œå¦‚æœä¸æ¸…ç©ºæ¢¯åº¦ï¼Œä¼šå½±å“åç»­çš„æ¢¯åº¦è®¡ç®—ã€‚</p> 
<p></p> 
<h3>2.7 backward å‡½æ•°</h3> 
<p>å¯¹è®¡ç®—å›¾è¿›è¡Œæ¢¯åº¦è®¡ç®—ï¼Œæ±‚è§£è®¡ç®—å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„æ¢¯åº¦ã€‚</p> 
<p></p> 
<h3>2.8 step å‡½æ•°</h3> 
<p>æ ¹æ® backward å‡½æ•°è®¡ç®—å‡ºçš„æ¢¯åº¦è¿›è¡Œå‚æ•°æ›´æ–°ã€‚</p> 
<p></p> 
<p>å‚è€ƒé“¾æ¥ï¼š</p> 
<p><a href="https://blog.csdn.net/weixin_45360119/article/details/123346305" title="çº¿æ€§å›å½’çš„å®ç°å­¦ä¹ _data.tensordataset_å¸¦åˆºçš„åšå´½çš„åšå®¢-CSDNåšå®¢">çº¿æ€§å›å½’çš„å®ç°å­¦ä¹ _data.tensordataset_å¸¦åˆºçš„åšå´½çš„åšå®¢-CSDNåšå®¢</a></p> 
<p><a href="https://blog.csdn.net/Just_do_myself/article/details/124195393" title="nn.Sequential()_ä¸€é¢—ç£çŸ³çš„åšå®¢-CSDNåšå®¢">nn.Sequential()_ä¸€é¢—ç£çŸ³çš„åšå®¢-CSDNåšå®¢</a></p> 
<p><a href="https://blog.csdn.net/zfhsfdhdfajhsr/article/details/115637954" title="ã€PytorchåŸºç¡€ã€‘torch.nn.MSELossæŸå¤±å‡½æ•°_ä¸€ç©·äºŒç™½åˆ°å¹´è–ªç™¾ä¸‡çš„åšå®¢-CSDNåšå®¢">ã€PytorchåŸºç¡€ã€‘torch.nn.MSELossæŸå¤±å‡½æ•°_ä¸€ç©·äºŒç™½åˆ°å¹´è–ªç™¾ä¸‡çš„åšå®¢-CSDNåšå®¢</a></p> 
<p><a href="https://blog.csdn.net/yuebowhu/article/details/118099124" title="pytorchä¹‹trainer.zero_grad()_FibonacciCodeçš„åšå®¢-CSDNåšå®¢">pytorchä¹‹trainer.zero_grad()_FibonacciCodeçš„åšå®¢-CSDNåšå®¢</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/622690174" rel="nofollow" title="æ¸…ç©ºæ¨¡å‹å‚æ•°æ¢¯åº¦çš„å‡½æ•° - çŸ¥ä¹">æ¸…ç©ºæ¨¡å‹å‚æ•°æ¢¯åº¦çš„å‡½æ•° - çŸ¥ä¹</a></p> 
<p><a href="https://blog.csdn.net/sinat_28731575/article/details/90342082" title="pytorchä¸­backward()å‡½æ•°è¯¦è§£_backwardå‡½æ•°_Camlin_Zçš„åšå®¢-CSDNåšå®¢">pytorchä¸­backward()å‡½æ•°è¯¦è§£_backwardå‡½æ•°_Camlin_Zçš„åšå®¢-CSDNåšå®¢</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/445009191" rel="nofollow" title="ç†è§£Pytorchçš„loss.backward()å’Œoptimizer.step() - çŸ¥ä¹">ç†è§£Pytorchçš„loss.backward()å’Œoptimizer.step() - çŸ¥ä¹</a></p> 
<hr> 
<p><strong>ğŸˆ </strong>æ„Ÿè§‰æœ‰å¸®åŠ©è®°å¾—<span style="color:#fe2c24;"><strong>ã€Œä¸€é”®ä¸‰è¿</strong><strong>ã€</strong></span>æ”¯æŒä¸‹å“¦ï¼æœ‰é—®é¢˜å¯åœ¨è¯„è®ºåŒºç•™è¨€ğŸ’¬ï¼Œæ„Ÿè°¢å¤§å®¶çš„ä¸€è·¯æ”¯æŒï¼ğŸ¤çŒ¿å“¥å°†æŒç»­è¾“å‡º<span style="color:#fe2c24;"><strong>ã€Œä¼˜è´¨æ–‡ç« </strong><strong>ã€</strong></span>å›é¦ˆå¤§å®¶ï¼ğŸ¤ğŸŒ¹ğŸŒ¹ğŸŒ¹ğŸŒ¹ğŸŒ¹ğŸŒ¹ğŸ¤</p> 
<hr> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d298ec6bcdaac0bee9c96914e3726949/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">centos7.4å®‰è£…tcpreplayæ˜¾ç¤ºNo package tcpreplay available.</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/44a40e1d63e61f52361289a874666c42/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">ã€é—®é¢˜åˆ†æè§£å†³ã€‘gitæ·»åŠ .gitignoreåä¸ç”Ÿæ•ˆé—®é¢˜</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ITå­¦ä¹ è€…åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>