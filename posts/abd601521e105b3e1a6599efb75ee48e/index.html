<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>win 10 mmdetection 配置 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="win 10 mmdetection 配置" />
<meta property="og:description" content="-----2019-7-22 更新
mmdetection 维护人员看来很用心啊，已经适配到了最新的pytorch 1.1 并且修改了编译的方式，看来是要官方支持Windows了，但是目前win下有两个bug 。
sigmoid_focal_loss 和 mask 那个层的编译有问题。官方作者在github 上已经给予了回复。貌似是torch的bug
目前如果想用的话，只能先注释掉相关的代码。
商汤科技（2018 COCO 目标检测挑战赛冠军）和香港中文大学最近开源了一个基于Pytorch实现的深度学习目标检测工具箱mmdetection，支持Faster-RCNN，Mask-RCNN，Fast-RCNN等主流的目标检测框架，后续会加入Cascade-RCNN以及其他一系列目标检测框架。
相比于Facebook开源的Detectron框架，作者声称mmdetection有三点优势：performance稍高、训练速度稍快、所需显存稍小。
我很早就听说了这个工具箱，但是一直没有开源。现在总算是开源了，发现官方没有对Windows系统进行适配，于是就迫不及待地对win10 进行了适配。下面将记录一下
首先官方给出的编译的方法是./compile.sh 我们发现这里面其实是执行了4 个python脚本，但是这4个setup.py 在win下执行会报错，我修改了一个版本。
首先dcn 目录下的setup.py 修改为两个文件，否则链接时候会出现错误。分别为setup_conv.py setup_pool.py
import os
from setuptools import setup
from torch.utils.cpp_extension import BuildExtension, CUDAExtension,CppExtension,CUDA_HOME
import torch
def get_extensions():
this_dir = os.path.dirname(os.path.abspath(__file__))
extension = CppExtension
extra_compile_args = {&#34;cxx&#34;: []}
define_macros = []
sources=[
&#39;src/deform_conv_cuda.cpp&#39;,
&#39;src/deform_conv_cuda_kernel.cu&#39;]
if torch.cuda.is_available() and CUDA_HOME is not None:
extension = CUDAExtension
extra_compile_args[&#34;nvcc&#34;] = [" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/abd601521e105b3e1a6599efb75ee48e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-04-11T11:01:26+08:00" />
<meta property="article:modified_time" content="2019-04-11T11:01:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">win 10 mmdetection 配置</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>-----2019-7-22 更新</p> 
<p>mmdetection 维护人员看来很用心啊，已经适配到了最新的pytorch 1.1 并且修改了编译的方式，看来是要官方支持Windows了，但是目前win下有两个bug 。</p> 
<p>sigmoid_focal_loss 和 mask 那个层的编译有问题。官方作者在github 上已经给予了回复。貌似是torch的bug</p> 
<p>目前如果想用的话，只能先注释掉相关的代码。</p> 
<p>商汤科技（2018 COCO 目标检测挑战赛冠军）和香港中文大学最近开源了一个基于Pytorch实现的深度学习目标检测工具箱mmdetection，支持Faster-RCNN，Mask-RCNN，Fast-RCNN等主流的目标检测框架，后续会加入Cascade-RCNN以及其他一系列目标检测框架。</p> 
<p>相比于Facebook开源的Detectron框架，作者声称mmdetection有三点优势：performance稍高、训练速度稍快、所需显存稍小。</p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p>我很早就听说了这个工具箱，但是一直没有开源。现在总算是开源了，发现官方没有对Windows系统进行适配，于是就迫不及待地对win10 进行了适配。下面将记录一下</p> 
<p><br> 首先官方给出的编译的方法是./compile.sh  我们发现这里面其实是执行了4 个python脚本，但是这4个setup.py 在win下执行会报错，我修改了一个版本。</p> 
<p>首先dcn 目录下的setup.py 修改为两个文件，否则链接时候会出现错误。分别为setup_conv.py setup_pool.py</p> 
<p> </p> 
<p>import os</p> 
<p>from setuptools import setup</p> 
<p>from torch.utils.cpp_extension import BuildExtension, CUDAExtension,CppExtension,CUDA_HOME</p> 
<p>import torch</p> 
<p> </p> 
<p>def get_extensions():</p> 
<p>this_dir = os.path.dirname(os.path.abspath(__file__))</p> 
<p>extension = CppExtension</p> 
<p>extra_compile_args = {"cxx": []}</p> 
<p>define_macros = []</p> 
<p>sources=[</p> 
<p>'src/deform_conv_cuda.cpp',</p> 
<p>'src/deform_conv_cuda_kernel.cu']</p> 
<p> </p> 
<p>if torch.cuda.is_available() and CUDA_HOME is not None:</p> 
<p>extension = CUDAExtension</p> 
<p>extra_compile_args["nvcc"] = [</p> 
<p>"-DCUDA_HAS_FP16=1",</p> 
<p>"-D__CUDA_NO_HALF_OPERATORS__",</p> 
<p>"-D__CUDA_NO_HALF_CONVERSIONS__",</p> 
<p>"-D__CUDA_NO_HALF2_OPERATORS__",</p> 
<p>]</p> 
<p>ext_modules = [</p> 
<p>extension(</p> 
<p>"deform_conv_cuda",</p> 
<p>sources,</p> 
<p>extra_compile_args=extra_compile_args,</p> 
<p>),</p> 
<p> </p> 
<p>]</p> 
<p> </p> 
<p>return ext_modules</p> 
<p> </p> 
<p>setup(</p> 
<p>name='deform_conv',</p> 
<p>ext_modules=get_extensions(),</p> 
<p>cmdclass={'build_ext': BuildExtension})</p> 
<p> </p> 
<p>import os</p> 
<p>from setuptools import setup</p> 
<p>from torch.utils.cpp_extension import BuildExtension, CUDAExtension,CppExtension,CUDA_HOME</p> 
<p>import torch</p> 
<p> </p> 
<p>def get_extensions():</p> 
<p>this_dir = os.path.dirname(os.path.abspath(__file__))</p> 
<p>extension = CppExtension</p> 
<p>extra_compile_args = {"cxx": []}</p> 
<p>define_macros = []</p> 
<p>sources=[</p> 
<p>'src/deform_pool_cuda.cpp',</p> 
<p>'src/deform_pool_cuda_kernel.cu'</p> 
<p>]</p> 
<p> </p> 
<p>if torch.cuda.is_available() and CUDA_HOME is not None:</p> 
<p>extension = CUDAExtension</p> 
<p>extra_compile_args["nvcc"] = [</p> 
<p>"-DCUDA_HAS_FP16=1",</p> 
<p>"-D__CUDA_NO_HALF_OPERATORS__",</p> 
<p>"-D__CUDA_NO_HALF_CONVERSIONS__",</p> 
<p>"-D__CUDA_NO_HALF2_OPERATORS__",</p> 
<p>]</p> 
<p>ext_modules = [</p> 
<p>extension(</p> 
<p>"deform_pool_cuda",</p> 
<p>sources,</p> 
<p>extra_compile_args=extra_compile_args,</p> 
<p>),</p> 
<p> </p> 
<p>]</p> 
<p> </p> 
<p>return ext_modules</p> 
<p> </p> 
<p>setup(</p> 
<p>name='deform_conv',</p> 
<p>ext_modules=get_extensions(),</p> 
<p>cmdclass={'build_ext': BuildExtension})</p> 
<p> </p> 
<p>接着 nms 目录下，</p> 
<p>import os.path as osp</p> 
<p>from setuptools import setup, Extension</p> 
<p> </p> 
<p>import numpy as np</p> 
<p>from Cython.Build import cythonize</p> 
<p>from Cython.Distutils import build_ext</p> 
<p>from torch.utils.cpp_extension import BuildExtension, CUDAExtension</p> 
<p> </p> 
<p>ext_args = dict(</p> 
<p>include_dirs=[np.get_include()],</p> 
<p>language='c++',</p> 
<p>extra_compile_args={<!-- --></p> 
<p>'cc': ['-Wno-unused-function', '-Wno-write-strings'],</p> 
<p>'nvcc': ['-c', '--compiler-options', '-fPIC'],</p> 
<p>},</p> 
<p>)</p> 
<p> </p> 
<p>extensions = [</p> 
<p>Extension('soft_nms_cpu', ['src/soft_nms_cpu.pyx'], **ext_args),</p> 
<p>]</p> 
<p><br>  </p> 
<p>def customize_compiler_for_nvcc(self):</p> 
<p>"""inject deep into distutils to customize how the dispatch</p> 
<p>to cc/nvcc works.</p> 
<p>If you subclass UnixCCompiler, it's not trivial to get your subclass</p> 
<p>injected in, and still have the right customizations (i.e.</p> 
<p>distutils.sysconfig.customize_compiler) run on it. So instead of going</p> 
<p>the OO route, I have this. Note, it's kindof like a wierd functional</p> 
<p>subclassing going on."""</p> 
<p> </p> 
<p># tell the compiler it can processes .cu</p> 
<p>self.src_extensions.append('.cu')</p> 
<p>super = self._compile</p> 
<p> </p> 
<p># now redefine the _compile method. This gets executed for each</p> 
<p># object but distutils doesn't have the ability to change compilers</p> 
<p># based on source extension: we add it.</p> 
<p>def _compile(obj, src, ext, cc_args, extra_postargs, pp_opts):</p> 
<p>if osp.splitext(src)[1] == '.cu':</p> 
<p># use the cuda for .cu files</p> 
<p>self.set_executable('nvcc')</p> 
<p># use only a subset of the extra_postargs, which are 1-1 translated</p> 
<p># from the extra_compile_args in the Extension class</p> 
<p>postargs = extra_postargs['nvcc']</p> 
<p>else:</p> 
<p>postargs = extra_postargs['cc']</p> 
<p> </p> 
<p>super(obj, src, ext, cc_args, postargs, pp_opts)</p> 
<p> </p> 
<p># inject our redefined _compile method into the class</p> 
<p>self._compile = _compile</p> 
<p><br>  </p> 
<p>class custom_build_ext(build_ext):</p> 
<p> </p> 
<p>def build_extensions(self):</p> 
<p>customize_compiler_for_nvcc(self.compiler)</p> 
<p>build_ext.build_extensions(self)</p> 
<p><br>  </p> 
<p>setup(</p> 
<p>name='soft_nms',</p> 
<p>cmdclass={'build_ext': custom_build_ext},</p> 
<p>ext_modules=cythonize(extensions),</p> 
<p>)</p> 
<p> </p> 
<p>setup(</p> 
<p>name='nms_cuda',</p> 
<p>ext_modules=[</p> 
<p>CUDAExtension('nms_cuda', [</p> 
<p>'src/nms_cuda.cpp',</p> 
<p>'src/nms_kernel.cu',</p> 
<p>]),</p> 
<p>CUDAExtension('nms_cpu', [</p> 
<p>'src/nms_cpu.cpp',</p> 
<p>]),</p> 
<p>],</p> 
<p>cmdclass={'build_ext': BuildExtension})</p> 
<p>roi_align 目录下</p> 
<p>import os</p> 
<p>from setuptools import setup</p> 
<p>from torch.utils.cpp_extension import BuildExtension, CUDAExtension,CppExtension,CUDA_HOME</p> 
<p>import torch</p> 
<p> </p> 
<p>def get_extensions():</p> 
<p>this_dir = os.path.dirname(os.path.abspath(__file__))</p> 
<p>extension = CppExtension</p> 
<p>extra_compile_args = {"cxx": []}</p> 
<p>define_macros = []</p> 
<p>sources=[</p> 
<p>'src/roi_align_cuda.cpp',</p> 
<p>'src/roi_align_kernel.cu']</p> 
<p> </p> 
<p>if torch.cuda.is_available() and CUDA_HOME is not None:</p> 
<p>extension = CUDAExtension</p> 
<p>extra_compile_args["nvcc"] = [</p> 
<p>"-DCUDA_HAS_FP16=1",</p> 
<p>"-D__CUDA_NO_HALF_OPERATORS__",</p> 
<p>"-D__CUDA_NO_HALF_CONVERSIONS__",</p> 
<p>"-D__CUDA_NO_HALF2_OPERATORS__",</p> 
<p>]</p> 
<p>ext_modules = [</p> 
<p>extension(</p> 
<p>"roi_align_cuda",</p> 
<p>sources,</p> 
<p>extra_compile_args=extra_compile_args,</p> 
<p>)</p> 
<p>]</p> 
<p> </p> 
<p>return ext_modules</p> 
<p> </p> 
<p>setup(</p> 
<p>name='roi_align_cuda',</p> 
<p>ext_modules=get_extensions(),</p> 
<p>cmdclass={'build_ext': BuildExtension})</p> 
<p>roi_pool 目录下</p> 
<p>import os</p> 
<p>from setuptools import setup</p> 
<p>from torch.utils.cpp_extension import BuildExtension, CUDAExtension,CppExtension,CUDA_HOME</p> 
<p>import torch</p> 
<p> </p> 
<p>def get_extensions():</p> 
<p>this_dir = os.path.dirname(os.path.abspath(__file__))</p> 
<p>extension = CppExtension</p> 
<p>extra_compile_args = {"cxx": []}</p> 
<p>define_macros = []</p> 
<p>sources=[</p> 
<p>'src/roi_pool_cuda.cpp',</p> 
<p>'src/roi_pool_kernel.cu']</p> 
<p> </p> 
<p>if torch.cuda.is_available() and CUDA_HOME is not None:</p> 
<p>extension = CUDAExtension</p> 
<p>extra_compile_args["nvcc"] = [</p> 
<p>"-DCUDA_HAS_FP16=1",</p> 
<p>"-D__CUDA_NO_HALF_OPERATORS__",</p> 
<p>"-D__CUDA_NO_HALF_CONVERSIONS__",</p> 
<p>"-D__CUDA_NO_HALF2_OPERATORS__",</p> 
<p>]</p> 
<p>ext_modules = [</p> 
<p>extension(</p> 
<p>"roi_pool_cuda",</p> 
<p>sources,</p> 
<p>extra_compile_args=extra_compile_args,</p> 
<p>)</p> 
<p>]</p> 
<p> </p> 
<p>return ext_modules</p> 
<p> </p> 
<p>setup(</p> 
<p>name='roi_pool_cuda',</p> 
<p>ext_modules=get_extensions(),</p> 
<p>cmdclass={'build_ext': BuildExtension})</p> 
<p>至此，就修改完了全部的setup.py  然后去各个目录分别执行python setup.py build_ext --inplace </p> 
<p>执行完成之后，到项目根目录下执行 python setuy.py install 即可。</p> 
<p>注意，VC++ 版本要和cuda 版本对应上，pytorch版本1.0 以上，</p> 
<p>Windows不支持distribution  库，训练时候，可能需要相应的修改源码，否则会报错。</p> 
<p> </p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6a184727eb67925c3ea028928d4069d7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">DOTA目标检测数据集</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b5cb66a07c79cb2ecbb72765a17b272b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">LLVM语言参考手册</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>