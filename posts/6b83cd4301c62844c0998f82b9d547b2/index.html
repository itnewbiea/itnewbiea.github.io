<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>YOLOv5S网络框架设计-CSC&amp;C3&amp;SPPF模块 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="YOLOv5S网络框架设计-CSC&amp;C3&amp;SPPF模块" />
<meta property="og:description" content="总体框架： 在6.0版本的框架中，Neck和Head是一个整体统称为Head
Yolov5s由Backbone（网络主干）和Head（头部）组成
各个小模块 CBS模块 CBS模块在common.py中定义为Class Conv：
class Conv(nn.Module): # Standard convolution def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True): # ch_in, ch_out, kernel, stride, padding, groups super().__init__() self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False) self.bn = nn.BatchNorm2d(c2) self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity()) def forward(self, x): return self.act(self.bn(self.conv(x))) def forward_fuse(self, x): return self.act(self.conv(x)) CBS: C代表Conv，B代表BatchNorm2d，S代表SiLu激活函数
CBS模块封装了卷积、批归一化和激活函数的组合操作" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/6b83cd4301c62844c0998f82b9d547b2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-03T23:09:38+08:00" />
<meta property="article:modified_time" content="2023-08-03T23:09:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">YOLOv5S网络框架设计-CSC&amp;C3&amp;SPPF模块</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_1"></a>总体框架：</h3> 
<p>在6.0版本的框架中，Neck和Head是一个整体统称为Head<br> Yolov5s由Backbone（网络主干）和Head（头部）组成<br> <img src="https://images2.imgbox.com/50/55/rJ0ILB5a_o.png" alt="yolov5s网络框架"></p> 
<h3><a id="_5"></a>各个小模块</h3> 
<h4><a id="CBS_7"></a>CBS模块</h4> 
<p><img src="https://images2.imgbox.com/3a/6e/gWh3YhQd_o.png" alt="CBS模块"></p> 
<p>CBS模块在common.py中定义为Class Conv：</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Conv</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Standard convolution</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ch_in, ch_out, kernel, stride, padding, groups</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token punctuation">,</span> s<span class="token punctuation">,</span> autopad<span class="token punctuation">(</span>k<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>g<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>c2<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>act <span class="token operator">=</span> nn<span class="token punctuation">.</span>SiLU<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> act <span class="token keyword">is</span> <span class="token boolean">True</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>act <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>act<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span> <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">forward_fuse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>CBS: C代表<code>Conv</code>，B代表<code>BatchNorm2d</code>，S代表<code>SiLu</code>激活函数</p> 
<p>CBS模块封装了卷积、批归一化和激活函数的组合操作</p> 
<p><code>self.conv </code>: 用<code>nn.Conv2d</code> 创建了一个二维卷积层</p> 
<p><code>self.bn</code>：使用 <code>nn.BatchNorm2d</code> 创建了一个二维批归一化层</p> 
<p><code>self.act</code>：根据 <code>act</code> 参数确定是否应用激活函数，默认为 <code>nn.SiLU()</code>，如果 <code>act</code> 既不是 <code>True</code> 也不是 <code>nn.Module</code> 类型，则应用恒等函数 <code>nn.Identity()</code>。</p> 
<p>运算顺序由前向传播方法<code>def forward</code> 中，先对输入 <code>x</code> 进行卷积操作，然后应用批归一化和激活函数，并返回结果。</p> 
<p>在融合正向传播方法 <code>forward_fuse</code> 中，与正向传播方法类似，但没有应用批归一化层，仅对卷积结果应用激活函数，并返回结果。</p> 
<h6><a id="nnConv2d__44"></a>nn.Conv2d 对由多个输入平面组成的输入信号进行二维卷积</h6> 
<p>二维卷积的定义：一维卷积卷积核只能在长度方向上进行滑窗操作，二维卷积可以在长和宽方向上进行滑窗操作，三维卷积可以在长、宽以及channel方向上进行滑窗操作。一个<a href="https://so.csdn.net/so/search?q=%E5%8D%B7%E7%A7%AF%E6%A0%B8&amp;spm=1001.2101.3001.7020">卷积核</a>运算一次得到一个值，output channel取决于卷积核的个数。</p> 
<blockquote> 
 <p><code>self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)</code></p> 
 <ul><li><code>c1</code>：输入通道数</li><li><code>c2</code>：输出通道数</li><li><code>k</code>：卷积核大小，默认为1</li><li><code>s</code>：步长，默认为1</li><li><code>autopad(k, p)</code> 是一个辅助函数，用于自动计算卷积操作中的填充大小,<code>k</code>：卷积核的大小,<code>p</code>：期望的输出特征图的大小,填充大小</li><li><code>groups</code>：分组数，默认为1，表示不使用分组卷积，大于1则使用分组卷积；</li><li><code>bias</code>：是否使用偏置项，默认为False，表示不使用偏置项</li></ul> 
</blockquote> 
<p>另：<code>Conv2d</code>中还有一个重要的参数就是空洞卷积<code>dilation</code>，通俗解释就是控制kernel点（卷积核点）间距的参数，通过改变卷积核间距实现特征图及特征信息的保留，在语义分割任务中空洞卷积比较有效。</p> 
<h6><a id="nnBatchNorm2d_60"></a><strong>nn.BatchNorm2d数据归一化处理</strong></h6> 
<p>在卷积神经网络的卷积层后一般会添加BatchNorm2d进行数据归一化处理，使数据在进行激活函数非线性处理单元之前不会因为数据过大而导致网络性能不稳定。</p> 
<p>目的：使特征图满足均值为0，方差为1的分布规律。对输入batch的每一个特征通道进行Normalize。</p> 
<h6><a id="nnSiLU_66"></a><strong>nn.SiLU激活函数</strong></h6> 
<p>激活函数定义：在多层神经网络中，上层节点的输出和下层节点的输入之间具有一个函数关系，这个函数称为激活函数。</p> 
<p>激活函数使神经网络具有非线性，决定感知机是否激发。这种非线性赋予了深度网络学习复杂函数的能力。如果不使用激活函数，则相当于f（x）=x，这也就是最原始的感知机，即每一层节点的输入都是上层输出的线性函数，使得网络的逼近能力有限。</p> 
<p>YOLOv5中激活函数实现的相关代码在utils/activations.py中</p> 
<h4><a id="C3_74"></a>C3模块</h4> 
<p>C3模块在common.py中定义为Class C3：</p> 
<p><img src="https://images2.imgbox.com/74/a0/pUKUDqFL_o.png" alt="C3模块"></p> 
<p>CSP即backbone中的C3，因为在backbone中C3存在shortcut，而在neck中C3不使用shortcut，所以backbone中的C3层使用CSP1_x表示，neck中的C3使用CSP2_x表示。</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">C3</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># CSP Bottleneck with 3 convolutions</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ch_in, ch_out, number, shortcut, groups, expansion</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>c2 <span class="token operator">*</span> e<span class="token punctuation">)</span>  <span class="token comment"># hidden channels 隐藏通道数</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#输入通道数，输出通道数，卷积核大小，步长</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv3 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> c_<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 输入通道数，输出通道数，卷积核大小，act=FReLU(c2)</span>
        self<span class="token punctuation">.</span>m <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">(</span>Bottleneck<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> shortcut<span class="token punctuation">,</span> g<span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cv3<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>m<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>参数说明：</p> 
 <ul><li><code>c_</code>:隐藏通道数</li><li><code>c1</code>：输入通道数</li><li><code>c2</code>：输出通道数</li><li><code>n</code>：CSP Bottleneck 的重复次数，默认为1</li><li><code>shortcut</code>：是否使用残差连接（shortcut connection），默认为True</li><li><code>g</code>：组卷积（group convolution）的分组数，默认为1</li><li><code>e</code>：通道扩展率（channel expansion rate），默认为0.5</li></ul> 
</blockquote> 
<p><code>self.cv1</code>：调用了自定义的 <code>Conv</code> 模块来进行1*1卷积操作，输入通道数c1，输出通道数是隐藏通道数c_</p> 
<p><code>self.cv2</code>：与self.cv1相同</p> 
<p><code>self.cv3</code>：将两个特征图压缩为输出通道数，输入通道数是隐藏通道数的二倍，输出通道数c2</p> 
<p><code>self.m</code>：self.m操作使用nn.Sequential将n个Bottleneck块串接到网络中（具体几个要结合配置文件里的参数计算!即number×depth_multiple个），每个Bottleneck块具有输入和输出通道数都为 <code>c_</code></p> 
<p><code>forward(self, x)</code>：前向传播方法，定义了模块的数据流。输入特征图有两个分支，一条分支通过第一个卷积层 <code>self.cv1</code>，再经过<code>self.m</code>进行 CSP Bottleneck 处理，得到子特征图1；另一分支通过第二个卷积层 <code>self.cv2</code>后得到子特征图2。最后将子特征图1和子特征图2按通道拼接（<code>torch.cat</code>）并通过第三个卷积层 <code>self.cv3</code> 得到最终输出。</p> 
<h6><a id="Bottleneck_119"></a>Bottleneck：瓶颈层</h6> 
<p>要想了解Bottleneck，还要从Resnet说起。在Resnet出现之前，人们的普遍为网络越深获取信息也越多，模型泛化效果越好。然而随后大量的研究表明，网络深度到达一定的程度后，模型的准确率反而大大降低。这并不是过拟合造成的，而是由于反向传播过程中的<strong>梯度爆炸</strong>和<strong>梯度消失</strong>。也就是说，网络越深，模型越难优化，而不是学习不到更多的特征。<br> <img src="https://images2.imgbox.com/b3/b6/rKfJZQO7_o.png" alt="在这里插入图片描述"></p> 
<p>为了能让深层次的网络模型达到更好的训练效果，残差网络中提出的残差映射替换了以往的基础映射。对于输入x，期望输出H(x)，网络利用恒等映射将x作为初始结果，将原来的映射关系变成F(x)+x。与其让多层卷积去近似估计H(x) ，不如近似估计H(x)-x，即近似估计残差F(x)。因此，ResNet相当于将学习目标改变为目标值H(x)和x的差值，后面的训练目标就是要将残差结果逼近于0</p> 
<blockquote> 
 <p>残差模块的优点：</p> 
 <p>1.梯度弥散方面。加入ResNet中的shortcut结构之后，在反传时，每两个block之间不仅传递了梯度，还加上了求导之前的梯度，这相当于把每一个block中向前传递的梯度人为加大了，也就会减小梯度弥散的可能性。<br> 2.特征冗余方面。正向卷积时，对每一层做卷积其实只提取了图像的一部分信息，这样一来，越到深层，原始图像信息的丢失越严重，而仅仅是对原始图像中的一小部分特征做提取。这显然会发生类似欠拟合的现象。加入shortcut结构，相当于在每个block中又加入了上一层图像的全部信息，一定程度上保留了更多的原始信息。</p> 
</blockquote> 
<p><strong>在resnet中，人们可以使用带有shortcut的残差模块搭建几百层甚至上千层的网络，而浅层的残差模块被命名为Basicblock（18、34），深层网络所使用的的残差模块，就被命名为了Bottleneck（50+）</strong></p> 
<p><img src="https://images2.imgbox.com/a3/6b/IrWnim0X_o.png" alt="在这里插入图片描述"></p> 
<p>Bottleneck与Basicblock最大的区别是卷积核的组成。 Basicblock由两个3x3的卷积层组成，Bottleneck由两个1x1卷积层夹一个3x3卷积层组成：其中1x1卷积层降维后再恢复维数，让3x3卷积在计算过程中的参数量更少、速度更快。<strong>Bottleneck减少了参数量，优化了计算，保持了原有的精度。</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Bottleneck</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Standard bottleneck</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ch_in, ch_out, shortcut, groups, expansion</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>c2 <span class="token operator">*</span> e<span class="token punctuation">)</span>  <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> g<span class="token operator">=</span>g<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add <span class="token operator">=</span> shortcut <span class="token keyword">and</span> c1 <span class="token operator">==</span> c2

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>add <span class="token keyword">else</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<p>可以看到，CSP中的Bottleneck同resnet模块中的类似，先是1x1的卷积层（CBS)，然后再是3x3的卷积层，最后通过shortcut与初始输入相加。但是这里与resnet的不同点在于：CSP将输入维度减半运算后并未再使用1x1卷积核进行升维，而是将原始输入x也降了维，采取concat的方法进行张量的拼接，得到与原始输入相同维度的输出。其实这里能区分一点就够了：<strong>resnet中的shortcut通过add实现，是特征图对应位置相加而通道数不变；而CSP中的shortcut通过concat实现，是通道数的增加。二者虽然都是信息融合的主要方式，但是对张量的具体操作又不相同.</strong></p> 
<p>其次，对于shortcut是可根据任务要求设置的，比如在backbone中shortcut=True，neck中shortcut=False。</p> 
<p><img src="https://images2.imgbox.com/67/1c/x65GRKuJ_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/eb/40/jgukXXwB_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="SPPF_164"></a>SPPF模块</h4> 
<p>SPPF模块在common.py中定义为Class SPPF：</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">SPPF</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># equivalent to SPP(k=(5, 9, 13))</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> c1 <span class="token operator">//</span> <span class="token number">2</span>  <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c_ <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>m <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span>k<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span>k <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">with</span> warnings<span class="token punctuation">.</span>catch_warnings<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            warnings<span class="token punctuation">.</span>simplefilter<span class="token punctuation">(</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>  <span class="token comment"># suppress torch 1.9.0 max_pool2d() warning</span>
            y1 <span class="token operator">=</span> self<span class="token punctuation">.</span>m<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            y2 <span class="token operator">=</span> self<span class="token punctuation">.</span>m<span class="token punctuation">(</span>y1<span class="token punctuation">)</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> y2<span class="token punctuation">,</span> self<span class="token punctuation">.</span>m<span class="token punctuation">(</span>y2<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/5e/3c/v4NR7E4o_o.png" alt="在这里插入图片描述"></p> 
<p>SSPF模块将经过CBS的x、一次池化后的y1、两次池化后的y2和3次池化后的self.m(y2)先进行拼接，然后再CBS提取特征</p> 
<p>SPPF 层通过使用不同大小的池化核来捕捉输入图像的<strong>多尺度信息</strong>，并且减少通道数。这有助于提高模型的感受野和特征表达能力。</p> 
<h6><a id="nnMaxPool2d_195"></a>nn.MaxPool2d:最大池化操作</h6> 
<p>卷积操作中池化层提取重要信息的操作，可以去掉不重要的信息，减少计算开销。最大池化操作相当于核在图像上移动的时候，筛选出被核覆盖区域的最大值。目的就是为了保留输入的特征，但是同时把数据量减少，对于整个网路来说，进行计算的参数就变少了，就会训练的更快。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3ac70a3dfe7a60cb5d36c36b863371fc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">深度学习——全维度动态卷积ODConv</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b1b8493f3cf60f32f430d6e49a7a8a46/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SpringDataJPA框架使用笔记</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>