<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Python计算机视觉编程】第二章 SIFT特征提取与检索及RANSAC实例 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Python计算机视觉编程】第二章 SIFT特征提取与检索及RANSAC实例" />
<meta property="og:description" content="文章目录 一.SIFT描述子1.SIFT特征简介1.1 SIFT算法可以解决的问题1.2 SIFT算法实现步骤1.3 关键点检测相关概念1.3.1 尺度空间1.3.2.关键点检测-Dog 2.检测感兴趣点（例题）3.描述子匹配（例题） 二.SIFT特征提取与检索（实验）1. 数据集准备2. 特征提取2.1 运行结果2.2 分析 3. 描述子匹配4. 输出匹配图片4. 1 代码4. 2 运行结果 三. 地理标记图像匹配3.1 代码3.2 运行结果 四. 实验中遇到的问题和得出的结论五. RANSAC原理及运用5.1 RANSAC——随机一致性采样5.2 示例5.3 使用RANSAC算法匹配5.3.1 源代码5.3.2 结果分析 一.SIFT描述子 1.SIFT特征简介 1.1 SIFT算法可以解决的问题 (1) 目标的旋转、缩放、平移（RST）
(2) 图像仿射/投影变换（视点viewpoint）
(3) 弱光照影响（illumination）
(4) 部分目标遮挡（occlusion）
(5) 杂物场景（clutter）
(6) 噪声
1.2 SIFT算法实现步骤 SIFT算法的实质可以归为在不同尺度空间上查找特征点（关键点）的问题。
实现特征匹配流程如下：
(1) 提取关键点；
(2) 对关键点附加 详细的信息（局部特征），即描述符；
(3) 通过特征点（附带上特征向量的关 键点）的两两比较找出相互匹配的若干对特征点，建立景物间的对应关系。
1.3 关键点检测相关概念 这些点是一些十分突出的点不会因光照、尺度、旋转等因素的改变而消失，比如角点、边缘点、暗区域的亮点以及亮区域的暗点。既然两幅图像中有相同的景物，那么使用某种方法分别提取各自的稳定点，这些点之间会有相互对应的匹配点。
1.3.1 尺度空间 尺度空间理论最早于1962年提出，其主要思想是通过 对原始图像进行尺度变换，获得图像多尺度下的空间表示。从而实现边缘、角点检测和不同分辨率上的特征提取，以满足特征点的尺度不变性。
尺度越大图像越模糊。
1.3.2.关键点检测-Dog 1.Dog的局部极值点" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/a0fd0d7b20701b329a9805ee4759f3c2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-03-08T13:37:20+08:00" />
<meta property="article:modified_time" content="2020-03-08T13:37:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Python计算机视觉编程】第二章 SIFT特征提取与检索及RANSAC实例</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#SIFT_1" rel="nofollow">一.SIFT描述子</a></li><li><ul><li><a href="#1SIFT_2" rel="nofollow">1.SIFT特征简介</a></li><li><ul><li><a href="#11_SIFT_3" rel="nofollow">1.1 SIFT算法可以解决的问题</a></li><li><a href="#12_SIFT_11" rel="nofollow">1.2 SIFT算法实现步骤</a></li><li><a href="#13__19" rel="nofollow">1.3 关键点检测相关概念</a></li><li><ul><li><a href="#131__21" rel="nofollow">1.3.1 尺度空间</a></li><li><a href="#132Dog_24" rel="nofollow">1.3.2.关键点检测-Dog</a></li></ul> 
    </li></ul> 
    </li><li><a href="#2_33" rel="nofollow">2.检测感兴趣点（例题）</a></li><li><a href="#3_73" rel="nofollow">3.描述子匹配（例题）</a></li></ul> 
   </li><li><a href="#SIFT_117" rel="nofollow">二.SIFT特征提取与检索（实验）</a></li><li><ul><li><a href="#1__118" rel="nofollow">1. 数据集准备</a></li><li><a href="#2__120" rel="nofollow">2. 特征提取</a></li><li><ul><li><a href="#21___121" rel="nofollow">2.1 运行结果</a></li><li><a href="#22___124" rel="nofollow">2.2 分析</a></li></ul> 
    </li><li><a href="#3__129" rel="nofollow">3. 描述子匹配</a></li><li><a href="#4__132" rel="nofollow">4. 输出匹配图片</a></li><li><ul><li><a href="#4_1__133" rel="nofollow">4. 1 代码</a></li><li><a href="#4_2__178" rel="nofollow">4. 2 运行结果</a></li></ul> 
   </li></ul> 
   </li><li><a href="#__185" rel="nofollow">三. 地理标记图像匹配</a></li><li><ul><li><a href="#31__186" rel="nofollow">3.1 代码</a></li><li><a href="#32__259" rel="nofollow">3.2 运行结果</a></li></ul> 
   </li><li><a href="#__265" rel="nofollow">四. 实验中遇到的问题和得出的结论</a></li><li><a href="#_RANSAC_282" rel="nofollow">五. RANSAC原理及运用</a></li><li><ul><li><a href="#51_RANSAC_283" rel="nofollow">5.1 RANSAC——随机一致性采样</a></li><li><a href="#52__306" rel="nofollow">5.2 示例</a></li><li><a href="#53_RANSAC_318" rel="nofollow">5.3 使用RANSAC算法匹配</a></li><li><ul><li><a href="#531__319" rel="nofollow">5.3.1 源代码</a></li><li><a href="#532__414" rel="nofollow">5.3.2 结果分析</a></li></ul> 
   </li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="SIFT_1"></a>一.SIFT描述子</h3> 
<h4><a id="1SIFT_2"></a>1.SIFT特征简介</h4> 
<h5><a id="11_SIFT_3"></a>1.1 SIFT算法可以解决的问题</h5> 
<p>(1) 目标的旋转、缩放、平移（RST）<br> (2) 图像仿射/投影变换（视点viewpoint）<br> (3) 弱光照影响（illumination）<br> (4) 部分目标遮挡（occlusion）<br> (5) 杂物场景（clutter）<br> (6) 噪声</p> 
<h5><a id="12_SIFT_11"></a>1.2 SIFT算法实现步骤</h5> 
<p>SIFT算法的实质可以归为在不同尺度空间上查找特征点（关键点）的问题。<br> <mark>实现特征匹配流程如下</mark>：<br> (1) 提取<mark>关键点</mark>；<br> (2) 对关键点附加 详细的信息（局部特征），即描述符；<br> (3) 通过特征点（附带上特征向量的关 键点）的两两比较找出相互匹配的若干对特征点，建立景物间的对应关系。<br> <img src="https://images2.imgbox.com/20/ee/hRYuLdmb_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="13__19"></a>1.3 关键点检测相关概念</h5> 
<p>这些点是一些十分突出的点不会因光照、尺度、旋转等因素的改变而消失，比如角点、边缘点、暗区域的亮点以及亮区域的暗点。既然两幅图像中有相同的景物，那么使用某种方法分别提取各自的稳定点，这些点之间会有相互对应的匹配点。</p> 
<h6><a id="131__21"></a>1.3.1 尺度空间</h6> 
<p>尺度空间理论最早于1962年提出，其主要思想是通过 对原始图像进行尺度变换，获得图像多尺度下的空间表示。从而实现边缘、角点检测和不同分辨率上的特征提取，以满足特征点的尺度不变性。<br> 尺度越大图像越模糊。</p> 
<h6><a id="132Dog_24"></a>1.3.2.关键点检测-Dog</h6> 
<p><img src="https://images2.imgbox.com/77/30/8cDpciWU_o.png" alt="在这里插入图片描述"><br> <mark>1.Dog的局部极值点</mark><br> <img src="https://images2.imgbox.com/a2/d3/KED83FtG_o.png" alt="在这里插入图片描述"></p> 
<p><mark>2.去除边缘响应</mark></p> 
<p><img src="https://images2.imgbox.com/51/62/e2EMJ9WB_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/2a/a7/fNQWSO7u_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="2_33"></a>2.检测感兴趣点（例题）</h4> 
<pre><code># -*- coding: utf-8 -*-from PIL import Image
from pylab import *
from PCV.localdescriptors import sift
from PCV.localdescriptors import harris

# 添加中文字体支持
from matplotlib.font_manager import FontProperties
font = FontProperties(fname=r"c:\windows\fonts\SimSun.ttc", size=14)

imname = 'D:/xjx\pythonCode/pcv_data/data/empire.jpg'
im = array(Image.open(imname).convert('L'))
sift.process_image(imname, 'empire.sift')
l1, d1 = sift.read_features_from_file('empire.sift')

figure()
gray()
subplot(131)
sift.plot_features(im, l1, circle=False)
title(u'SIFT特征',fontproperties=font)
subplot(132)
sift.plot_features(im, l1, circle=True)
title(u'用圆圈表示SIFT特征尺度',fontproperties=font)

# 检测harris角点
harrisim = harris.compute_harris_response(im)

subplot(133)
filtered_coords = harris.get_harris_points(harrisim, 6, 0.1)
imshow(im)
plot([p[1] for p in filtered_coords], [p[0] for p in filtered_coords], '*')
axis('off')
title(u'Harris角点',fontproperties=font)

show()

</code></pre> 
<p><img src="https://images2.imgbox.com/5a/5b/eK4KL3Hx_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="3_73"></a>3.描述子匹配（例题）</h4> 
<pre><code># -*- coding: utf-8 -*-
from PIL import Image
from pylab import *
import sys
from PCV.localdescriptors import sift


if len(sys.argv) &gt;= 3:
  im1f, im2f = sys.argv[1], sys.argv[2]
else:
#  im1f = '../data/sf_view1.jpg'
#  im2f = '../data/sf_view2.jpg'
  im1f = 'D:/xjx\pythonCode/pcv_data/data/crans_1_small.jpg'
  im2f = 'D:/xjx\pythonCode/pcv_data/data/crans_2_small.jpg'
#  im1f = '../data/climbing_1_small.jpg'
#  im2f = '../data/climbing_2_small.jpg'
im1 = array(Image.open(im1f))
im2 = array(Image.open(im2f))

sift.process_image(im1f, 'out_sift_1.txt')
l1, d1 = sift.read_features_from_file('out_sift_1.txt')
figure()
gray()
subplot(121)
sift.plot_features(im1, l1, circle=False)

sift.process_image(im2f, 'out_sift_2.txt')
l2, d2 = sift.read_features_from_file('out_sift_2.txt')
subplot(122)
sift.plot_features(im2, l2, circle=False)

#matches = sift.match(d1, d2)
matches = sift.match_twosided(d1, d2)
print '{} matches'.format(len(matches.nonzero()[0]))

figure()
gray()
sift.plot_matches(im1, im2, l1, l2, matches, show_below=True)
show()
</code></pre> 
<p><img src="https://images2.imgbox.com/09/99/Le3zhZsw_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="SIFT_117"></a>二.SIFT特征提取与检索（实验）</h3> 
<h4><a id="1__118"></a>1. 数据集准备</h4> 
<p><img src="https://images2.imgbox.com/a7/a8/vmx5nCFJ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="2__120"></a>2. 特征提取</h4> 
<h5><a id="21___121"></a>2.1 运行结果</h5> 
<p><img src="https://images2.imgbox.com/af/67/xObtP4i4_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="22___124"></a>2.2 分析</h5> 
<p>由实验结果可知，SIFT算法具有较好的稳定性和不变性，能够适应旋转、尺度缩放、亮度的变化，能在一定程度上不受视角变化、仿射变换、噪声的干扰。还具有多量性，就算只有单个物体，也能产生大量特征向量<br> 对比SIFT特征提取与Harris角点检测结果，可以看出Harris角点检测算法提取出的特征点明显低于SIFT算法。对于比较平坦的区域，Harris角点检测算法能检测到的特征点很少甚至没有。故而，由于无法检测到足够的特征点，Harris角点检测算法在特征点有效性、计算时效性以及特征点相似不变性三个方面均不如SIFT算法显的高效。</p> 
<h4><a id="3__129"></a>3. 描述子匹配</h4> 
<p><img src="https://images2.imgbox.com/92/84/oD4kQGgv_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ab/f0/InrPULqH_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="4__132"></a>4. 输出匹配图片</h4> 
<h5><a id="4_1__133"></a>4. 1 代码</h5> 
<pre><code>from PIL import Image
from pylab import *
from PCV.localdescriptors import sift
import matplotlib.pyplot as plt


im1f = 'D:/python/images/test_3/11.jpg'
im1 = array(Image.open(im1f))
sift.process_image(im1f, 'out_sift_1.txt')
l1, d1 = sift.read_features_from_file('out_sift_1.txt')

arr=[]
arrHash = {}
for i in range(1,15):

    im2f = (r'D:/python/images/test_3/'+str(i)+'.jpg')
    im2 = array(Image.open(im2f))
    sift.process_image(im2f, 'out_sift_2.txt')
    l2, d2 = sift.read_features_from_file('out_sift_2.txt')
    matches = sift.match_twosided(d1, d2)
    length=len(matches.nonzero()[0])
    length=int(length)
    arr.append(length)
    arrHash[length]=im2f

arr.sort()
arr=arr[::-1]
arr=arr[:3]
i=0
plt.figure(figsize=(5,12))
for item in arr:
    if(arrHash.get(item)!=None):
        img=arrHash.get(item)
        im1 = array(Image.open(img))
        ax=plt.subplot(511 + i)
        ax.set_title('{} matches'.format(item))
        plt.axis('off')
        imshow(im1)
        i = i + 1

plt.show()
</code></pre> 
<h5><a id="4_2__178"></a>4. 2 运行结果</h5> 
<p>输入：<br> <img src="https://images2.imgbox.com/8e/cd/Pu2krXxu_o.jpg" alt="在这里插入图片描述"></p> 
<p>输出：<br> <img src="https://images2.imgbox.com/11/a6/K7b5xLKW_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="__185"></a>三. 地理标记图像匹配</h3> 
<h4><a id="31__186"></a>3.1 代码</h4> 
<pre><code># -*- coding: utf-8 -*-
from pylab import *
from PIL import Image
from PCV.localdescriptors import sift
from PCV.tools import imtools
import pydot

""" This is the example graph illustration of matching images from Figure 2-10.
To download the images, see ch2_download_panoramio.py."""

#download_path = "panoimages"  # set this to the path where you downloaded the panoramio images
#path = "/FULLPATH/panoimages/"  # path to save thumbnails (pydot needs the full system path)

download_path = "F:/dropbox/Dropbox/translation/pcv-notebook/data/panoimages"  # set this to the path where you downloaded the panoramio images
path = "F:/dropbox/Dropbox/translation/pcv-notebook/data/panoimages/"  # path to save thumbnails (pydot needs the full system path)

# list of downloaded filenames
imlist = imtools.get_imlist(download_path)
nbr_images = len(imlist)

# extract features
featlist = [imname[:-3] + 'sift' for imname in imlist]
for i, imname in enumerate(imlist):
    sift.process_image(imname, featlist[i])

matchscores = zeros((nbr_images, nbr_images))

for i in range(nbr_images):
    for j in range(i, nbr_images):  # only compute upper triangle
        print 'comparing ', imlist[i], imlist[j]
        l1, d1 = sift.read_features_from_file(featlist[i])
        l2, d2 = sift.read_features_from_file(featlist[j])
        matches = sift.match_twosided(d1, d2)
        nbr_matches = sum(matches &gt; 0)
        print 'number of matches = ', nbr_matches
        matchscores[i, j] = nbr_matches
print "The match scores is: \n", matchscores

# copy values
for i in range(nbr_images):
    for j in range(i + 1, nbr_images):  # no need to copy diagonal
        matchscores[j, i] = matchscores[i, j]

#可视化

threshold = 2  # min number of matches needed to create link

g = pydot.Dot(graph_type='graph')  # don't want the default directed graph

for i in range(nbr_images):
    for j in range(i + 1, nbr_images):
        if matchscores[i, j] &gt; threshold:
            # first image in pair
            im = Image.open(imlist[i])
            im.thumbnail((100, 100))
            filename = path + str(i) + '.png'
            im.save(filename)  # need temporary files of the right size
            g.add_node(pydot.Node(str(i), fontcolor='transparent', shape='rectangle', image=filename))

            # second image in pair
            im = Image.open(imlist[j])
            im.thumbnail((100, 100))
            filename = path + str(j) + '.png'
            im.save(filename)  # need temporary files of the right size
            g.add_node(pydot.Node(str(j), fontcolor='transparent', shape='rectangle', image=filename))

            g.add_edge(pydot.Edge(str(i), str(j)))
g.write_png('whitehouse.png')
</code></pre> 
<h4><a id="32__259"></a>3.2 运行结果</h4> 
<p><img src="https://images2.imgbox.com/70/c8/EiHqBlYg_o.png" alt="在这里插入图片描述"></p> 
<ol><li>观察结果可知，数据集中只有9张图片形成关联，其他图片未形成关联，问题大概是所选图片数据集的不太好，导致结果误差偏大。</li><li>图片光线明暗和遮挡物以及角度对结果也颇有影响，较暗图片几乎都没有关联匹配的图片。</li></ol> 
<h3><a id="__265"></a>四. 实验中遇到的问题和得出的结论</h3> 
<p><mark>问题</mark></p> 
<ol><li>因为家里实在没有适合的场景可供拍摄，所以网上搜索的图匹配效果不那么好，影响了实验效果</li><li>图片开始像素过多， 导致程序运行电脑多次卡机，修改像素后有所改善</li><li>某些图片像素值不一样 ，导致图片无法匹配</li><li>安装pydot中出现诸多问题，应该先安装graphviz软件，再安装Pydot<br> (安装详细过程可参考<a href="https://blog.csdn.net/fy_eng/article/details/81366723?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task">详细教程</a>)</li></ol> 
<p><mark>结论</mark></p> 
<ol start="6"><li>SIFT特征不只具有尺度不变性，即使改变旋转角度，图像亮度或拍摄视角，仍然能够得到好的检测效果。</li><li>SIFT独特性好，信息量丰富，适合于在海量特征数据库中进行快速、准确的匹配。</li><li>SIFT有多量性，即使少数的几个物体也可以产生大量的SIFT特征向量。</li><li>相比于Harris角点检测，SIFT特征提取在特征点有效性、计算时效性以及特征点相似不变性几个方面都较为高效。</li></ol> 
<h3><a id="_RANSAC_282"></a>五. RANSAC原理及运用</h3> 
<h4><a id="51_RANSAC_283"></a>5.1 RANSAC——随机一致性采样</h4> 
<p>RANSAC主要解决样本中的外点问题，最多可处理50%的外点情况。</p> 
<p><mark>(1) 基本思想</mark></p> 
<p>RANSAC通过反复选择数据中的一组随机子集来达成目标。被选取的子集被假设为局内点，并用下述方法进行验证：</p> 
<ol><li>有一个模型适用于假设的局内点，即所有的未知参数都能从假设的局内点计算得出。</li><li>用1中得到的模型去测试所有的其它数据，如果某个点适用于估计的模型，认为它也是局内点。</li><li>如果有足够多的点被归类为假设的局内点，那么估计的模型就足够合理。</li><li>然后，用所有假设的局内点去重新估计模型，因为它仅仅被初始的假设局内点估计过。</li><li>最后，通过估计局内点与模型的错误率来评估模型。</li></ol> 
<p>这个过程被重复执行固定的次数，每次产生的模型要么因为局内点太少而被舍弃，要么因为它比现有的模型更好而被选用。<br> <img src="https://images2.imgbox.com/a6/bc/tSW6kjdQ_o.jpg" alt="在这里插入图片描述"><br> <mark>(2) 步骤</mark></p> 
<ol><li>随机选择四对匹配特征</li><li>根据DLT计算单应矩阵 H (唯一解)</li><li>对所有匹配点，计算映射误差ε= ||pi’, H pi||</li><li>根据误差阈值，确定inliers（例如3-5像素）</li><li>针对最大inliers集合，重新计算单应矩阵 H</li></ol> 
<h4><a id="52__306"></a>5.2 示例</h4> 
<p>1.在给定若干二维空间中的点，求直线 y=ax+b ，使得该直线对空间点的拟合误差最小。<br> <img src="https://images2.imgbox.com/bd/31/VguH52aN_o.png" alt="在这里插入图片描述"><br> 2.随机选择两个点，根据这两个点构造直线，再计算剩余点到该直线的距离<br> 给定阈值（距离小于设置的阈值的点为inliers），计算inliers数量<br> <img src="https://images2.imgbox.com/31/b0/U7dJ2ICn_o.png" alt="在这里插入图片描述"><br> 3.再随机选取两个点，同样计算inliers数量<br> <img src="https://images2.imgbox.com/d5/a2/i7P5XXZH_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/13/8f/D06A8Js8_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/fe/29/xPbf7bMq_o.png" alt="在这里插入图片描述"><br> 4.循环迭代，其中inliers最大的点集即为最大一致集，最后将该最大一致集里面的点利用最小二乘拟合出一条直线。</p> 
<h4><a id="53_RANSAC_318"></a>5.3 使用RANSAC算法匹配</h4> 
<h5><a id="531__319"></a>5.3.1 源代码</h5> 
<pre><code># ch3_panorama_test.py
from pylab import *
from numpy import *
from PIL import Image

# If you have PCV installed, these imports should work
from PCV.geometry import homography, warp
from PCV.localdescriptors import sift

import os
root=os.getcwd()+"\\"

"""
This is the panorama example from section 3.3.
"""

# set paths to data folder
featname = ['../data/wanren/uu' + str(i + 1) + '.sift' for i in range(5)]
imname = ['../data/wanren/uu' + str(i + 1) + '.jpg' for i in range(5)]

# extract features and match
l = {}
d = {}
for i in range(5):
    sift.process_image(root+imname[i], root+featname[i])
    l[i], d[i] = sift.read_features_from_file(featname[i])

matches = {}
for i in range(4):
    matches[i] = sift.match(d[i + 1], d[i])

# visualize the matches (Figure 3-11 in the book)
for i in range(4):
    im1 = array(Image.open(imname[i]))
    im2 = array(Image.open(imname[i + 1]))
    figure()
    sift.plot_matches(im2, im1, l[i + 1], l[i], matches[i], show_below=True)


# function to convert the matches to hom. points
def convert_points(j):
    ndx = matches[j].nonzero()[0]
    fp = homography.make_homog(l[j + 1][ndx, :2].T)
    ndx2 = [int(matches[j][i]) for i in ndx]
    tp = homography.make_homog(l[j][ndx2, :2].T)

    # switch x and y - TODO this should move elsewhere
    fp = vstack([fp[1], fp[0], fp[2]])
    tp = vstack([tp[1], tp[0], tp[2]])
    return fp, tp


# estimate the homographies
model = homography.RansacModel()

fp, tp = convert_points(1)
H_12 = homography.H_from_ransac(fp, tp, model)[0]  # im 1 to 2

fp, tp = convert_points(0)
H_01 = homography.H_from_ransac(fp, tp, model)[0]  # im 0 to 1

tp, fp = convert_points(2)  # NB: reverse order
H_32 = homography.H_from_ransac(fp, tp, model)[0]  # im 3 to 2

tp, fp = convert_points(3)  # NB: reverse order
H_43 = homography.H_from_ransac(fp, tp, model)[0]  # im 4 to 3

# warp the images
delta = 2000  # for padding and translation

im1 = array(Image.open(imname[1]), "uint8")
im2 = array(Image.open(imname[2]), "uint8")
im_12 = warp.panorama(H_12, im1, im2, delta, delta)

im1 = array(Image.open(imname[0]), "f")
im_02 = warp.panorama(dot(H_12, H_01), im1, im_12, delta, delta)

im1 = array(Image.open(imname[3]), "f")
im_32 = warp.panorama(H_32, im1, im_02, delta, delta)

im1 = array(Image.open(imname[4]), "f")
im_42 = warp.panorama(dot(H_32, H_43), im1, im_32, delta, 2 * delta)

figure()
imshow(array(im_42, "uint8"))
axis('off')
savefig("quanjing.png", dpi=300)
show()



</code></pre> 
<h5><a id="532__414"></a>5.3.2 结果分析</h5> 
<p><mark>景深丰富：</mark></p> 
<p><strong>有RANSAC:</strong><br> 第一组：<br> <img src="https://images2.imgbox.com/0e/75/KncUEMxP_o.png" alt="在这里插入图片描述"><br> 第二组：<br> <img src="https://images2.imgbox.com/1d/0c/EQJlGKmf_o.png" alt="在这里插入图片描述"><br> 第三组：<br> <img src="https://images2.imgbox.com/cc/63/l1BV1ORm_o.png" alt="在这里插入图片描述"><br> <strong>无RANSAC的第一组匹配结果:</strong><br> <img src="https://images2.imgbox.com/b5/5d/MdH1ud56_o.png" alt="在这里插入图片描述"><br> 此结果显示特征匹配不够细致</p> 
<p><mark>景深单一：</mark><br> <strong>有RANSAC:</strong><br> <img src="https://images2.imgbox.com/ae/5c/MAo5j4KB_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/80/cc/bYFPnSSC_o.png" alt="在这里插入图片描述"><br> 景深单一匹配到的特征较少，且此组照片不能拼接，暂且不知原因；</p> 
<p><strong>无RANSAC:</strong><br> <img src="https://images2.imgbox.com/d7/7f/NmmMhIHh_o.png" alt="在这里插入图片描述"><br> 结果显示0匹配；</p> 
<p><strong>实验遇到的问题：</strong><br> 多组实验图片拼接效果都不理想，黑暗区域较多，原因暂且未知，或许是拍摄手法的问题。<br> 实验拼接效果的数据集：<img src="https://images2.imgbox.com/ca/b9/Sk5o3hwJ_o.png" alt="在这里插入图片描述"><br> 结果：<br> ？？？<img src="https://images2.imgbox.com/8b/be/fp33RaYX_o.png" alt="在这里插入图片描述"></p> 
<p><strong>经多次试验结果归纳及对比可知：</strong></p> 
<ol><li>在运用RANSAC 的算法中，景深丰富的场景匹配效果更精确，错误匹配减少；</li><li>未运用RANSAC的算法中，景深单一的场景甚至匹配不到特征，但运用RANSAC后，可精确匹配少数特征，但差别不大；</li><li>可知RANSAC不仅能删除错误匹配，在细节处理方面也更细致；</li></ol>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4db8dbc7901a7d547e7b8c1ef4a2a13c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">计算机视觉-SIFT特征提取及匹配</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e8223287c4ce184c08041c1483ac8042/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">GB/T 35273—2020《信息安全技术个人信息安全规范》正式发布</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>