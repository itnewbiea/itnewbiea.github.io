<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>7. Flink on yarn模式部署以及flink和hive的集成 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="7. Flink on yarn模式部署以及flink和hive的集成" />
<meta property="og:description" content="文章目录 1. Flink Yarn 模式高可用性配置(自己通过源码编译的Flink)2. Hive2.1. Hive简介2.2. Hive的数据存储2.3. [Hive基本架构](https://blog.csdn.net/u013595419/article/details/79632928)2.4. [Hive为什么要启用Metastore](https://blog.csdn.net/qq_35440040/article/details/82462269)2.5. [hive集群搭建](https://blog.csdn.net/yangang1223/article/details/80183038) 3. [Hive Integration](https://ci.apache.org/projects/flink/flink-docs-release-1.10/zh/dev/table/hive/)4. [Flink 1.10 SQL、HiveCatalog与事件时间整合示例](https://www.jianshu.com/p/fe49b8f25313)5. 寄语：当你遇到困难时，你会如何去面对， 这将会决定你的人生最终能够走多远! 1. Flink Yarn 模式高可用性配置(自己通过源码编译的Flink) 本次采用自编译（基于Flink-1.10，hadoop-2.9.2）搭建集群
flink-shaded-hadoop-2-uber官方链接
参考链接
Flink高可用集群搭建Flink JobManager HA高可用flink on yarn模式下两种提交job方式 启动集群时遇到的错误
错误一
java.lang.NoSuchMethodError: org.apache.commons.cli.Option.builder(Ljava/lang/String;)Lorg/apache/commons/cli/Option$Builder; at org.apache.flink.yarn.cli.FlinkYarnSessionCli.&lt;init&gt;(FlinkYarnSessionCli.java:197) at org.apache.flink.yarn.cli.FlinkYarnSessionCli.&lt;init&gt;(FlinkYarnSessionCli.java:173) at org.apache.flink.yarn.cli.FlinkYarnSessionCli.main(FlinkYarnSessionCli.java:836) 解决方案
在 flink-shaded-9.0/flink-shaded-hadoop-2-uber/pom.xml 中的 dependencyManagement 标签中添加如下依赖Apache Commons CLI » 1.4；重新编译mvn clean install -DskipTests -Drat.skip=true -Pvendor-repos -Dhadoop.version=2.9.2;最后再重新编译flink源码mvn clean package -T 4 -Dfast -Drat.skip=true -Pinclude-hadoop -Dhadoop.version=2.9.2 -Dmaven.compile.fork=true -DskipTests -Dscala-2.11
错误二" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/2b0acd4950999f9f67386877629b8267/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-03-29T18:21:48+08:00" />
<meta property="article:modified_time" content="2020-03-29T18:21:48+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">7. Flink on yarn模式部署以及flink和hive的集成</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1_Flink_Yarn_Flink_1" rel="nofollow">1. Flink Yarn 模式高可用性配置(自己通过源码编译的Flink)</a></li><li><a href="#2_Hive_131" rel="nofollow">2. Hive</a></li><li><ul><li><a href="#21_Hive_132" rel="nofollow">2.1. Hive简介</a></li><li><a href="#22_Hive_137" rel="nofollow">2.2. Hive的数据存储</a></li><li><a href="#23_Hivehttpsblogcsdnnetu013595419articledetails79632928_146" rel="nofollow">2.3. [Hive基本架构](https://blog.csdn.net/u013595419/article/details/79632928)</a></li><li><a href="#24_HiveMetastorehttpsblogcsdnnetqq_35440040articledetails82462269_149" rel="nofollow">2.4. [Hive为什么要启用Metastore](https://blog.csdn.net/qq_35440040/article/details/82462269)</a></li><li><a href="#25_hivehttpsblogcsdnnetyangang1223articledetails80183038_155" rel="nofollow">2.5. [hive集群搭建](https://blog.csdn.net/yangang1223/article/details/80183038)</a></li></ul> 
  </li><li><a href="#3_Hive_Integrationhttpsciapacheorgprojectsflinkflinkdocsrelease110zhdevtablehive_160" rel="nofollow">3. [Hive Integration](https://ci.apache.org/projects/flink/flink-docs-release-1.10/zh/dev/table/hive/)</a></li><li><a href="#4_Flink_110_SQLHiveCataloghttpswwwjianshucompfe49b8f25313_192" rel="nofollow">4. [Flink 1.10 SQL、HiveCatalog与事件时间整合示例](https://www.jianshu.com/p/fe49b8f25313)</a></li><li><a href="#5___194" rel="nofollow">5. 寄语：当你遇到困难时，你会如何去面对， 这将会决定你的人生最终能够走多远!</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1_Flink_Yarn_Flink_1"></a>1. Flink Yarn 模式高可用性配置(自己通过源码编译的Flink)</h2> 
<p><code>本次采用自编译（基于Flink-1.10，hadoop-2.9.2）搭建集群</code></p> 
<ul><li> <p><a href="https://repo.maven.apache.org/maven2/org/apache/flink/flink-shaded-hadoop-2-uber/" rel="nofollow">flink-shaded-hadoop-2-uber官方链接</a></p> </li><li> <p>参考链接</p> 
  <ul><li><a href="https://www.jianshu.com/p/4dc0a980e7e9" rel="nofollow">Flink高可用集群搭建</a></li><li><a href="https://www.jianshu.com/p/ee30a5da90ba?tdsourcetag=s_pcqq_aiomsg" rel="nofollow">Flink JobManager HA高可用</a></li><li><a href="https://www.cnblogs.com/asker009/p/11327533.html" rel="nofollow">flink on yarn模式下两种提交job方式</a></li></ul> </li><li> <p><mark>启动集群时遇到的错误</mark></p> 
  <ul><li> <p>错误一</p> <pre><code>java.lang.NoSuchMethodError: org.apache.commons.cli.Option.builder(Ljava/lang/String;)Lorg/apache/commons/cli/Option$Builder;
	at org.apache.flink.yarn.cli.FlinkYarnSessionCli.&lt;init&gt;(FlinkYarnSessionCli.java:197)
	at org.apache.flink.yarn.cli.FlinkYarnSessionCli.&lt;init&gt;(FlinkYarnSessionCli.java:173)
	at org.apache.flink.yarn.cli.FlinkYarnSessionCli.main(FlinkYarnSessionCli.java:836)
</code></pre> </li><li> <p><code>解决方案</code><br> 在 flink-shaded-9.0/<code>flink-shaded-hadoop-2-uber</code>/pom.xml 中的 dependencyManagement 标签中添加如下依赖<a href="https://mvnrepository.com/artifact/commons-cli/commons-cli/1.4" rel="nofollow">Apache Commons CLI » 1.4</a>；重新编译<code>mvn clean install -DskipTests -Drat.skip=true -Pvendor-repos -Dhadoop.version=2.9.2</code>;最后再重新编译flink源码<code>mvn clean package -T 4 -Dfast -Drat.skip=true -Pinclude-hadoop -Dhadoop.version=2.9.2 -Dmaven.compile.fork=true -DskipTests -Dscala-2.11</code><br> <img src="https://images2.imgbox.com/d5/c2/0KLNn6NP_o.png" alt="在这里插入图片描述"></p> </li><li> <p>错误二</p> <pre><code>java.io.IOException: Could not create FileSystem for highly available storage path (hdfs://xiaofan/flink/ha/default)
        at org.apache.flink.runtime.blob.BlobUtils.createFileSystemBlobStore(BlobUtils.java:103)
        at org.apache.flink.runtime.blob.BlobUtils.createBlobStoreFromConfig(BlobUtils.java:89)
        at org.apache.flink.runtime.highavailability.HighAvailabilityServicesUtils.createHighAvailabilityServices(HighAvailabilityServicesUtils.java:125)
        at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.&lt;init&gt;(TaskManagerRunner.java:132)
        at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.runTaskManager(TaskManagerRunner.java:308)
        at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.lambda$runTaskManagerSecurely$2(TaskManagerRunner.java:322)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
        at org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)
        at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.runTaskManagerSecurely(TaskManagerRunner.java:321)
        at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.main(TaskManagerRunner.java:287)
Caused by: java.io.IOException: Cannot instantiate file system for URI: hdfs://xiaofan/flink/ha/default
        at org.apache.flink.runtime.fs.hdfs.HadoopFsFactory.create(HadoopFsFactory.java:192)
        at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:446)
        at org.apache.flink.core.fs.FileSystem.get(FileSystem.java:362)
        at org.apache.flink.core.fs.Path.getFileSystem(Path.java:298)
        at org.apache.flink.runtime.blob.BlobUtils.createFileSystemBlobStore(BlobUtils.java:100)
        ... 11 more
Caused by: java.lang.IllegalArgumentException: java.net.UnknownHostException: xiaofan
        at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:443)
        at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:132)
        at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:351)
        at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:285)
        at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:164)
        at org.apache.flink.runtime.fs.hdfs.HadoopFsFactory.create(HadoopFsFactory.java:164)
        ... 15 more
Caused by: java.net.UnknownHostException: xiaofan
        ... 21 more
</code></pre> </li><li> <p><code>解决方案:</code>修改配置文件<br> <img src="https://images2.imgbox.com/9b/c2/o4FYnY6A_o.png" alt="在这里插入图片描述"></p> </li></ul> </li><li> <p><a href="https://www.jianshu.com/p/b58988bcfb48" rel="nofollow">Flink–对parallelism 和 slot的理解</a></p> 
  <ul><li>每个 Flink TaskManager 在集群中提供 slot。 slot 的数量通常与每个 TaskManager 的可用 CPU 内核数成比例。<code>一般情况下你的 slot 数是你每个 TaskManager 的 cpu 的核数。</code><br> <img src="https://images2.imgbox.com/2e/3f/5e9BkZiv_o.png" alt="在这里插入图片描述"></li><li>parallelism 是指 taskmanager 实际使用的并发能力<br> <img src="https://images2.imgbox.com/fa/cd/ZGblcjTD_o.png" alt="在这里插入图片描述"></li></ul> </li><li> <p><mark>Flink集群高可用HA测试</mark></p> 
  <ul><li> <p><code>standalone模式</code></p> 
    <ul><li>启动集群<br> <img src="https://images2.imgbox.com/ed/d0/Kt2mcDzG_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/09/53/cPW3TWBS_o.png" alt="在这里插入图片描述"></li><li>浏览器访问<code>由于端口占用，我用了8083端口号</code><br> <img src="https://images2.imgbox.com/a2/47/kl1GoK88_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/88/42/j7qgpmk3_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/76/bf/H7zdlrJY_o.png" alt="在这里插入图片描述"></li><li>关闭集群<br> <img src="https://images2.imgbox.com/e3/eb/rQB6xSK2_o.png" alt="在这里插入图片描述"></li></ul> </li><li> <p><code>Flink On Yarn模式</code></p> 
    <ul><li> <p>首先需要修改hadoop中 yarn-site.xml 中的配置，设置提交应用程序的最大尝试次数</p> <pre><code>&lt;property&gt;
	&lt;name&gt;yarn.resourcemanager.am.max-attempts&lt;/name&gt;
	&lt;value&gt;8&lt;/value&gt;
	&lt;description&gt;
		The maximum number of application master execution attempts.
	&lt;/description&gt;
&lt;/property&gt;
</code></pre> </li><li> <p>配置Yarn重试次数（<code>此参数代表Flink Job（yarn中称为application）在Jobmanager（或者叫Application Master）恢复时，允许重启的最大次数。</code>）</p> <pre><code>vi conf/flink-conf.yaml
yarn.application-attempts: 8
</code></pre> </li><li> <p><mark>注意：Flink On Yarn环境中，当Jobmanager（Application Master）失败时，yarn会尝试重启JobManager（AM），重启后，会重新启动Flink的Job（application）。因此，yarn.application-attempts的设置不应该超过yarn.resourcemanager.am.max-attemps.</mark></p> </li><li> <p>Flink on yarn实现逻辑<br> <img src="https://images2.imgbox.com/2d/90/DB9b7Ym4_o.png" alt="在这里插入图片描述"></p> </li><li> <p><mark>启动方式</mark></p> 
      <ul><li> <p><strong>第一种方式</strong>(<code>启动一个一直运行的flink集群</code>)：<code>yarn-session.sh</code>(开辟资源)+<code>flink run</code>(提交任务)</p> <pre><code># 下面的命令会申请4个taskmanager，每个1G内存和2个solt，超过集群总资源将会启动失败。
./bin/yarn-session.sh -n 4 -tm 1024 -s 2 --nm xiaofan-flink -d
</code></pre> 
        <ul><li>-n ,–container 分配多少个yarn容器（=taskmanager的数量）</li><li>-D 动态属性</li><li>-d, --detached 独立运行</li><li>-jm,–jobManagerMemory JobManager的内存 [in MB]</li><li>-nm,–name 在YARN上为一个自定义的应用设置一个名字</li><li>-q,–query 显示yarn中可用的资源 (内存, cpu核数)</li><li>-qu,–queue 指定YARN队列.</li><li>-s,–slots 每个TaskManager使用的slots(vcore)数量</li><li>-tm,–taskManagerMemory 每个TaskManager的内存 [in MB]</li><li>-z,–zookeeperNamespace 针对HA模式在zookeeper上创建NameSpace</li></ul> </li><li> <p>运行结果如图<br> <img src="https://images2.imgbox.com/83/fe/x4s4H8dF_o.png" alt="在这里插入图片描述"></p> </li><li> <p>浏览器中访问 <code>http://baojiabei:8083</code><br> <img src="https://images2.imgbox.com/d3/2c/e5Om7qj3_o.png" alt="在这里插入图片描述"></p> </li><li> <p>yarn web-ui中<code>http://192.168.1.27:8088</code><br> <img src="https://images2.imgbox.com/c4/bb/8R3wzeYC_o.png" alt="在这里插入图片描述"></p> </li><li> <p><code>注意：部署长期运行的flink on yarn实例后，在flink web上看到的TaskManager以及Slots都为0。只有在提交任务的时候，才会依据分配资源给对应的任务执行</code></p> </li><li> <p>提交Job到长期运行的flink on yarn实例上（<code>注意：要在FlinkYarnSessionCli启动的节点上提交</code>）</p> <pre><code>./bin/flink run ./examples/batch/WordCount.jar -input hdfs://cluster/words.txt -output hdfs://cluster/flink-word-count
</code></pre> </li><li> <p>通过web ui可以看到已经运行完成的任务<br> <img src="https://images2.imgbox.com/9f/31/F087mih9_o.png" alt="在这里插入图片描述"></p> </li><li> <p><strong>第二种启动方式</strong>flink run -m yarn-cluster(开辟资源+提交任务)</p> <pre><code> ./bin/flink run -m yarn-cluster  ./examples/batch/WordCount.jar -input hdfs://cluster/words.txt -output hdfs://cluster/flink-word-count—2
</code></pre> </li><li> <p><code>注意jar包的位置</code></p> </li><li> <p>运行结果<br> <img src="https://images2.imgbox.com/ae/0b/N5vuU1Ng_o.png" alt="在这里插入图片描述"></p> </li></ul> </li></ul> </li></ul> </li></ul> 
<h2><a id="2_Hive_131"></a>2. Hive</h2> 
<h3><a id="21_Hive_132"></a>2.1. Hive简介</h3> 
<ul><li>Hive是基于Hadoop的一个离线数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。</li><li>元数据存储：Hive 将元数据存储在数据库中。<code>Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</code></li><li>Hive可以自由的扩展集群的规模，一般情况下不需要重启服务。</li></ul> 
<h3><a id="22_Hive_137"></a>2.2. Hive的数据存储</h3> 
<ul><li>Hive中所有的数据都存储在 HDFS 中，没有专门的数据存储格式（可支持Text，SequenceFile，ParquetFile，RCFILE等）</li><li>只需要在创建表的时候告诉 Hive 数据中的列分隔符和行分隔符，Hive 就可以解析数据。</li><li>Hive 中包含以下数据模型：<code>DB</code>、<code>Table</code>，<code>External Table</code>，<code>Partition</code>，<code>Bucket</code>。 
  <ul><li>db：在hdfs中表现为${hive.metastore.warehouse.dir}目录下一个文件夹</li><li>table：在hdfs中表现所属db目录下一个文件夹</li><li>external table：与table类似，不过其数据存放位置可以在任意指定路径</li><li>partition：在hdfs中表现为table目录下的子目录</li><li>bucket：在hdfs中表现为同一个表目录下根据hash散列之后的多个文件</li></ul> </li></ul> 
<h3><a id="23_Hivehttpsblogcsdnnetu013595419articledetails79632928_146"></a>2.3. <a href="https://blog.csdn.net/u013595419/article/details/79632928">Hive基本架构</a></h3> 
<p><img src="https://images2.imgbox.com/db/a2/PTqksLmI_o.png" alt=""><br> <img src="https://images2.imgbox.com/36/af/qtDzrV6Q_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="24_HiveMetastorehttpsblogcsdnnetqq_35440040articledetails82462269_149"></a>2.4. <a href="https://blog.csdn.net/qq_35440040/article/details/82462269">Hive为什么要启用Metastore</a></h3> 
<ul><li>服务端metastore 启动方式：<code>hive --service metastore -p 9083 &amp;</code></li><li>hiveserver2启动方式：前台<code>bin/hiveserver2</code> 后台<code>nohup bin/hiveserver2 1&gt;/var/log/hiveserver.log 2&gt;/var/log/hiveserver.err &amp;</code>（注意权限问题）</li><li>client端链接hiveserver2：<code>bin/beeline -u jdbc:hive2://192.168.1.27:10000 -n hadoop</code><br> <img src="https://images2.imgbox.com/56/39/bENYwBDA_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6f/67/1t0kDIHz_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="25_hivehttpsblogcsdnnetyangang1223articledetails80183038_155"></a>2.5. <a href="https://blog.csdn.net/yangang1223/article/details/80183038">hive集群搭建</a></h3> 
<ul><li><a href="https://blog.csdn.net/luckyzsion/article/details/89471441">centos6 mysql安装</a> 
  <ul><li><a href="https://blog.csdn.net/hello_world_qwp/article/details/79551789">ERROR 1819 (HY000): Your password does not satisfy the current policy requirements</a></li></ul> </li><li><a href="https://www.cnblogs.com/julyme/p/5969626.html" rel="nofollow">centos7 mysql安装</a></li><li><a href="https://blog.csdn.net/lu1171901273/article/details/86515310">安装hive2.3.4</a></li></ul> 
<h2><a id="3_Hive_Integrationhttpsciapacheorgprojectsflinkflinkdocsrelease110zhdevtablehive_160"></a>3. <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/zh/dev/table/hive/" rel="nofollow">Hive Integration</a></h2> 
<ul><li>${FLINK_HOME}/lib目录添加jar包<br> <img src="https://images2.imgbox.com/79/b1/zFjvI8GM_o.png" alt="在这里插入图片描述"></li><li>HiveCatalog 
  <ul><li> <p>启动metastore服务， 并通过hive客户端测试连接该服务</p> </li><li> <p>配置Flink群集和SQL CLI</p> </li><li> <p>建立Kafka集群，并验验证集群</p> 
    <ul><li>生产端生产数据<code>bin/kafka-console-producer.sh --broker-list 192.168.1.25:9091 --topic xiaofan_test</code></li><li>消费端消费数据<code>bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.25:9091 --topic xiaofan_test --from-beginning</code></li></ul> </li><li> <p>启动SQL Client，并使用Flink SQL DDL创建一个Kafka表</p> <pre><code>CREATE TABLE mykafka (name String, age Int) WITH (
   'connector.type' = 'kafka',
   'connector.version' = 'universal',
   'connector.topic' = 'xiaofan_test',
   'connector.properties.zookeeper.connect' = '192.168.1.23:2181',
   'connector.properties.bootstrap.servers' = '192.168.1.23:9091',
   'format.type' = 'csv',
   'update-mode' = 'append'
);
</code></pre> <p><img src="https://images2.imgbox.com/36/73/VyHOakoa_o.png" alt="在这里插入图片描述"></p> </li><li> <p>通过Hive Cli验证该表对Hive也可见，并注意该表具有属性is_generic=true：<br> <img src="https://images2.imgbox.com/74/95/INC36YVS_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/7d/6e/ZTwnAteW_o.png" alt="在这里插入图片描述"></p> </li><li> <p>运行Flink SQL查询Kakfa表, 在Kafka主题中产生更多消息,应该立即在SQL Client中看到Flink产生的结果，如下所示<br> <img src="https://images2.imgbox.com/a5/ae/otkWRDsA_o.png" alt="在这里插入图片描述"></p> </li><li> <p><code>注意：要在${FLINK_HOME}/lib目录下面配置相关的jar</code><br> <img src="https://images2.imgbox.com/67/d1/aRIBVuYy_o.png" alt="在这里插入图片描述"></p> </li></ul> </li></ul> 
<h2><a id="4_Flink_110_SQLHiveCataloghttpswwwjianshucompfe49b8f25313_192"></a>4. <a href="https://www.jianshu.com/p/fe49b8f25313" rel="nofollow">Flink 1.10 SQL、HiveCatalog与事件时间整合示例</a></h2> 
<h2><a id="5___194"></a>5. 寄语：当你遇到困难时，你会如何去面对， 这将会决定你的人生最终能够走多远!</h2>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/aeaa97e1c2056371a68fad29807a6faa/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">反编译工具.NET Reactor  简明教程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8134e3b69c20bf34ad7dc824c7503174/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">IEEE trans模板格式中左下角添加脚注的方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>