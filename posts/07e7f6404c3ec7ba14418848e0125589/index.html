<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>从2D图像如何生成3D模型（点云）深度学习的方法 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="从2D图像如何生成3D模型（点云）深度学习的方法" />
<meta property="og:description" content="原文地址：https://chenhsuanlin.bitbucket.io/3D-point-cloud-generation/paper.pdf
摘要：
对于3D物体的重建，信息主要丰富在表面。本文的目的在于以密集点云的形式表示3D模型，
这边文章讲的就是用2D图像如何生成3D模型。2D图像也是从3D的世界投影来的，从3D到2D必然是缺少了很多信息的，所以单一视角的2D图像是不可能恢复出3D模型的。如果非要的必须要有一些先验知识。
作者说采用这种编码解码学习一个压缩的表达，是最有希望的方式（黑人问号？）
关于3D模型的表达方式，有以下三种：
先看看体素网格：
体素网格就是用规则的有体积的小网格去表达3D模型，会损失一些细节，当分辨率越高，需要的小网格也就越多，但其实我们只需要表面的，所以就算量比较大，要衡量分辨率和计算量之间的权衡，不过这种表达方式还是比较容易地输入到CNN里面。
多边形网丝：由顶点、边缘和朝向（定义表面的3要素）组成，它可以抓住细小的细节。
点云：（x,y,z),点云数量越多表达的越细节。
以上两个优点在于表达细腻，但是不能直接用于CNN网络
方案：
我们使用点云紧实的的表达和传统的2d 卷积，学习先验的形状信息。
第一步：3D结构生成器 该模块根据2D的RGB图和物体对应的binary mask预测像素点的三维坐标（x,y,z)，
该步骤的输入输出为：
其中：2D projection == 3D coordinates (x,y,z) &#43; binary mask (m)
第二步：Point Cloud Fusion（点云融合）
融合点云成3D模型，这是可行的（因为每幅图像对应的3D姿态是固定的且事先知道的）
其输入输出如下：
第三步：根据3D模型生成新的2D投影，跟GroundTruth比对计算loss
其输入输出如下：
也就是说如果生成的3D模型是接近真实的，那么新视角的投影应该也是接近真实的ground_truth
总体的流程如下图所示：
结果对比： 下图是真实的点云信息和生成的点云信息的对比：
最终的结果：
总结： 本文确实是从一系列的2D图像以及每张图片对应的映射矩阵生成3D模型，最聪明的举动在于融合和新角度的渲染生成，陈生了差异以及几何意义，利用这种差异我们才能从2D投影学习到3D点云。
代码地址： Pytorch code: https://github.com/lkhphuc/pytorch-3d-point-cloud-generation
Tensorflow code: https://github.com/chenhsuanlin/3D-point-cloud-generation
Paper: https://arxiv.org/abs/1706.07036
Original project website: https://chenhsuanlin.bitbucket.io/3D-point-cloud-generation/" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/07e7f6404c3ec7ba14418848e0125589/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-04-24T17:53:44+08:00" />
<meta property="article:modified_time" content="2020-04-24T17:53:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">从2D图像如何生成3D模型（点云）深度学习的方法</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>原文地址：https://chenhsuanlin.bitbucket.io/3D-point-cloud-generation/paper.pdf<br> 摘要：<br> 对于3D物体的重建，信息主要丰富在表面。本文的目的在于以密集点云的形式表示3D模型，<br> 这边文章讲的就是用2D图像如何生成3D模型。2D图像也是从3D的世界投影来的，从3D到2D必然是缺少了很多信息的，所以单一视角的2D图像是不可能恢复出3D模型的。如果非要的必须要有一些先验知识。<br> <img src="https://images2.imgbox.com/8f/0f/Z0oF87s5_o.png" alt="在这里插入图片描述"><br> 作者说采用这种编码解码学习一个压缩的表达，是最有希望的方式（黑人问号？）<br> <img src="https://images2.imgbox.com/a0/e0/SbT9D8xC_o.png" alt="在这里插入图片描述"><br> 关于3D模型的表达方式，有以下三种：<br> <img src="https://images2.imgbox.com/cd/6f/yn1oWOiL_o.png" alt="在这里插入图片描述"><br> 先看看体素网格：<br> 体素网格就是用规则的有体积的小网格去表达3D模型，会损失一些细节，当分辨率越高，需要的小网格也就越多，但其实我们只需要表面的，所以就算量比较大，要衡量分辨率和计算量之间的权衡，不过这种表达方式还是比较容易地输入到CNN里面。<br> <img src="https://images2.imgbox.com/e9/fd/0R8F9Znb_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/72/b7/QDVyoQWp_o.png" alt="在这里插入图片描述"><br> 多边形网丝：由顶点、边缘和朝向（定义表面的3要素）组成，它可以抓住细小的细节。<br> 点云：（x,y,z),点云数量越多表达的越细节。<br> 以上两个优点在于表达细腻，但是不能直接用于CNN网络<br> 方案：<br> 我们使用点云紧实的的表达和传统的2d 卷积，学习先验的形状信息。</p> 
<h3><a id="3D_19"></a>第一步：3D结构生成器</h3> 
<p>该模块根据2D的RGB图和物体对应的binary mask预测像素点的三维坐标（x,y,z)，<br> <img src="https://images2.imgbox.com/03/a1/Z2npBncA_o.png" alt="在这里插入图片描述"><br> 该步骤的输入输出为：<br> <img src="https://images2.imgbox.com/97/4a/gxvFYAUV_o.png" alt="在这里插入图片描述"><br> 其中：2D projection == 3D coordinates (x,y,z) + binary mask (m)</p> 
<p>第二步：Point Cloud Fusion（点云融合）<br> <img src="https://images2.imgbox.com/31/fc/NWagn6DJ_o.png" alt="在这里插入图片描述"><br> 融合点云成3D模型，这是可行的（因为每幅图像对应的3D姿态是固定的且事先知道的）<br> 其输入输出如下：<br> <img src="https://images2.imgbox.com/67/30/vleukr3p_o.png" alt="在这里插入图片描述"><br> 第三步：根据3D模型生成新的2D投影，跟GroundTruth比对计算loss<br> <img src="https://images2.imgbox.com/b5/0f/JrpQmxPi_o.png" alt="在这里插入图片描述"><br> 其输入输出如下：<img src="https://images2.imgbox.com/66/e9/1LDDAY9M_o.png" alt="在这里插入图片描述"><br> 也就是说如果生成的3D模型是接近真实的，那么新视角的投影应该也是接近真实的ground_truth</p> 
<p>总体的流程如下图所示：<br> <img src="https://images2.imgbox.com/b1/af/Bgtz1R4p_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_41"></a>结果对比：</h3> 
<p>下图是真实的点云信息和生成的点云信息的对比：<br> <img src="https://images2.imgbox.com/cd/c9/FX5rGJTo_o.png" alt="在这里插入图片描述"><br> 最终的结果：<br> <img src="https://images2.imgbox.com/31/48/gvppR43Z_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_47"></a>总结：</h3> 
<p>本文确实是从一系列的2D图像以及每张图片对应的映射矩阵生成3D模型，最聪明的举动在于融合和新角度的渲染生成，陈生了差异以及几何意义，利用这种差异我们才能从2D投影学习到3D点云。</p> 
<h3><a id="_50"></a>代码地址：</h3> 
<p>Pytorch code: https://github.com/lkhphuc/pytorch-3d-point-cloud-generation<br> Tensorflow code: https://github.com/chenhsuanlin/3D-point-cloud-generation<br> Paper: https://arxiv.org/abs/1706.07036<br> Original project website: https://chenhsuanlin.bitbucket.io/3D-point-cloud-generation/</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/03700c23ac061d14be8cf9f01fea597c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">交换两变量值--两种较高效率方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/85657b8520a1e3e2d287523ff62e15ce/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C语言浮点数的输出方法和示例</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>