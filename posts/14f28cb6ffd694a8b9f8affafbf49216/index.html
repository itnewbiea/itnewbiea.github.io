<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>图神经网络学习4 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="图神经网络学习4" />
<meta property="og:description" content="节点的预测任务 首先定义图神经网络的网络结构，这里使用了torch_geometric.nn.Sequential容器，详细内容可见于官方文档。我们通过hidden_channels_list参数来设置每一层GATConv的outchannel，通过修改hidden_channels_list，我们就可构造出不同的图神经网络。这里通过了三种方式改变网络结构
1、使用不同的卷积层2、使用不同的层数3、每层的不同的神经元个数 1、通过不同的卷积层
这里使用了GCNConv、GATConv、SAGEConv、GraphConv和TransformerConv五种卷积核，运行效果如下：
# 先定义数据 from torch_geometric.datasets import Planetoid from torch_geometric.transforms import NormalizeFeatures dataset = Planetoid(root=&#39;dataset&#39;, name=&#39;Cora&#39;, transform=NormalizeFeatures()) print() print(f&#39;Dataset: {dataset}:&#39;) print(&#39;======================&#39;) print(f&#39;Number of graphs: {len(dataset)}&#39;) print(f&#39;Number of features: {dataset.num_features}&#39;) print(f&#39;Number of classes: {dataset.num_classes}&#39;) data = dataset[0] # Get the first graph object. print() print(data) print(&#39;======================&#39;) # Gather some statistics about the graph. print(f&#39;Number of nodes: {data.num_nodes}&#39;) print(f&#39;Number of edges: {data.num_edges}&#39;) print(f&#39;Average node degree: {data.num_edges / data.num_nodes:.2f}&#39;) print(f&#39;Number of training nodes: {data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/14f28cb6ffd694a8b9f8affafbf49216/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-06-27T21:36:13+08:00" />
<meta property="article:modified_time" content="2021-06-27T21:36:13+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">图神经网络学习4</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_0"></a>节点的预测任务</h3> 
<p>首先定义图神经网络的网络结构，这里使用了<code>torch_geometric.nn.Sequential</code>容器，详细内容可见于<a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.sequential.Sequential" rel="nofollow">官方文档</a>。我们通过<code>hidden_channels_list</code>参数来设置每一层<code>GATConv</code>的<code>outchannel</code>，通过修改<code>hidden_channels_list</code>，我们就可构造出不同的图神经网络。这里通过了三种方式改变网络结构</p> 
<ul><li>1、使用不同的卷积层</li><li>2、使用不同的层数</li><li>3、每层的不同的神经元个数</li></ul> 
<p><strong>1、通过不同的卷积层</strong><br> 这里使用了GCNConv、GATConv、SAGEConv、GraphConv和TransformerConv五种卷积核，运行效果如下：</p> 
<pre><code class="prism language-python"><span class="token comment"># 先定义数据</span>
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Planetoid
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> NormalizeFeatures

dataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'dataset'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'Cora'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>NormalizeFeatures<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Dataset: {dataset}:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'======================'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Number of graphs: {len(dataset)}'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Number of features: {dataset.num_features}'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Number of classes: {dataset.num_classes}'</span><span class="token punctuation">)</span>

data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># Get the first graph object.</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'======================'</span><span class="token punctuation">)</span>

<span class="token comment"># Gather some statistics about the graph.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Number of nodes: {data.num_nodes}'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Number of edges: {data.num_edges}'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Average node degree: {data.num_edges / data.num_nodes:.2f}'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Number of training nodes: {data.train_mask.sum()}'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Contains isolated nodes: {data.contains_isolated_nodes()}'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Contains self-loops: {data.contains_self_loops()}'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Is undirected: {data.is_undirected()}'</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">####### 定义GCN网络结构</span>
<span class="token keyword">class</span> <span class="token class-name">GCN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> hidden_channels_list<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GCN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">12345</span><span class="token punctuation">)</span>
        hns <span class="token operator">=</span> <span class="token punctuation">[</span>num_features<span class="token punctuation">]</span> <span class="token operator">+</span> hidden_channels_list
        conv_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_channels_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            conv_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>GCNConv<span class="token punctuation">(</span>hns<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> hns<span class="token punctuation">[</span>idx<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'x, edge_index -&gt; x'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            conv_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>convseq <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token string">'x, edge_index'</span><span class="token punctuation">,</span> conv_list<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> Linear<span class="token punctuation">(</span>hidden_channels_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>convseq<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre> 
<p>其他网络层结构与上面类似，最终实验结果如图所示<br> <img src="https://images2.imgbox.com/5b/07/fvEAeS9x_o.png" alt="在这里插入图片描述"></p> 
<p><strong>2、使用不同层数</strong></p> 
<ul><li>hidden_channels_list=[2]</li><li>hidden_channels_list=[100]</li><li>hidden_channels_list=[200, 100]</li><li>hidden_channels_list=[200, 100, 50]</li><li>hidden_channels_list=[500, 200, 100]</li><li>hidden_channels_list=[500, 200, 100, 50]</li></ul> 
<pre><code class="prism language-python">layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token keyword">def</span> <span class="token function">test_case</span><span class="token punctuation">(</span>layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> GCN<span class="token punctuation">(</span>num_features<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> hidden_channels_list<span class="token operator">=</span>layer<span class="token punctuation">,</span> num_classes<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
    criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">301</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        loss <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Test Accuracy: {test_acc:.4f}'</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>
    test_case<span class="token punctuation">(</span>layer<span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/c6/b9/Fm8KTCZo_o.png" alt="在这里插入图片描述"><br> <strong>3、每层使用不同的神经元</strong></p> 
<ul><li>hidden_channels_list=[2]</li><li>hidden_channels_list=[20]</li><li>hidden_channels_list=[200]</li></ul> 
<pre><code class="prism language-python">layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token keyword">def</span> <span class="token function">test_case</span><span class="token punctuation">(</span>layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> GCN<span class="token punctuation">(</span>num_features<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> hidden_channels_list<span class="token operator">=</span>layer<span class="token punctuation">,</span> num_classes<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
    criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">101</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        loss <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Test Accuracy: {test_acc:.4f}'</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>
    test_case<span class="token punctuation">(</span>layer<span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/5e/de/MuTltiMn_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_118"></a>边的预测任务</h3> 
<p>边预测任务，目标是预测两个节点之间是否存在边。拿到一个图数据集，我们有节点属性<code>x</code>，边端点<code>edge_index</code>。<code>edge_index</code>存储的便是正样本。为了构建边预测任务，我们需要生成一些负样本，即采样一些不存在边的节点对作为负样本边，正负样本数量应平衡。此外要将样本分为训练集、验证集和测试集三个集合。</p> 
<p>PyG中为我们提供了现成的采样负样本边的方法，<code>train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1)</code>，其</p> 
<ul><li>第一个参数为<code>torch_geometric.data.Data</code>对象，</li><li>第二参数为验证集所占比例，</li><li>第三个参数为测试集所占比例。</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os<span class="token punctuation">.</span>path <span class="token keyword">as</span> osp

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> roc_auc_score
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Planetoid
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCNConv
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>utils <span class="token keyword">import</span> negative_sampling<span class="token punctuation">,</span> train_test_split_edges

<span class="token comment">###### 用Squential实现</span>
<span class="token comment"># class GAT(torch.nn.Module):</span>
<span class="token comment">#     def __init__(self, num_features, hidden_channels_list, num_classes):</span>
<span class="token comment">#         super(GAT, self).__init__()</span>
<span class="token comment">#         torch.manual_seed(12345)</span>
<span class="token comment">#         hns = [num_features] + hidden_channels_list</span>
<span class="token comment">#         conv_list = []</span>
<span class="token comment">#         for idx in range(len(hidden_channels_list)):</span>
<span class="token comment">#             conv_list.append((GATConv(hns[idx], hns[idx+1]), 'x, edge_index -&gt; x'))</span>
<span class="token comment">#             conv_list.append(ReLU(inplace=True),)</span>

<span class="token comment">#         self.convseq = Sequential('x, edge_index', conv_list)</span>
<span class="token comment">#         self.linear = Linear(hidden_channels_list[-1], num_classes)</span>

<span class="token comment">#     def forward(self, x, edge_index):</span>
<span class="token comment">#         x = self.convseq(x, edge_index)</span>
<span class="token comment">#         x = F.dropout(x, p=0.5, training=self.training)</span>
<span class="token comment">#         x = self.linear(x)</span>
<span class="token comment">#         return x</span>

<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> hidden_channels_list<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        hns <span class="token operator">=</span> <span class="token punctuation">[</span>in_channels<span class="token punctuation">]</span> <span class="token operator">+</span> hidden_channels_list
        conv_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_channels_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            conv_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>GCNConv<span class="token punctuation">(</span>hns<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> hns<span class="token punctuation">[</span>idx<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'x, edge_index -&gt; x'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            conv_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>convseq <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token string">'x, edge_index'</span><span class="token punctuation">,</span> conv_list<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> Linear<span class="token punctuation">(</span>hidden_channels_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>convseq<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">,</span> pos_edge_index<span class="token punctuation">,</span> neg_edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        edge_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>pos_edge_index<span class="token punctuation">,</span> neg_edge_index<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>z<span class="token punctuation">[</span>edge_index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">*</span> z<span class="token punctuation">[</span>edge_index<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">decode_all</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>
        prob_adj <span class="token operator">=</span> z @ z<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>prob_adj <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>as_tuple<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">get_link_labels</span><span class="token punctuation">(</span>pos_edge_index<span class="token punctuation">,</span> neg_edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_links <span class="token operator">=</span> pos_edge_index<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> neg_edge_index<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    link_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_links<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
    link_labels<span class="token punctuation">[</span><span class="token punctuation">:</span>pos_edge_index<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span>
    <span class="token keyword">return</span> link_labels


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

    neg_edge_index <span class="token operator">=</span> negative_sampling<span class="token punctuation">(</span>
        edge_index<span class="token operator">=</span>data<span class="token punctuation">.</span>train_pos_edge_index<span class="token punctuation">,</span>
        num_nodes<span class="token operator">=</span>data<span class="token punctuation">.</span>num_nodes<span class="token punctuation">,</span>
        num_neg_samples<span class="token operator">=</span>data<span class="token punctuation">.</span>train_pos_edge_index<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    train_neg_edge_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">tuple</span><span class="token punctuation">,</span> neg_edge_index<span class="token punctuation">.</span>T<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    val_pos_edge_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">tuple</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>val_pos_edge_index<span class="token punctuation">.</span>T<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_pos_edge_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">tuple</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>test_pos_edge_index<span class="token punctuation">.</span>T<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_neg_edge_set <span class="token operator">&amp;</span> val_pos_edge_set<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_neg_edge_set <span class="token operator">&amp;</span> test_pos_edge_set<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'wrong!'</span><span class="token punctuation">)</span>

    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    z <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>train_pos_edge_index<span class="token punctuation">)</span>
    link_logits <span class="token operator">=</span> model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">,</span> data<span class="token punctuation">.</span>train_pos_edge_index<span class="token punctuation">,</span> neg_edge_index<span class="token punctuation">)</span>
    link_labels <span class="token operator">=</span> get_link_labels<span class="token punctuation">(</span>data<span class="token punctuation">.</span>train_pos_edge_index<span class="token punctuation">,</span> neg_edge_index<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>binary_cross_entropy_with_logits<span class="token punctuation">(</span>link_logits<span class="token punctuation">,</span> link_labels<span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> loss


@torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    z <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>train_pos_edge_index<span class="token punctuation">)</span>

    results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> prefix <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        pos_edge_index <span class="token operator">=</span> data<span class="token punctuation">[</span>f<span class="token string">'{prefix}_pos_edge_index'</span><span class="token punctuation">]</span>
        neg_edge_index <span class="token operator">=</span> data<span class="token punctuation">[</span>f<span class="token string">'{prefix}_neg_edge_index'</span><span class="token punctuation">]</span>
        link_logits <span class="token operator">=</span> model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">,</span> pos_edge_index<span class="token punctuation">,</span> neg_edge_index<span class="token punctuation">)</span>
        link_probs <span class="token operator">=</span> link_logits<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        link_labels <span class="token operator">=</span> get_link_labels<span class="token punctuation">(</span>pos_edge_index<span class="token punctuation">,</span> neg_edge_index<span class="token punctuation">)</span>
        results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>roc_auc_score<span class="token punctuation">(</span>link_labels<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> link_probs<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> results

<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
    
    dataset <span class="token operator">=</span> <span class="token string">'Cora'</span>
    path <span class="token operator">=</span> <span class="token string">'./dataset'</span>
    dataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span>path<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> transform<span class="token operator">=</span>T<span class="token punctuation">.</span>NormalizeFeatures<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    
<span class="token comment">#     dataset = 'Cora'</span>
<span class="token comment">#     path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)</span>
<span class="token comment">#     dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())</span>
<span class="token comment">#     data = dataset[0]</span>
    
    
    
    ground_truth_edge_index <span class="token operator">=</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    data<span class="token punctuation">.</span>train_mask <span class="token operator">=</span> data<span class="token punctuation">.</span>val_mask <span class="token operator">=</span> data<span class="token punctuation">.</span>test_mask <span class="token operator">=</span> data<span class="token punctuation">.</span>y <span class="token operator">=</span> <span class="token boolean">None</span>
    data <span class="token operator">=</span> train_test_split_edges<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    model <span class="token operator">=</span> Net<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>params<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

    best_val_auc <span class="token operator">=</span> test_auc <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        loss <span class="token operator">=</span> train<span class="token punctuation">(</span>data<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>
        val_auc<span class="token punctuation">,</span> tmp_test_auc <span class="token operator">=</span> test<span class="token punctuation">(</span>data<span class="token punctuation">,</span> model<span class="token punctuation">)</span>
        <span class="token keyword">if</span> val_auc <span class="token operator">&gt;</span> best_val_auc<span class="token punctuation">:</span>
            best_val_auc <span class="token operator">=</span> val_auc
            test_auc <span class="token operator">=</span> tmp_test_auc
        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '</span>
              f<span class="token string">'Test: {test_auc:.4f}'</span><span class="token punctuation">)</span>

    z <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>train_pos_edge_index<span class="token punctuation">)</span>
    final_edge_index <span class="token operator">=</span> model<span class="token punctuation">.</span>decode_all<span class="token punctuation">(</span>z<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果（这里出现wrong的原因是存在训练集负样本与验证集负样本存在交集，或训练集负样本与测试集负样本存在交集）：<br> <img src="https://images2.imgbox.com/e9/9d/Zv3uExfv_o.png" alt="在这里插入图片描述"><br> <strong>本文内容主要来自datawhale开源课程</strong></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/37b465b93103c0862fb15304adf5a645/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux 下解压.tgz文件报错gzip: stdin: invalid compressed data--format violated的解决办法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b4351764557954460518a22c027586d4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">计算机桌面显示左右有黑边,电脑两边黑边怎么还原</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>