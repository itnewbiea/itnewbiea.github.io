<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>不使用框架实现卷积神经网络(Python) - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="不使用框架实现卷积神经网络(Python)" />
<meta property="og:description" content="不使用框架实现卷积神经网络(Python) 之前为了对卷积神经网络有更深入的了解，结合别人的成果和自己的思考，在仅使用numpy和cv2的前提下，实现了深度卷积神经网络，并使用mnist数据集进行了训练和测试。不过速度真的非常慢，代码：https://github.com/WepLeo/cnn_without_frame。
主要参考了这两个： https://github.com/hsmyy/zhihuzhuanlan刘建平的博客:http://www.cnblogs.com/pinard/p/6494810.html 自己遇到的问题 自己之前卡住的地方，有俩：一个是卷积层的反向传播，这个之前看博客推公式搞了好久；另一个是参数初始化，之前使用框架的时候没用心，导致卡了好久。怪自己之前考虑不深入。
卷积层的反向传播 这一块，看好多人都是根据前后两层的关系（conv-conv, conv-pooling…），分不同情况讨论，一直不是很理解（我觉得每一层都是独立的啊，为啥还要分情况讨论，希望有人明示），只有刘建平的博客是将每一层独立开的，才看明白。卷积层的反向传播中，在计算梯度时，就是在找前向传播中，两两相乘的另一半，以及与该乘积相关的那次求和的结果。我们可以记住对应的另一半以及求和结果，也可以通过翻转的方式找到，但是要注意padding和步长的影响，下面是input_size=(6,6), kernel_size=(3,3),padding=1,步长为1时的正反向传播过程：
正向传播 反向传播 初始化 之前一直都是使用框架，参数的初始化都是默认的，就没在意，结果就想当然的使用正太分布初始化了，结果训练的时候死活都不收敛，而且loss总是NAN，打印每一层的输出，发现后面几层绝对值都特别大，最后才发现是参数初始化的值数量级大了的原因，使用glorot_uniform后分分钟就看到效果了，最后精度为98%左右。
总结 写的非常粗糙，欢迎交流。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/30dadebe24d951ebcbf217d95c56d554/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-02-27T22:40:38+08:00" />
<meta property="article:modified_time" content="2018-02-27T22:40:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">不使用框架实现卷积神经网络(Python)</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2 id="不使用框架实现卷积神经网络python">不使用框架实现卷积神经网络(Python)</h2> 
<p>  之前为了对卷积神经网络有更深入的了解，结合别人的成果和自己的思考，在仅使用numpy和cv2的前提下，实现了深度卷积神经网络，并使用mnist数据集进行了训练和测试。不过速度真的非常慢，代码：<a href="https://github.com/WepLeo/cnn_without_frame">https://github.com/WepLeo/cnn_without_frame</a>。</p> 
<h4 id="主要参考了这两个">主要参考了这两个：</h4> 
<ul><li><a href="https://github.com/hsmyy/zhihuzhuanlan">https://github.com/hsmyy/zhihuzhuanlan</a></li><li>刘建平的博客:<a href="http://www.cnblogs.com/pinard/p/6494810.html" rel="nofollow">http://www.cnblogs.com/pinard/p/6494810.html</a></li></ul> 
<h4 id="自己遇到的问题">自己遇到的问题</h4> 
<p>  自己之前卡住的地方，有俩：一个是卷积层的反向传播，这个之前看博客推公式搞了好久；另一个是参数初始化，之前使用框架的时候没用心，导致卡了好久。怪自己之前考虑不深入。</p> 
<h4 id="卷积层的反向传播">卷积层的反向传播</h4> 
<p>  这一块，看好多人都是根据前后两层的关系（conv-conv, conv-pooling…），分不同情况讨论，一直不是很理解（我觉得每一层都是独立的啊，为啥还要分情况讨论，希望有人明示），只有刘建平的博客是将每一层独立开的，才看明白。卷积层的反向传播中，在计算梯度时，就是在找前向传播中，两两相乘的另一半，以及与该乘积相关的那次求和的结果。我们可以记住对应的另一半以及求和结果，也可以通过翻转的方式找到，但是要注意padding和步长的影响，下面是input_size=(6,6), kernel_size=(3,3),padding=1,步长为1时的正反向传播过程：</p> 
<h5 id="正向传播">正向传播</h5> 
<p><img src="https://images2.imgbox.com/2e/98/YjqFehrx_o.png" alt="正向传播" title=""> <br> <img src="https://images2.imgbox.com/de/05/3gL27s3e_o.png" alt="正向传播" title=""> <br> <img src="https://images2.imgbox.com/ae/91/Qf9d65wa_o.png" alt="正向传播" title=""></p> 
<h5 id="反向传播">反向传播</h5> 
<p><img src="https://images2.imgbox.com/90/1d/sjgvixF1_o.png" alt="反向传播" title=""> <br> <img src="https://images2.imgbox.com/7e/e6/BfPXQt5Y_o.png" alt="反向传播" title=""> <br> <img src="https://images2.imgbox.com/c3/d2/CT17bX14_o.png" alt="反向传播" title=""> <br> <img src="https://images2.imgbox.com/39/de/BDDYZmEa_o.png" alt="反向传播" title=""></p> 
<h4 id="初始化">初始化</h4> 
<p>  之前一直都是使用框架，参数的初始化都是默认的，就没在意，结果就想当然的使用正太分布初始化了，结果训练的时候死活都不收敛，而且loss总是NAN，打印每一层的输出，发现后面几层绝对值都特别大，最后才发现是参数初始化的值数量级大了的原因，使用glorot_uniform后分分钟就看到效果了，最后精度为98%左右。</p> 
<h4 id="总结">总结</h4> 
<p>  写的非常粗糙，欢迎交流。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/14339b3a0190c5eb0754ecb8ebe128e4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【bugku】过狗一句话 writeup</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/068f08f32c2014fae1d1da75b442439a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">java.net.NoRouteToHostException: No route to host</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>