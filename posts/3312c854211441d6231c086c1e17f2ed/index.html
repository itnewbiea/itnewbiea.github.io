<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ffmpeg 实现多视频轨录制到同一个文件 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ffmpeg 实现多视频轨录制到同一个文件" />
<meta property="og:description" content="引言 在视频录制中，有时会碰到这样一个需求，将不同摄像头的画面写入到一个视频文件，这个叫法很多，有的厂家叫合流模式，有的叫多画面多流模式。无论如何，它们的实质都是在一个视频文件上实现多路不同分辨率视频的保存。
经过调查，支持这种需求封装格式的有MP4、MOV、MKV 等，这里因为MP4 格式应用最广泛。
原理 ffmpeg 有一个map命令，可以将多路视频轨封装在一个视频容器，掰ffmpeg源码发现其实新建一个新的AVStream，修改stream-&gt;index，就可以实现多流录制的目的。
ffmpeg -i input.mp4 -i test.mp4 -map 0:v:0 -map 1:v -map 0:a -map 1:a -c copy -y mix.mp4 #include &lt;iostream&gt; #include &lt;string&gt; extern &#34;C&#34; { #include &lt;libavutil/timestamp.h&gt; #include &lt;libavformat/avformat.h&gt; } typedef struct { char* file_name; AVFormatContext* fmt_ctx; int video_index; int audio_index; int source_index; double last_pts[2]; double last_dts[2]; AVRational video_time_base; AVRational audio_time_base; bool is_end; }InputStream; int create_stream(InputStream *input_stream, AVFormatContext* out_fmt_ctx, int &amp;stream_num) { int i = 0; int ret = 0; if ((ret = avformat_open_input(&amp;input_stream-&gt;fmt_ctx, input_stream-&gt;file_name, 0, 0)) &lt; 0) //打开输出文件 { fprintf(stderr, &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/3312c854211441d6231c086c1e17f2ed/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-06T16:03:57+08:00" />
<meta property="article:modified_time" content="2023-12-06T16:03:57+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ffmpeg 实现多视频轨录制到同一个文件</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>   引言</h3> 
<p>    在视频录制中，有时会碰到这样一个需求，将不同摄像头的画面写入到一个视频文件，这个叫法很多，有的厂家叫合流模式，有的叫多画面多流模式。无论如何，它们的实质都是在一个视频文件上实现多路不同分辨率视频的保存。</p> 
<p>     经过调查，支持这种需求封装格式的有MP4、MOV、MKV 等，这里因为MP4 格式应用最广泛。</p> 
<p></p> 
<h3>   原理</h3> 
<p>     ffmpeg 有一个map命令，可以将多路视频轨封装在一个视频容器，掰ffmpeg源码发现其实新建一个新的AVStream，修改stream-&gt;index，就可以实现多流录制的目的。</p> 
<p>   </p> 
<pre><code class="language-cpp">ffmpeg -i input.mp4 -i  test.mp4  -map 0:v:0 -map 1:v -map 0:a -map 1:a -c copy  -y mix.mp4</code></pre> 
<p>   </p> 
<pre><code class="language-cpp">#include &lt;iostream&gt;
#include &lt;string&gt;

extern "C"
{
	#include &lt;libavutil/timestamp.h&gt;
	#include &lt;libavformat/avformat.h&gt;
}

typedef struct
{
	char* file_name;
	AVFormatContext* fmt_ctx;
	int video_index;
	int audio_index;
	int source_index;
	
	double last_pts[2];
	double last_dts[2];
	AVRational video_time_base;
	AVRational audio_time_base;
	bool is_end;
}InputStream;


int create_stream(InputStream *input_stream, AVFormatContext* out_fmt_ctx, int &amp;stream_num)
{
	int i = 0;
	int ret = 0;

	if ((ret = avformat_open_input(&amp;input_stream-&gt;fmt_ctx, input_stream-&gt;file_name, 0, 0)) &lt; 0) //打开输出文件
	{
		fprintf(stderr, "Could not open input file '%s'", input_stream-&gt;file_name);
		goto end;
	}

	if ((ret = avformat_find_stream_info(input_stream-&gt;fmt_ctx, 0)) &lt; 0) //打开输入
	{
		fprintf(stderr, "Failed to retrieve input stream information");
		goto end;
	}

	//av_dump_format(input_stream-&gt;fmt_ctx, 0, input_stream-&gt;file_name, 0);//打印信息

	for (size_t i = 0; i &lt; input_stream-&gt;fmt_ctx-&gt;nb_streams; i++)
	{
		AVStream* in_stream = input_stream-&gt;fmt_ctx-&gt;streams[i];
		AVStream* out_stream = avformat_new_stream(out_fmt_ctx, in_stream-&gt;codec-&gt;codec);

		if (in_stream-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_AUDIO)
		{
			input_stream-&gt;audio_index = i;
			input_stream-&gt;audio_time_base = in_stream-&gt;time_base;
			printf("流 %d 是音频 \n", input_stream-&gt;source_index + i);
		}

		if (in_stream-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_VIDEO)
		{
			input_stream-&gt;video_index = i;
			input_stream-&gt;video_time_base = in_stream-&gt;time_base;
			printf("流 %d 是视频 \n", input_stream-&gt;source_index + i);
		}

		if (!out_stream)
		{
			fprintf(stderr, "Failed allocating output stream\n");
			goto end;
		}

		ret = avcodec_copy_context(out_stream-&gt;codec, in_stream-&gt;codec);

		if (ret &lt; 0)
		{
			fprintf(stderr, "Failed to copy context from input to output stream codec context\n");
			goto end;
		}
		out_stream-&gt;codec-&gt;codec_tag = 0;

		if (out_fmt_ctx-&gt;oformat-&gt;flags &amp; AVFMT_GLOBALHEADER)
			out_stream-&gt;codec-&gt;flags |= AV_CODEC_FLAG_GLOBAL_HEADER;

		stream_num++;
	}
end:
	return ret;
}

int write_a_channel(InputStream *stream, AVFormatContext *out_fmt_ctx)
{
	int ret = -1;
	AVPacket packet;
	ret = av_read_frame(stream-&gt;fmt_ctx, &amp;packet);

	if (ret &lt; 0)
	{
		if (ret == AVERROR_EOF)
		{
			//printf("readFrame报错 %d\n", ret);
			av_free_packet(&amp;packet);
			return ret;
		}
	}

	AVRational time_base = {0};
	AVStream* in_stream = stream-&gt;fmt_ctx-&gt;streams[packet.stream_index];
	AVStream* out_stream = out_fmt_ctx-&gt;streams[packet.stream_index];
	packet.stream_index = stream-&gt;source_index + packet.stream_index;

	if (in_stream-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_VIDEO)
	{
		time_base = stream-&gt;video_time_base;
	}

	if (in_stream-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_AUDIO)
	{
		time_base = stream-&gt;audio_time_base;
	}

	packet.pts = av_rescale_q_rnd(packet.pts, time_base, out_stream-&gt;time_base, (AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
	packet.dts = av_rescale_q_rnd(packet.dts, time_base, out_stream-&gt;time_base, (AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));

	if (packet.pts &lt; 0)
	{
		packet.pts = 0;
	}

	if (packet.dts &lt; 0)
	{
		packet.dts = 0;
	}
	//printf("%d, pts %d dts %d \n", packet.stream_index, packet.pts, packet.dts);

	ret = av_interleaved_write_frame(out_fmt_ctx, &amp;packet);
	if (ret &lt; 0)
	{
		printf("写入错误\n");
	}

	av_free_packet(&amp;packet);
	return ret;
}


int main(int argc, char** argv)
{

	int ret = -1;
	char file_path[100][100] = {"D:\\素材\\test1.mp4", "D:\\素材\\test2.mp4", "D:\\素材\\test3.mp4", "D:\\素材\\test4.mp4"};
	int count = sizeof(file_path) / sizeof(char);
	const char *out_fileName = "my_muxing.mp4";
	av_register_all();
	
	AVOutputFormat* ofmt = NULL;
	AVFormatContext* out_fmt_ctx = NULL;

	const int channel_num = 4;
	avformat_alloc_output_context2(&amp;out_fmt_ctx, NULL, NULL, out_fileName);
	//创建streams	
	InputStream stream_arry[channel_num] = {0};
	int stream_index = 0;

	for (int i = 0; i &lt; channel_num; i++)
	{		
		int stream_num = 0;
		stream_arry[i].file_name = file_path[i];
		stream_arry[i].source_index = stream_index;
		ret = create_stream(&amp;stream_arry[i], out_fmt_ctx, stream_index);
		stream_index += stream_num;
	}

	if (!out_fmt_ctx)
	{
		return -1;
	}

	ofmt = out_fmt_ctx-&gt;oformat;
	if (!(ofmt-&gt;flags &amp; AVFMT_NOFILE))
	{
		ret = avio_open(&amp;out_fmt_ctx-&gt;pb, out_fileName, AVIO_FLAG_WRITE);
		if (ret &lt; 0)
		{
			fprintf(stderr, "Could not open output file '%s'", out_fileName);
			return -1;
		}
	}


	AVDictionary* opts = NULL;
	av_dict_set(&amp;opts, "movflags", "frag_keyframe+empty_moov", 0);//fmp4输出
	ret = avformat_write_header(out_fmt_ctx, &amp;opts);
	if (ret &lt; 0)
	{
		fprintf(stderr, "Error occurred when opening output file\n");
		return -1;
	}
	
	while (true)
	{
		int finish_count = 0;
		
		for (int i = 0; i &lt; channel_num; i++)
		{
			if (!stream_arry[i].is_end)
			{
				ret = write_a_channel(&amp;stream_arry[i], out_fmt_ctx);
				if (ret == AVERROR_EOF)
				{
					stream_arry[i].is_end = true;
					finish_count++;
				}
				else
				{
					continue;
				}
			}
		}

		if (finish_count &gt;= channel_num - 1)
		{
			break;
		}
	}

	//清理
	for (size_t i = 0; i &lt; channel_num; i++)
	{
		avformat_close_input(&amp;stream_arry[i].fmt_ctx);
	}

	ret = av_write_trailer(out_fmt_ctx);
	printf("==============合并完毕，写文件尾部 %d=============\n", ret);
	return 0;
}</code></pre> 
<p>设置flags 避免播放器拖动的时候出现花屏。</p> 
<pre><code class="hljs"> packet-&gt;flags = isKeyFrame ? packet-&gt;flags | AV_PKT_FLAG_KEY : packet-&gt;flags;</code></pre> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f5877df4be3d9f2a8b29696d848bf9fe/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">学会python如何利用业余时间赚外快？分享几个接单途径</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b16461c0cfacec1034ab73f4197e078d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">springboot引入swagger2</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>