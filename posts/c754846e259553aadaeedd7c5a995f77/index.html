<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>一种快速的自适应二值化算法-wallner - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="一种快速的自适应二值化算法-wallner" />
<meta property="og:description" content="wallner算法原理简述：
我们用P(n)来表示第n个点的灰度值. T(n)来表示二值化后的值。用f­ s (n) 来表示第n个点之前s个点的灰度值的和,就是
用这个s和另一个变量t就可以简单的说明P(n)应该是0还是1了, 这个公式就是
根据经验值来看, 这里的s和t最佳的取值范围是s= image.width/8, 而t=15的时候效果最好.且1为黑（背景），0为白（前景））
但是有个问题，现在定义T(n)的时候,用的是平均值,也就是说之前扫描过的若干点对于当前点的影响或者说权重是一样的。
所以这里改进成离当前点越近的像素对当前点的影响越大,越远则越小。用g(n)代替T(n)。公式如下：
还有一个问题存在, 就是现在的颜色计算依赖于我的扫描顺序,(一般都是水平扫描的). 这样的话, 我的像素值实际上取决于我水平位置上的邻接点的灰度值, 可是竖直方向的像素如何关联起来呢? 这里也有一个说明, 我们可以维护前面依次水平扫描产生的g_prev(n)序列, 在某个g(n)被使用之前, 我们可以让他和前一个g_prev(n)取一个平均值, 这样的话, 这个最终的值就更有说服力了.
另外由于需要给定一个初始的迭代值，这里取g(n) = 127 *s，127是灰度0~255的中间值
代码实现：
#include&lt;opencv2\opencv.hpp&gt; #include&lt;iostream&gt; using namespace std; using namespace cv; void wallner(Mat &amp; src, Mat &amp; dst) { /* * pn = 当前点的灰度值 * s = 图片宽度/n （n = 8时效果最好） * t = 比例阈值 * 公式：g(n) = g(n-1) * (1-1/s) &#43; p(n) */ int t = 15; int s = src." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/c754846e259553aadaeedd7c5a995f77/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-07-29T20:39:24+08:00" />
<meta property="article:modified_time" content="2018-07-29T20:39:24+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">一种快速的自适应二值化算法-wallner</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>wallner算法原理简述：</p> 
<p style="margin-left:0px;"><span style="color:#333333;">我们用P(n)来表示第n个点的灰度值. T(n)来表示二值化后的值。用<em>f­ s  (n) </em>来表示第n个点之前s个点的灰度值的和,就是</span></p> 
<p style="margin-left:0px;"><span style="color:#333333;"><img alt="f_{s}(n) = \sum_{i = 0}^{s-1}p_{n-i}" class="mathcode" src="https://images2.imgbox.com/d8/ad/1aRLPAu6_o.gif"></span></p> 
<p style="margin-left:0px;">用这个s和另一个变量t就可以简单的说明P(n)应该是0还是1了, 这个公式就是</p> 
<p style="margin-left:0px;"><img alt="T(n)=\begin{Bmatrix}1 &amp;if\ p_{n} &lt;(\frac{f_{s}(n)}{s})(\frac{100-t}{100}) &amp; \\ 0 &amp; otherwise\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \end{Bmatrix}" class="mathcode" src="https://images2.imgbox.com/e7/b9/rXmeLgZ8_o.gif"></p> 
<p style="margin-left:0px;">根据经验值来看, 这里的s和t最佳的取值范围是s= image.width/8, 而t=15的时候效果最好.且1为黑（背景），0为白（前景））</p> 
<p style="margin-left:0px;">但是有个问题，现在定义T(n)的时候,用的是平均值,也就是说之前扫描过的若干点对于当前点的影响或者说权重是一样的。</p> 
<p style="margin-left:0px;">所以这里改进成离当前点越近的像素对当前点的影响越大,越远则越小。用g(n)代替T(n)。公式如下：</p> 
<p style="margin-left:0px;"><img alt="\begin{matrix}g_{s}(n) = g_{s}(n-1) +\frac{ g_{s}(n-1)}{s} + p(n) &amp; &amp; \\ \: \: \: \: \:\: \: \: \: \: = p(n) + (1-\frac{1}{s})\cdot g_{s}(n-1) &amp; &amp; \\ \: \:\: \: \:\: \: \:\ \: \:\ \: \:\ \: \:\ \: \:\ \: \:\:\:\:\:\:\: \: \: \: \: \: = p(n) + (1-\frac{1}{s})p_{n-1}+ (1-\frac{1}{s})^{2}p_{n-2} +...&amp; &amp; \\ =\sum_{i=0}^{n}(1-\frac{1}{s})^{i}p_{n-1}\;\;\; \end{matrix}" class="mathcode" src="https://images2.imgbox.com/4f/4f/v8EQd9cA_o.gif"></p> 
<p style="margin-left:0px;">还有一个问题存在, 就是现在的颜色计算依赖于我的扫描顺序,(一般都是水平扫描的). 这样的话, 我的像素值实际上取决于我水平位置上的邻接点的灰度值, 可是竖直方向的像素如何关联起来呢? 这里也有一个说明, 我们可以维护前面依次水平扫描产生的g_prev(n)序列, 在某个g(n)被使用之前, 我们可以让他和前一个g_prev(n)取一个平均值, 这样的话, 这个最终的值就更有说服力了.</p> 
<p style="margin-left:0px;">另外由于需要给定一个初始的迭代值，这里取g(n) = 127 *s，127是灰度0~255的中间值</p> 
<p style="margin-left:0px;">代码实现：</p> 
<pre class="has"><code class="language-cpp">#include&lt;opencv2\opencv.hpp&gt;
#include&lt;iostream&gt;
using namespace std;
using namespace cv;

void wallner(Mat &amp; src, Mat &amp; dst)
{
	/*
	* pn = 当前点的灰度值
	* s = 图片宽度/n （n = 8时效果最好）
	* t = 比例阈值
	* 公式：g(n) = g(n-1) * (1-1/s) + p(n)
	*/
	int t = 15;
	int s = src.cols &gt;&gt; 3;
	const int S = 9;
	const int power2S = 1 &lt;&lt; S;//加速因子
	int factor = power2S * (100 - t) / (100 * s);
	/*使用初始值127*s *s是因为 原先算法采用均值也就是fn 是前n个像素之和 
	这次算法优化为与当前点越相邻对其影响越大的思路*/
	int gn = 127 * s;
	int q = power2S - power2S / s;
	int pn, hn;
	int *prev_gn = NULL;//前一行各点像素值
	//Mat dst = Mat::zeros(src.size(), CV_8UC1);
	prev_gn = new int[src.cols];
	for (int i = 0; i &lt; src.cols; i++)
		prev_gn[i] = gn;
	uchar * scanline = NULL;
	for (int i = 0; i &lt; src.rows; i++)
	{
		scanline = src.ptr&lt;uchar&gt;(i);
		for (int j = 0; j &lt; src.cols; j++)//从左向右遍历
		{
			pn = scanline[j];
			gn = ((gn * q) &gt;&gt; S) + pn;
			hn = (gn + prev_gn[j]) &gt;&gt; 1;
			prev_gn[j] = gn;
			pn &lt; (hn * factor) &gt;&gt; S ? dst.at&lt;uchar&gt;(i, j) = 0 : dst.at&lt;uchar&gt;(i, j) = 255;
		}
		i++;
		if (i == src.rows)
			break;
		scanline = src.ptr&lt;uchar&gt;(i);
		for (int j = src.cols - 1; j &gt;= 0; j--)//从右向左遍历
		{
			pn = scanline[j];
			gn = ((gn * q) &gt;&gt; S) + pn;
			hn = (gn + prev_gn[j]) &gt;&gt; 1;
			prev_gn[j] = gn;
			pn &lt; (hn * factor) &gt;&gt; S ? dst.at&lt;uchar&gt;(i, j) = 0 : dst.at&lt;uchar&gt;(i, j) = 255;
		}
	}
}

void main()
{
	Mat src = imread("Checkerboard.jpg", IMREAD_GRAYSCALE);
	Mat cmp = src.clone();
	Mat dst = Mat::zeros(src.size(), CV_8UC1);
	threshold(cmp, cmp, 0, 255, THRESH_OTSU);
	wallner(src, dst);
	imshow("src", src);
	imshow("dst", dst);
	imshow("cmp", cmp);
	waitKey();
}</code></pre> 
<p style="margin-left:0px;">实现结果：</p> 
<p style="margin-left:0px;">①原图选用因光照角度导致的棋盘光影亮暗不均</p> 
<p style="margin-left:0px;">②通过对比OTSU效果说明该文实现的自适应二值化阈值的好处</p> 
<p style="margin-left:0px;">原图：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/2c/2a/g01QN10L_o.jpg"></p> 
<p>实现效果：</p> 
<p>①otsu：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/48/01/14Pof54F_o.jpg"></p> 
<p>②wallner：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/2c/57/RM46qkSU_o.jpg"></p> 
<p>结论：可以看到wallner以实现局部自适应的方式相较于otsu全局自适应更大程度还原了原图。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3ab82a922277b4e801b1b0c8b982234e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">纯JS打造多选下拉框select&#43;模糊查询功能</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/28ae67dec4f1a85fab579b7722d7153c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【神经网络】用python从底层实现一个卷积神经网络</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>