<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>RK3568笔记六：基于Yolov8的训练及部署 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="RK3568笔记六：基于Yolov8的训练及部署" />
<meta property="og:description" content="若该文为原创文章，转载请注明原文出处。
基于Yolov8的训练及部署，参考鲁班猫的手册训练自己的数据集部署到RK3568,用的是正点的板子。
1、 使用 conda 创建虚拟环境 conda create -n yolov8 python=3.8 ​ conda activate yolov8 2、 安装 pytorch 等等 根据pytorch自行安装
3、 安装 ，直接使用命令安装 方法有两种，个人使用的是第二种方法：
方法一：
通过pip安装
pip install ultralytics -i https://mirror.baidu.com/pypi/simple 方法二：
通过拉取仓库然后安装
git clone https://github.com/ultralytics/ultralytics ​ cd ultralytics ​ pip install -e . # 安装成功后，使用命令 yolo 简单看下版本
(yolov8) llh@anhao:/$ yolo version ​ 8.0.206 4、简单测试 下载权重文件
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt *获取测试图片，可以下面位置获取，可能会失败，也可以从配套例程获取
wget https://ultralytics.com/images/bus.jpg 使用 yolo 命令进行测试
yolo detect predict model=./yolov8n.pt source=./bus.jpg ​# 预测图片结果保存在当前 runs 目录下，具体路径是." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/79606b099e240bfe6c36c60d05db4005/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-28T22:33:51+08:00" />
<meta property="article:modified_time" content="2023-11-28T22:33:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">RK3568笔记六：基于Yolov8的训练及部署</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>若该文为原创文章，转载请注明原文出处。</p> 
<p>基于Yolov8的训练及部署，参考鲁班猫的手册训练自己的数据集部署到RK3568,用的是正点的板子。</p> 
<h5><em>1、</em> 使用 <em>conda</em> 创建虚拟环境</h5> 
<pre><code class="hljs">conda create -n yolov8 python=3.8
​
conda activate yolov8</code></pre> 
<h5><em>2、</em> 安装 <em>pytorch</em> 等等</h5> 
<p>根据pytorch自行安装</p> 
<h5>3、 安装 ，直接使用命令安装</h5> 
<p>方法有两种，个人使用的是第二种方法：</p> 
<p><strong>方法一：</strong></p> 
<p>通过pip安装</p> 
<pre><code class="hljs">pip install ultralytics -i https://mirror.baidu.com/pypi/simple</code></pre> 
<p><strong>方法二：</strong></p> 
<p>通过拉取仓库然后安装</p> 
<pre><code class="hljs">git clone https://github.com/ultralytics/ultralytics
​
cd ultralytics
​
pip install -e .</code></pre> 
<p><em>#</em> 安装成功后，使用命令 <em>yolo</em> 简单看下版本</p> 
<pre><code class="hljs">(yolov8) llh@anhao:/$ yolo version
​
8.0.206</code></pre> 
<h5>4、<strong>简单测试</strong></h5> 
<p>下载权重文件</p> 
<pre><code class="hljs">wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt</code></pre> 
<p>*获取测试图片，可以下面位置获取，可能会失败，也可以从配套例程获取</p> 
<pre><code class="hljs">wget https://ultralytics.com/images/bus.jpg</code></pre> 
<p>使用 yolo 命令进行测试</p> 
<pre><code class="hljs">yolo detect predict model=./yolov8n.pt source=./bus.jpg</code></pre> 
<pre>​# 预测图片结果保存在当前 runs 目录下，具体路径是./runs/detect/predict/bus.jpg</pre> 
<blockquote> 
 <pre>参数说明：
# 第一个参数是指任务 [detect, segment, classify], 这里测试目标检测是 detect，该参数
是可选的；
# 第二个参数 model，设置模型，该参数必须指定；
# 其他参数，source 指定要预测的图片路径，imgsz 指定图像尺寸等等，更多参数具体参考下：
https://docs.ultralytics.com/usage/cfg/</pre> 
</blockquote> 
<h5>5、<strong>模型训练</strong></h5> 
<p>以COCO128为例，训练测试</p> 
<pre><code class="hljs">yolo detect train data=coco128.yaml model=yolov8n.pt epochs=300 imgsz=640</code></pre> 
<p>测试</p> 
<pre><code class="hljs">yolo detect predict model=./runs/detect/train/weights/best.pt source=./bus.jpg</code></pre> 
<p>6、<strong>模型导出</strong></p> 
<p>使用 airockchip/ultralytics_yolov8 可以直接导出适配 rknpu 的模型，在 npu 上获得更高的推理效率。</p> 
<p>该仓库对模型进行了优化：</p> 
<p>• dfl 结构在 NPU 处理上性能不佳，移至模型外部。</p> 
<p>• 假设有 6000 个候选框，原模型将 dfl 结构放置于’’框置信度过滤”前，则 6000 个候选框</p> 
<p>都需要计算经过 dfl 计算；而将 dfl 结构放置于’’框置信度过滤”后，假设过滤后剩 100 个</p> 
<p>候选框，则 dfl 部分计算量减少至 100 个，大幅减少了计算资源、带宽资源的占用。</p> 
<p>假设有 6000 个候选框，检测类别是 80 类，则阈值检索操作需要重复 6000* 80 ~= 4.8*10^5 次，占据</p> 
<p>了较多耗时。故导出模型时，在模型中额外新增了对 80 类检测目标进行求和操作，用于快速过滤</p> 
<p>置信度。</p> 
<p>(该结构在部分情况下有效，与模型的训练结果有关) 可以在./ultralytics/nn/modules/head.py</p> 
<p>52 行 ~54 行的位置，注释掉这部分优化，对应的代码是:</p> 
<pre><code class="hljs">cls_sum = torch.clamp(y[-1].sum(1, keepdim=True), 0, 1)
y.append(cls_sum)</code></pre> 
<p>具体参考下 RKOPT_README.md 。</p> 
<p><strong>导出torchscript模型</strong></p> 
<pre><code class="hljs"># 拉取 airockchip/ultralytics_yolov8
git clone https://github.com/airockchip/ultralytics_yolov8.git
cd ultralytics_yolov8
​
# 复制训练的模型 yolov8n.pt 到 ultralytics_yolov8 目录下
# 然后修改./ultralytics/cfg/default.yaml 文件，主要是设置下 model，为自己训练的模型
路径：
model: ./yolov8n.pt # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml
data: # (str, optional) path to data file, i.e. coco128.yaml
epochs: 100 # (int) number of epochs to train for
​
# 导出模型：
python ./ultralytics/engine/exporter.py
#导出的模型，保存在当前目录下的 yolov8n_rknnopt.torchscript</code></pre> 
<p><strong>导出ONNX模型</strong></p> 
<pre><code class="hljs">yolo export model=path/to/best.pt format=onnx  # export custom trained model</code></pre> 
<h5><img alt="" height="220" src="https://images2.imgbox.com/f4/fd/jiPxmoao_o.png" width="887"></h5> 
<h5>7、RKNN模型转换</h5> 
<p>模型转换是通过tooolkit2转成rknn模型的，需要先安装toolkit2，具体安装参考正点原子的。</p> 
<p>这是使用的是 <strong>rknn_model_zoo</strong> 仓库 的程序，直接转换模型,</p> 
<pre><code class="hljs"># 拉取 rknn_model_zoo，（注意教程测试时 rknn_model_zoo 的 SHA 是
22462182b91c7d856b59a8ec3e4a25bba8813d17）
git clone https://github.com/airockchip/rknn_model_zoo.git
# 然后切换到 models/CV/object_detection/yolo/RKNN_model_convert 目录下
cd rknn_model_zoo/models/CV/object_detection/yolo/RKNN_model_convert</code></pre> 
<p>在录前目录下创建yolov8_rk3568.yml文件，内容如下：</p> 
<pre><code class="hljs"># model_framework: onnx
model_framework: pytorch
model_file_path: /mnt/f/wsl_file/wsl_ai/yolov8/ultralytics_yolov8/yolov8n_rknnopt.torchscript
RK_device_platform: rk3568
# RK_device_id: simulator
dataset: ../../../../../datasets/COCO/coco_subset_10.txt
quantize: True
# pre_compile: online
graph:
in_0:
shape: 1,3,640,640
mean_values: 0
std_values: 255
img_type: RGB
configs:
quantized_dtype: asymmetric_quantized-8
quantized_algorithm: normal
optimization_level: 3
# force_builtin_perm: True</code></pre> 
<p>注意三个地方：</p> 
<pre>1、model_framework可以使用onnx也可以是pytorch
2、model_file_path：模型路径
3、RK_device_platform： 平台</pre> 
<p>使用命令或者创建脚本执行模型转换等操作</p> 
<pre><code class="hljs"># 使用 rknn_convert.py，转换模型
python ../../../../../common/rknn_converter/rknn_convert.py --yml_path ./yolov8_rk3568.yml</code></pre> 
<p>转换的模型保存在当前目录 model_cvt/RK3568/下，模型文件是 yolov8n_rknnopt_RK3568_i8.rknn。</p> 
<h5>8、部署</h5> 
<p>使用 rknn_model_zoo 仓库 提供的 RKNN_C_demo，在板端部署</p> 
<pre><code class="hljs"># 拉取 rknn_model_zoo 仓库源码，注意教程测试的 rknn_model_zoo 仓库版本是
22462182b91c7d856b59a8ec3e4a25bba8813d17
​
git clone https://github.com/airockchip/rknn_model_zoo.git
# 切换到~/rknn_model_zoo/libs/rklibs 目录，然后拉取相关库，包括 rknpu2 和 librga
cd ~/rknn_model_zoo/libs/rklibs
git clone https://github.com/rockchip-linux/rknpu2
git clone https://github.com/airockchip/librga
# 然后切换到~/rknn_model_zoo/models/CV/object_detection/yolo/RKNN_C_demo/RKNN_toolkit_2/rknn_yolo_demo 目录
cd rknn_model_zoo/models/CV/object_detection/yolo/RKNN_C_→demo/RKNN_toolkit_2/rknn_yolo_demo
# 运行 build-linux_RK3568.sh 脚本，编译工程（使用系统默认的编译器），最后生成的文件安装
在 build/目录下
./build-linux_RK3568.sh</code></pre> 
<p>执行命令进行模型推理：</p> 
<pre># 切换到 install/rk3568/Linux/rknn_yolo_demo 目录下，复制前面转换出的 yolov8n_→rknnopt_RK3568_i8.rknn 模型文件到目录下，
# 然后把文件拷贝到开发板上执行下面命令：
</pre> 
<pre><code class="hljs">./rknn_yolo_demo␣yolov8 q8 ./yolov8n_rknnopt_RK3588_i8.rknn ./model/bus640.jpg</code></pre> 
<pre>#运行后会在目录下生成out.jpg</pre> 
<p></p> 
<p><strong>参考链接</strong></p> 
<p><a href="https://docs.ultralytics.com/quickstart/" rel="nofollow" title="Quickstart - Ultralytics YOLOv8 Docs">Quickstart - Ultralytics YOLOv8 Docs</a></p> 
<p><a href="https://github.com/ultralytics/ultralytics" title="GitHub - ultralytics/ultralytics: NEW - YOLOv8 🚀 in PyTorch &gt; ONNX &gt; OpenVINO &gt; CoreML &gt; TFLite">GitHub - ultralytics/ultralytics: NEW - YOLOv8 🚀 in PyTorch &gt; ONNX &gt; OpenVINO &gt; CoreML &gt; TFLite</a></p> 
<p><a href="https://github.com/airockchip/ultralytics_yolov8" title="GitHub - airockchip/ultralytics_yolov8: NEW - YOLOv8 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite">GitHub - airockchip/ultralytics_yolov8: NEW - YOLOv8 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite</a></p> 
<p><a href="https://github.com/airockchip/rknn_model_zoo" title="GitHub - airockchip/rknn_model_zoo">GitHub - airockchip/rknn_model_zoo</a></p> 
<p></p> 
<p>如有侵权，或需要完整代码，请及时联系博主。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1944ac526e80bd9810ab14af4b0991d3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python 重定向输出到控件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/507e05241b14354f071bb0edf3e235e2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ground truth 在深度学习任务中代表的是什么意思？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>