<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED" />
<meta property="og:description" content="下面所有博客是个人对EEG脑电的探索，项目代码是早期版本不完整，需要完整项目代码和资料请私聊。
数据集
1、脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED
相关论文阅读分析：
1、EEG-SEED数据集作者的—基线论文阅读和分析
2、图神经网络EEG论文阅读和分析：《EEG-Based Emotion Recognition Using Regularized Graph Neural Networks》
3、EEG-GNN论文阅读和分析：《EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks》
4、论文阅读和分析:Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification
5、论文阅读和分析：《DeepGCNs: Can GCNs Go as Deep as CNNs?》
6、论文阅读和分析： “How Attentive are Graph Attention Networks?”
7、论文阅读和分析：Simplifying Graph Convolutional Networks
8、论文阅读和分析：LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation
9、图神经网络汇总和总结
相关实验和代码实现：
1、用于图神经网络的脑电数据处理实现_图神经网络 脑电
2、使用GCN训练和测试EEG的公开SEED数据集
3、使用GAT训练和测试EEG公开的SEED数据集
4、使用SGC训练和测试SEED数据集
5、使用Transformer训练和测试EEG的公开SEED数据集_eeg transformer" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/d7f743221f0ea80897411b7c540e97bd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-05T12:22:53+08:00" />
<meta property="article:modified_time" content="2023-04-05T12:22:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><br><br></p> 
<blockquote> 
 <p><strong><font size="3" face="Courier New">下面所有博客是个人对EEG脑电的探索，项目代码是早期版本不完整，需要完整项目代码和资料请私聊。</font></strong><br> <br><br> <strong><font size="3" face="Courier New">数据集</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128589175?spm=1001.2014.3001.5501">脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED</a><br> <strong><font size="3" face="Courier New">相关论文阅读分析：</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128607350?spm=1001.2014.3001.5501">EEG-SEED数据集作者的—基线论文阅读和分析</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/128637894?spm=1001.2014.3001.5501">图神经网络EEG论文阅读和分析：《EEG-Based Emotion Recognition Using Regularized Graph Neural Networks》</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/128679724?spm=1001.2014.3001.5501">EEG-GNN论文阅读和分析：《EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks》</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/128882363?spm=1001.2014.3001.5501">论文阅读和分析:Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/128892103?spm=1001.2014.3001.5501">论文阅读和分析：《DeepGCNs: Can GCNs Go as Deep as CNNs?》</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/128911280?spm=1001.2014.3001.5501">论文阅读和分析： “How Attentive are Graph Attention Networks?”</a><br> 7、<a href="https://blog.csdn.net/KPer_Yang/article/details/128927668?spm=1001.2014.3001.5501">论文阅读和分析：Simplifying Graph Convolutional Networks</a><br> 8、<a href="https://blog.csdn.net/KPer_Yang/article/details/128945159?spm=1001.2014.3001.5501">论文阅读和分析：LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</a><br> 9、<a href="https://blog.csdn.net/KPer_Yang/article/details/129968785?spm=1001.2014.3001.5502">图神经网络汇总和总结</a><br> <strong><font size="3" face="Courier New">相关实验和代码实现：</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128740968?spm=1001.2014.3001.5501">用于图神经网络的脑电数据处理实现_图神经网络 脑电</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/129034169?spm=1001.2014.3001.5501">使用GCN训练和测试EEG的公开SEED数据集</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/129074872?spm=1001.2014.3001.5501">使用GAT训练和测试EEG公开的SEED数据集</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/129094901?spm=1001.2014.3001.5501">使用SGC训练和测试SEED数据集</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/129095088?spm=1001.2014.3001.5501">使用Transformer训练和测试EEG的公开SEED数据集_eeg transformer</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/129133439?spm=1001.2014.3001.5501">使用RGNN训练和测试EEG公开的SEED数据集</a><br> <strong><font size="3" face="Courier New">辅助学习资料：</font></strong><br> 1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128808874?spm=1001.2014.3001.5501">官网三个简单Graph示例说明三种层次的应用_graph 简单示例</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/128810698?spm=1001.2014.3001.5501">PPI数据集示例项目学习图神经网络</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/128859245?spm=1001.2014.3001.5501">geometric库的数据处理详解</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/128880391?spm=1001.2014.3001.5501">NetworkX的dicts of dicts以及解决Seven Bridges of Königsberg问题</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/128889737?spm=1001.2014.3001.5501">geometric源码阅读和分析：MessagePassin类详解和使用</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/129095501?spm=1001.2014.3001.5501">cora数据集示例项目学习图神经网络</a><br> 7、<a href="https://blog.csdn.net/KPer_Yang/article/details/129102055?spm=1001.2014.3001.5501">Graph 聚合</a><br> 8、<a href="https://blog.csdn.net/KPer_Yang/article/details/129105477?spm=1001.2014.3001.5501">QM9数据集示例项目学习图神经网络</a><br> 9、<a href="https://blog.csdn.net/KPer_Yang/article/details/129105010?spm=1001.2014.3001.5501">处理图的开源库</a></font></font></font></p> 
</blockquote> 
<h4><a id="_39"></a>数据集介绍：</h4> 
<h5><a id="SEED1_41"></a>使用上海交大的SEED数据集<sup class="footnote-ref"><a href="#fn1" rel="nofollow" id="fnref1">1</a></sup></h5> 
<p><font size="4" face="楷体">SEED数据集包含12名受试者的脑电图和眼动数据以及另外3名受试者的脑电图数据。数据是在他们观看电影片段时收集的。电影片段是精心挑选的，以诱导不同类型的情绪，积极的，消极的，和中性的。</font></p> 
<p><font size="4" face="楷体">从实验材料中选择了15个中国电影片段(积极、中性和消极情绪)作为刺激。影片剪辑的评选标准如下:<br> (a)整个实验的时长不宜过长，以免引起受试者疲劳;<br> (b)录像内容应在无需解释的情况下被理解;<br> ©视频应引起单一的预期目标情绪。</font></p> 
<p><font size="4" face="楷体">每个电影片段的时长约为4分钟。每一个电影片段都经过精心剪辑，以创造连贯的情感诱导和最大限度地发挥情感意义。实验中使用的电影片段细节如下:</font></p> 
<p><img src="https://images2.imgbox.com/23/85/VwXFXnbS_o.png" alt="在这里插入图片描述" width="350"></p> 
<p><font size="4" face="楷体">每个影片片段有15个试验者。在每次剪辑前有5秒的提示，每次剪辑后有45秒的自我评估时间，15秒的休息时间。呈现的顺序是这样安排的，两个针对同一情感的电影片段不会连续播放。为了得到反馈，参与者被要求在看完每个电影片段后立即填写问卷，报告他们对每个电影片段的情绪反应。具体方案如下:</font></p> 
<p><img src="https://images2.imgbox.com/74/f7/uqjdeHPT_o.png" alt="在这里插入图片描述" width="400"></p> 
<p><font size="4" face="楷体">使用62通道ESI NeuroScan系统和SMI眼动追踪眼镜采集脑电图信号和眼球运动。实验场景及相应的EEG电极布置如下图所示。</font></p> 
<p><img src="https://images2.imgbox.com/f7/94/6Wg5I8xq_o.png" alt="在这里插入图片描述" width="400"></p> 
<p><font size="4" face="楷体">中文15名(男7名，女8名;MEAN: 23.27, STD: 2.37)参与实验。为了保护个人隐私，我们隐藏了他们的名字，并给每个人标上从1到15的数字。第1 -5和第8 -14名受试者(12名)有EEG和眼动数据，而第6、第7和第15名受试者只有EEG数据。</font></p> 
<h5><a id="2_3_67"></a>数据集文件夹<sup class="footnote-ref"><a href="#fn2" rel="nofollow" id="fnref2">2</a></sup> <sup class="footnote-ref"><a href="#fn3" rel="nofollow" id="fnref3">3</a></sup>：</h5> 
<p><font size="4" face="楷体">SEED由两部分组成:SEED_EEG和SEED_Multimodal。SEED_EEG包含15名受试者的脑电图数据。SEED_Multimodal包含12名受试者的脑电图和眼动数据。这两部分的索引是相同的。例如，如果一个科目在SEED_EEG中的索引是1st，那么这个科目在SEED_Multimodal中的索引也是1st。</font></p> 
<h6><a id="SEEDEEG_71"></a>SEED-EEG</h6> 
<p><strong>A：</strong></p> 
<p><font size="4" face="楷体">在“Preprocessed_EEG”文件夹中，有一些文件包含了MATLAB中EEG数据的下采样、预处理和分割版本(.mat文件)。数据被采样到200hz。应用0 - 75 Hz的带通频率滤波器。我们提取了与每部电影持续时间相对应的脑电图片段。一共有45个扩展名为.mat的文件(MATLAB文件)，每个实验一个。每个受试者进行三次实验，间隔约为一周。每个主题文件包含16个数组。15个数组包含一个实验中15个试验的分割预处理EEG数据(eeg_1~eeg_15, channel×data)。数组名称标签包含相应的情感标签(-1表示消极，0表示中立，+1表示积极)。通道的详细顺序包含在数据集中。根据国际10 - 20系统的62个通道的脑电图上限如下所示:</font></p> 
<p><img src="https://images2.imgbox.com/82/df/cUJcCf7n_o.png" alt="在这里插入图片描述" width="400"></p> 
<p><strong>B:</strong></p> 
<p><font size="4" face="楷体">在“Extracted_Features”文件夹中，有提取EEG信号的微分熵(DE)特征的文件，该特征在[2]中首次提出。这些数据非常适合那些想要快速测试分类方法而不预处理原始脑电图数据的人。文件格式与Data_preprocessed相同。我们还计算了27对半球不对称电极的微分不对称(DASM)和有理不对称(RASM)特征作为DE特征之间的差异和比值。所有的特征进一步平滑与传统的移动平均和线性动态系统(LDS)方法。关于特征提取和特征平滑的详细信息请参考[1]和[2]。</font></p> 
<p><font size="4" face="Times New Roman">[1]. Wei-Long Zheng, and Bao-Liang Lu, Investigating Critical Frequency Bands and Channels for EEG-based Emotion Recognition with Deep Neural Networks, accepted by IEEE Transactions on Autonomous Mental Development (IEEE TAMD) 7(3): 162-175, 2015. [<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7104132&amp;tag=1" rel="nofollow">link</a>] [<a href="https://bcmi.sjtu.edu.cn/home/seed/resource/bib/1.htm" rel="nofollow">BibTex</a>]</font></p> 
<p><font size="4" face="Times New Roman">[2]. Ruo-Nan Duan, Jia-Yi Zhu and Bao-Liang Lu, Differential Entropy Feature for EEG-based Emotion Classification, Proc. of the 6th International IEEE EMBS Conference on Neural Engineering (NER). 2013: 81-84. [<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6695876" rel="nofollow">link</a>] [<a href="https://bcmi.sjtu.edu.cn/home/seed/resource/bib/2.htm" rel="nofollow">BibTex</a>]</font></p> 
<h6><a id="SEED_Multimodal_88"></a>SEED_Multimodal</h6> 
<p><font size="4" face="楷体"><strong>A:“Chinese”文件夹包含四个子文件夹。</strong><br> a. 01-EEG-raw:包含。cnt格式的原始EEG信号，采样率为1000Hz。<br> b: 02-EEG-DE-feature:包含1秒和4秒滑动窗口提取的DE特征和读取数据的源代码。<br> c: 03-Eye-tracking-excel:包含眼动信息的excel文件。<br> d: 04-眼球追踪功能:包含pickle格式的眼球追踪功能和读取数据的源代码</font></p> 
<p><font size="4" face="楷体"><strong>B:’ code '文件夹包含本文使用的模型的源代码。</strong><br> a: 支持向量机，KNN，和逻辑回归源代码。<br> b: DNN源代码。<br> c: 传统的融合方法。<br> e:双峰深度自编码器,带有注意机制的深度典型相关分析。<br> f:源代码也可以在GitHub上找到。</font></p> 
<p><font size="4" face="楷体"><strong>C :information.xlsx:包含实验信息和被试信息。</strong><br> a:对于电影片段，积极、消极和中性情绪分别被标记为1、-1和0。<br> b:为了构建分类器，我们分别使用2、0、1表示积极、消极和中性情绪(即，影片剪辑标签加1)。此外，我们没有在眼动特征中保存标签，因为眼动标签与EEG DE特征的标签是一样的。</font></p> 
<h5><a id="_109"></a>采集数据示意图如下：</h5> 
<p><img src="https://images2.imgbox.com/f4/a1/EszOPKJp_o.png" alt="在这里插入图片描述" width="400"></p> 
<p><img src="https://images2.imgbox.com/cd/1b/YUA8UiLX_o.png" alt="在这里插入图片描述" width="400"></p> 
<p><img src="https://images2.imgbox.com/59/18/ELWhJJde_o.gif" alt="在这里插入图片描述" width="300"></p> 
<p>参考文献:</p> 
<hr class="footnotes-sep"> 
<section class="footnotes"> 
 <ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>https://bcmi.sjtu.edu.cn/home/seed/seed.html <a href="#fnref1" rel="nofollow" class="footnote-backref">↩︎</a></p> </li><li id="fn2" class="footnote-item"><p>Wei-Long Zheng, and Bao-Liang Lu, Investigating Critical Frequency Bands and Channels for EEG-based Emotion Recognition with Deep Neural Networks, accepted by IEEE Transactions on Autonomous Mental Development (IEEE TAMD) 7(3): 162-175, 2015. <a href="#fnref2" rel="nofollow" class="footnote-backref">↩︎</a></p> </li><li id="fn3" class="footnote-item"><p>Ruo-Nan Duan, Jia-Yi Zhu and Bao-Liang Lu, Differential Entropy Feature for EEG-based Emotion Classification, Proc. of the 6th International IEEE EMBS Conference on Neural Engineering (NER). 2013: 81-84. <a href="#fnref3" rel="nofollow" class="footnote-backref">↩︎</a></p> </li></ol> 
</section>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/336c883db1e231585b71b72aaccaf9a0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">QNAP&#43;Transmission</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bbb2fec79ef1a8acfbc1f2268b10b831/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用Transformer训练和测试EEG的公开SEED数据集</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>