<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>行人重识别(REID)——原理方法 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="行人重识别(REID)——原理方法" />
<meta property="og:description" content="行人重识别：短时 类内差异增大，类间差异减小 应用——行人跟踪 单摄像头单目标单摄像头多目标多摄像头多目标 行人重识别系统 特征提取
学习能够应对在不同摄像头下行人变化的特征
度量学习
将学习到的特征映射到新的空间使相同的人更近，不同的人更远
图像检索
根据图片特征之间的距离进行排序，返回检索结果
评价模式 single query vs multi query
Single query是指probe中每个人的图像为一张（N=1），而multi query是指probe中每个人的图像为N&gt;1张图像，然后融合N张图片的特征（最大池化或者平均池化）作为最终特征。同样的Rank-k下，一般N越大，得到的识别率越高。
特征 全局特征 每一张图片的全局信息进行一个特征抽取，全局特征没有任何的空间信息。
噪声区域会对全局特征造成极大的干扰姿态的不对齐也会使全局特征无法匹配 局部特征 对图像的某一个区域进行特征提取，最后将多个局部特征融合起来作为最终特征
水平切块 ★★★ 将图像进行水平方向的等分，每一个水平切块通过水平池化提取一个特征
Gate Siamese 和 AlignedReID 通过设计规则融合所有的局部特征计算距离
PCB，ICNN，SCPNet 对每一个局部特征计算一个 ReID 损失，直接将局部特征拼接起来
联合局部特征和全局特征往往能够得到更好的结果
Gate Siamese
每一块经过 CNN 网络得到特征，局部特征按顺序输入到 LSTM 网络，自动表达为图像最终的特征利用对比损失训练网络 AlignedReID
主要解决姿态不对齐的问题
骨架网络为 ResNet50
动态对齐 (DMLI) 假如输入图像为256×128，输出的特征图尺寸为 8×4×2048利用水平池化得到 8 个局部特征，并计算一个 8×8 的距离方阵对齐局部信息不能有跳连（从上到下）利用 shortest path 来找到最优的动态连接 PCB
输入图像 384×128，分成 6 块利用 ResNet50 提取特征，最后 24×8 的 feature map每一行提取一个局部特征，连接一个 ReID loss使用的时候把 6 个局部特征 concatenate 起来 ICNN" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/213980dd477c4ed5a98ccc57e0771f06/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-04T00:00:09+08:00" />
<meta property="article:modified_time" content="2023-05-04T00:00:09+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">行人重识别(REID)——原理方法</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>行人重识别：短时</h2> 
<ul><li>类内差异增大，类间差异减小</li></ul> 
<h3><a id="_4"></a>应用——行人跟踪</h3> 
<ol><li>单摄像头单目标</li><li>单摄像头多目标</li><li>多摄像头多目标</li></ol> 
<h3><a id="_10"></a>行人重识别系统</h3> 
<p><img src="https://images2.imgbox.com/fc/0c/pD4tWcPP_o.png" alt="行人重识别系统"></p> 
<ol><li> <p>特征提取</p> <p>学习能够应对在不同摄像头下行人变化的特征</p> </li><li> <p>度量学习</p> <p>将学习到的特征映射到新的空间使相同的人更近，不同的人更远</p> </li><li> <p>图像检索</p> <p>根据图片特征之间的距离进行排序，返回检索结果</p> </li></ol> 
<h3><a id="_26"></a>评价模式</h3> 
<ul><li> <p>single query vs multi query</p> <p>Single query是指probe中每个人的图像为一张（N=1），而multi query是指probe中每个人的图像为N&gt;1张图像，然后融合N张图片的特征（最大池化或者平均池化）作为最终特征。同样的Rank-k下，一般N越大，得到的识别率越高。</p> </li></ul> 
<h2><a id="_32"></a>特征</h2> 
<h3><a id="_34"></a>全局特征</h3> 
<p>每一张图片的全局信息进行一个特征抽取，全局特征没有任何的空间信息。</p> 
<ul><li>噪声区域会对全局特征造成极大的干扰</li><li>姿态的不对齐也会使全局特征无法匹配</li></ul> 
<h3><a id="_41"></a>局部特征</h3> 
<p>对图像的某一个区域进行特征提取，最后将多个局部特征融合起来作为最终特征</p> 
<h4><a id="__45"></a>水平切块 ★★★</h4> 
<ul><li> <p>将图像进行水平方向的等分，每一个水平切块通过水平池化提取一个特征</p> </li><li> <p>Gate Siamese 和 AlignedReID 通过设计规则融合所有的局部特征计算距离</p> </li><li> <p>PCB，ICNN，SCPNet 对每一个局部特征计算一个 ReID 损失，直接将局部特征拼接起来</p> </li><li> <p>联合局部特征和全局特征往往能够得到更好的结果</p> </li></ul> 
<p><strong>Gate Siamese</strong></p> 
<ul><li>每一块经过 CNN 网络得到特征，局部特征按顺序输入到 LSTM 网络，自动表达为图像最终的特征</li><li>利用对比损失训练网络</li></ul> 
<p><strong>AlignedReID</strong></p> 
<ul><li> <p>主要解决姿态不对齐的问题</p> </li><li> <p>骨架网络为 ResNet50</p> <h6><a id="_DMLI_64"></a>动态对齐 (DMLI)</h6> 
  <ul><li>假如输入图像为256×128，输出的特征图尺寸为 8×4×2048</li><li>利用水平池化得到 8 个局部特征，并计算一个 8×8 的距离方阵</li><li>对齐局部信息不能有跳连（从上到下）</li><li>利用 shortest path 来找到最优的动态连接</li></ul> </li></ul> 
<p><strong>PCB</strong></p> 
<ul><li>输入图像 384×128，分成 6 块</li><li>利用 ResNet50 提取特征，最后 24×8 的 feature map</li><li>每一行提取一个局部特征，连接一个 ReID loss</li><li>使用的时候把 6 个局部特征 concatenate 起来</li></ul> 
<p><strong>ICNN</strong></p> 
<p>ICNN≈PCB + global branch with triplet loss</p> 
<p><strong>SCPNet</strong></p> 
<p>利用 spatial part 特征连监督 channel group 特征，将 local feature 传给 global feature</p> 
<h4><a id="__86"></a>姿态信息 ★★★</h4> 
<ul><li>利用一个姿态估计模型得到行人的（14个）关键姿态点</li><li>根据姿态点得到具有语义信息的 part 区域</li><li>对于每个 part 区域提取局部特征</li><li>联合局部特征和全局特征往往能够得到更好的结果</li><li>姿态点估计模型：Hourglass、OpenPose、CPM、AlphaPose</li><li>Part：通过一定规则<strong>手工设置</strong>一些矩形框区域</li><li>Attention：网络<strong>自动学习</strong>出的比较重要的任意形状区域</li></ul> 
<p><strong>PIE</strong></p> 
<ul><li>CRM 提取姿态点</li><li>分成几个part，进行仿射变换对齐</li><li>融合原图和仿射图的特征</li><li>采用 ID 损失训练网络</li></ul> 
<p><strong>Spindle Net</strong></p> 
<ul><li>FFN 网络提取特征，FFN 网络层次性地融合特征</li></ul> 
<p><strong>PDC</strong></p> 
<ul><li>利用姿态点信息分割为六个part</li><li>改进 STN 网络为 PTN 网络，学习仿射变换参数得到 modified part image</li><li>融合全局特征和局部特征</li><li>计算三个 ReID 损失</li><li>浅层网络共享，高层网络独立</li></ul> 
<p><strong>GLAD</strong></p> 
<ul><li>分为头，上身，下身三个 part</li><li>融合全局特征和三个 part 的特征</li></ul> 
<p><strong>PABP</strong></p> 
<ul><li>利用 ReID 网络提取 feature map A</li><li>利用 openpose 提取 feature map P</li><li>A 和 R 每个对应像素位置的向量进行外积，并向量化</li><li>会激活对应位置的外观特征</li></ul> 
<h4><a id="__127"></a>分割信息 ★★</h4> 
<ul><li>图像语义分割是一种极精细的像素级别 part 信息</li><li>图像分割分为粗粒度的行人前景分割和细粒度的肢体语义分割</li><li>分割结果通常作为图像预处理的 Mask 或者 feature map 中的 attention 相乘</li><li>目前基于分割的方法没有取得特别广泛的应用</li></ul> 
<p><strong>前背景提取</strong></p> 
<p><strong>SPReID</strong></p> 
<h4><a id="__138"></a>网格特征 ★</h4> 
<ul><li>网格特征是比较细粒度的物理区域特征</li><li>早期工作将网格特征扩展为part特征计算两幅图像的特征图差</li><li>近期利用网格特征解决 partial ReID 工作</li><li>总体而言网格特征并不常用</li></ul> 
<p><strong>IDLA</strong></p> 
<ul><li>骨干网络为 Siamese 网络计算</li><li>两幅图 5x5 网格特征差值</li><li>交换"主客"分别计算 K 和 K’</li><li>计算二分类验证损失</li></ul> 
<p><strong>PersonNet</strong></p> 
<p><strong>DSR</strong></p> 
<ul><li>将一副图像的所有网格特征作为一个特征集合</li><li>对两个特征集合进行稀疏重建得到集合距离</li></ul> 
<h2><a id="_159"></a>序列重识别</h2> 
<p><img src="https://images2.imgbox.com/54/28/vvLZdX0h_o.png" alt="论文"></p> 
<ul><li>姿态变化丰富</li><li>遮挡现象普遍</li><li>总有几帧质量好，也有几帧质量差</li><li>需要考虑如何融合各帧的信息</li></ul> 
<h3><a id="___168"></a>单帧 → 序列</h3> 
<ul><li>对每一帧图像都提取一个ReID特征</li><li>直接通过平均池化或者最大池化来得到最终的ReID特征</li><li>比较简单，性能依赖于单帧 ReID 的性能</li></ul> 
<h3><a id="CNNLSTM_174"></a>CNN+LSTM</h3> 
<ul><li>类似于动作识别，利用 CNN 提取特征，然后利用 LSTM 提取时序特征</li></ul> 
<h3><a id="_178"></a>难点</h3> 
<ul><li>如何对多帧特征进行特征融合？</li><li>如何对每帧图像进行质量判断？</li><li>如何提取序列图像的运动特征？</li><li>如何解决序列帧数不统一问题？</li><li>如何提高序列 ReID 的运算效率？</li></ul> 
<h3><a id="_186"></a>学术尝试</h3> 
<p><strong>AMOC</strong></p> 
<ul><li>帧与帧之间存在着运动（步态）特征，也有利于 ReID 任务</li><li>包含空间子网络和运动子网络 
  <ul><li>空间子网络提取单帧图像的内容特征</li><li>运动子网络提取相邻两帧的运动特征</li><li>融合内容特征与运动特征作为该帧的最终特征</li></ul> </li><li>利用 RNN 网络融合所有帧的特征信息</li><li>利用对比损失判断两个序列是否属于同一个行人ID</li></ul> 
<p><strong>DFGP</strong></p> 
<ul><li>采用传统的 LOMO 特征提取序列每一帧图像的行人特征</li></ul> 
<ol><li>利用 PCN 网络提取每一帧特征，之后平均池化得到序列特征，找到最稳定帧 MSVP</li><li>对 MSVP 提取 LOMO 特征，并与序列q计算特征距离，按照距离进行 softmin 归一化，得到每帧权重</li><li>特征×权重之后进行最大池化</li><li>融合池化后的序列特征和最稳定帧的特征作为最终特征</li></ol> 
<p><strong>RQEN</strong></p> 
<ul><li>遮挡是序列重识别中非常普遍的一个问题，会造成特征分布不均匀</li></ul> 
<ol><li> <p>对每帧行人提取14个关键姿态点，并分为3个语义 part</p> </li><li> <p>当某个姿态点被遮挡之后，pose map 的响应值会非常低</p> </li></ol> 
<ul><li>全局分支提取全局特征</li><li>局部分支提取局部特征</li><li>姿态分支对图像进行质量（遮挡）判断</li></ul> 
<h2><a id="_GAN__219"></a>基于 GAN 的方法</h2> 
<h3><a id="_221"></a>痛点</h3> 
<ul><li>数据不够用 → 生成图像 
  <ul><li>政府限制监控数据的采集</li><li>人工标注采集数据价格昂贵</li><li>缺乏一些极难的极端样本</li></ul> </li><li>数据有偏差 → 减小偏差 
  <ul><li>姿态与姿态之间存在偏差</li><li>相机与相机之间存在偏差</li><li>地域与地域之间存在偏差</li></ul> </li></ul> 
<h3><a id="_232"></a>组成</h3> 
<ul><li>生成器：随机数 → 生成样本</li><li>判别器：判断生成样本是否真实</li></ul> 
<h3><a id="_237"></a>代表方法</h3> 
<p><strong>GAN+LSRO</strong></p> 
<p>利用 GAN 网络随机生成行人图片，利用 LSRO 技术平滑 ID 标签，训练交叉熵损失</p> 
<ul><li>照片随机生成，ID 信息不可靠</li></ul> 
<p><strong>CamStyle</strong></p> 
<p>利用 CycleGAN 来实现任意两个相机之间的风格转换</p> 
<ul><li>原始样本计算ID损失，生成样本利用平滑标签计算交叉熵损失</li></ul> 
<p><strong>PTGAN</strong></p> 
<p>不同场景下采集的数据存在明显的偏差</p> 
<ul><li>利用 PSPNet 分割行人前景 mask</li><li>利用 CycleGAN 的思想进行图像风格转换</li><li>计算mask区域生成损失，保持行人前景尽可能不变</li><li>联合风格损失与生成损失</li></ul> 
<p><strong>SPGAN</strong></p> 
<p>与 PTGAN 类似，利用 source domain 的数据生成 target domain，解决不同场景下采集的数据间的明显偏差</p> 
<p><strong>PNGAN</strong></p> 
<p>利用 GAN 来生成固定姿态样本</p> 
<ul><li>利用 GAN 生成目标姿态的样本</li><li>原图和生成图分别进入两个 ReID 网络</li><li>融合原图和生成图的特征作为最终特征，融合方式使用max池化</li></ul> 
<h3><a id="_272"></a>对比</h3> 
<table><thead><tr><th>算法</th><th>GAN</th><th>CycleGAN</th><th>PTGAN</th><th>SPGAN</th><th>PNGAN</th></tr></thead><tbody><tr><td>基础</td><td>GAN</td><td>CycleGAN</td><td>CycleGAN</td><td>CycleGAN</td><td>InfoGAN</td></tr><tr><td>额外</td><td>标签平滑</td><td>标签平滑</td><td>前景分割</td><td>孪生网络</td><td>姿态估计</td></tr><tr><td>目标</td><td>数据增广</td><td>相机偏差</td><td>数据域偏差</td><td>数据域偏差</td><td>姿态偏差</td></tr></tbody></table>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3b95ad3ba539119013ab80d6af1418d3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">docker本地私有仓库与harbor私有仓库</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5c98415201b5a31cdea10be026b39490/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">百万级数据导入导出优化总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>