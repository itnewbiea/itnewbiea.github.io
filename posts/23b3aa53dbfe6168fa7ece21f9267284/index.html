<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>竞赛选题 题目：基于LSTM的预测算法 - 股票预测 天气预测 房价预测 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="竞赛选题 题目：基于LSTM的预测算法 - 股票预测 天气预测 房价预测" />
<meta property="og:description" content="文章目录 0 简介1 基于 Keras 用 LSTM 网络做时间序列预测2 长短记忆网络3 LSTM 网络结构和原理3.1 LSTM核心思想3.2 遗忘门3.3 输入门3.4 输出门 4 基于LSTM的天气预测4.1 数据集4.2 预测示例 5 基于LSTM的股票价格预测5.1 数据集5.2 实现代码 6 lstm 预测航空旅客数目数据集预测代码 7 最后 0 简介 🔥 优质竞赛项目系列，今天要分享的是
基于LSTM的预测算法 - 股票预测 天气预测 房价预测
该项目较为新颖，适合作为竞赛课题方向，学长非常推荐！
🧿 更多资料, 项目分享：
https://gitee.com/dancheng-senior/postgraduate
1 基于 Keras 用 LSTM 网络做时间序列预测 时间序列预测是一类比较困难的预测问题。
与常见的回归预测模型不同，输入变量之间的“序列依赖性”为时间序列问题增加了复杂度。
一种能够专门用来处理序列依赖性的神经网络被称为 递归神经网络（Recurrent Neural
Networks、RNN）。因其训练时的出色性能，长短记忆网络（Long Short-Term Memory
Network，LSTM）是深度学习中广泛使用的一种递归神经网络（RNN）。
在本篇文章中，将介绍如何在 R 中使用 keras 深度学习包构建 LSTM 神经网络模型实现时间序列预测。
如何为基于回归、窗口法和时间步的时间序列预测问题建立对应的 LSTM 网络。对于非常长的序列，如何在构建 LSTM 网络和用 LSTM 网络做预测时保持网络关于序列的状态（记忆）。 2 长短记忆网络 长短记忆网络，或 LSTM 网络，是一种递归神经网络（RNN），通过训练时在“时间上的反向传播”来克服梯度消失问题。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/23b3aa53dbfe6168fa7ece21f9267284/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-24T17:37:41+08:00" />
<meta property="article:modified_time" content="2023-11-24T17:37:41+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">竞赛选题 题目：基于LSTM的预测算法 - 股票预测 天气预测 房价预测</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#0__2" rel="nofollow">0 简介</a></li><li><a href="#1__Keras__LSTM__15" rel="nofollow">1 基于 Keras 用 LSTM 网络做时间序列预测</a></li><li><a href="#2__30" rel="nofollow">2 长短记忆网络</a></li><li><a href="#3_LSTM__49" rel="nofollow">3 LSTM 网络结构和原理</a></li><li><ul><li><a href="#31_LSTM_66" rel="nofollow">3.1 LSTM核心思想</a></li><li><a href="#32__81" rel="nofollow">3.2 遗忘门</a></li><li><a href="#33__99" rel="nofollow">3.3 输入门</a></li><li><a href="#34__106" rel="nofollow">3.4 输出门</a></li></ul> 
  </li><li><a href="#4_LSTM_116" rel="nofollow">4 基于LSTM的天气预测</a></li><li><ul><li><a href="#41__118" rel="nofollow">4.1 数据集</a></li><li><a href="#42__131" rel="nofollow">4.2 预测示例</a></li></ul> 
  </li><li><a href="#5_LSTM_224" rel="nofollow">5 基于LSTM的股票价格预测</a></li><li><ul><li><a href="#51__226" rel="nofollow">5.1 数据集</a></li><li><a href="#52__232" rel="nofollow">5.2 实现代码</a></li></ul> 
  </li><li><a href="#6_lstm__305" rel="nofollow">6 lstm 预测航空旅客数目</a></li><li><ul><li><a href="#_307" rel="nofollow">数据集</a></li><li><a href="#_318" rel="nofollow">预测代码</a></li></ul> 
  </li><li><a href="#7__433" rel="nofollow">7 最后</a></li></ul> 
</div> 
<p></p> 
<h2><a id="0__2"></a>0 简介</h2> 
<p>🔥 优质竞赛项目系列，今天要分享的是</p> 
<p><strong>基于LSTM的预测算法 - 股票预测 天气预测 房价预测</strong></p> 
<p>该项目较为新颖，适合作为竞赛课题方向，学长非常推荐！</p> 
<p>🧿 <strong>更多资料, 项目分享：</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p> 
<h2><a id="1__Keras__LSTM__15"></a>1 基于 Keras 用 LSTM 网络做时间序列预测</h2> 
<p>时间序列预测是一类比较困难的预测问题。</p> 
<p>与常见的回归预测模型不同，输入变量之间的“序列依赖性”为时间序列问题增加了复杂度。</p> 
<p>一种能够专门用来处理序列依赖性的神经网络被称为 递归神经网络（Recurrent Neural<br> Networks、RNN）。因其训练时的出色性能，长短记忆网络（Long Short-Term Memory<br> Network，LSTM）是深度学习中广泛使用的一种递归神经网络（RNN）。</p> 
<p>在本篇文章中，将介绍如何在 R 中使用 keras 深度学习包构建 LSTM 神经网络模型实现时间序列预测。</p> 
<ul><li>如何为基于回归、窗口法和时间步的时间序列预测问题建立对应的 LSTM 网络。</li><li>对于非常长的序列，如何在构建 LSTM 网络和用 LSTM 网络做预测时保持网络关于序列的状态（记忆）。</li></ul> 
<h2><a id="2__30"></a>2 长短记忆网络</h2> 
<p>长短记忆网络，或 LSTM 网络，是一种递归神经网络（RNN），通过训练时在“时间上的反向传播”来克服梯度消失问题。</p> 
<p>LSTM 网络可以用来构建大规模的递归神经网络来处理机器学习中复杂的序列问题，并取得不错的结果。</p> 
<p>除了神经元之外，LSTM 网络在神经网络层级（layers）之间还存在记忆模块。</p> 
<p>一个记忆模块具有特殊的构成，使它比传统的神经元更“聪明”，并且可以对序列中的前后部分产生记忆。模块具有不同的“门”（gates）来控制模块的状态和输出。一旦接收并处理一个输入序列，模块中的各个门便使用<br> S 型的激活单元来控制自身是否被激活，从而改变模块状态并向模块添加信息（记忆）。</p> 
<p>一个激活单元有三种门：</p> 
<ul><li>遗忘门（Forget Gate）：决定抛弃哪些信息。</li><li>输入门（Input Gate）：决定输入中的哪些值用来更新记忆状态。</li><li>输出门（Output Gate）：根据输入和记忆状态决定输出的值。</li></ul> 
<p>每一个激活单元就像是一个迷你状态机，单元中各个门的权重通过训练获得。</p> 
<h2><a id="3_LSTM__49"></a>3 LSTM 网络结构和原理</h2> 
<p>long short term memory，即我们所称呼的LSTM，是为了解决长期以来问题而专门设计出来的，所有的RNN都具有一种重复神</p> 
<p><img src="https://images2.imgbox.com/66/da/FAWXkMZ4_o.png" alt="在这里插入图片描述"></p> 
<p>LSTM 同样是这样的结构，但是重复的模块拥有一个不同的结构。不同于单一神经网络层，这里是有四个，以一种非常特殊的方式进行交互。</p> 
<p><img src="https://images2.imgbox.com/1e/63/VvS3D7cQ_o.png" alt="在这里插入图片描述"></p> 
<p>不必担心这里的细节。我们会一步一步地剖析 LSTM 解析图。现在，我们先来熟悉一下图中使用的各种元素的图标。</p> 
<p><img src="https://images2.imgbox.com/14/92/hoKFSqTa_o.png" alt="在这里插入图片描述"></p> 
<p>在上面的图例中，每一条黑线传输着一整个向量，从一个节点的输出到其他节点的输入。粉色的圈代表 pointwise<br> 的操作，诸如向量的和，而黄色的矩阵就是学习到的神经网络层。合在一起的线表示向量的连接，分开的线表示内容被复制，然后分发到不同的位置。</p> 
<h3><a id="31_LSTM_66"></a>3.1 LSTM核心思想</h3> 
<p>LSTM的关键在于细胞的状态整个(如下图)，和穿过细胞的那条水平线。</p> 
<p>细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传保持不变会很容易。</p> 
<p><img src="https://images2.imgbox.com/e8/fc/Uzj8ZOMg_o.png" alt="在这里插入图片描述"><br> 门可以实现选择性地让信息通过，主要是通过一个 sigmoid 的神经层 和一个逐点相乘的操作来实现的。</p> 
<p><img src="https://images2.imgbox.com/21/39/DiB42PxL_o.png" alt="在这里插入图片描述"><br> sigmoid 层输出（是一个向量）的每个元素都是一个在 0 和 1 之间的实数，表示让对应信息通过的权重（或者占比）。比如， 0<br> 表示“不让任何信息通过”， 1 表示“让所有信息通过”。</p> 
<p>LSTM通过三个这样的本结构来实现信息的保护和控制。这三个门分别输入门、遗忘门和输出门。</p> 
<h3><a id="32__81"></a>3.2 遗忘门</h3> 
<p>在我们 LSTM 中的第一步是决定我们会从细胞状态中丢弃什么信息。这个决定通过一个称为忘记门层完成。该门会读取和，输出一个在 0到<br> 1之间的数值给每个在细胞状态中的数字。1 表示“完全保留”，0 表示“完全舍弃”。</p> 
<p>让我们回到语言模型的例子中来基于已经看到的预测下一个词。在这个问题中，细胞状态可能包含当前主语的性别，因此正确的代词可以被选择出来。当我们看到新的主语，我们希望忘记旧的主语。</p> 
<p><img src="https://images2.imgbox.com/54/1e/BpXjmuYt_o.png" alt="在这里插入图片描述"><br> 其中</p> 
<p><img src="https://images2.imgbox.com/78/45/dB3rdemb_o.png" alt="在这里插入图片描述"></p> 
<p>表示的是 上一时刻隐含层的 输出，</p> 
<p><img src="https://images2.imgbox.com/2b/b8/6wwnqXTb_o.png" alt="在这里插入图片描述"></p> 
<p>表示的是当前细胞的输入。σ表示sigmod函数。</p> 
<h3><a id="33__99"></a>3.3 输入门</h3> 
<p>下一步是决定让多少新的信息加入到 cell 状态 中来。实现这个需要包括两个步骤：首先，一个叫做“input gate layer ”的 sigmoid<br> 层决定哪些信息需要更新；一个 tanh 层生成一个向量，也就是备选的用来更新的内容。在下一步，我们把这两部分联合起来，对 cell 的状态进行一个更新。</p> 
<p><img src="https://images2.imgbox.com/95/bc/i2sMB99o_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="34__106"></a>3.4 输出门</h3> 
<p>最终，我们需要确定输出什么值。这个输出将会基于我们的细胞状态，但是也是一个过滤后的版本。首先，我们运行一个 sigmoid<br> 层来确定细胞状态的哪个部分将输出出去。接着，我们把细胞状态通过 tanh 进行处理（得到一个在 -1 到 1 之间的值）并将它和 sigmoid<br> 门的输出相乘，最终我们仅仅会输出我们确定输出的那部分。</p> 
<p>在语言模型的例子中，因为他就看到了一个代词，可能需要输出与一个动词相关的信息。例如，可能输出是否代词是单数还是负数，这样如果是动词的话，我们也知道动词需要进行的词形变化。</p> 
<p><img src="https://images2.imgbox.com/54/62/FvjnTGxs_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="4_LSTM_116"></a>4 基于LSTM的天气预测</h2> 
<h3><a id="41__118"></a>4.1 数据集</h3> 
<p><img src="https://images2.imgbox.com/61/b3/1qbssagF_o.png" alt="在这里插入图片描述"></p> 
<p>如上所示，每10分钟记录一次观测值，一个小时内有6个观测值，一天有144（6x24）个观测值。</p> 
<p>给定一个特定的时间，假设要预测未来6小时的温度。为了做出此预测，选择使用5天的观察时间。因此，创建一个包含最后720（5x144）个观测值的窗口以训练模型。</p> 
<p>下面的函数返回上述时间窗以供模型训练。参数 history_size 是过去信息的滑动窗口大小。target_size<br> 是模型需要学习预测的未来时间步，也作为需要被预测的标签。</p> 
<p>下面使用数据的前300,000行当做训练数据集，其余的作为验证数据集。总计约2100天的训练数据。</p> 
<h3><a id="42__131"></a>4.2 预测示例</h3> 
<p>多步骤预测模型中，给定过去的采样值，预测未来一系列的值。对于多步骤模型，训练数据再次包括每小时采样的过去五天的记录。但是，这里的模型需要学习预测接下来12小时的温度。由于每10分钟采样一次数据，因此输出为72个预测值。</p> 
<p>​</p> 
<pre><code class="prism language-python">future_target <span class="token operator">=</span> <span class="token number">72</span>
x_train_multi<span class="token punctuation">,</span> y_train_multi <span class="token operator">=</span> multivariate_data<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> dataset<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>
                                                 TRAIN_SPLIT<span class="token punctuation">,</span> past_history<span class="token punctuation">,</span>
                                                 future_target<span class="token punctuation">,</span> STEP<span class="token punctuation">)</span>
x_val_multi<span class="token punctuation">,</span> y_val_multi <span class="token operator">=</span> multivariate_data<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> dataset<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                             TRAIN_SPLIT<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> past_history<span class="token punctuation">,</span>
                                             future_target<span class="token punctuation">,</span> STEP<span class="token punctuation">)</span>
</code></pre> 
<p><strong>划分数据集</strong></p> 
<p>​</p> 
<pre><code class="prism language-python">train_data_multi <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_train_multi<span class="token punctuation">,</span> y_train_multi<span class="token punctuation">)</span><span class="token punctuation">)</span>
train_data_multi <span class="token operator">=</span> train_data_multi<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>BUFFER_SIZE<span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span>BATCH_SIZE<span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token punctuation">)</span>

val_data_multi <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_val_multi<span class="token punctuation">,</span> y_val_multi<span class="token punctuation">)</span><span class="token punctuation">)</span>
val_data_multi <span class="token operator">=</span> val_data_multi<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>BATCH_SIZE<span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>​</p> 
<p><strong>绘制样本点数据</strong></p> 
<p>​</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">multi_step_plot</span><span class="token punctuation">(</span>history<span class="token punctuation">,</span> true_future<span class="token punctuation">,</span> prediction<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    num_in <span class="token operator">=</span> create_time_steps<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>history<span class="token punctuation">)</span><span class="token punctuation">)</span>
    num_out <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>true_future<span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>num_in<span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>history<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'History'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_out<span class="token punctuation">)</span><span class="token operator">/</span>STEP<span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>true_future<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'bo'</span><span class="token punctuation">,</span>
           label<span class="token operator">=</span><span class="token string">'True Future'</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> prediction<span class="token punctuation">.</span><span class="token builtin">any</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_out<span class="token punctuation">)</span><span class="token operator">/</span>STEP<span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'ro'</span><span class="token punctuation">,</span>
                 label<span class="token operator">=</span><span class="token string">'Predicted Future'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> train_data_multi<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  multi_step_plot<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>​</p> 
<p><img src="https://images2.imgbox.com/f1/c1/jD03M7ew_o.png" alt="在这里插入图片描述"></p> 
<p>此处的任务比先前的任务复杂一些，因此该模型现在由两个LSTM层组成。最后，由于需要预测之后12个小时的数据，因此Dense层将输出为72。</p> 
<p>​</p> 
<pre><code class="prism language-python">multi_step_model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
multi_step_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span>
                                          return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                          input_shape<span class="token operator">=</span>x_train_multi<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
multi_step_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
multi_step_model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">72</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

multi_step_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>clipvalue<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">'mae'</span><span class="token punctuation">)</span>
</code></pre> 
<p>​</p> 
<p><strong>训练</strong></p> 
<p>​</p> 
<pre><code class="prism language-python">multi_step_history <span class="token operator">=</span> multi_step_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_data_multi<span class="token punctuation">,</span> epochs<span class="token operator">=</span>EPOCHS<span class="token punctuation">,</span>
                                          steps_per_epoch<span class="token operator">=</span>EVALUATION_INTERVAL<span class="token punctuation">,</span>
                                          validation_data<span class="token operator">=</span>val_data_multi<span class="token punctuation">,</span>
                                          validation_steps<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/db/43/fbITFmyY_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/79/cc/88UwB3Qn_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="5_LSTM_224"></a>5 基于LSTM的股票价格预测</h2> 
<h3><a id="51__226"></a>5.1 数据集</h3> 
<p>股票数据总共有九个维度，分别是</p> 
<p><img src="https://images2.imgbox.com/81/79/CJDe484W_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="52__232"></a>5.2 实现代码</h3> 
<p>​</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span><span class="token comment">#显示中文</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token comment">#显示负号</span>

<span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    test_x_batch <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">r'test_x_batch.npy'</span><span class="token punctuation">,</span>allow_pickle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_y_batch <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">r'test_y_batch.npy'</span><span class="token punctuation">,</span>allow_pickle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>test_x_batch<span class="token punctuation">,</span>test_y_batch<span class="token punctuation">)</span>

<span class="token comment">#定义lstm单元</span>
<span class="token keyword">def</span> <span class="token function">lstm_cell</span><span class="token punctuation">(</span>units<span class="token punctuation">)</span><span class="token punctuation">:</span>
    cell <span class="token operator">=</span> tf<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>BasicLSTMCell<span class="token punctuation">(</span>num_units<span class="token operator">=</span>units<span class="token punctuation">,</span>forget_bias<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token comment">#activation默认为tanh</span>
    <span class="token keyword">return</span> cell

<span class="token comment">#定义lstm网络</span>
<span class="token keyword">def</span> <span class="token function">lstm_net</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>w<span class="token punctuation">,</span>b<span class="token punctuation">,</span>num_neurons<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#将输入变成一个列表，列表的长度及时间步数</span>
    inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    cells <span class="token operator">=</span> <span class="token punctuation">[</span>lstm_cell<span class="token punctuation">(</span>units<span class="token operator">=</span>n<span class="token punctuation">)</span> <span class="token keyword">for</span> n <span class="token keyword">in</span> num_neurons<span class="token punctuation">]</span>
    stacked_lstm_cells <span class="token operator">=</span> tf<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>MultiRNNCell<span class="token punctuation">(</span>cells<span class="token punctuation">)</span>
    outputs<span class="token punctuation">,</span>_ <span class="token operator">=</span>  tf<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>static_rnn<span class="token punctuation">(</span>stacked_lstm_cells<span class="token punctuation">,</span>inputs<span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>outputs<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b

<span class="token comment">#超参数</span>
num_neurons <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">]</span>

<span class="token comment">#定义输出层的weight和bias</span>
w <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>num_neurons<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#定义placeholder</span>
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment">#定义pred和saver</span>
pred <span class="token operator">=</span> lstm_net<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w<span class="token punctuation">,</span>b<span class="token punctuation">,</span>num_neurons<span class="token punctuation">)</span>
saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>

    <span class="token comment">#开启交互式Session</span>
    sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>InteractiveSession<span class="token punctuation">(</span><span class="token punctuation">)</span>
    saver<span class="token punctuation">.</span>restore<span class="token punctuation">(</span>sess<span class="token punctuation">,</span><span class="token string">r'D:\股票预测\model_data\my_model.ckpt'</span><span class="token punctuation">)</span>

    <span class="token comment">#载入数据</span>
    test_x<span class="token punctuation">,</span>test_y <span class="token operator">=</span> load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">#预测</span>
    predicts <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>pred<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>x<span class="token punctuation">:</span>test_x<span class="token punctuation">}</span><span class="token punctuation">)</span>
    predicts <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>predicts<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> predicts<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>predicts<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> predicts<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#数学校准</span>

    <span class="token comment">#可视化</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>predicts<span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'预测曲线'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>test_y<span class="token punctuation">,</span><span class="token string">'g'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'真实曲线'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'第几天/days'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'开盘价(归一化)'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'股票开盘价曲线预测(测试集)'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
	plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#关闭会话</span>
    sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>	
</code></pre> 
<p><img src="https://images2.imgbox.com/d2/47/ej05Mk6G_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="6_lstm__305"></a>6 lstm 预测航空旅客数目</h2> 
<h3><a id="_307"></a>数据集</h3> 
<p>airflights passengers dataset下载地址</p> 
<p>https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-<br> passengers.csv</p> 
<p>这个dataset包含从1949年到1960年每个月的航空旅客数目，共12*12=144个数字。</p> 
<p>下面的程序中，我们以1949-1952的数据预测1953的数据，以1950-1953的数据预测1954的数据，以此类推，训练模型。</p> 
<h3><a id="_318"></a>预测代码</h3> 
<p>​</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler
<span class="token keyword">import</span> os
 
<span class="token comment"># super parameters</span>
EPOCH <span class="token operator">=</span> <span class="token number">400</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.01</span>
seq_length <span class="token operator">=</span> <span class="token number">4</span>   <span class="token comment"># 序列长度</span>
n_feature <span class="token operator">=</span> <span class="token number">12</span>   <span class="token comment"># 序列中每个元素的特征数目。本程序采用的序列元素为一年的旅客，一年12个月，即12维特征。</span>
 
<span class="token comment"># data</span>
data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'airline-passengers.csv'</span><span class="token punctuation">)</span>   <span class="token comment"># 共 "12年*12个月=144" 个数据</span>
data <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values        <span class="token comment"># dataFrame, shape (144,1)</span>
data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
sc <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> sc<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>          <span class="token comment"># 归一化</span>
data <span class="token operator">=</span> data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> n_feature<span class="token punctuation">)</span>     <span class="token comment"># shape (12, 12)</span>
 
trainData_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
trainData_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-</span>seq_length<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tmp_x <span class="token operator">=</span> data<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>seq_length<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    tmp_y <span class="token operator">=</span> data<span class="token punctuation">[</span>i<span class="token operator">+</span>seq_length<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    trainData_x<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmp_x<span class="token punctuation">)</span>
    trainData_y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmp_y<span class="token punctuation">)</span>
 
<span class="token comment"># model</span>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">,</span> hidden_dim<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> output_dim<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">,</span> n_layer<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>in_dim <span class="token operator">=</span> in_dim
        self<span class="token punctuation">.</span>hidden_dim <span class="token operator">=</span> hidden_dim
        self<span class="token punctuation">.</span>output_dim <span class="token operator">=</span> output_dim
        self<span class="token punctuation">.</span>n_layer <span class="token operator">=</span> n_layer
        self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token operator">=</span>in_dim<span class="token punctuation">,</span> hidden_size<span class="token operator">=</span>hidden_dim<span class="token punctuation">,</span> num_layers<span class="token operator">=</span>n_layer<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        _<span class="token punctuation">,</span> <span class="token punctuation">(</span>h_out<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># h_out是序列最后一个元素的hidden state</span>
                                      <span class="token comment"># h_out's shape (batchsize, n_layer*n_direction, hidden_dim), i.e. (1, 1, 10)</span>
                                      <span class="token comment"># n_direction根据是“否为双向”取值为1或2</span>
        h_out <span class="token operator">=</span> h_out<span class="token punctuation">.</span>view<span class="token punctuation">(</span>h_out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># h_out's shape (batchsize, n_layer * n_direction * hidden_dim), i.e. (1, 10)</span>
        h_out <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>h_out<span class="token punctuation">)</span>    <span class="token comment"># h_out's shape (batchsize, output_dim), (1, 12)</span>
        <span class="token keyword">return</span> h_out
 
train <span class="token operator">=</span> <span class="token boolean">True</span>
<span class="token keyword">if</span> train<span class="token punctuation">:</span>
    model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss_func <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>
    <span class="token comment"># train</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>EPOCH<span class="token punctuation">)</span><span class="token punctuation">:</span>
        total_loss <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> iteration<span class="token punctuation">,</span> X <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>trainData_x<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># X's shape (seq_length, n_feature)</span>
            X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            X <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>                <span class="token comment"># X's shape (1, seq_length, n_feature), 1 is batchsize</span>
            output <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>       <span class="token comment"># output's shape (1,12)</span>
            output <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>output<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>trainData_y<span class="token punctuation">[</span>iteration<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># clear gradients for this training iteration</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token comment"># computing gradients</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># update weights</span>
            total_loss <span class="token operator">+=</span> loss
 
        <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch:{:3d}, loss:{:6.4f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> total_loss<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># torch.save(model, 'flight_model.pkl')  # 这样保存会弹出UserWarning，建议采用下面的保存方法，详情可参考https://zhuanlan.zhihu.com/p/129948825</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'state_dict'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token string">'checkpoint.pth.tar'</span><span class="token punctuation">)</span>
 
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token comment"># model = torch.load('flight_model.pth')</span>
    model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'checkpoint.pth.tar'</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 
<span class="token comment"># predict</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
predict <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> X <span class="token keyword">in</span> trainData_x<span class="token punctuation">:</span>             <span class="token comment"># X's shape (seq_length, n_feature)</span>
    X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>     <span class="token comment"># X's shape (1, seq_length, n_feature), 1 is batchsize</span>
    output <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>             <span class="token comment"># output's shape (1,12)</span>
    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>output<span class="token punctuation">)</span>
    predict<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
<span class="token comment"># plot</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
predict <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>predict<span class="token punctuation">)</span>
predict <span class="token operator">=</span> predict<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_tick <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>predict<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>seq_length<span class="token operator">*</span>n_feature<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>x_tick<span class="token punctuation">)</span><span class="token punctuation">,</span> predict<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'predict data'</span><span class="token punctuation">)</span>
 
data_original <span class="token operator">=</span> data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_original<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> data_original<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'original data'</span><span class="token punctuation">)</span>
 
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果</p> 
<p><img src="https://images2.imgbox.com/c1/49/6szJVxZL_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/e4/c6/wdMt7QAU_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="7__433"></a>7 最后</h2> 
<p>🧿 <strong>更多资料, 项目分享：</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/cf86cb2ade7334ed508fa2b94f4aaca2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">访问者模式 (Visitor Pattern)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/db4b05224b4819a2781dc131ad8faedf/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Linux基础】Linux常见指令总结及周边小知识</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>