<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>TFill：Bridging Global Context Interactions for High-Fidelity Image Completion论文阅读笔记 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="TFill：Bridging Global Context Interactions for High-Fidelity Image Completion论文阅读笔记" />
<meta property="og:description" content="-CVPR 2022
-提出问题： 正确桥接全局上下文交互对于使用大掩摸完成高保真图像非常重要。以前的方法通过深或大的感受野（RF）卷积来尝试这一点，但无法摆脱附近相互作用的主导地位，这是劣势。
通过堆叠卷积层得到的全局信息，存在限制：
①由于卷积的平移不变性，信息流主要是局部的，全局信息只是通过多层的类热传播逐渐共享。
②在推理阶段，相邻层之家你的元素通过学习但固定的权重来链接，而不是依赖于输入的自适应权重，这就意味着长距离信息只在一个非常深的层中低效传播，导致网络趋向于以孔洞附近的信息为基础填充孔洞，而不是远距离可见像素。
-主要工作
本文提出将图像修复任务视为无方向的序列-序列的预测任务，使用Transformer可以保证去信息平等的流动到各个像素上。主要贡献如下：
①利用限制性的CNN提出图像表征 token representation，减轻了从局部可见区域传播到缺失区域的影响。
②通过一个以transformer为基础的架构，这些token之间的远程交互被显式地建模，其中掩蔽令牌可以感知其他机会平等的可见令牌，而不管它们的位置如何。这导致了对最先进的方法有了显著的改进。
③本文引入了一种具有自适应注意平衡的新型注意意识层，以获得更高质量和分辨率的结果。
-网络结构
（a）首先将mask input失真图像resize固定为256*256大小，然后输入Restrictive CNN生成token，再喂入transformer中进行远距离交互，得到初步的coarse result。
（b）将mask input 与coarse result重新组合，输入到refinement network中，该network中包含Attention-Aware Layer 从可见区域和生成区域传输高质量的信息。
- Method
① Content Inference Network:TFill-Coarse
考虑到固定长度的位置嵌入和计算成本，本文先将图片任何大小的图片resize至256*256.
Restrictive CNN:该模块的主要作用就是提取感受野不重叠的token。
先前的token representation 方式要不就是采用某个像素点会使得下采样的过程中丢失大量的信息，要不就是整张图像，不同的token之间存在重叠。
本文利用Restrictive CNN来进行token representation。这个模块包括四个block，在每一个block中，利用1x1卷积和layernorm来进行非线性映射，然后再用部分卷积（k=2，s=2）来提取可用信息。通过上述做法，保证每个token只代表局部patch中的可见信息。
Weighted self-attention layer：
为了进一步鼓励模型偏向于重要的可见值，作者用weighted self-attention代替了普通的self-attention。即应用一个权重来衡量注意力分数。初始的权重通过计算一个patch中可见像素的比例。然后在每个编码器层后面按照的方式更新权重。 CNN-based Decoder
利用卷积层组成的decoder端对特征进行上采样，以此生成coarse result初步图像。
② Appearance Refinement Network：TFill-Refined
尽管Coarse网络已经生成合理的结果，但还是存在不足。由于固定的input size 256*256，这使得coarse网络不适用于高分辨率图像。且生成的结果可能会和原始的外观不完全一致。如下图所示：左右眼睛异瞳
为了解决上述问题，提出了refinement network。为了进一步利用全局中可见的高频细节，设计了一个注意力感知层AAL来从编码和解码的特征中远程复制信息。
如下图所示，给定一个解码特征xd，首先计算其注意力分数
再以mask为基础将A分为Av（可见区域相似度）和Am（生成区域相似度），然后经过softmax后与编、解码特征相乘
我们使用1×1滤波器γ和α来调节权重的比值。采用Softmax归一化，确保wv&#43;和=1在每个空间位置：
最终，输出z为两个特征的加权：
③损失函数 两个阶段的网络都使用下列的损失函数进行训练：
其中Lpixel为l1 loss,Lper为感知损失，Lgan为生成对抗损失" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/143f7a722d3973ab81516ed414fd2acc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-18T16:39:46+08:00" />
<meta property="article:modified_time" content="2023-04-18T16:39:46+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">TFill：Bridging Global Context Interactions for High-Fidelity Image Completion论文阅读笔记</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><img alt="" height="247" src="https://images2.imgbox.com/f7/ca/keHhXzbg_o.png" width="1105"></p> 
<p>-CVPR 2022</p> 
<p> -提出问题： </p> 
<p>                        正确桥接全局上下文交互对于使用大掩摸完成高保真图像非常重要。以前的方法通过深或大的感受野（RF）卷积来尝试这一点，但无法摆脱附近相互作用的主导地位，这是劣势。</p> 
<p>                        通过堆叠卷积层得到的全局信息，存在限制：</p> 
<p>                        ①由于卷积的平移不变性，信息流主要是局部的，全局信息只是通过多层的类热传播逐渐共享。</p> 
<p>                        ②在推理阶段，相邻层之家你的元素通过学习但固定的权重来链接，而不是依赖于输入的自适应权重，这就意味着长距离信息只在一个非常深的层中低效传播，导致网络趋向于以孔洞附近的信息为基础填充孔洞，而不是远距离可见像素。</p> 
<p></p> 
<p>-主要工作</p> 
<p>        本文提出将图像修复任务视为无方向的序列-序列的预测任务，使用Transformer可以保证去信息平等的流动到各个像素上。主要贡献如下：</p> 
<p>        ①利用限制性的CNN提出图像表征 token representation，减轻了从局部可见区域传播到缺失区域的影响。</p> 
<p>        ②通过一个以transformer为基础的架构，这些token之间的远程交互被显式地建模，其中掩蔽令牌可以感知其他机会平等的可见令牌，而不管它们的位置如何。这导致了对最先进的方法有了显著的改进。</p> 
<p>        ③本文引入了一种具有自适应注意平衡的新型注意意识层，以获得更高质量和分辨率的结果。</p> 
<p></p> 
<p>-网络结构</p> 
<p><img alt="" height="505" src="https://images2.imgbox.com/26/d0/mktLflY5_o.png" width="1040"></p> 
<p>      （a）首先将mask input失真图像resize固定为256*256大小，然后输入Restrictive CNN生成token，再喂入transformer中进行远距离交互，得到初步的coarse result。</p> 
<p>      （b）将mask input 与coarse result重新组合，输入到refinement network中，该network中包含Attention-Aware Layer 从可见区域和生成区域传输高质量的信息。</p> 
<p></p> 
<p>- Method</p> 
<p>        ① Content Inference Network:TFill-Coarse</p> 
<p>           考虑到固定长度的位置嵌入和计算成本，本文先将图片任何大小的图片resize至256*256.</p> 
<p>           Restrictive CNN:该模块的主要作用就是提取感受野不重叠的token。</p> 
<p class="img-center"><img alt="" height="383" src="https://images2.imgbox.com/31/62/HmgpACNO_o.png" width="587"></p> 
<p>         先前的token representation 方式要不就是采用某个像素点会使得下采样的过程中丢失大量的信息，要不就是整张图像，不同的token之间存在重叠。</p> 
<p>        本文利用Restrictive CNN来进行token representation。这个模块包括四个block，在每一个block中，利用1x1卷积和layernorm来进行非线性映射，然后再用部分卷积（k=2，s=2）来提取可用信息。通过上述做法，保证每个token只代表局部patch中的可见信息。</p> 
<p></p> 
<p>        Weighted self-attention layer：</p> 
<p>        为了进一步鼓励模型偏向于重要的可见值，作者用weighted self-attention代替了普通的self-attention。即应用一个权重来衡量注意力分数。初始的权重通过计算一个patch中可见像素的比例。然后在每个编码器层后面按照<img alt="" height="35" src="https://images2.imgbox.com/12/2c/asYeALfa_o.png" width="170">的方式更新权重。 </p> 
<p></p> 
<p>        CNN-based Decoder</p> 
<p>                利用卷积层组成的decoder端对特征进行上采样，以此生成coarse result初步图像。</p> 
<p></p> 
<p></p> 
<p>     ② Appearance Refinement Network：TFill-Refined</p> 
<p>        尽管Coarse网络已经生成合理的结果，但还是存在不足。由于固定的input size 256*256，这使得coarse网络不适用于高分辨率图像。且生成的结果可能会和原始的外观不完全一致。如下图所示：左右眼睛异瞳</p> 
<p></p> 
<p class="img-center"><img alt="" height="351" src="https://images2.imgbox.com/fe/f6/oHVySOSL_o.png" width="323"></p> 
<p>        为了解决上述问题，提出了refinement network。为了进一步利用全局中可见的高频细节，设计了一个注意力感知层AAL来从编码和解码的特征中远程复制信息。</p> 
<p>        如下图所示，给定一个解码特征xd，首先计算其注意力分数</p> 
<p class="img-center"><img alt="" height="30" src="https://images2.imgbox.com/c9/6d/LAiARVxA_o.png" width="127"></p> 
<p>        再以mask为基础将A分为Av（可见区域相似度）和Am（生成区域相似度），然后经过softmax后与编、解码特征相乘</p> 
<p class="img-center"><img alt="" height="51" src="https://images2.imgbox.com/98/06/pZmICq8w_o.png" width="455"></p> 
<p> 我们使用1×1滤波器γ和α来调节权重的比值。采用Softmax归一化，确保wv+和=1在每个空间位置：</p> 
<p class="img-center"><img alt="" height="48" src="https://images2.imgbox.com/66/66/s8WekC15_o.png" width="448"></p> 
<p> 最终，输出z为两个特征的加权：</p> 
<p class="img-center"><img alt="" height="38" src="https://images2.imgbox.com/7d/c4/CvJCjvhk_o.png" width="273"></p> 
<p></p> 
<p class="img-center"><img alt="" height="313" src="https://images2.imgbox.com/a9/9f/wYibtsiX_o.png" width="624"></p> 
<p></p> 
<p></p> 
<p>③损失函数 </p> 
<p>        两个阶段的网络都使用下列的损失函数进行训练：</p> 
<p class="img-center"><img alt="" height="42" src="https://images2.imgbox.com/32/cd/AE1Si8co_o.png" width="311"></p> 
<p>        其中Lpixel为l1 loss,Lper为感知损失，Lgan为生成对抗损失</p> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/11d8d377ac83dce14d2164d350129f07/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">js实现下拉框功能</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/49154b31b1efa851a6abb59bc005e310/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43;：string类的简单使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>