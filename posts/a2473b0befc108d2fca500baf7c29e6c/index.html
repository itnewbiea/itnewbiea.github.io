<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【ONNX】ONNX结构分析 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【ONNX】ONNX结构分析" />
<meta property="og:description" content="ONNX结构分析 onnx将每一个网络的每一层或者说是每一个算子当作节点Node，再由这些Node去构建一个Graph，相当于是一个网络。最后将Graph和这个onnx模型的其他信息结合在一起，生成一个model，也就是最终的.onnx的模型。
onnx.helper----node、graph、model 在构建onnx模型这个过程中，这个文件至关重要。其中make_node、make_graph、make_model是不可或缺的。make_tensor_value_info和make_tensor是构建graph中所需要用到的。
make_node [类型:NodeProto] make_node(op_type,inputs,outputs,name=None,doc_string=None,**kwargs)
op_type:节点的算子类型 [类型:字符串]
比如Conv、Relu、Add这类，详细可以参考onnx给出的算子列表，这个可以自己赋值，但最好与官网对应上，否则其他框架在跑onnx的时候会不知道这是什么。inputs:存放节点输入的名字 [类型:字符串列表]
每个节点输入的数量根据情况会有不同，比如inputs(2-3)，即输入为2个或3个，可选的输入都会标注(optional)。以Conv为例，必有输入X和权重W，偏置B作为可选。outputs:存放节点输出的名字 [类型:字符串列表]
与inputs类似，同样需要根据官网给出的输出个数来设置，大多数情况是一个输出，我暂且还没碰到多输出情况。name:节点名，可有可无，不要和op_type搞混了doc_string:描述文档的字符串，这个默认为None [类型:字符串]kwargs:存放节点的属性attributes [类型:任意]
这个**kwargs**可以是字典形式输入，也可以拆开分别赋值(类型任意)，反正不管是什么最后这个node都给你转换成NodeProto的形式。在用IDE的时候，你可以进到一个onnx_ml_pb2.py的文件中，你可以看到诸如AttributeType、DataType、AttributeProto、ValueInfoProto、NodeProto这些描述符号。onnx_ml_pb2.py是由protoc buffer编译器通过onnx-ml.proto生成的。
Attributes在官网也被明确的给出了，一般被标注(default:xxxxx)的可以根据自己的需求不设置，没有标注default的属性则一定需要设置。
以Conv举例：
auto_pad:VALID,dilations:[1,1,1],group:1,kernel_shape:(7,7),pads:[3,3,3,3],strides:(2,2)
可以写成： dict = {&#34;kernel_shape&#34;: (7, 7), &#34;group&#34;: 1,#default为1，所以可以不写 &#34;strides&#34;: (2, 2), &#34;auto_pad&#34;: &#34;VALID&#34;, &#34;dilations&#34;: [1, 1, 1], &#34;pads&#34;: [3, 3, 3, 3]}#顺序无所谓 node_def = helper.make_node( NodeType, # 节点名 X_name, # 输入 Y_name, # 输出 **dict ) 也可以写成：
node_def = helper.make_node( NodeType, # 节点名 X_name, # 输入 Y_name, # 输出 kernel_shape = (7,7), strides = (2,2), auto_pad = &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/a2473b0befc108d2fca500baf7c29e6c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-11-23T17:34:44+08:00" />
<meta property="article:modified_time" content="2018-11-23T17:34:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【ONNX】ONNX结构分析</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="ONNX_0"></a>ONNX结构分析</h3> 
<p>onnx将每一个网络的每一层或者说是每一个算子当作节点<strong>Node</strong>，再由这些<strong>Node</strong>去构建一个<strong>Graph</strong>，相当于是一个网络。最后将<strong>Graph</strong>和这个onnx模型的其他信息结合在一起，生成一个<strong>model</strong>，也就是最终的.onnx的模型。</p> 
<h4><a id="onnxhelpernodegraphmodel_2"></a>onnx.helper----node、graph、model</h4> 
<p>在构建onnx模型这个过程中，这个文件至关重要。其中<strong>make_node</strong>、<strong>make_graph</strong>、<strong>make_model</strong>是不可或缺的。<strong>make_tensor_value_info</strong>和<strong>make_tensor</strong>是构建graph中所需要用到的。</p> 
<h5><a id="make_node_NodeProto_4"></a>make_node [类型:NodeProto]</h5> 
<p>make_node(op_type,inputs,outputs,name=None,doc_string=None,**kwargs)</p> 
<ul><li><strong>op_type</strong>:节点的算子类型 [类型:字符串]<br> 比如Conv、Relu、Add这类，详细可以参考<a href="https://github.com/onnx/onnx/blob/f2daca5e9b9315a2034da61c662d2a7ac28a9488/docs/Operators.md">onnx给出的算子列表</a>，这个可以自己赋值，但最好与官网对应上，否则其他框架在跑onnx的时候会不知道这是什么。</li><li><strong>inputs</strong>:存放节点输入的名字 [类型:字符串列表]<br> 每个节点输入的数量根据情况会有不同，比如inputs(2-3)，即输入为2个或3个，可选的输入都会标注(optional)。以Conv为例，必有输入X和权重W，偏置B作为可选。</li><li><strong>outputs</strong>:存放节点输出的名字 [类型:字符串列表]<br> 与<strong>inputs</strong>类似，同样需要根据官网给出的输出个数来设置，大多数情况是一个输出，我暂且还没碰到多输出情况。</li><li><strong>name</strong>:节点名，可有可无，不要和op_type搞混了</li><li><strong>doc_string</strong>:描述文档的字符串，这个默认为None [类型:字符串]</li><li><strong><strong>kwargs</strong>:存放节点的属性attributes [类型:任意]<br> 这个</strong>**kwargs**可以是字典形式输入，也可以拆开分别赋值(类型任意)，反正不管是什么最后这个node都给你转换成NodeProto的形式。在用IDE的时候，你可以进到一个onnx_ml_pb2.py的文件中，你可以看到诸如AttributeType、DataType、AttributeProto、ValueInfoProto、NodeProto这些描述符号。onnx_ml_pb2.py是由protoc buffer编译器通过onnx-ml.proto生成的。<br> Attributes在官网也被明确的给出了，一般被标注(default:xxxxx)的可以根据自己的需求不设置，没有标注default的属性则一定需要设置。<br> 以Conv举例：<br> <code>auto_pad</code>:VALID,<code>dilations</code>:[1,1,1],<code>group</code>:1,<code>kernel_shape</code>:(7,7),<code>pads</code>:[3,3,3,3],<code>strides</code>:(2,2)<br> 可以写成：</li></ul> 
<pre><code>dict = {"kernel_shape": (7, 7),
"group": 1,#default为1，所以可以不写
"strides": (2, 2), 
"auto_pad": "VALID", 
"dilations": [1, 1, 1],
"pads": [3, 3, 3, 3]}#顺序无所谓
node_def = helper.make_node(
        NodeType,  # 节点名
        X_name,  # 输入
        Y_name,  # 输出
        **dict
    )
</code></pre> 
<p>也可以写成：</p> 
<pre><code>node_def = helper.make_node(
        NodeType,  # 节点名
        X_name,  # 输入
        Y_name,  # 输出
        kernel_shape = (7,7),
        strides = (2,2),
        auto_pad = "VALID",
        dilations = [1,1,1],
        pads = [3,3,3,3], 
    )
</code></pre> 
<p>当然你也可以自己魔改，想放什么进去都可以，不过尽量还是统一符合官网要求比较好~</p> 
<h5><a id="make_graph_GraphProto_50"></a>make_graph [类型:GraphProto]</h5> 
<p>make_graph(nodes,name,inputs,outputs,initializer=None,doc_string=None,value_info=[])</p> 
<ul><li><strong>nodes</strong>:用make_node生成的节点列表 [类型:NodeProto列表]<br> 比如[node1,node2,node3,…]这种的</li><li><strong>name</strong>:graph的名字 [类型:字符串]</li><li><strong>inputs</strong>:存放graph的输入数据信息 [类型:ValueInfoProto列表]<br> 输入数据的信息以ValueInfoProto的形式存储，会用到<strong>make_tensor_value_info</strong>，来将输入数据的名字、数据类型、形状(维度)给记录下来。</li><li><strong>outputs</strong>:存放graph的输出数据信息 [类型:ValueInfoProto列表]<br> 与<strong>inputs</strong>相同。</li><li><strong>initializer</strong>:存放超参数 [类型:TensorProto列表]<br> 比如Conv的权重W、偏置B，BatchNormalization的scale、B、mean、var。这些参数数据都是通过<strong>make_tensor</strong>来转换成TensorProto形式。</li><li><strong>doc_string</strong>:描述文档的字符串，这个默认为None [类型:字符串]</li><li><strong>value_info</strong>:存放中间层产生的输出数据的信息 [类型:ValueInfoProto列表]</li></ul> 
<p><strong>注意！</strong> inputs、outputs、value_info都是ValueInfoProto列表形式，那么它们各自存放什么东西呢？<br> 对于一个多层网络而言，其中间层的输入有来自上一层的输出，也有来自外界的超参数和数据，为了区分，onnx中将来自外界的超参数信息和输入数据信息统一放在inputs里，而value_info里存放的是来自经过前向计算得到的中间层输出数据的信息(2019.04.09更新：现在onnx官方提供了前向推理计算value_info并生成onnx模型的<a href="https://github.com/onnx/onnx/blob/f2daca5e9b9315a2034da61c662d2a7ac28a9488/docs/PythonAPIOverview.md#running-shape-inference-on-an-onnx-model">api</a>)。注意，是信息，不是具体数据值。outputs只存放整个网络的输出信息。</p> 
<p><strong>第二个需要注意的是：</strong> initializer作为存放超参数具体数值的TensorProto列表，其中每个TensorProto总会有与其对应的ValueInfoProto存在，对应关系通过name来联系。比如inputs里放了一个Conv1的权重参数信息，名字为"Conv1_W"那么对应的initializer里会有个名字与其相同的TensorProto来存储这个权重参数的具体数值。</p> 
<p><strong>第三个需要注意的是：</strong> 对于一个网络而言如何能体现其网络结构呢？即节点与节点之间的关联。<br> 在构建每一个node时就需要注意，当前node的输入来自于哪一个node的输出，名字要匹配上，才能将node间联系体现出来。</p> 
<h5><a id="make_model_72"></a>make_model</h5> 
<p>make_model(graph, **kwargs)</p> 
<ul><li><strong>graph</strong>:用make_graph生成的GraphProto</li><li>**<strong>kwargs</strong>:构建ModelProto中的opset_import，这个还没弄太清楚，不过不影响生成模型</li></ul> 
<p>这个函数中会先实例化一个ModelProto----model，其中会对它的ir_version(现在默认是3)、graph(就是把传入的graph复制进model.graph)、opset_import做处理。具体可以看helper里的make_model这个函数。我们只要知道这是个最后把graph和模型其他信息组合在一起构建出一个完整的onnx model的函数就可以了。</p> 
<h4><a id="onnxhelpertensortensor_value_infoattribute_79"></a>onnx.helper----tensor、tensor value info、attribute</h4> 
<h5><a id="make_tensor_TensorProto_80"></a>make_tensor [类型:TensorProto]</h5> 
<p>make_tensor(name,data_type,dims,vals,raw=False)</p> 
<ul><li><strong>name</strong>:数据名字，要与该数据的信息tensor value info中名字对应 [类型:字符串]</li><li><strong>data_type</strong>:数据类型 [类型:TensorProto.DataType] 如TensorProto.FLOAT、TensorProto.UINT8、TensorProto.FLOAT16等</li><li><strong>dims</strong>:数据维度 [类型:int列表/元组]</li><li><strong>vals</strong>:数据值，好像要可迭代的 [类型:任意]</li><li><strong>raw</strong>:选择是否用二进制编码 [类型:bool]<br> raw为False的时候，就会用相应的TensorProto来存储基于data_type的值，若raw为True，则是用二进制编码来存储数据。<br> **注：**我发现cntk官方转onnx用的是raw为False的方式，而pytorch官方转onnx用的是raw为True的方式。</li></ul> 
<h5><a id="make_tensor_value_info_ValueInfoProto_90"></a>make_tensor_value_info [类型:ValueInfoProto]</h5> 
<p>make_tensor_value_info(name,elem_type,shape,doc_string="",shape_denotation=None)</p> 
<ul><li><strong>name</strong>:数据信息名字 [类型:字符串]</li><li><strong>elem_type</strong>:数据类型 [类型:TensorProto.DataType]</li><li><strong>shape</strong>:数据维度(形状) [类型:int列表/元组]</li><li><strong>doc_string</strong>:描述文档的字符串，这个默认为None [类型:字符串]</li><li><strong>shape_denotation</strong>:这个没太看懂，可能是对shape的描述 [类型:字符串列表]<br> 根据数据类型和形状创建一个ValueInfoProto。</li></ul> 
<h5><a id="make_attribute_AttributeProto_99"></a>make_attribute [类型:AttributeProto]</h5> 
<p>make_attribute(key,value,doc_string=None)</p> 
<ul><li><strong>key</strong>:键值 [类型:字符串]</li><li><strong>value</strong>:数值 [类型:任意]</li><li><strong>doc_string</strong>:描述文档的字符串，这个默认为None [类型:字符串]<br> 根据数值类型来创建一个AttributeProto，这个函数用在了make_node里，用于将make_node传入的**kwargs转为AttributeProto形式。</li></ul> 
<p><strong>构建一个简单的onnx模型，实质上，只要构建好每一个node，然后将它们和输入输出超参数一起塞到graph，最后转成model就可以了。</strong></p> 
<p>写了一个base，在构建onnx的时候可以直接调用createOnnxNode、createOnnxModel来构建一个onnx模型，可以选择把onnx保存为txt格式，很大就是了。具体流程后续补上。<br> <a href="https://github.com/htshinichi/LearnONNX/blob/master/createONNX/base.py">代码</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bc86e5d64ef8ee217d2879e51109ac7a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">网页可能暂时无法连接，或者它已永久性地移动到了新网址，返回ERR_TUNNEL_CONNECTION_FAILED</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f7ab23806e5f52b7348038cc32a25bfc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">react中实现点击跳转到新页面方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>