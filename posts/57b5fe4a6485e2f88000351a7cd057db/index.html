<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>事件相机 Event Camera 论文汇总（总是在持续更新中的汇总） - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="事件相机 Event Camera 论文汇总（总是在持续更新中的汇总）" />
<meta property="og:description" content="事件相机 Event Camera 论文汇总（总是在持续更新中的汇总） 目录
Survey ECCV
2020 ECCV
2018 ECCV CVPR
2020 CVPR
2019 CVPR
2018 CVPR
2017 CVPR
ICCV
2019 ICCV
2017 ICCV
WACV
2020 WACV
AAAI 2020 AAAI
ICME
2019 ICME
Survey Event-based vision: A survey
Event-based media processing and analysis: A survey of the literature
ECCV 2020 ECCV Reducing the Sim-to-Real Gap for EventCameras
Spike-FlowNet: Event-based Optical FlowEstimation with Energy-Efficient Hybrid NeuralNetworks
Entropy Minimisation Framework forEvent-based Vision Model Estimation" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/57b5fe4a6485e2f88000351a7cd057db/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-09-11T11:24:55+08:00" />
<meta property="article:modified_time" content="2020-09-11T11:24:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">事件相机 Event Camera 论文汇总（总是在持续更新中的汇总）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="%E4%BA%8B%E4%BB%B6%E7%9B%B8%E6%9C%BA%20Event%20Camera%20%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB%EF%BC%88%E6%80%BB%E6%98%AF%E5%9C%A8%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%E4%B8%AD%E7%9A%84%E6%B1%87%E6%80%BB%EF%BC%89">事件相机 Event Camera 论文汇总（总是在持续更新中的汇总）</h2> 
<p id="main-toc"> </p> 
<p> </p> 
<p><strong>目录</strong></p> 
<p id="%E4%BA%8B%E4%BB%B6%E7%9B%B8%E6%9C%BA%20Event%20Camera%20%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB%EF%BC%88%E6%80%BB%E6%98%AF%E5%9C%A8%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%E4%B8%AD%E7%9A%84%E6%B1%87%E6%80%BB%EF%BC%89-toc" style="margin-left:0px;"><a href="#screen-reader-main-title" rel="nofollow">Survey </a></p> 
<p id="ECCV-toc" style="margin-left:0px;"><a href="#ECCV" rel="nofollow">ECCV</a></p> 
<p id="2020%20ECCV-toc" style="margin-left:40px;"><a href="#2020%20ECCV" rel="nofollow">2020 ECCV</a></p> 
<p id="2018%20ECCV%C2%A0-toc" style="margin-left:40px;"><a href="#2018%20ECCV%C2%A0" rel="nofollow">2018 ECCV </a></p> 
<p id="CVPR-toc" style="margin-left:0px;"><a href="#CVPR" rel="nofollow">CVPR</a></p> 
<p id="2020%20CVPR-toc" style="margin-left:40px;"><a href="#2020%20CVPR" rel="nofollow">2020 CVPR</a></p> 
<p id="2019%20CVPR-toc" style="margin-left:40px;"><a href="#2019%20CVPR" rel="nofollow">2019 CVPR</a></p> 
<p id="2018%20CVPR-toc" style="margin-left:40px;"><a href="#2018%20CVPR" rel="nofollow">2018 CVPR</a></p> 
<p id="2017%20CVPR-toc" style="margin-left:40px;"><a href="#2017%20CVPR" rel="nofollow">2017 CVPR</a></p> 
<p id="ICCV-toc" style="margin-left:0px;"><a href="#ICCV" rel="nofollow">ICCV</a></p> 
<p id="2019%20ICCV-toc" style="margin-left:40px;"><a href="#2019%20ICCV" rel="nofollow">2019 ICCV</a></p> 
<p id="2017%20ICCV-toc" style="margin-left:40px;"><a href="#2017%20ICCV" rel="nofollow">2017 ICCV</a></p> 
<p id="WACV-toc" style="margin-left:0px;"><a href="#WACV" rel="nofollow">WACV</a></p> 
<p id="2020%20WACV-toc" style="margin-left:40px;"><a href="#2020%20WACV" rel="nofollow">2020 WACV</a></p> 
<p id="AAAI%C2%A0-toc" style="margin-left:0px;"><a href="#AAAI%C2%A0" rel="nofollow">AAAI </a></p> 
<p id="2020%20AAAI-toc" style="margin-left:40px;"><a href="#2020%20AAAI" rel="nofollow">2020 AAAI</a></p> 
<p id="ICME-toc" style="margin-left:0px;"><a href="#ICME" rel="nofollow">ICME</a></p> 
<p id="2019%20ICME-toc" style="margin-left:40px;"><a href="#2019%20ICME" rel="nofollow">2019 ICME</a></p> 
<hr id="hr-toc"> 
<h2 id="screen-reader-main-title">Survey </h2> 
<p><strong><a href="https://arxiv.org/abs/1904.08405" rel="nofollow" id="4Be6lM9Zn5AJ">Event-based vision: A survey</a></strong></p> 
<p><a href="http://chrome-extension//ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=https%3A%2F%2Fwww.iti.gr%2F~bmezaris%2Fpublications%2Fjivc16_survey_preprint.pdf" rel="nofollow">Event-based media processing and analysis: A survey of the literature</a></p> 
<p> </p> 
<h2 id="ECCV">ECCV</h2> 
<h3 id="2020%20ECCV"><span style="color:#86ca5e;">2020 ECCV</span></h3> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123720528.pdf" rel="nofollow">Reducing the Sim-to-Real Gap for EventCameras</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123740358.pdf" rel="nofollow">Spike-FlowNet: Event-based Optical FlowEstimation with Energy-Efficient Hybrid NeuralNetworks</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500154.pdf" rel="nofollow">Entropy Minimisation Framework forEvent-based Vision Model Estimation</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123510494.pdf" rel="nofollow">Jointly learning visual motion and confidencefrom local patches in event cameras</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530409.pdf" rel="nofollow">Event-based AsynchronousSparse Convolutional Networks</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530681.pdf" rel="nofollow">Learning Event-Driven Video Deblurringand Interpolation</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123580154.pdf" rel="nofollow">Event Enhanced High-Quality Image Recovery</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630647.pdf" rel="nofollow">Learning to See in the Dark with Events</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650137.pdf" rel="nofollow">A Differentiable Recurrent Surface forAsynchronous Event-Based Data</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710052.pdf" rel="nofollow">Globally-Optimal Event CameraMotion Estimation</a></p> 
<p> </p> 
<h3 id="2018%20ECCV%C2%A0"><span style="color:#86ca5e;">2018 ECCV </span></h3> 
<p><a href="https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Alex_Zhu_Realtime_Time_Synchronized_ECCV_2018_paper.pdf" rel="nofollow">Realtime Time Synchronized Event-based Stereo</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Yi_Zhou_Semi-Dense_3D_Reconstruction_ECCV_2018_paper.pdf" rel="nofollow">Semi-Dense 3D Reconstruction witha Stereo Event Camera</a></p> 
<p><a href="https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Daniel_Gehrig_Asynchronous_Photometric_Feature_ECCV_2018_paper.pdf" rel="nofollow">Asynchronous, Photometric Feature Trackingusing Events and Frames</a></p> 
<p> </p> 
<h2 id="CVPR">CVPR</h2> 
<h3 id="2020%20CVPR"><span style="color:#86ca5e;">2020 CVPR</span></h3> 
<p><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Gehrig_Video_to_Events_Recycling_Video_Datasets_for_Event_Cameras_CVPR_2020_paper.html" rel="nofollow">Video to Events: Recycling Video Datasets for Event Cameras</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Gehrig_Video_to_Events_Recycling_Video_Datasets_for_Event_Cameras_CVPR_2020_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Gehrig_Video_to_Events_CVPR_2020_supplemental.zip" rel="nofollow">supp</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Mitrokhin_Learning_Visual_Motion_Segmentation_Using_Event_Surfaces_CVPR_2020_paper.html" rel="nofollow">Learning Visual Motion Segmentation Using Event Surfaces</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Mitrokhin_Learning_Visual_Motion_Segmentation_Using_Event_Surfaces_CVPR_2020_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Mitrokhin_Learning_Visual_Motion_CVPR_2020_supplemental.pdf" rel="nofollow">supp</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Pan_Single_Image_Optical_Flow_Estimation_With_an_Event_Camera_CVPR_2020_paper.html" rel="nofollow">Single Image Optical Flow Estimation With an Event Camera</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Pan_Single_Image_Optical_Flow_Estimation_With_an_Event_Camera_CVPR_2020_paper.pdf" rel="nofollow">pdf</a>] [<a href="http://arxiv.org/abs/2004.00347v1" rel="nofollow">arXiv</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Xu_EventCap_Monocular_3D_Capture_of_High-Speed_Human_Motions_Using_an_CVPR_2020_paper.html" rel="nofollow">EventCap: Monocular 3D Capture of High-Speed Human Motions Using an Event Camera</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_EventCap_Monocular_3D_Capture_of_High-Speed_Human_Motions_Using_an_CVPR_2020_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Xu_EventCap_Monocular_3D_CVPR_2020_supplemental.pdf" rel="nofollow">supp</a>] [<a href="http://arxiv.org/abs/1908.11505v1" rel="nofollow">arXiv</a>] [<a href="https://www.youtube.com/watch?v=cpKKCisB5mQ" rel="nofollow">video</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Jiang_Learning_Event-Based_Motion_Deblurring_CVPR_2020_paper.html" rel="nofollow">Learning Event-Based Motion Deblurring</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_Learning_Event-Based_Motion_Deblurring_CVPR_2020_paper.pdf" rel="nofollow">pdf</a>] [<a href="http://arxiv.org/abs/2004.05794v1" rel="nofollow">arXiv</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Globally_Optimal_Contrast_Maximisation_for_Event-Based_Motion_Estimation_CVPR_2020_paper.html" rel="nofollow">Globally Optimal Contrast Maximisation for Event-Based Motion Estimation</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Globally_Optimal_Contrast_Maximisation_for_Event-Based_Motion_Estimation_CVPR_2020_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Liu_Globally_Optimal_Contrast_CVPR_2020_supplemental.pdf" rel="nofollow">supp</a>] [<a href="http://arxiv.org/abs/2002.10686v3" rel="nofollow">arXiv</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Baldwin_Event_Probability_Mask_EPM_and_Event_Denoising_Convolutional_Neural_Network_CVPR_2020_paper.html" rel="nofollow">Event Probability Mask (EPM) and Event Denoising Convolutional Neural Network (EDnCNN) for Neuromorphic Cameras</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Baldwin_Event_Probability_Mask_EPM_and_Event_Denoising_Convolutional_Neural_Network_CVPR_2020_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Baldwin_Event_Probability_Mask_CVPR_2020_supplemental.zip" rel="nofollow">supp</a>] [<a href="http://arxiv.org/abs/2003.08282v2" rel="nofollow">arXiv</a>] [<a href="https://www.youtube.com/watch?v=HR6P7PxgGQY" rel="nofollow">video</a>] [<a href="https://cove.thecvf.com/datasets/318" rel="nofollow">dataset</a>] </p> 
<p> </p> 
<h3 id="2019%20CVPR"><span style="color:#86ca5e;">2019 CVPR</span></h3> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Unsupervised_Event-Based_Learning_of_Optical_Flow_Depth_and_Egomotion_CVPR_2019_paper.html" rel="nofollow">Unsupervised Event-Based Learning of Optical Flow, Depth, and Egomotion</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Unsupervised_Event-Based_Learning_of_Optical_Flow_Depth_and_Egomotion_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Aakur_A_Perceptual_Prediction_Framework_for_Self_Supervised_Event_Segmentation_CVPR_2019_paper.html" rel="nofollow">A Perceptual Prediction Framework for Self Supervised Event Segmentation</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Aakur_A_Perceptual_Prediction_Framework_for_Self_Supervised_Event_Segmentation_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rebecq_Events-To-Video_Bringing_Modern_Computer_Vision_to_Event_Cameras_CVPR_2019_paper.html" rel="nofollow">Events-To-Video: Bringing Modern Computer Vision to Event Cameras</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Rebecq_Events-To-Video_Bringing_Modern_Computer_Vision_to_Event_Cameras_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Rebecq_Events-To-Video_Bringing_Modern_CVPR_2019_supplemental.zip" rel="nofollow">supp</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sekikawa_EventNet_Asynchronous_Recursive_Event_Processing_CVPR_2019_paper.html" rel="nofollow">EventNet: Asynchronous Recursive Event Processing</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Sekikawa_EventNet_Asynchronous_Recursive_Event_Processing_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Sekikawa_EventNet_Asynchronous_Recursive_CVPR_2019_supplemental.zip" rel="nofollow">supp</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_EV-Gait_Event-Based_Robust_Gait_Recognition_Using_Dynamic_Vision_Sensors_CVPR_2019_paper.html" rel="nofollow">EV-Gait: Event-Based Robust Gait Recognition Using Dynamic Vision Sensors</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_EV-Gait_Event-Based_Robust_Gait_Recognition_Using_Dynamic_Vision_Sensors_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Bringing_a_Blurry_Frame_Alive_at_High_Frame-Rate_With_an_CVPR_2019_paper.html" rel="nofollow">Bringing a Blurry Frame Alive at High Frame-Rate With an Event Camera</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Pan_Bringing_a_Blurry_Frame_Alive_at_High_Frame-Rate_With_an_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://www.youtube.com/watch?v=h2Ve268bYcE&amp;t=2109" rel="nofollow">video</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ionescu_Object-Centric_Auto-Encoders_and_Dummy_Anomalies_for_Abnormal_Event_Detection_in_CVPR_2019_paper.html" rel="nofollow">Object-Centric Auto-Encoders and Dummy Anomalies for Abnormal Event Detection in Video</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Ionescu_Object-Centric_Auto-Encoders_and_Dummy_Anomalies_for_Abnormal_Event_Detection_in_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Event-Based_High_Dynamic_Range_Image_and_Very_High_Frame_Rate_CVPR_2019_paper.html" rel="nofollow">Event-Based High Dynamic Range Image and Very High Frame Rate Video Generation Using Conditional Generative Adversarial Networks</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Event-Based_High_Dynamic_Range_Image_and_Very_High_Frame_Rate_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Manderscheid_Speed_Invariant_Time_Surface_for_Learning_to_Detect_Corner_Points_CVPR_2019_paper.html" rel="nofollow">Speed Invariant Time Surface for Learning to Detect Corner Points With Event-Based Cameras</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Manderscheid_Speed_Invariant_Time_Surface_for_Learning_to_Detect_Corner_Points_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Manderscheid_Speed_Invariant_Time_CVPR_2019_supplemental.pdf" rel="nofollow">supp</a>] </p> 
<p> </p> 
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gallego_Focus_Is_All_You_Need_Loss_Functions_for_Event-Based_Vision_CVPR_2019_paper.html" rel="nofollow">Focus Is All You Need: Loss Functions for Event-Based Vision</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Gallego_Focus_Is_All_You_Need_Loss_Functions_for_Event-Based_Vision_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Gallego_Focus_Is_All_CVPR_2019_supplemental.pdf" rel="nofollow">supp</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Stoffregen_Event_Cameras_Contrast_Maximization_and_Reward_Functions_An_Analysis_CVPR_2019_paper.html" rel="nofollow">Event Cameras, Contrast Maximization and Reward Functions: An Analysis</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Stoffregen_Event_Cameras_Contrast_Maximization_and_Reward_Functions_An_Analysis_CVPR_2019_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Stoffregen_Event_Cameras_Contrast_CVPR_2019_supplemental.pdf" rel="nofollow">supp</a>] </p> 
<p> </p> 
<h3 id="2018%20CVPR"><span style="color:#86ca5e;">2018 CVPR</span></h3> 
<p><a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Sironi_HATS_Histograms_of_CVPR_2018_paper.html" rel="nofollow">HATS: Histograms of Averaged Time Surfaces for Robust Event-Based Object Classification</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Sironi_HATS_Histograms_of_CVPR_2018_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_cvpr_2018/Supplemental/1083-supp.pdf" rel="nofollow">supp</a>] [<a href="http://arxiv.org/abs/1803.07913v1" rel="nofollow">arXiv</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Gallego_A_Unifying_Contrast_CVPR_2018_paper.html" rel="nofollow">A Unifying Contrast Maximization Framework for Event Cameras, With Applications to Motion, Depth, and Optical Flow Estimation</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Gallego_A_Unifying_Contrast_CVPR_2018_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_cvpr_2018/Supplemental/2974-supp.zip" rel="nofollow">supp</a>] [<a href="http://arxiv.org/abs/1804.01306v1" rel="nofollow">arXiv</a>] [<a href="https://www.youtube.com/watch?v=GKAsIh0o1mM&amp;list=PL_bDvITUYucCIT8iNGW8zCXeY5_u6hg-y&amp;index=12&amp;t=0s" rel="nofollow">video</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Maqueda_Event-Based_Vision_Meets_CVPR_2018_paper.html" rel="nofollow">Event-Based Vision Meets Deep Learning on Steering Prediction for Self-Driving Cars</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Maqueda_Event-Based_Vision_Meets_CVPR_2018_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_cvpr_2018/Supplemental/2970-supp.pdf" rel="nofollow">supp</a>] [<a href="http://arxiv.org/abs/1804.01310v1" rel="nofollow">arXiv</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Andreopoulos_A_Low_Power_CVPR_2018_paper.html" rel="nofollow">A Low Power, High Throughput, Fully Event-Based Stereo System</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Andreopoulos_A_Low_Power_CVPR_2018_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_cvpr_2018/Supplemental/3791-supp.zip" rel="nofollow">supp</a>] [<a href="https://www.youtube.com/watch?v=zVYY9HaEJnc&amp;list=PL_bDvITUYucCIT8iNGW8zCXeY5_u6hg-y&amp;index=2&amp;t=0s" rel="nofollow">video</a>] </p> 
<p> </p> 
<h3 id="2017%20CVPR"><span style="color:#86ca5e;">2017 CVPR</span></h3> 
<p><a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Zhu_Event-Based_Visual_Inertial_CVPR_2017_paper.html" rel="nofollow">Event-Based Visual Inertial Odometry</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhu_Event-Based_Visual_Inertial_CVPR_2017_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_cvpr_2017/supplemental/Zhu_Event-Based_Visual_Inertial_2017_CVPR_supplemental.zip" rel="nofollow">supp</a>] [<a href="https://openaccess.thecvf.com/content_cvpr_2017/poster/2274_POSTER.pdf" rel="nofollow">poster</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Amir_A_Low_Power_CVPR_2017_paper.html" rel="nofollow">A Low Power, Fully Event-Based Gesture Recognition System</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Amir_A_Low_Power_CVPR_2017_paper.pdf" rel="nofollow">pdf</a>] </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<h2 id="ICCV">ICCV</h2> 
<h3 id="2019%20ICCV"><span style="color:#86ca5e;">2019 ICCV</span></h3> 
<p><a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Tulyakov_Learning_an_Event_Sequence_Embedding_for_Dense_Event-Based_Deep_Stereo_ICCV_2019_paper.html" rel="nofollow">Learning an Event Sequence Embedding for Dense Event-Based Deep Stereo</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Tulyakov_Learning_an_Event_Sequence_Embedding_for_Dense_Event-Based_Deep_Stereo_ICCV_2019_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Tulyakov_Learning_an_Event_ICCV_2019_supplemental.pdf" rel="nofollow">supp</a>] [<a href="https://www.youtube.com/watch?v=my3jocjpD0U" rel="nofollow">video</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Gehrig_End-to-End_Learning_of_Representations_for_Asynchronous_Event-Based_Data_ICCV_2019_paper.html" rel="nofollow">End-to-End Learning of Representations for Asynchronous Event-Based Data</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Gehrig_End-to-End_Learning_of_Representations_for_Asynchronous_Event-Based_Data_ICCV_2019_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Gehrig_End-to-End_Learning_of_ICCV_2019_supplemental.pdf" rel="nofollow">supp</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Stoffregen_Event-Based_Motion_Segmentation_by_Motion_Compensation_ICCV_2019_paper.html" rel="nofollow">Event-Based Motion Segmentation by Motion Compensation</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Stoffregen_Event-Based_Motion_Segmentation_by_Motion_Compensation_ICCV_2019_paper.pdf" rel="nofollow">pdf</a>] [<a href="https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Stoffregen_Event-Based_Motion_Segmentation_ICCV_2019_supplemental.pdf" rel="nofollow">supp</a>] </p> 
<p> </p> 
<p> </p> 
<h3 id="2017%20ICCV"><span style="color:#86ca5e;">2017 ICCV</span></h3> 
<p><a href="https://openaccess.thecvf.com/content_iccv_2017/html/Fan_Complex_Event_Detection_ICCV_2017_paper.html" rel="nofollow">Complex Event Detection by Identifying Reliable Shots From Untrimmed Videos</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Fan_Complex_Event_Detection_ICCV_2017_paper.pdf" rel="nofollow">pdf</a>] </p> 
<p><br><a href="https://openaccess.thecvf.com/content_iccv_2017/html/Li_Leveraging_Weak_Semantic_ICCV_2017_paper.html" rel="nofollow">Leveraging Weak Semantic Relevance for Complex Video Event Classification</a></p> 
<p>[<a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Li_Leveraging_Weak_Semantic_ICCV_2017_paper.pdf" rel="nofollow">pdf</a>] </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<h2 id="WACV">WACV</h2> 
<h3 id="2020%20WACV"><span style="color:#86ca5e;">2020 WACV</span></h3> 
<p><a href="https://openaccess.thecvf.com/content_WACV_2020/html/Scheerlinck_Fast_Image_Reconstruction_with_an_Event_Camera_WACV_2020_paper.html" rel="nofollow">Fast Image Reconstruction with an Event Camera</a></p> 
<p><br><a href="https://openaccess.thecvf.com/content_WACV_2020/html/Seok_Robust_Feature_Tracking_in_DVS_Event_Stream_using_Bezier_Mapping_WACV_2020_paper.html" rel="nofollow">Robust Feature Tracking in DVS Event Stream using Bezier Mapping</a></p> 
<p><br><a href="https://openaccess.thecvf.com/content_WACV_2020/html/Nagata_QR-code_Reconstruction_from_Event_Data_via_Optimization_in_Code_Subspace_WACV_2020_paper.html" rel="nofollow">QR-code Reconstruction from Event Data via Optimization in Code Subspace</a></p> 
<p><br><a href="https://openaccess.thecvf.com/content_WACV_2020/html/Bagchi_Event-based_Star_Tracking_via_Multiresolution_Progressive_Hough_Transforms_WACV_2020_paper.html" rel="nofollow">Event-based Star Tracking via Multiresolution Progressive Hough Transforms</a></p> 
<p><br><a href="https://openaccess.thecvf.com/content_WACV_2020/html/Guo_Graph_Neural_Networks_for_Image_Understanding_Based_on_Multiple_Cues_WACV_2020_paper.html" rel="nofollow">Graph Neural Networks for Image Understanding Based on Multiple Cues: Group Emotion Recognition and Event Recognition as Use Cases</a></p> 
<p> </p> 
<p> </p> 
<p> </p> 
<h2 id="AAAI%C2%A0">AAAI </h2> 
<h3 id="2020%20AAAI"><span style="color:#86ca5e;">2020 AAAI</span></h3> 
<p><a href="https://arxiv.org/pdf/2002.05911.pdf" rel="nofollow">End-to-end Learning of Object Motion Estimation from Retinal Events for Event-based Object Tracking</a></p> 
<p> </p> 
<p> </p> 
<h2 id="ICME">ICME</h2> 
<h3 id="2019%20ICME"><span style="color:#86ca5e;">2019 ICME</span></h3> 
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8784777" rel="nofollow">Event-Based Vision Enhanced: A Joint Detection Framework in Autonomous Driving</a></p> 
<p> </p> 
<h2>arXiv</h2> 
<p> </p> 
<p>2019</p> 
<p><a href="https://arxiv.org/pdf/1912.01584.pdf" rel="nofollow">EventGAN: Leveraging Large Scale Image Datasets for Event Cameras</a> [<a href="https://github.com/alexzzhu/EventGAN">github</a>]</p> 
<p> </p> 
<h2>Journal</h2> 
<p><a href="http://www.roboticsproceedings.org/rss14/p62.pdf" rel="nofollow">EV-FlowNet: Self-Supervised Optical Flow Estimation for Event-based Cameras</a>   Robotics: Science and Systems 2018.</p> 
<p> </p> 
<h2>Dataset</h2> 
<p><a href="https://github.com/wl082013/ESIM_dataset">ESIM Dataset</a></p> 
<p><a href="https://daniilidis-group.github.io/mvsec/" rel="nofollow">MVSEC Dataset</a></p> 
<p><a href="https://supitalp.github.io/research/publication/ced_cvprw/" rel="nofollow">CED: Color Event Camera Dataset</a></p> 
<p><a href="https://supitalp.github.io/research/publication/fpv_icra19/" rel="nofollow">UZH-FPV Drone Racing Dataset</a></p> 
<p> </p> 
<p>DDD20 Dataset：<a href="https://sites.google.com/view/davis-driving-dataset-2020/home" rel="nofollow">project</a>（需要 Google）；<a href="https://github.com/SensorsINI/ddd20-utils">code</a>；<a href="https://docs.google.com/document/d/1Nnyjo4j0rvdgHQ0cS8z0Q1QBRLHDtwh7XW1u9ygmQEs/edit" rel="nofollow">Document </a>（需要 Google）</p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/52a9797fa41aad22310c2bf7cdaa67b7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">30个极简python代码(demo）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4bc3a52cfb2a87c18b24d4ee293c2d66/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python 提取jpg文件名字到txt</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>