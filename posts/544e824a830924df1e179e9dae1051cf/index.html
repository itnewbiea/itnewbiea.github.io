<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>SSD写放大的优化策略要统一标准了吗？ - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="SSD写放大的优化策略要统一标准了吗？" />
<meta property="og:description" content="写放大，Write Amplification Factor，缩写WAF，这一术语最早是在2008年左右，由Intel公司和SiliconSystems公司（2009 年被西部数字收购）第一次在公开稿件中提出了并使用。WAF代表的含义就是NAND实际写入数据量与host写入量的比值，最理想的情况就是WAF=1，这个值越接近1越好。
linux环境的nvme ssd举例，可以通过nvme smart-log-add命令获取NAND和host写入量：
nvme smart-log-add /dev/nvme0 Additional Smart Log for NVME device:nvme0 namespace-id:ffffffff key normalized raw program_fail_count : 100% 0 erase_fail_count : 100% 0 wear_leveling : 62% min: 1114, max: 1161, avg: 1134 end_to_end_error_detection_count: 100% 0 crc_error_count : 100% 0 timed_workload_media_wear : 100% 37.941% timed_workload_host_reads : 100% 51% timed_workload_timer : 100% 446008 min thermal_throttle_status : 100% 0%, cnt: 0 retry_buffer_overflow_count : 100% 0 pll_lock_loss_count : 100% 0 nand_bytes_written : 100% sectors: 16185227 host_bytes_written : 100% sectors: 6405605 要想完全理解写放大，我们需要先了解固态硬盘的读写机制。我们知道，固态硬盘的存储单元是由闪存颗粒组成的，无法实现物理性的数据覆盖，只能擦除然后写入，重复这一过程。因而，我们可以想象得到，在实际读写过程中，数据的读写势必会在闪存颗粒上进行多次的擦除写入，特别是当某些区块已经完全被塞满的情况下。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/544e824a830924df1e179e9dae1051cf/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-26T22:30:57+08:00" />
<meta property="article:modified_time" content="2022-10-26T22:30:57+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">SSD写放大的优化策略要统一标准了吗？</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>写放大，Write Amplification Factor，缩写WAF，这一术语最早是在2008年左右，由Intel公司和SiliconSystems公司（2009 年被西部数字收购）第一次在公开稿件中提出了并使用。<strong>WAF代表的含义就是NAND实际写入数据量与host写入量的比值，最理想的情况就是WAF=1，这个值越接近1越好</strong>。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/b2/de/mbP3VHUe_o.png"></p> 
<p>linux环境的nvme ssd举例，可以通过nvme smart-log-add命令获取NAND和host写入量：</p> 
<pre>nvme smart-log-add /dev/nvme0

Additional Smart Log for NVME device:nvme0 namespace-id:ffffffff

key                               normalized raw

program_fail_count              : 100%       0

erase_fail_count                : 100%       0

wear_leveling                   :  62%       min: 1114, max: 1161, avg: 1134

end_to_end_error_detection_count: 100%       0

crc_error_count                 : 100%       0

timed_workload_media_wear       : 100%       37.941%

timed_workload_host_reads       : 100%       51%

timed_workload_timer            : 100%       446008 min

thermal_throttle_status         : 100%       0%, cnt: 0

retry_buffer_overflow_count     : 100%       0

pll_lock_loss_count             : 100%       0

nand_bytes_written              : 100%       sectors: 16185227

host_bytes_written              : 100%       sectors: 6405605</pre> 
<p>要想完全理解写放大，我们需要先了解固态硬盘的读写机制。我们知道，固态硬盘的存储单元是由闪存颗粒组成的，无法实现物理性的数据覆盖，只能擦除然后写入，重复这一过程。因而，我们可以想象得到，在实际读写过程中，数据的读写势必会在闪存颗粒上进行多次的擦除写入，特别是当某些区块已经完全被塞满的情况下。</p> 
<p>这些多次的操作，增加的写入数量和原始需要写入的数量的比值，就是所谓的写入放大。所以说，<strong>写入放大数值高，会损耗固态硬盘寿命</strong>。（固态硬盘闪存颗粒有着额定的P/E值，即最大的读写次数，写入放大高，P/E损耗快，寿命低。）在QLC介质中，WAF的影响更加致命。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/c6/26/4OQpXV3W_o.png"></p> 
<p>举个例子，最坏情况下的，假如我要写入一个4KB的数据Z覆盖A，并恰好目标块没有空余的页区，需要进行GC回收。这个时候就需要把B、C、D、E、F五分数据都搬走，然后擦除整个数据块，擦除完成后再整体写入6个数据页。这个整个过程，Host虽然只写了4KB的数据，但实际过程中，由于GC的问题，NAND最终写入了24KB。那么写放大WAF=24KB/4KB=6.</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/25/c2/Yhf09ZpC_o.png"></p> 
<p><br><strong>影响WAF的因素</strong>：</p> 
<ul><li> <p>SSD FTL算法的设计会影响写入放大的大小</p> </li><li> <p>Wear Leveling，WL磨损均衡：这一机制主要是通过均衡所有的闪存颗粒，从而延长整体的使用寿命，然而依旧是增加整体的写放大</p> </li><li> <p>Over-Provisioning，OP冗余空间：也会影响NAND写入的比例，最终影响写放大</p> </li><li> <p>Garbage Collection，GC垃圾回收：比如上面的例子，就是GC垃圾回收搬迁数据，擦除数据块后写入带来了整体写放大提升。</p> </li><li> <p>业务读写的数据模型：随机写和顺序写对NAND的写入比例有非常大的影响，直接影响写放大的系数</p> </li><li> <p>系统层的TRIM操作：会影响invalid无效数据是否在GC过程中搬迁，对写放大影响也有重要的作用。</p> </li></ul> 
<p></p> 
<p>写放大WAF是NAND-based SSD寿命消耗的关键参数，WAF越大，寿命消耗越快，越接近1，则寿命消耗越慢，也是最理想的情况。</p> 
<p>所以，为了让SSD的WAF写放大系数接近1，这些年，各种方案也被提出来。</p> 
<p><strong>第一种优化写放大的方式</strong>：也是用的最多方式，就是<strong>增加OP冗余空间</strong>，降低WAF，提升寿命。比如根据Intel的白皮书信息来看，以P4510 4T为例</p> 
<ul><li> <p>没有OP情况下，JEDEC标准压力下的DWPD=0.85</p> </li><li> <p>在OP 10%情况下，容量3.6T，DWPD上升到1.52，几乎翻了一倍。</p> </li><li> <p>在OP 20%情况下，容量3.2T，DWPD上升到2.27，接近原始容量的3倍。</p> </li></ul> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/cb/7e/nOJ4flGY_o.png"></p> 
<p>JEDEC标准压力如下：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/a4/40/T5qI9euY_o.png"></p> 
<p><strong>第二种优化写放大的方式：执行trim指令</strong>。</p> 
<p>TRIM是SSD的一个特性，目的是让固态硬盘SSD在进行内部GC垃圾回收的时候，避免搬迁已经被OS删除的数据，减少无用的数据的搬迁从而降低写放大，提升SSD固态硬盘的寿命，同时也可以提升盘的有效带宽。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/c5/0b/YOrT6Ndx_o.png"></p> 
<p>更多细节请参考：<a href="http://mp.weixin.qq.com/s?__biz=MzIwNTUxNDgwNg==&amp;mid=2247485371&amp;idx=1&amp;sn=0bebf0fff981835da78f27ce6c97caaf&amp;chksm=972ef6e2a0597ff471436046660dd7b82427943601ee042c436b7d3e84de51acb4dfc6cad0c3&amp;scene=21#wechat_redirect" rel="nofollow" title="固态硬盘SSD格式化后，数据恢复的可能性有多大？">固态硬盘SSD格式化后，数据恢复的可能性有多大？</a></p> 
<p>Linux内核态下常用fstrim完成系统的trim命令。在NVME协议中，trim有另外一个叫法：Deallocate，原理是一样的。</p> 
<pre>$ sudo /usr/sbin/fstrim --help

Usage:
 fstrim [options] &lt;mount point&gt;

Discard unused blocks on a mounted filesystem.

Options:
 -a, --all           trim all supported mounted filesystems
 -A, --fstab         trim all supported mounted filesystems from /etc/fstab
 -o, --offset &lt;num&gt;  the offset in bytes to start discarding from
 -l, --length &lt;num&gt;  the number of bytes to discard
 -m, --minimum &lt;num&gt; the minimum extent length to discard
 -v, --verbose       print number of discarded bytes
     --quiet         suppress error messages
 -n, --dry-run       does everything, but trim

 -h, --help          display this help
 -V, --version       display version</pre> 
<p></p> 
<p><strong>第三种优化写放大的方式</strong>：使用<strong>multi-stream</strong>的方案</p> 
<p>从NVMe协议Spec 1.3开始新增的特性，<strong>Multi-stream write(多流写)技术</strong>可以使SSD根据主机端提供的Stream ID，将具有相同或相似生命周期的数据写入到相同的擦除单元中去，大大提高了GC时的效率，减少了写放大，使得SSD的性能和寿命都有了较大的提升。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/36/b0/raB5Q7zH_o.jpg"></p> 
<p>更多细节请参考：<a href="http://mp.weixin.qq.com/s?__biz=MzIwNTUxNDgwNg==&amp;mid=2247485305&amp;idx=1&amp;sn=0857ef6020d3b591cc4a26a35ae2c317&amp;chksm=972ef620a0597f363888558f5655b96f5e9ece2da6eab230e22438edd9b097da0cd1b97c1ad9&amp;scene=21#wechat_redirect" rel="nofollow" title="浅析企业级SSD Multi-Stream Write技术">浅析企业级SSD Multi-Stream Write技术</a></p> 
<p></p> 
<p><strong>第四种优化写放大的方式</strong>：使用<strong>NVM sets和Endurance Group</strong></p> 
<p>在NVMe协议Spec 1.4中新增NVM sets和Endurance Group，不同的NVM Sets使用的不同的NAND物理资源，而且相互独立</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/47/6b/E4iUk3hy_o.png"></p> 
<p>每个NVM set又可以有多个namespace用户空间，不同的NVM sets读写之间不受干扰，可以有更好的IO稳定性。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/6e/ce/PoKUcpCs_o.png"></p> 
<p>同时，多个NVM sets可以组成一个Endurance Group，不同的业务压力模型写入不同的Endurance Group，整体降低数据的搬迁，降低写放大。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/2c/ad/2AiG1nf1_o.png"></p> 
<p><strong>第五种优化写放大的方式</strong>：使用ZNS SSD</p> 
<p>目的也是适配不同的业务场景，以最大的性价比完成性能/寿命/成本等多个因素的统一。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/c7/81/q3dTMEzk_o.png"></p> 
<p>ZNS SSD的原理是把namespace空间划分多个zone空间，zone空间内部执行顺序读写。这样做的优势：</p> 
<ul><li> <p>降低SSD内部的写放大，提升SSD的寿命</p> </li><li> <p>降低OP空间，host可以获得更大的使用空间</p> </li><li> <p>降低SSD内部DRAM的容量，降低整体的SSD成本</p> </li><li> <p>降低SSD读写延迟</p> </li><li> <p>ZNS写入了标准NVME协议，更易于打造软件生态，利于普及</p> </li></ul> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/97/87/4tqQ42ZY_o.png"></p> 
<p>更多细节请参考：<a href="http://mp.weixin.qq.com/s?__biz=MzIwNTUxNDgwNg==&amp;mid=2247485273&amp;idx=1&amp;sn=a2521f0106ee16f05b99cbf43c759769&amp;chksm=972ef600a0597f16d9bc0c0bea0fd4f44fed1797af552d2d9cc4e40e7c49bef37633c46ff068&amp;scene=21#wechat_redirect" rel="nofollow" title="炙手可热的ZNS SSD将会为数据中心带来什么？">炙手可热的ZNS SSD将会为数据中心带来什么？</a></p> 
<p></p> 
<p><strong>第六种优化写放大的方式</strong>：SPDK <strong>WSR</strong>模型</p> 
<p>基于WSR(Write-Shaping RAID)的写入对NAND非常友好，大块写且顺序，同时与SSD IU对齐。这样实现的方式从软件上做了彻底的优化，降低写放大。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/63/5e/L3JRhUK8_o.png"></p> 
<p>整个WSR的数据流过程，主要有几个步骤：</p> 
<ul><li> <p>第1步：数据会写写入WSR Bev</p> </li><li> <p>第2步：通过Append-only追加写的方式，写入数据到Optane SSD，同时基于VSS实现meta的安全校验，保证数据安全性。</p> </li><li> <p>第3步：更新软件管理的L2P映射表，这里面为了提升效果，热点访问的映射表放在DRAM，其他的放在Optane缓存盘。</p> </li><li> <p>第4步：通知用户完成写入。到这里跟用户之间的交互就完成了。</p> </li><li> <p>第5-7步：是后台执行的动作，Optane SSD中通过聚合/压缩等算法，形成大块顺序写场景，把数据下刷到QLC SSD，同时更新QLC对映的L2P映射表。</p> </li></ul> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/bc/84/qFbJpTj6_o.png"></p> 
<p>更多细节请参考：<a href="http://mp.weixin.qq.com/s?__biz=MzIwNTUxNDgwNg==&amp;mid=2247485673&amp;idx=1&amp;sn=9a32c11c3a8308a7be5f075fcb358bdb&amp;chksm=972ef9b0a05970a6b8515afff72a21261b66132136a87adf22702fca9fa36d54563d3fece78b&amp;scene=21#wechat_redirect" rel="nofollow" title="阿里云Optane+QLC存储实践案例分享">阿里云Optane+QLC存储实践案例分享</a></p> 
<p>目前谷歌和Meta正在酝酿一件大事，希望把<strong>优化写放大的方式完成统一，并实现WAF接近1的目标</strong>。谷歌和Meta向NVME协议组织提交了<strong>Flexible Direct Placement TP4146提案</strong>，通过FDP的概念，可以把不同的workload写入不同的介质区间，写放大从3降低到1. </p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/63/72/32Pu1r4G_o.png"></p> 
<p>从目前已经公开的部分信息来看，FDP功能需要Host提供写入数据在NAND分布的提示，支持Standard Device Feature Enable/Disable和Host Enable Data / Media Alignment，对读操作没有影响，LBA放置也没有限制，支持XOR和多个namespace等。这个提案具体细节还没公布。看上去更像是NVM sets和Multi-Stream功能的技术融合，具体实现细节可能要等最终确定进入NVME Spec在说。有可能在NVME Spec 2.x就可以看到了。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/0a/b7/xo7PPEWB_o.png"></p> 
<p>如果这个FDP实现，是不是就完成了写放大优化策略的大统一呢？也不好说，让我们拭目以待。</p> 
<p><strong>除了以上优化写放大的方式，你还有其他的想法吗？欢迎评论留言交流～</strong></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/27ecda493ddbbbf32f722e36d7f34973/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">操作系统-内存</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2a78831a549949bb6c094890594a0eb3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python装饰器的使用方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>