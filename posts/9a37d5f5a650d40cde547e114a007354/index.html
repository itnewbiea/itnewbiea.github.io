<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop Hdfs扩容 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Hadoop Hdfs扩容" />
<meta property="og:description" content="现状和目标
Hadoop目前运行三个节点上，有一台做Namenode，其余为DataNode 主机IP 功能
主机IP功能10.3.5.40NameNode10.3.5.39DataNode10.3.5.41DataNode Hadoop以后运行在6个节点上，有一台做Namenode，其余为DataNode
主机IP功能10.3.5.40NameNode10.3.5.39DataNode10.3.5.41DataNode10.3.5.123DataNode10.3.5124DataNode10.3.5.125DataNode 对业务影响
指标数据暂时无法查询
前置条件和准备过程
Transter-metricstore先关闭优先关闭Transter-metricstore模块登录10.3.5.101 [root@zfr ~]# cd /home/ycm/ycmsys/transfer-metricstore [root@zfr ~]# ./transfer.sh stop SSH无密码认证
在做Hbase、OpenTsDb扩容的时候已经做好了无密码认证。 制作无密码进入过程可参考如下方式：
生成密钥对
[root@zfr ~]# ssh-keygen -t rsa #
把密钥追加到授权的key里面去
[root@zfr ~]# cat id_rsa.pub &gt;&gt; authorized_keys
把公钥复制所有的Slave机器上 把各个机器的密钥追加到授权的key里面去
修改配置文件 修改sshd_config文件
[root@zfr ~]# vi /etc/ssh/sshd_config 修改如下参数 RSAAuthentication yes # 启用 RSA 认证 PubkeyAuthentication yes # 启用公钥私钥配对认证方式 AuthorizedKeysFile .ssh/authorized_keys # 公钥文件路径（和上面生成的文件同） 重启ssh服务 [root@zfr ~]# systemctl restart sshd.service 授权 授权方式需要严格执行
[root@zfr ~]# chmod 755 /root/." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/9a37d5f5a650d40cde547e114a007354/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-03-04T15:32:27+08:00" />
<meta property="article:modified_time" content="2019-03-04T15:32:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop Hdfs扩容</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>现状和目标</strong></p> 
<blockquote> 
 <p>Hadoop目前运行三个节点上，有一台做Namenode，其余为DataNode 主机IP 功能</p> 
</blockquote> 
<table><thead><tr><th>主机IP</th><th>功能</th></tr></thead><tbody><tr><td>10.3.5.40</td><td>NameNode</td></tr><tr><td>10.3.5.39</td><td>DataNode</td></tr><tr><td>10.3.5.41</td><td>DataNode</td></tr></tbody></table> 
<blockquote> 
 <p>Hadoop以后运行在6个节点上，有一台做Namenode，其余为DataNode</p> 
</blockquote> 
<table><thead><tr><th>主机IP</th><th>功能</th></tr></thead><tbody><tr><td>10.3.5.40</td><td>NameNode</td></tr><tr><td>10.3.5.39</td><td>DataNode</td></tr><tr><td>10.3.5.41</td><td>DataNode</td></tr><tr><td>10.3.5.123</td><td>DataNode</td></tr><tr><td>10.3.5124</td><td>DataNode</td></tr><tr><td>10.3.5.125</td><td>DataNode</td></tr></tbody></table> 
<p><strong>对业务影响</strong></p> 
<blockquote> 
 <p>指标数据暂时无法查询</p> 
</blockquote> 
<p><strong>前置条件和准备过程</strong></p> 
<blockquote> 
 <ol><li>Transter-metricstore先关闭</li><li>优先关闭Transter-metricstore模块</li><li>登录10.3.5.101</li></ol> 
</blockquote> 
<pre><code>[root@zfr ~]# cd /home/ycm/ycmsys/transfer-metricstore
[root@zfr ~]# ./transfer.sh stop
</code></pre> 
<p><strong>SSH无密码认证</strong></p> 
<blockquote> 
 <p>在做Hbase、OpenTsDb扩容的时候已经做好了无密码认证。 制作无密码进入过程可参考如下方式：</p> 
</blockquote> 
<ol><li> <p>生成密钥对</p> <p>[root@zfr ~]# ssh-keygen -t rsa #</p> </li><li> <p>把密钥追加到授权的key里面去</p> <p>[root@zfr ~]# cat id_rsa.pub &gt;&gt; authorized_keys</p> </li></ol> 
<blockquote> 
 <p>把公钥复制所有的Slave机器上 把各个机器的密钥追加到授权的key里面去</p> 
</blockquote> 
<ol start="3"><li>修改配置文件</li></ol> 
<blockquote> 
 <p>修改sshd_config文件</p> 
</blockquote> 
<pre><code>[root@zfr ~]# vi /etc/ssh/sshd_config
修改如下参数

RSAAuthentication yes # 启用 RSA 认证
PubkeyAuthentication yes # 启用公钥私钥配对认证方式
AuthorizedKeysFile .ssh/authorized_keys # 公钥文件路径（和上面生成的文件同）
</code></pre> 
<ol start="4"><li>重启ssh服务</li></ol> 
<pre><code>[root@zfr ~]# systemctl restart sshd.service
</code></pre> 
<ol start="5"><li>授权</li></ol> 
<blockquote> 
 <p>授权方式需要严格执行</p> 
</blockquote> 
<pre><code>[root@zfr ~]# chmod 755 /root/.ssh
[root@zfr ~]# chmod 644 authorized_keys
[root@zfr ~]# chmod 644 id_rsa.pub
[root@zfr ~]# chmod 600 id_rsa
</code></pre> 
<blockquote> 
 <p>代码同步 通过scp方式把现生产环境的Hadoop传到10.3.5.123、10.3.5.124、10.3.5.125上。</p> 
</blockquote> 
<ol start="6"><li>关闭防火墙</li></ol> 
<pre><code>[root@zfr ~]# service iptables stop 临时关闭，重启后失效
[root@zfr ~]# chkconfig iptables off 永久关闭
</code></pre> 
<ol start="7"><li>查看防火墙状态</li></ol> 
<pre><code>[root@zfr ~]# service iptables stauts
</code></pre> 
<ol start="8"><li>关闭SELinux</li></ol> 
<pre><code>[root@zfr ~]# vim /etc/sysconfig/selinux
</code></pre> 
<blockquote> 
 <p>按i进入编辑模式 设置：SELINUX=disabled 按Esc进入退出编辑，输入:wq!回车，即为保存并退出,或者shift+z+z</p> 
</blockquote> 
<p><strong>搭建Java环境</strong></p> 
<blockquote> 
 <p>修改环境变量 /etc/profile</p> 
</blockquote> 
<pre><code>  [root@zfr ~]# vim /etc/profile
</code></pre> 
<blockquote> 
 <p>增加如下内容</p> 
</blockquote> 
<pre><code>export JAVA_HOME=/home/ycm/jdk8
export HADOOP_HOME=/home/ycm/hadoop272/hadoop
export PATH=$JAVA_HOME/bin:$PATH
export PATH=$HADOOP_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
</code></pre> 
<ul><li>修改Hosts文件</li></ul> 
<blockquote> 
 <p>修改每台机器的 /etc/hosts<br> 增加如下内容，因扩容OpenTSDb的时候已经添加完毕</p> 
</blockquote> 
<pre><code>10.3.5.40 yyy-prod-ecs-01
10.3.5.39 yyy-prod-ecs-02
10.3.5.41 yyy-prod-ecs-03
10.3.5.123 opentsdb-1
10.3.5.124 opentsdb-2
10.3.5.125 opentsdb-3
</code></pre> 
<p><strong>变更过程</strong></p> 
<ol><li>修改slave文件</li></ol> 
<blockquote> 
 <p>修改slave 文件 在Hadoop的配置文件中添加节点的主机名称</p> 
</blockquote> 
<pre><code>vim /home/ycm/hadoop/etc/hadoop/slave

yyy-prod-ecs-01
yyy-prod-ecs-02
yyy-prod-ecs-03
opentsdb-1
opentsdb-2
opentsdb-3
</code></pre> 
<ol start="2"><li><a href="http://xn--hadoop-env-yu6pe85r.sh" rel="nofollow">修改hadoop-env.sh</a> 文件</li></ol> 
<blockquote> 
 <p>增加如下内容 因为代码是拷贝过来的，所以此步骤可以忽略</p> 
</blockquote> 
<pre><code>export JAVA_HOME=/home/ycm/jdk7
</code></pre> 
<ol start="3"><li>修改core-site.xml 文件</li></ol> 
<blockquote> 
 <p>编辑 core-site.xml文件 因为代码是拷贝过来的，所以此步骤可以忽略</p> 
</blockquote> 
<pre><code>&lt;configuration&gt;
 &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;**hdfs://yyy-prod-ecs-01:9000**&lt;/value&gt;
    &lt;/property&gt;
 &lt;property&gt;
  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
  &lt;value&gt;**/home/hadoop/data/tmp**&lt;/value&gt;
 &lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.native.lib&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
  &lt;description&gt;Should native hadoop libraries, if present, be used.&lt;/description&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<ol start="4"><li>修改hdfs-site.xml文件</li></ol> 
<blockquote> 
 <p>编辑hdfs-site.xml文件 修改副本数和数据存储路径</p> 
</blockquote> 
<pre><code>&lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;**3**&lt;/value&gt;
    &lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.data.dir&lt;/name&gt;
    &lt;value&gt;**/home/hadoop/data**&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
</code></pre> 
<p><strong>启动Hadoop</strong></p> 
<blockquote> 
 <p>切换到/home/ycm/hadoop/sbin 路径下，根据需求执行如下命令。</p> 
</blockquote> 
<pre><code>./hadoop-daemon.sh start secondarynamenode./hadoop-daemon.sh start namenode./hadoop-daemon.sh start datanode
</code></pre> 
<blockquote> 
 <p>注意：<br> 因为10.3.5.40当时Hadoop在根目录，根目录大小为40G，无法扩容。所以不能启动DataNode节点，否则会引起40这台机器磁盘爆炸！！！造成应用不可用。</p> 
</blockquote> 
<p><strong>变更效果检查</strong></p> 
<ol><li>管理控制台检测</li></ol> 
<blockquote> 
 <p>登录Hadoop管理控制页面</p> 
 <p><a href="http://172.20.8.173:50070/dfshealth.html#tab-datanode" rel="nofollow">http://172.20.8.173:50070/dfshealth.html#tab-datanode</a> 检查<br> 但：由于集团堡垒机把50070端口封住，所以此方法暂时无法使用。</p> 
</blockquote> 
<ol start="2"><li>进程检测</li></ol> 
<blockquote> 
 <p>1). 检查Hadoop的NameNode、DataNode进程的状况。<br> 2). 检测Hadoop、Hbase功能<br> 3). Opentsdb和Hbase正常<br> 对其服务和监控的影响 Zabbix会报警 报警预计涉及模块：Hadoop、Hbase、OpenTsDb</p> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/60074d1ed93b20d52d1c93b861a23928/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">三星研究院上机题（Optimal Path）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/109361d0471ec00332eb190c403f841a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">node.js学习第一天</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>