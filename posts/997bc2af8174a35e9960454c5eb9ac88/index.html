<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【论文目录】人体表面细节重建相关论文(自用) - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【论文目录】人体表面细节重建相关论文(自用)" />
<meta property="og:description" content="主要以单目RGB重建为主，包含部分相关的姿态估计方法。
目录 2020年Combining implicit function learning and parametric models for 3d human reconstructionPeelNet: Textured 3D reconstruction of human body using single view RGB imageDo As I Do: Transferring Human Motion and Appearance between Monocular Videos with Spatial and Temporal ConstraintsPIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization.Implicit functions in feature space for 3d shape reconstruction and completionRobust 3D Self-portraits in SecondsARCH: Animatable Reconstruction of Clothed Humans（相关论文）*High Accuracy Face Geometry Capture using a Smartphone Video* 2019年PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human DigitizationLearning to reconstruct people in clothing from a single RGB cameraSiclope: Silhouette-based clothed peopleLivecap: Real-time human performance capture from monocular videoMulti-Garment Net: Learning to Dress 3D People from ImagesLearning Dense Wide Baseline Stereo Matching for People360-Degree Textures of People in Clothing from a Single ImageMoulding Humans: Non-parametric 3D Human Shape Estimation from Single Images3DPeople: Modeling the Geometry of Dressed HumansTex2Shape: Detailed Full Human Body Geometry from a Single ImageDelving Deep Into Hybrid Annotations for 3D Human Recovery in the WildDeepHuman: 3D Human Reconstruction from a Single ImageA Neural Network for Detailed Human Depth Estimation from a Single ImageDetailed Human Shape Estimation from a Single Image by Hierarchical Mesh DeformationLiquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis（相关论文）*TexturePose: Supervising Human Mesh Estimation with Texture Consistency**Self-Supervised Learning of 3D Human Pose using Multi-view Geometry**Shape-Aware Human Pose and Shape Reconstruction Using Multi-View Images**Temporally Coherent Full 3D Mesh Human Pose Recovery from Monocular Video**VIBE: Video Inference for Human Body Pose and Shape Estimation* 2018年Detailed human avatars from monocular videoVideo based reconstruction of 3d people modelsMonoperfcap: Human performance capture from monocular videoDeep volumetric video from very sparse multi-view performance captureVolumetric performance capture from minimal camera viewpointsShape Reconstruction Using Volume Sweeping and Learned PhotoconsistencyBodynet: Volumetric inference of 3d human body shapes（相关论文）*DensePose: Dense Human Pose Estimation In The Wild**Learning to Estimate 3D Human Pose and Shape from a Single Color Image**Learning Monocular 3D Human Pose Estimation from Multi-view Images**DeepWrinkles: Accurate and Realistic ClothingModeling* ~2017年Surfacenet: An end-to-end 3d neural network for multiview stereopsis(2017) 2020年 Combining implicit function learning and parametric models for 3d human reconstruction pdf" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/997bc2af8174a35e9960454c5eb9ac88/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-09-16T10:16:18+08:00" />
<meta property="article:modified_time" content="2020-09-16T10:16:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【论文目录】人体表面细节重建相关论文(自用)</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>主要以单目RGB重建为主，包含部分相关的姿态估计方法。<br> </p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><ul><li><a href="#2020_4" rel="nofollow">2020年</a></li><li><ul><li><a href="#Combining_implicit_function_learning_and_parametric_models_for_3d_human_reconstruction_5" rel="nofollow">Combining implicit function learning and parametric models for 3d human reconstruction</a></li><li><a href="#PeelNet_Textured_3D_reconstruction_of_human_body_using_single_view_RGB_image_9" rel="nofollow">PeelNet: Textured 3D reconstruction of human body using single view RGB image</a></li><li><a href="#Do_As_I_Do_Transferring_Human_Motion_and_Appearance_between_Monocular_Videos_with_Spatial_and_Temporal_Constraints_12" rel="nofollow">Do As I Do: Transferring Human Motion and Appearance between Monocular Videos with Spatial and Temporal Constraints</a></li><li><a href="#PIFuHD_MultiLevel_PixelAligned_Implicit_Function_for_HighResolution_3D_Human_Digitization_15" rel="nofollow">PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization.</a></li><li><a href="#Implicit_functions_in_feature_space_for_3d_shape_reconstruction_and_completion_19" rel="nofollow">Implicit functions in feature space for 3d shape reconstruction and completion</a></li><li><a href="#Robust_3D_Selfportraits_in_Seconds_24" rel="nofollow">Robust 3D Self-portraits in Seconds</a></li><li><a href="#ARCH_Animatable_Reconstruction_of_Clothed_Humans_28" rel="nofollow">ARCH: Animatable Reconstruction of Clothed Humans</a></li><li><a href="#_34" rel="nofollow">（相关论文）</a></li><li><ul><li><a href="#High_Accuracy_Face_Geometry_Capture_using_a_Smartphone_Video_35" rel="nofollow">*High Accuracy Face Geometry Capture using a Smartphone Video*</a></li></ul> 
   </li></ul> 
   </li><li><a href="#2019_38" rel="nofollow">2019年</a></li><li><ul><li><a href="#PIFu_PixelAligned_Implicit_Function_for_HighResolution_Clothed_Human_Digitization_39" rel="nofollow">PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization</a></li><li><a href="#Learning_to_reconstruct_people_in_clothing_from_a_single_RGB_camera_46" rel="nofollow">Learning to reconstruct people in clothing from a single RGB camera</a></li><li><a href="#Siclope_Silhouettebased_clothed_people_54" rel="nofollow">Siclope: Silhouette-based clothed people</a></li><li><a href="#Livecap_Realtime_human_performance_capture_from_monocular_video_60" rel="nofollow">Livecap: Real-time human performance capture from monocular video</a></li><li><a href="#MultiGarment_Net_Learning_to_Dress_3D_People_from_Images_65" rel="nofollow">Multi-Garment Net: Learning to Dress 3D People from Images</a></li><li><a href="#Learning_Dense_Wide_Baseline_Stereo_Matching_for_People_69" rel="nofollow">Learning Dense Wide Baseline Stereo Matching for People</a></li><li><a href="#360Degree_Textures_of_People_in_Clothing_from_a_Single_Image_73" rel="nofollow">360-Degree Textures of People in Clothing from a Single Image</a></li><li><a href="#Moulding_Humans_Nonparametric_3D_Human_Shape_Estimation_from_Single_Images_75" rel="nofollow">Moulding Humans: Non-parametric 3D Human Shape Estimation from Single Images</a></li><li><a href="#3DPeople_Modeling_the_Geometry_of_Dressed_Humans_77" rel="nofollow">3DPeople: Modeling the Geometry of Dressed Humans</a></li><li><a href="#Tex2Shape_Detailed_Full_Human_Body_Geometry_from_a_Single_Image_80" rel="nofollow">Tex2Shape: Detailed Full Human Body Geometry from a Single Image</a></li><li><a href="#Delving_Deep_Into_Hybrid_Annotations_for_3D_Human_Recovery_in_the_Wild_82" rel="nofollow">Delving Deep Into Hybrid Annotations for 3D Human Recovery in the Wild</a></li><li><a href="#DeepHuman_3D_Human_Reconstruction_from_a_Single_Image_85" rel="nofollow">DeepHuman: 3D Human Reconstruction from a Single Image</a></li><li><a href="#A_Neural_Network_for_Detailed_Human_Depth_Estimation_from_a_Single_Image_87" rel="nofollow">A Neural Network for Detailed Human Depth Estimation from a Single Image</a></li><li><a href="#Detailed_Human_Shape_Estimation_from_a_Single_Image_by_Hierarchical_Mesh_Deformation_89" rel="nofollow">Detailed Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation</a></li><li><a href="#Liquid_Warping_GAN_A_Unified_Framework_for_Human_Motion_Imitation_Appearance_Transfer_and_Novel_View_Synthesis_92" rel="nofollow">Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis</a></li><li><a href="#_96" rel="nofollow">（相关论文）</a></li><li><ul><li><a href="#TexturePose_Supervising_Human_Mesh_Estimation_with_Texture_Consistency_97" rel="nofollow">*TexturePose: Supervising Human Mesh Estimation with Texture Consistency*</a></li><li><a href="#SelfSupervised_Learning_of_3D_Human_Pose_using_Multiview_Geometry_102" rel="nofollow">*Self-Supervised Learning of 3D Human Pose using Multi-view Geometry*</a></li><li><a href="#ShapeAware_Human_Pose_and_Shape_Reconstruction_Using_MultiView_Images_106" rel="nofollow">*Shape-Aware Human Pose and Shape Reconstruction Using Multi-View Images*</a></li><li><a href="#Temporally_Coherent_Full_3D_Mesh_Human_Pose_Recovery_from_Monocular_Video_109" rel="nofollow">*Temporally Coherent Full 3D Mesh Human Pose Recovery from Monocular Video*</a></li><li><a href="#VIBE_Video_Inference_for_Human_Body_Pose_and_Shape_Estimation_112" rel="nofollow">*VIBE: Video Inference for Human Body Pose and Shape Estimation*</a></li></ul> 
   </li></ul> 
   </li><li><a href="#2018_116" rel="nofollow">2018年</a></li><li><ul><li><a href="#Detailed_human_avatars_from_monocular_video_117" rel="nofollow">Detailed human avatars from monocular video</a></li><li><a href="#Video_based_reconstruction_of_3d_people_models_122" rel="nofollow">Video based reconstruction of 3d people models</a></li><li><a href="#Monoperfcap_Human_performance_capture_from_monocular_video_128" rel="nofollow">Monoperfcap: Human performance capture from monocular video</a></li><li><a href="#Deep_volumetric_video_from_very_sparse_multiview_performance_capture_132" rel="nofollow">Deep volumetric video from very sparse multi-view performance capture</a></li><li><a href="#Volumetric_performance_capture_from_minimal_camera_viewpoints_135" rel="nofollow">Volumetric performance capture from minimal camera viewpoints</a></li><li><a href="#Shape_Reconstruction_Using_Volume_Sweeping_and_Learned_Photoconsistency_137" rel="nofollow">Shape Reconstruction Using Volume Sweeping and Learned Photoconsistency</a></li><li><a href="#Bodynet_Volumetric_inference_of_3d_human_body_shapes_141" rel="nofollow">Bodynet: Volumetric inference of 3d human body shapes</a></li><li><a href="#_144" rel="nofollow">（相关论文）</a></li><li><ul><li><a href="#DensePose_Dense_Human_Pose_Estimation_In_The_Wild_145" rel="nofollow">*DensePose: Dense Human Pose Estimation In The Wild*</a></li><li><a href="#Learning_to_Estimate_3D_Human_Pose_and_Shape_from_a_Single_Color_Image_148" rel="nofollow">*Learning to Estimate 3D Human Pose and Shape from a Single Color Image*</a></li><li><a href="#Learning_Monocular_3D_Human_Pose_Estimation_from_Multiview_Images_151" rel="nofollow">*Learning Monocular 3D Human Pose Estimation from Multi-view Images*</a></li><li><a href="#DeepWrinkles_Accurate_and_Realistic_ClothingModeling_154" rel="nofollow">*DeepWrinkles: Accurate and Realistic ClothingModeling*</a></li></ul> 
   </li></ul> 
   </li><li><a href="#2017_157" rel="nofollow">~2017年</a></li><li><ul><li><a href="#Surfacenet_An_endtoend_3d_neural_network_for_multiview_stereopsis2017_158" rel="nofollow">Surfacenet: An end-to-end 3d neural network for multiview stereopsis(2017)</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="2020_4"></a>2020年</h3> 
<h4><a id="Combining_implicit_function_learning_and_parametric_models_for_3d_human_reconstruction_5"></a>Combining implicit function learning and parametric models for 3d human reconstruction</h4> 
<p><a href="https://arxiv.org/pdf/2007.11432" rel="nofollow">pdf</a></p> 
<h4><a id="PeelNet_Textured_3D_reconstruction_of_human_body_using_single_view_RGB_image_9"></a>PeelNet: Textured 3D reconstruction of human body using single view RGB image</h4> 
<p><a href="https://arxiv.org/pdf/2002.06664" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/85/96/RIUF4U9H_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Do_As_I_Do_Transferring_Human_Motion_and_Appearance_between_Monocular_Videos_with_Spatial_and_Temporal_Constraints_12"></a>Do As I Do: Transferring Human Motion and Appearance between Monocular Videos with Spatial and Temporal Constraints</h4> 
<p><a href="https://arxiv.org/pdf/2001.02606.pdf" rel="nofollow">pdf</a><img src="https://images2.imgbox.com/e7/25/ADK5WFBU_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="PIFuHD_MultiLevel_PixelAligned_Implicit_Function_for_HighResolution_3D_Human_Digitization_15"></a>PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization.</h4> 
<p><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Saito_PIFuHD_Multi-Level_Pixel-Aligned_Implicit_Function_for_High-Resolution_3D_Human_Digitization_CVPR_2020_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/8b/42/TqIl5V08_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Implicit_functions_in_feature_space_for_3d_shape_reconstruction_and_completion_19"></a>Implicit functions in feature space for 3d shape reconstruction and completion</h4> 
<p><a href="https://arxiv.org/pdf/2003.01456" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/24/47/g9PtUpj5_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Robust_3D_Selfportraits_in_Seconds_24"></a>Robust 3D Self-portraits in Seconds</h4> 
<p><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Robust_3D_Self-Portraits_in_Seconds_CVPR_2020_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/58/be/2F5YMOgd_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="ARCH_Animatable_Reconstruction_of_Clothed_Humans_28"></a>ARCH: Animatable Reconstruction of Clothed Humans</h4> 
<p><a href="https://arxiv.org/pdf/2004.04572" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/8a/c1/Bw7w1ms5_o.png" alt="在这里插入图片描述"></p> 
<br> 
<h4><a id="_34"></a>（相关论文）</h4> 
<h5><a id="High_Accuracy_Face_Geometry_Capture_using_a_Smartphone_Video_35"></a><em>High Accuracy Face Geometry Capture using a Smartphone Video</em></h5> 
<p><a href="http://openaccess.thecvf.com/content_WACV_2020/papers/Agrawal_High_Accuracy_Face_Geometry_Capture_using_a_Smartphone_Video_WACV_2020_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/3f/fd/KBKdVHPm_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2019_38"></a>2019年</h3> 
<h4><a id="PIFu_PixelAligned_Implicit_Function_for_HighResolution_Clothed_Human_Digitization_39"></a>PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Saito_PIFu_Pixel-Aligned_Implicit_Function_for_High-Resolution_Clothed_Human_Digitization_ICCV_2019_paper.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/shunsukesaito/PIFu"><strong>github</strong></a><br> <img src="https://images2.imgbox.com/7f/9b/kzZ9xgKT_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Learning_to_reconstruct_people_in_clothing_from_a_single_RGB_camera_46"></a>Learning to reconstruct people in clothing from a single RGB camera</h4> 
<p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Alldieck_Learning_to_Reconstruct_People_in_Clothing_From_a_Single_RGB_CVPR_2019_paper.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/thmoa/octopus"><strong>github</strong></a></p> 
<p><img src="https://images2.imgbox.com/8a/28/NvdupkPZ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Siclope_Silhouettebased_clothed_people_54"></a>Siclope: Silhouette-based clothed people</h4> 
<p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Natsume_SiCloPe_Silhouette-Based_Clothed_People_CVPR_2019_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/0c/25/WVULIa8W_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/f9/32/CTwHqer7_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Livecap_Realtime_human_performance_capture_from_monocular_video_60"></a>Livecap: Real-time human performance capture from monocular video</h4> 
<p><a href="https://arxiv.org/pdf/1810.02648" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/73/89/CfylIPf6_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="MultiGarment_Net_Learning_to_Dress_3D_People_from_Images_65"></a>Multi-Garment Net: Learning to Dress 3D People from Images</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Bhatnagar_Multi-Garment_Net_Learning_to_Dress_3D_People_From_Images_ICCV_2019_paper.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/bharat-b7/MultiGarmentNetwork"><strong>github</strong></a><br> <img src="https://images2.imgbox.com/e9/a7/jjEWmBu6_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Learning_Dense_Wide_Baseline_Stereo_Matching_for_People_69"></a>Learning Dense Wide Baseline Stereo Matching for People</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/3DRW/Caliskan_Learning_Dense_Wide_Baseline_Stereo_Matching_for_People_ICCVW_2019_paper.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/akcalakcal/Learning-Dense-Wide-Baseline-Stereo-Matching-for-People">github(to be released)</a><br> <img src="https://images2.imgbox.com/83/bd/cUAJSGyv_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="360Degree_Textures_of_People_in_Clothing_from_a_Single_Image_73"></a>360-Degree Textures of People in Clothing from a Single Image</h4> 
<p><a href="https://arxiv.org/pdf/1908.07117" rel="nofollow">pdf</a></p> 
<h4><a id="Moulding_Humans_Nonparametric_3D_Human_Shape_Estimation_from_Single_Images_75"></a>Moulding Humans: Non-parametric 3D Human Shape Estimation from Single Images</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Gabeur_Moulding_Humans_Non-Parametric_3D_Human_Shape_Estimation_From_Single_Images_ICCV_2019_paper.pdf" rel="nofollow">pdf</a></p> 
<h4><a id="3DPeople_Modeling_the_Geometry_of_Dressed_Humans_77"></a>3DPeople: Modeling the Geometry of Dressed Humans</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Pumarola_3DPeople_Modeling_the_Geometry_of_Dressed_Humans_ICCV_2019_paper.pdf" rel="nofollow">pdf</a></p> 
<h4><a id="Tex2Shape_Detailed_Full_Human_Body_Geometry_from_a_Single_Image_80"></a>Tex2Shape: Detailed Full Human Body Geometry from a Single Image</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Alldieck_Tex2Shape_Detailed_Full_Human_Body_Geometry_From_a_Single_Image_ICCV_2019_paper.pdf" rel="nofollow">pdf</a></p> 
<h4><a id="Delving_Deep_Into_Hybrid_Annotations_for_3D_Human_Recovery_in_the_Wild_82"></a>Delving Deep Into Hybrid Annotations for 3D Human Recovery in the Wild</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Rong_Delving_Deep_Into_Hybrid_Annotations_for_3D_Human_Recovery_in_ICCV_2019_paper.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/penincillin/DCT_ICCV-2019"><strong>github</strong></a></p> 
<h4><a id="DeepHuman_3D_Human_Reconstruction_from_a_Single_Image_85"></a>DeepHuman: 3D Human Reconstruction from a Single Image</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Zheng_DeepHuman_3D_Human_Reconstruction_From_a_Single_Image_ICCV_2019_paper.pdf" rel="nofollow">pdf</a></p> 
<h4><a id="A_Neural_Network_for_Detailed_Human_Depth_Estimation_from_a_Single_Image_87"></a>A Neural Network for Detailed Human Depth Estimation from a Single Image</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Tang_A_Neural_Network_for_Detailed_Human_Depth_Estimation_From_a_ICCV_2019_paper.pdf" rel="nofollow">pdf</a></p> 
<h4><a id="Detailed_Human_Shape_Estimation_from_a_Single_Image_by_Hierarchical_Mesh_Deformation_89"></a>Detailed Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation</h4> 
<p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Detailed_Human_Shape_Estimation_From_a_Single_Image_by_Hierarchical_CVPR_2019_paper.pdf" rel="nofollow">pdf</a></p> 
<h4><a id="Liquid_Warping_GAN_A_Unified_Framework_for_Human_Motion_Imitation_Appearance_Transfer_and_Novel_View_Synthesis_92"></a>Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis</h4> 
<p><a href="https://github.com/svip-lab/impersonator"><strong>github</strong></a></p> 
<h4><a id="_96"></a>（相关论文）</h4> 
<h5><a id="TexturePose_Supervising_Human_Mesh_Estimation_with_Texture_Consistency_97"></a><em>TexturePose: Supervising Human Mesh Estimation with Texture Consistency</em></h5> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Pavlakos_TexturePose_Supervising_Human_Mesh_Estimation_With_Texture_Consistency_ICCV_2019_paper.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/geopavlakos/TexturePose"><strong>github</strong></a><br> <img src="https://images2.imgbox.com/1b/bd/zUNFluYn_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="SelfSupervised_Learning_of_3D_Human_Pose_using_Multiview_Geometry_102"></a><em>Self-Supervised Learning of 3D Human Pose using Multi-view Geometry</em></h5> 
<p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Kocabas_Self-Supervised_Learning_of_3D_Human_Pose_Using_Multi-View_Geometry_CVPR_2019_paper.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/mkocabas/EpipolarPose"><strong>github</strong></a><br> <img src="https://images2.imgbox.com/b7/56/5s0S14lF_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="ShapeAware_Human_Pose_and_Shape_Reconstruction_Using_MultiView_Images_106"></a><em>Shape-Aware Human Pose and Shape Reconstruction Using Multi-View Images</em></h5> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Liang_Shape-Aware_Human_Pose_and_Shape_Reconstruction_Using_Multi-View_Images_ICCV_2019_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/04/f4/N3AFOLwJ_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="Temporally_Coherent_Full_3D_Mesh_Human_Pose_Recovery_from_Monocular_Video_109"></a><em>Temporally Coherent Full 3D Mesh Human Pose Recovery from Monocular Video</em></h5> 
<p><a href="https://arxiv.org/pdf/1906.00161.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/4a/6b/6rXzqNDW_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="VIBE_Video_Inference_for_Human_Body_Pose_and_Shape_Estimation_112"></a><em>VIBE: Video Inference for Human Body Pose and Shape Estimation</em></h5> 
<p><a href="https://arxiv.org/pdf/1912.05656.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/mkocabas/VIBE"><strong>github</strong></a><br> <img src="https://images2.imgbox.com/57/f3/lgoQ0lsu_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2018_116"></a>2018年</h3> 
<h4><a id="Detailed_human_avatars_from_monocular_video_117"></a>Detailed human avatars from monocular video</h4> 
<p><a href="https://arxiv.org/pdf/1808.01338" rel="nofollow">pdf</a><br> <a href="https://github.com/thmoa/semantic_human_texture_stitching"><strong>github</strong></a><br> <img src="https://images2.imgbox.com/06/17/egGsY7Ap_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Video_based_reconstruction_of_3d_people_models_122"></a>Video based reconstruction of 3d people models</h4> 
<p><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Alldieck_Video_Based_Reconstruction_CVPR_2018_paper.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/thmoa/videoavatars"><strong>github</strong></a></p> 
<p><img src="https://images2.imgbox.com/3e/37/snL0IKYY_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/ea/c4/joRXdbi6_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Monoperfcap_Human_performance_capture_from_monocular_video_128"></a>Monoperfcap: Human performance capture from monocular video</h4> 
<p><a href="https://arxiv.org/pdf/1708.02136" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/c4/fa/cJodRjG9_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0a/9a/lKOuiwA8_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Deep_volumetric_video_from_very_sparse_multiview_performance_capture_132"></a>Deep volumetric video from very sparse multi-view performance capture</h4> 
<p><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Zeng_Huang_Deep_Volumetric_Video_ECCV_2018_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/f0/63/Mk58dhj2_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Volumetric_performance_capture_from_minimal_camera_viewpoints_135"></a>Volumetric performance capture from minimal camera viewpoints</h4> 
<p><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Andrew_Gilbert_Volumetric_performance_capture_ECCV_2018_paper.pdf" rel="nofollow">pdf</a> <img src="https://images2.imgbox.com/95/12/CHDCvCCQ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Shape_Reconstruction_Using_Volume_Sweeping_and_Learned_Photoconsistency_137"></a>Shape Reconstruction Using Volume Sweeping and Learned Photoconsistency</h4> 
<p><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Vincent_Leroy_Shape_Reconstruction_Using_ECCV_2018_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/52/c8/RpnEOBQw_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Bodynet_Volumetric_inference_of_3d_human_body_shapes_141"></a>Bodynet: Volumetric inference of 3d human body shapes</h4> 
<p><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Gul_Varol_BodyNet_Volumetric_Inference_ECCV_2018_paper.pdf" rel="nofollow">pdf</a></p> 
<h4><a id="_144"></a>（相关论文）</h4> 
<h5><a id="DensePose_Dense_Human_Pose_Estimation_In_The_Wild_145"></a><em>DensePose: Dense Human Pose Estimation In The Wild</em></h5> 
<p><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Guler_DensePose_Dense_Human_CVPR_2018_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/7f/60/41MeXNx1_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="Learning_to_Estimate_3D_Human_Pose_and_Shape_from_a_Single_Color_Image_148"></a><em>Learning to Estimate 3D Human Pose and Shape from a Single Color Image</em></h5> 
<p><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Pavlakos_Learning_to_Estimate_CVPR_2018_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/71/84/vUikhZuj_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="Learning_Monocular_3D_Human_Pose_Estimation_from_Multiview_Images_151"></a><em>Learning Monocular 3D Human Pose Estimation from Multi-view Images</em></h5> 
<p><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Rhodin_Learning_Monocular_3D_CVPR_2018_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/c3/64/C7SXILfB_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="DeepWrinkles_Accurate_and_Realistic_ClothingModeling_154"></a><em>DeepWrinkles: Accurate and Realistic ClothingModeling</em></h5> 
<p><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Zorah_Laehner_DeepWrinkles_Accurate_and_ECCV_2018_paper.pdf" rel="nofollow">pdf</a><br> <img src="https://images2.imgbox.com/57/3d/WdYjMSvy_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2017_157"></a>~2017年</h3> 
<h4><a id="Surfacenet_An_endtoend_3d_neural_network_for_multiview_stereopsis2017_158"></a>Surfacenet: An end-to-end 3d neural network for multiview stereopsis(2017)</h4> 
<p><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Ji_SurfaceNet_An_End-To-End_ICCV_2017_paper.pdf" rel="nofollow">pdf</a><br> <a href="https://github.com/mjiUST/SurfaceNet"><strong>github</strong></a><br> <img src="https://images2.imgbox.com/7c/29/d9eSgk75_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6a3b142220ad6d059bc96a4828453b8c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">447，双指针解旋转链表</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bafd78f50f06e22237311d08bb849e94/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Ubuntu18.04 sudo apt update无法解析域名的解决，亲测有效！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>