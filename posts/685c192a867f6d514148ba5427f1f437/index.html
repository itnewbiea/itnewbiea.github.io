<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark内核 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Spark内核" />
<meta property="og:description" content="1. Spark 内核概述 1.1核心组件 1.1.1 Driver master(唯一的一个) Spark驱动节点,用于 Spark 任务中的 main 方法,fuze实际代码的执行工作. Driver 在 Spark 作业执行时主要负责:
1. 将用户程序转化为作业( job );
2. 在 Executor 之间调度任务( task );
3. 跟踪 Executor 的执行情况;
4.通过 UI 展示查询运行情况;
1.1.2 Executor worker（多个） Spark Executor节点是一个JVM进程，负责在 Spark 作业中运行具体任务，任务彼此之间相互独立。Spark 应用启动时，Executor节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。（spark的容错机制）
Executor有两个核心功能：
1. 负责运行组成Spark应用的任务，并将结果返回给驱动器进程；
2. 它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 是直接缓存在Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。
1.2运行流程 如图 Spark 的运行流程不论Spark以何种模式进行部署，任务提交后，都会先启动Driver.进程.随后Driver进程向集群管理器注册应用程序，之后集群管理器根据此任务的配置文件分配Executor并启动，当Driver所需的资源全部满足后，Driver开始执行main函数，Spark查询为懒执行，当执行到action算子时开始反向推算，根据宽依赖进行stage的划分，随后每一个stage对应一个taskset，taskset中有多个task，根据本地化原则，task会被分发到指定的Executor去执行，在任务执行的过程中，Executor也会不断与Driver进行通信，报告任务运行情况。
2.部署模式 Spark支持3种集群管理器（Cluster Manager），分别为：
1. Standalone：（测试中）独立模式，Spark原生的简单集群管理器，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统，使用Standalone可以很方便地搭建一个集群;
2. Apache Mesos：一个强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括yarn；
3.Hadoop YARN：统一的资源管理机制，在上面可以运行多套计算框架，如map reduce、storm等，根据driver在集群中的位置不同，分为yarn client（测试中）和yarn cluster。（实际工作中，只能用这种模式）部署在hadoop集群中，由yarn来管理资源分配。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/685c192a867f6d514148ba5427f1f437/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-17T22:45:57+08:00" />
<meta property="article:modified_time" content="2023-09-17T22:45:57+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark内核</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 style="text-align:justify;"><span style="color:#0d0016;"><strong>1. Spark 内核概述</strong></span></h2> 
<h3><span style="color:#0d0016;"><strong>1.1核心组件</strong></span></h3> 
<h4><span style="color:#be191c;"><strong>1.1.1 Driver  master(唯一的一个)</strong></span></h4> 
<p><span style="color:#4da8ee;">Spark驱动节点,用于 Spark 任务中的 main 方法,fuze实际代码的执行工作. Driver 在 Spark 作业执行时主要负责:</span></p> 
<p><span style="color:#956fe7;">1. 将用户程序转化为作业( job );</span></p> 
<p><span style="color:#956fe7;">2. 在 Executor 之间调度任务( task );</span></p> 
<p><span style="color:#956fe7;">3. 跟踪 Executor 的执行情况;</span></p> 
<p><span style="color:#956fe7;">4.通过 UI 展示查询运行情况;</span></p> 
<h4 style="text-align:justify;"><span style="color:#be191c;">1.1.2 Executor   worker（多个）</span></h4> 
<p><span style="color:#38d8f0;">Spark Executor节点是一个JVM进程，负责在 Spark 作业中运行具体任务，任务彼此之间相互独立。Spark 应用启动时，Executor节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。</span><span style="color:#ff0000;">如果有Executor节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。</span><span style="color:#ff0000;">（</span><span style="color:#ff0000;">spark的容错机制</span><span style="color:#ff0000;">）</span></p> 
<p><strong><span style="color:#0d0016;">Executor有两个核心功能：</span></strong></p> 
<p><span style="color:#38d8f0;">1. 负责运行组成Spark应用的任务，并将结果返回给驱动器进程；</span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="color:#38d8f0;">2. 它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 是直接缓存在Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</span></p> 
<h3 style="background-color:transparent;margin-left:.0001pt;text-align:justify;"><span style="color:#0d0016;">1.2运行流程</span></h3> 
<p><img alt="" height="556" src="https://images2.imgbox.com/2f/c5/8AQ5Mp00_o.png" width="737"></p> 
<p><span style="color:#be191c;"><strong>如图</strong></span> <span style="color:#0d0016;">Spark 的运行流程不论Spark以何种模式进行部署，任务提交后，都会先启动Driver.进程.随后Driver进程向集群管理器注册应用程序，之后集群管理器根据此任务的配置文件分配Executor并启动，当Driver所需的资源全部满足后，Driver开始执行<span style="background-color:#ff0000;">main</span>函数，Spark查询为懒执行，当执行到action算子时开始反向推算，根据宽依赖进行stage的划分，随后每一个stage对应一个taskset，taskset中有多个task，根据本地化原则，task会被分发到指定的Executor去执行，在任务执行的过程中，Executor也会不断与Driver进行通信，报告任务运行情况。</span></p> 
<h2><span style="color:#0d0016;"><strong>2.部署模式</strong></span></h2> 
<p>Spark支持3种集群管理器（Cluster Manager），分别为：</p> 
<p>1. Standalone：（测试中）独立模式，Spark原生的简单集群管理器，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统，使用Standalone可以很方便地搭建一个集群;</p> 
<p>2. Apache Mesos：一个强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括yarn；</p> 
<p>3.Hadoop YARN：统一的资源管理机制，在上面可以运行多套计算框架，如map reduce、storm等，根据driver在集群中的位置不同，分为yarn client（测试中）和<span style="color:#ff0000;">yarn cluster</span><span style="color:#ff0000;">。</span><span style="color:#ff0000;">（实际工作中，只能用这种模式）部署在</span><span style="color:#ff0000;">hadoop集群中，由yarn来管理资源分配。</span></p> 
<p><span style="color:#0d0016;"><strong>Spark内部也提供了一些方便用户测试和学习的简单集群部署模式。由于在实际工厂环境下使用的绝大多数的集群管理器是Hadoop YARN，因此我们关注的重点是Hadoop YARN模式下的Spark集群部署。</strong></span></p> 
<p><img alt="" height="846" src="https://images2.imgbox.com/2d/32/u737xJl4_o.png" width="874"></p> 
<p><span style="color:#0d0016;"><strong>用户在提交任务给Spark处理时，以下两个参数共同决定了Spark的运行方式。</strong></span></p> 
<p><span style="color:#a2e043;"><strong>· –master MASTER_URL ：决定了Spark任务提交给哪种集群处理。</strong></span></p> 
<p><strong><span style="color:#a2e043;">· –deploy-mode DEPLOY_MODE：决定了Driver的运行方式，可选值为Client或者Cluster。</span></strong></p> 
<h3><span style="color:#0d0016;"><strong>2.1Standalone模式运行机制</strong></span></h3> 
<p><strong><span style="color:#be191c;">Standalone集群有四个重要组成部分:</span></strong></p> 
<ol><li>Driver：是一个进程，我们编写的Spark应用程序就运行在Driver上，由Driver进程执行；</li><li>Master(RM)：是一个进程，主要负责资源的调度和分配，并进行集群的监控等职责；</li><li>Worker(NM)：是一个进程，一个Worker运行在集群中的一台服务器上，主要负责两个职责，<span style="color:#ff0000;">一个是用自己的内存存储RDD的某个或某些partition；另一个是启动其他进程和线程（Executor），对RDD上的partition进行并行的处理和计算。</span></li><li>Executor：是一个进程，一个Worker上可以运行多个Executor，Executor通过启动多个线程（task）来执行对RDD的partition进行并行计算，也就是执行我们对RDD定义的例如map、flatMap、reduce等算子操作。</li></ol> 
<p> </p> 
<h4><span style="color:#0d0016;"><strong>2.1.1Standalone Client模式</strong></span></h4> 
<p><img alt="" height="439" src="https://images2.imgbox.com/82/a6/njKMe3sc_o.png" width="852"></p> 
<p><span style="color:#be191c;"> 在Standalone Client模式下，Driver在任务提交的本地机器上运行，Driver启动后向Master注册应用程序，Master根据submit脚本的资源需求找到内部资源至少可以启动一个Executor的所有Worker，然后在这些Worker之间分配Executor，Worker上的Executor启动后会向Driver反向注册，所有的Executor注册完成后，Driver开始执行main函数，之后执行到Action算子时，开始划分stage，每个stage生成对应的taskSet，之后将task分发到各个Executor上执行。</span></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0ae38f342380f3360f4a4228f0686a00/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python中swith-case,python的case写法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5a5e7fb086cf53c113160300de114b7d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux驱动之MISC设备驱动</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>