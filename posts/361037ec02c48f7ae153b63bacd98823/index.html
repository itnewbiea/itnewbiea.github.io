<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>PPI数据集示例项目学习图神经网络 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="PPI数据集示例项目学习图神经网络" />
<meta property="og:description" content="下面所有博客是个人对EEG脑电的探索，项目代码是早期版本不完整，需要完整项目代码和资料请私聊。
数据集
1、脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED
相关论文阅读分析：
1、EEG-SEED数据集作者的—基线论文阅读和分析
2、图神经网络EEG论文阅读和分析：《EEG-Based Emotion Recognition Using Regularized Graph Neural Networks》
3、EEG-GNN论文阅读和分析：《EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks》
4、论文阅读和分析:Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification
5、论文阅读和分析：《DeepGCNs: Can GCNs Go as Deep as CNNs?》
6、论文阅读和分析： “How Attentive are Graph Attention Networks?”
7、论文阅读和分析：Simplifying Graph Convolutional Networks
8、论文阅读和分析：LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation
9、图神经网络汇总和总结
相关实验和代码实现：
1、用于图神经网络的脑电数据处理实现_图神经网络 脑电
2、使用GCN训练和测试EEG的公开SEED数据集
3、使用GAT训练和测试EEG公开的SEED数据集
4、使用SGC训练和测试SEED数据集
5、使用Transformer训练和测试EEG的公开SEED数据集_eeg transformer" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/361037ec02c48f7ae153b63bacd98823/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-05T12:27:06+08:00" />
<meta property="article:modified_time" content="2023-04-05T12:27:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">PPI数据集示例项目学习图神经网络</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p><strong><font size="3" face="Courier New">下面所有博客是个人对EEG脑电的探索，项目代码是早期版本不完整，需要完整项目代码和资料请私聊。</font></strong><br> <br><br> <strong><font size="3" face="Courier New">数据集</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128589175?spm=1001.2014.3001.5501">脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED</a><br> <strong><font size="3" face="Courier New">相关论文阅读分析：</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128607350?spm=1001.2014.3001.5501">EEG-SEED数据集作者的—基线论文阅读和分析</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/128637894?spm=1001.2014.3001.5501">图神经网络EEG论文阅读和分析：《EEG-Based Emotion Recognition Using Regularized Graph Neural Networks》</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/128679724?spm=1001.2014.3001.5501">EEG-GNN论文阅读和分析：《EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks》</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/128882363?spm=1001.2014.3001.5501">论文阅读和分析:Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/128892103?spm=1001.2014.3001.5501">论文阅读和分析：《DeepGCNs: Can GCNs Go as Deep as CNNs?》</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/128911280?spm=1001.2014.3001.5501">论文阅读和分析： “How Attentive are Graph Attention Networks?”</a><br> 7、<a href="https://blog.csdn.net/KPer_Yang/article/details/128927668?spm=1001.2014.3001.5501">论文阅读和分析：Simplifying Graph Convolutional Networks</a></font></font></p> 
 <p>8、<a href="https://blog.csdn.net/KPer_Yang/article/details/128945159?spm=1001.2014.3001.5501">论文阅读和分析：LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</a><br> 9、<a href="https://blog.csdn.net/KPer_Yang/article/details/129968785?spm=1001.2014.3001.5502">图神经网络汇总和总结</a><br> <strong><font size="3" face="Courier New">相关实验和代码实现：</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128740968?spm=1001.2014.3001.5501">用于图神经网络的脑电数据处理实现_图神经网络 脑电</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/129034169?spm=1001.2014.3001.5501">使用GCN训练和测试EEG的公开SEED数据集</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/129074872?spm=1001.2014.3001.5501">使用GAT训练和测试EEG公开的SEED数据集</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/129094901?spm=1001.2014.3001.5501">使用SGC训练和测试SEED数据集</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/129095088?spm=1001.2014.3001.5501">使用Transformer训练和测试EEG的公开SEED数据集_eeg transformer</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/129133439?spm=1001.2014.3001.5501">使用RGNN训练和测试EEG公开的SEED数据集</a><br> <strong><font size="3" face="Courier New">辅助学习资料：</font></strong><br> 1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128808874?spm=1001.2014.3001.5501">官网三个简单Graph示例说明三种层次的应用_graph 简单示例</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/128810698?spm=1001.2014.3001.5501">PPI数据集示例项目学习图神经网络</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/128859245?spm=1001.2014.3001.5501">geometric库的数据处理详解</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/128880391?spm=1001.2014.3001.5501">NetworkX的dicts of dicts以及解决Seven Bridges of Königsberg问题</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/128889737?spm=1001.2014.3001.5501">geometric源码阅读和分析：MessagePassin类详解和使用</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/129095501?spm=1001.2014.3001.5501">cora数据集示例项目学习图神经网络</a><br> 7、<a href="https://blog.csdn.net/KPer_Yang/article/details/129102055?spm=1001.2014.3001.5501">Graph 聚合</a><br> 8、<a href="https://blog.csdn.net/KPer_Yang/article/details/129105477?spm=1001.2014.3001.5501">QM9数据集示例项目学习图神经网络</a><br> 9、<a href="https://blog.csdn.net/KPer_Yang/article/details/129105010?spm=1001.2014.3001.5501">处理图的开源库</a></font></p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><ul><li><a href="#PPI_35" rel="nofollow">PPI数据集：</a></li><li><ul><li><a href="#PPI_50" rel="nofollow">PPI数据集代码的理解</a></li></ul> 
   </li><li><a href="#_86" rel="nofollow">算法原理：</a></li><li><a href="#_109" rel="nofollow">代码实现：</a></li><li><a href="#_213" rel="nofollow">代码理解</a></li><li><a href="#_259" rel="nofollow">训练过程</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="PPI_35"></a>PPI数据集：</h3> 
<p>参考：https://blog.csdn.net/weixin_43580130/article/details/116449062</p> 
<p>PPI(生物化学结构) 网络是蛋白质相互作用（Protein-Protein Interaction,PPI）网络的简称，在GCN中主要用于<strong>节点分类任务</strong><br> PPI是指两种或以上的蛋白质结合的过程，通常旨在执行其生化功能。一般地，如果两个蛋白质共同参与一个生命过程或者协同完成某一功能，都被看作这两个蛋白质之间存在相互作用。多个蛋白质之间的复杂的相互作用关系可以用PPI网络来描述。</p> 
<p>PPI数据集共24张图，每张图对应不同的人体组织，平均每张图有2371个节点，共56944个节点818716条边，每个节点特征长度为50，其中包含<strong>位置基因集，基序集和免疫学特征</strong>。基因本体基作为label(总共121个)，label不是one-hot编码。</p> 
<p>valid_feats.npy文件保存节点的特征，shape为(56944, 50)(节点数目，特征维度)，值为0或1，且1的数目稀少；<br> ppi-class_map.json为节点的label文件，shape为(121, 56944),每个节点的label为121维；<br> ppi-G.json文件为节点和链接的描述信息，节点：{“test”: true, “id”: 56708, “val”: false}, 表示节点id为56708的节点是否为test集或者val集，链接：“links”: [{“source”: 0, “target”: 372}, {“source”: 0, “target”: 1101}, 表示节点id为0的节点和为1101的节点之间有links。<br> ppi-walks.txt文件中为链接信息<br> ppi-id_map.json文件为节点id信息</p> 
<h4><a id="PPI_50"></a>PPI数据集代码的理解</h4> 
<pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        root<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
        split<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">'train'</span><span class="token punctuation">,</span>
        transform<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Callable<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        pre_transform<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Callable<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        pre_filter<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Callable<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token keyword">assert</span> split <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span>

        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>root<span class="token punctuation">,</span> transform<span class="token punctuation">,</span> pre_transform<span class="token punctuation">,</span> pre_filter<span class="token punctuation">)</span>

        <span class="token keyword">if</span> split <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>slices <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_paths<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> split <span class="token operator">==</span> <span class="token string">'val'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>slices <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_paths<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> split <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>slices <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_paths<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>1、PPI数据集使用三个pt文件分别保存train val test，这一点值得学习。</p> 
<p>2、使用图的库networkx处理图数据；</p> 
<p>3、使用mask的思路处理数据集的，这一点在其他数据集的处理中也可以观察到，可以节约内存，减少数据的拷贝</p> 
<pre><code class="prism language-python">data <span class="token operator">=</span> Data<span class="token punctuation">(</span>edge_index<span class="token operator">=</span>edge_index<span class="token punctuation">,</span> x<span class="token operator">=</span>x<span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>y<span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_86"></a>算法原理：</h3> 
<p>参考：https://arxiv.org/abs/1707.04638</p> 
<p><img src="https://images2.imgbox.com/5b/83/5b6qnOY6_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>OhmNet的伪码在算法1中给出。</p> 
<p>在第一阶段，OhmNet应用Node2vec算法（Grover和Leskovec，2016）为每个层中的每个节点构建网络邻居。给定层Gi和节点u∈Vi，该算法模拟用户定义的从节点u开始的固定长度随机游动数（算法1中的步骤4）。</p> 
<p>在第二阶段，OhmNet使用了一种迭代方法，在该方法中，与层次结构中的每个对象相关的特征通过固定其余的特征来迭代更新。迭代方法的优点在于，它可以容易地合并为层次结构的内部对象开发的封闭形式更新（算法1中的步骤11），从而加速OhmNet算法的收敛。对于每个叶对象i，OhmNet隔离了等式（7）中优化问题中的项，这些项取决于定义函数fi的模型参数。OhmNet然后通过对fi模型参数执行一个时期的随机梯度下降（SGD1）来优化等式（6）（算法1中的步骤15）。OhmNet的两个阶段依次执行。OhmNet算法可扩展到大型多层网络，因为每个阶段都可并行化并异步执行。使用分层模型对网络层之间的依赖性进行建模的选择需要<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         O 
        
       
         ( 
        
       
         ∣ 
        
       
         M 
        
       
         ∣ 
        
       
         N 
        
       
         ) 
        
       
      
        O(|M|N) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">O</span><span class="mopen">(</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right: 0.109em;">M</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mclose">)</span></span></span></span></span>时间，而不是需要<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         O 
        
       
         ( 
        
        
        
          K 
         
        
          2 
         
        
       
         N 
        
       
         ) 
        
       
      
        O(K^2N) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0641em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mclose">)</span></span></span></span></span>时间的完全成对模型。</p> 
<p>等式6：</p> 
<p><img src="https://images2.imgbox.com/43/8d/b55uTvsQ_o.png" alt="在这里插入图片描述" width="450"></p> 
<p>等式7：</p> 
<p><img src="https://images2.imgbox.com/b2/66/DzfAkBJt_o.png" alt="在这里插入图片描述" width="450"></p> 
<h3><a id="_109"></a>代码实现：</h3> 
<p>参考：<a href="https://www.pyg.org/" rel="nofollow">PyG</a></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os<span class="token punctuation">.</span>path <span class="token keyword">as</span> osp

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> f1_score
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear

<span class="token keyword">import</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> PPI
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>loader <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCN2Conv

path <span class="token operator">=</span> osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>realpath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'GCN2_PPI'</span><span class="token punctuation">)</span>
pre_transform <span class="token operator">=</span> T<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>T<span class="token punctuation">.</span>GCNNorm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> T<span class="token punctuation">.</span>ToSparseTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
train_dataset <span class="token operator">=</span> PPI<span class="token punctuation">(</span>path<span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> pre_transform<span class="token operator">=</span>pre_transform<span class="token punctuation">)</span>
val_dataset <span class="token operator">=</span> PPI<span class="token punctuation">(</span>path<span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'val'</span><span class="token punctuation">,</span> pre_transform<span class="token operator">=</span>pre_transform<span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> PPI<span class="token punctuation">(</span>path<span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">,</span> pre_transform<span class="token operator">=</span>pre_transform<span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> alpha<span class="token punctuation">,</span> theta<span class="token punctuation">,</span>
                 shared_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>lins <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lins<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Linear<span class="token punctuation">(</span>train_dataset<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lins<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Linear<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> train_dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>convs <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>convs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                GCN2Conv<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> alpha<span class="token punctuation">,</span> theta<span class="token punctuation">,</span> layer <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                         shared_weights<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> adj_t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x_0 <span class="token operator">=</span> self<span class="token punctuation">.</span>lins<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>convs<span class="token punctuation">:</span>
            h <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
            h <span class="token operator">=</span> conv<span class="token punctuation">(</span>h<span class="token punctuation">,</span> x_0<span class="token punctuation">,</span> adj_t<span class="token punctuation">)</span>
            x <span class="token operator">=</span> h <span class="token operator">+</span> x
            x <span class="token operator">=</span> x<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>

        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>lins<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x


device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> Net<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> theta<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>
            shared_weights<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCEWithLogitsLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

    total_loss <span class="token operator">=</span> total_examples <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
        data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>adj_t<span class="token punctuation">)</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> data<span class="token punctuation">.</span>num_nodes
        total_examples <span class="token operator">+=</span> data<span class="token punctuation">.</span>num_nodes
    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> total_examples


<span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    ys<span class="token punctuation">,</span> preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
        ys<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">.</span>y<span class="token punctuation">)</span>
        out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>adj_t<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
        preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>out <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    y<span class="token punctuation">,</span> pred <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>ys<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> f1_score<span class="token punctuation">(</span>y<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token string">'micro'</span><span class="token punctuation">)</span> <span class="token keyword">if</span> pred<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token number">0</span>


<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    val_f1 <span class="token operator">=</span> test<span class="token punctuation">(</span>val_loader<span class="token punctuation">)</span>
    test_f1 <span class="token operator">=</span> test<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token punctuation">:</span><span class="token format-spec">04d</span><span class="token punctuation">}</span></span><span class="token string">, Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, Val: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>val_f1<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, '</span></span>
          <span class="token string-interpolation"><span class="token string">f'Test: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>test_f1<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

</code></pre> 
<h3><a id="_213"></a>代码理解</h3> 
<p>GCN2Conv：</p> 
<p>论文：<a href="https://arxiv.org/pdf/2007.02133.pdf" rel="nofollow">Simple and Deep Graph Convolutional Networks (arxiv.org)</a></p> 
<p>图卷积网络（GCN）是一种针对图结构数据的强大的深度学习方法。最近，GCN及其后续变体在真实世界数据集上的各个应用领域表现出了优异的性能。**尽管图卷积网络（GCN）取得了成功，但由于过度平滑的问题（ over-smoothing problem），目前的GCN模型大多是浅层网络。GCNII是普通GCN模型的扩展，具有两种简单而有效的技术：初始残差和直接映射（Initial residual and Identity mapping）。**提供了理论和经验证据，证明这两种技术有效地缓解了过度平滑的问题。实验表明，深度GCNII模型在各种半监督和全监督任务上优于最先进的方法。代码可从https://github.com/chennnM/GCNII获取。</p> 
<p>而且，在PPI数据集上面实现SOTA水平：</p> 
<p><img src="https://images2.imgbox.com/e4/69/GbYCi4iW_o.png" alt="在这里插入图片描述" width="400"></p> 
<p>GCN2Conv的接口：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> channels<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> alpha<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span> theta<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
               layer<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> shared_weights<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
               cached<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> add_self_loops<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
               normalize<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
</code></pre> 
<p>‘’’<br> channels 输入和输出样本的size<br> alpha 初始的残差连接的强度<br> theta 超参数，用于计算直接映射的强度<br> layer 模型被运行的\ell层<br> shared_weights 是否共享权重，False：会使用不同的权重矩阵到平滑的表示和初始残差<br> cached True:缓存计算结果D，transductive learning scenarios下必须设置True<br> add_self_loops： False则不添加自环<br> normalize：是否添加自环和归一化<br> ‘’’</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> x_0<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> edge_index<span class="token punctuation">:</span> Adj<span class="token punctuation">,</span>
            edge_weight<span class="token punctuation">:</span> OptTensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>edge_index<span class="token punctuation">,</span> Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
	<span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>edge_index<span class="token punctuation">,</span> SparseTensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<p>需要注意的是：<br> edge_index可以接受两种形式的表示，稀疏表示和稠密表示;其中的SparseTensor可以由T.ToSparseTensor()，转变成稀疏张量，注意放在transform的最后。并且可以结合T.GCNNorm()：图归一化。pre_transform = T.Compose([T.GCNNorm(), T.ToSparseTensor()])作为PPI数据集的预处理步骤。</p> 
<h3><a id="_259"></a>训练过程</h3> 
<p>Epoch: 0001, Loss: 1.9191, Val: 0.4088, Test: 0.4114<br> Epoch: 0002, Loss: 0.6159, Val: 0.4249, Test: 0.4259<br> Epoch: 0003, Loss: 0.5772, Val: 0.4379, Test: 0.4397<br> Epoch: 0004, Loss: 0.5610, Val: 0.4301, Test: 0.4313<br> Epoch: 0005, Loss: 0.5526, Val: 0.4385, Test: 0.4401<br> Epoch: 0006, Loss: 0.5474, Val: 0.4469, Test: 0.4491<br> Epoch: 0007, Loss: 0.5423, Val: 0.4494, Test: 0.4520<br> Epoch: 0008, Loss: 0.5371, Val: 0.4595, Test: 0.4623<br> Epoch: 0009, Loss: 0.5318, Val: 0.4723, Test: 0.4763<br> Epoch: 0010, Loss: 0.5275, Val: 0.4933, Test: 0.4979<br> Epoch: 0011, Loss: 0.5246, Val: 0.4837, Test: 0.4884<br> Epoch: 0012, Loss: 0.5214, Val: 0.4830, Test: 0.4877<br> Epoch: 0013, Loss: 0.5189, Val: 0.4987, Test: 0.5044<br> Epoch: 0014, Loss: 0.5172, Val: 0.5008, Test: 0.5068<br> Epoch: 0015, Loss: 0.5158, Val: 0.5069, Test: 0.5133<br> Epoch: 0016, Loss: 0.5133, Val: 0.4901, Test: 0.4964<br> Epoch: 0017, Loss: 0.5116, Val: 0.4744, Test: 0.4807<br> Epoch: 0018, Loss: 0.5089, Val: 0.4992, Test: 0.5062<br> Epoch: 0019, Loss: 0.5067, Val: 0.5103, Test: 0.5185<br> Epoch: 0020, Loss: 0.5045, Val: 0.5130, Test: 0.5212<br> 807<br> Epoch: 0018, Loss: 0.5089, Val: 0.4992, Test: 0.5062<br> Epoch: 0019, Loss: 0.5067, Val: 0.5103, Test: 0.5185<br> Epoch: 0020, Loss: 0.5045, Val: 0.5130, Test: 0.5212<br> Epoch: 0021, Loss: 0.5022, Val: 0.5113, Test: 0.5198</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bbb2fec79ef1a8acfbc1f2268b10b831/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">使用Transformer训练和测试EEG的公开SEED数据集</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5d6f5b5ed88d20e11881d95ded82b22f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">cora数据集示例项目学习图神经网络</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>