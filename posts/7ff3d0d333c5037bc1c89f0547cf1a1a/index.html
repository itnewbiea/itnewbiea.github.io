<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python爬虫基础知识与项目实战 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python爬虫基础知识与项目实战" />
<meta property="og:description" content="目录
一、Requests库
二、爬虫的Robots.txt
三、Beautiful Soup库
四、正则表达式
五、项目实战（佛系更新...)
一、Requests库 Requests库介绍：提交爬取请求并爬取html网页，返回可供解析的对象。http（hypertext transfer protocol）：超文本传输协议 ，采用url作为定位网络资源。 http://host[:port][path]
host：合法的Internet主机域名或IP地址
port：端口号，缺省端口为80
path：所请求资源的路径
http协议中对url的操作方法与requests库中的六个方法一致（获取、头信息、修改、删除）
3.Requests的七个主要方法
方法说明requests.request()构造爬虫请求，以下六个方法均自该方法基础上发展而来requests.get() 获取html页面
requests.head()获取html页面头信息requests.post()添加资源，重复执行，效果累加requests.put()更改资源，重复执行，覆盖重复字段requests.patch()向html页面提交局部修改请求，会更新原有资源requests.delete()向html页面提交删除请求 4.部分方法详解
4.1 requests.get()
r=requests.get(url,params=None, **kwargs) 返回url链接对应的内容，为Response对象，**kwargs是可选参数，可以是header等
Response对象的属性 属性说明r.status_code请求返回的状态，200表示链接成功r.text http响应内容的字符串形式，即url对应的内容
r.contenthttp响应内容的二进制形式r.encoding从http header中猜测的响应内容编码方式r.apparent_encodeing从http内容中分析出的响应内容编码方式 4.2post Vs put方法
二者都可以更改指定url的语义，但PUT被定义为idempotent的方法，即重复执行多次，产生的效果是一样的；POST则不是：
PUT请求：如果两个请求相同，后一个请求会把第一个请求覆盖掉。（所以PUT用来改资源）
Post请求：后一个请求不会把第一个请求覆盖掉。（所以Post用来增资源）
4.3 requests.request(method,url,**kwargs)
requests库的基础方法，其他皆由此发展而来
method：请求方式，对应七种方法get/head/post/put/patch/delete/options
**kwargs：控制访问的参数，13个，在方法中一致
参数数据类型功能params字典或字节作为参数增加到url中data字典或字节或文件对象作为Requests的内容反馈到服务器jsonJSON格式的数据作为Requests的内容反馈到服务器headers字典HTTP定制头信息，可用于更改用户（Mozilla/5.0），易于简单爬取cokkies字典或cokkie JarRequests中的cookieauth元组支持http的认证功能files字典 用于向服务器传输文件
ex：fs={‘file’：open(&#39;data.txt&#39;,&#39;rb&#39;)}
r=requests.request(&#39;POST&#39;,url,files=fs)
timeout数字，单位s设置超时时间，防止时间过长的无效爬取prixies字典设定访问代理服务器，可以增加登录认证（防止爬虫逆追踪）allow_redirects布尔默认True，重定向开关stream布尔默认True，获取内容后立即下载verify布尔默认True，认证SSL证书开关cert保证本地证书 路径 二、爬虫的Robots.txt 1.网络爬虫的限制
来源审查：检查来访http协议头的User-Agent域，只响应浏览器或友好爬虫访问，常可定义为
Mozilla/5.0 发布公告：Robots协议 ，建议遵守的爬取策略（哪些可以爬，哪些不能），一般位于网站根目录的robots.txt下。
2.在Robots协议中，#表示注释，*代表所有，/代表根目录
3.建议在进行 较大访问且访问频繁的爬虫时，遵守robots协议
三、Beautiful Soup库 from bs4 import BeautifulSoup（注意大小写），从bs4中引入BeautifulSoup类
Beautiful Soup库（bs4）是解析、遍历、维护“标签树”的功能库
BeautifulSoup类对应html/xml文档的全部内容，解析html如下：
soup=BeautifulSoup（r，’html.parser&#39;）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/7ff3d0d333c5037bc1c89f0547cf1a1a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-27T11:37:47+08:00" />
<meta property="article:modified_time" content="2023-06-27T11:37:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python爬虫基础知识与项目实战</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81Requests%E5%BA%93-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81Requests%E5%BA%93" rel="nofollow">一、Requests库</a></p> 
<p id="%E4%BA%8C%E3%80%81%E7%88%AC%E8%99%AB%E7%9A%84Robots.txt-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E7%88%AC%E8%99%AB%E7%9A%84Robots.txt" rel="nofollow">二、爬虫的Robots.txt</a></p> 
<p id="%E4%B8%89%E3%80%81Beautiful%20Soup%E5%BA%93-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81Beautiful%20Soup%E5%BA%93" rel="nofollow">三、Beautiful Soup库</a></p> 
<p id="%E5%9B%9B%E3%80%81%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F" rel="nofollow">四、正则表达式</a></p> 
<p id="%E4%BA%94%E3%80%81%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%88%E4%BD%9B%E7%B3%BB%E6%9B%B4%E6%96%B0...)-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%88%E4%BD%9B%E7%B3%BB%E6%9B%B4%E6%96%B0...%29" rel="nofollow">五、项目实战（佛系更新...)</a></p> 
<hr> 
<h2 id="%E4%B8%80%E3%80%81Requests%E5%BA%93">一、Requests库</h2> 
<ol><li>Requests库介绍：提交爬取请求并爬取html网页，返回可供解析的对象。</li><li>http（hypertext transfer protocol）：超文本传输协议 ，采用url作为定位网络资源。</li></ol> 
<p><strong>                                                http://host[:port][path]</strong></p> 
<p><strong>                                           </strong>     host：合法的Internet主机域名或IP地址</p> 
<p>                                                port：端口号，缺省端口为80</p> 
<p>                                                path：所请求资源的路径</p> 
<p>          http协议中对url的操作方法与requests库中的六个方法一致（获取、头信息、修改、删除）</p> 
<p>3.Requests的七个主要方法</p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>方法</td><td>说明</td></tr><tr><td>requests.request()</td><td>构造爬虫请求，以下六个方法均自该方法基础上发展而来</td></tr><tr><td>requests.get()</td><td> <p>获取html页面</p> </td></tr><tr><td>requests.head()</td><td>获取html页面头信息</td></tr><tr><td>requests.post()</td><td>添加资源，重复执行，效果累加</td></tr><tr><td>requests.put()</td><td>更改资源，重复执行，覆盖重复字段</td></tr><tr><td>requests.patch()</td><td>向html页面提交<strong>局部</strong>修改请求，会更新原有资源</td></tr><tr><td>requests.delete()</td><td>向html页面提交删除请求</td></tr></tbody></table> 
<hr> 
<p>4.部分方法详解</p> 
<hr> 
<p>4.1 requests.get()</p> 
<ul><li>r=requests.get(url,params=None, **kwargs)</li></ul> 
<p>         返回url链接对应的内容，为Response对象，<strong>**kwargs</strong>是可选参数，可以是header等</p> 
<ul><li>Response对象的属性</li></ul> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>属性</td><td>说明</td></tr><tr><td>r.status_code</td><td>请求返回的状态，<strong>200</strong>表示链接成功</td></tr><tr><td>r.text</td><td> <p>http响应内容的<strong>字符串形式</strong>，即url对应的内容</p> </td></tr><tr><td>r.content</td><td>http响应内容的<strong>二进制形式</strong></td></tr><tr><td>r.encoding</td><td>从http header中<strong>猜测</strong>的响应内容编码方式</td></tr><tr><td>r.apparent_encodeing</td><td>从http内容中<strong>分析</strong>出的响应内容编码方式</td></tr></tbody></table> 
<hr> 
<p><strong>4.2post Vs put方法</strong></p> 
<p>二者都可以更改指定url的语义，但PUT被定义为idempotent的方法，即重复执行多次，产生的效果是一样的；POST则不是：</p> 
<p>PUT请求：如果两个请求相同，后一个请求会把第一个请求覆盖掉。（所以PUT用来改资源）</p> 
<p>Post请求：后一个请求不会把第一个请求覆盖掉。（所以Post用来增资源）<br>  </p> 
<hr> 
<p>4.3 requests.request(method,url,**kwargs)</p> 
<p>requests库的基础方法，其他皆由此发展而来</p> 
<p>method：请求方式，对应七种方法get/head/post/put/patch/delete/options</p> 
<p>**kwargs：控制访问的参数，13个，在方法中一致</p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>参数</td><td>数据类型</td><td>功能</td></tr><tr><td><strong>params</strong></td><td>字典或字节</td><td>作为参数增加到url中</td></tr><tr><td><strong>data</strong></td><td>字典或字节或文件对象</td><td>作为Requests的内容反馈到服务器</td></tr><tr><td>json</td><td>JSON格式的数据</td><td>作为Requests的内容反馈到服务器</td></tr><tr><td><strong>headers</strong></td><td>字典</td><td>HTTP定制头信息，可用于更改用户（Mozilla/5.0），易于简单爬取</td></tr><tr><td>cokkies</td><td>字典或cokkie Jar</td><td>Requests中的cookie</td></tr><tr><td>auth</td><td>元组</td><td>支持http的认证功能</td></tr><tr><td><strong>files</strong></td><td>字典</td><td> <p>用于向服务器传输文件</p> <p>ex：fs={‘file’：open('data.txt','rb')}</p> <p>        r=requests.request('POST',url,files=fs)</p> </td></tr><tr><td><strong>timeout</strong></td><td>数字，单位s</td><td>设置超时时间，防止时间过长的无效爬取</td></tr><tr><td>prixies</td><td>字典</td><td>设定访问代理服务器，可以增加登录认证（防止爬虫逆追踪）</td></tr><tr><td>allow_redirects</td><td>布尔</td><td>默认True，重定向开关</td></tr><tr><td>stream</td><td>布尔</td><td>默认True，获取内容后立即下载</td></tr><tr><td>verify</td><td>布尔</td><td>默认True，认证SSL证书开关</td></tr><tr><td>cert</td><td></td><td>保证本地证书 路径 </td></tr></tbody></table> 
<h2 id="%E4%BA%8C%E3%80%81%E7%88%AC%E8%99%AB%E7%9A%84Robots.txt">二、爬虫的Robots.txt</h2> 
<p>1.网络爬虫的限制</p> 
<p>来源审查：检查来访http协议头的User-Agent域，只响应浏览器或友好爬虫访问，常可定义为</p> 
<pre><strong>Mozilla/5.0 </strong></pre> 
<p>发布公告：<strong>Robots协议</strong> ，建议遵守的爬取策略（哪些可以爬，哪些不能），一般位于网站根目录的robots.txt下。</p> 
<p>2.在Robots协议中，#表示注释，*代表所有，/代表根目录</p> 
<p>3.建议在进行 较大访问且访问频繁的爬虫时，遵守robots协议</p> 
<h2 id="%E4%B8%89%E3%80%81Beautiful%20Soup%E5%BA%93">三、Beautiful Soup库</h2> 
<p>from bs4 import BeautifulSoup（注意大小写），从bs4中引入BeautifulSoup类</p> 
<p>Beautiful Soup库（bs4）是解析、遍历、维护“<strong>标签树</strong>”的功能库</p> 
<p>BeautifulSoup类对应html/xml文档的全部内容，解析html如下：</p> 
<p style="text-align:center;"><strong>soup=BeautifulSoup（r，’html.parser'）</strong></p> 
<p>1.BeautifulSoup类的基本元素：标签</p> 
<p style="text-align:center;"><strong>&lt;p class="title"&gt; ... &lt;/p&gt;</strong></p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>基本元素</td><td>说明</td><td>格式</td></tr><tr><td>Tag</td><td>标签，以&lt;&gt;开头和&lt;/&gt;结尾；最基本的信息组织单元；</td><td>soup.&lt;Tag&gt;返回完整标签信息（此处Tag可以是标签的名字）</td></tr><tr><td>Name</td><td>标签名,&lt;p&gt;..&lt;/p&gt;的名字为p，字符串类型</td><td>&lt;Tag&gt;.name返回标签名字p</td></tr><tr><td>Attributes</td><td>标签属性，字典形式</td><td>&lt;Tag&gt;.attrs，返回{“class”：“title”}</td></tr><tr><td>NavigableString</td><td>标签内非属性的字符串</td><td>&lt;Tag&gt;.string，返回...</td></tr><tr><td>Comment</td><td>标签内字符串的注释部分</td><td></td></tr></tbody></table> 
<p>html是通过预定义标签的不同形式来组织不同类型的信息的</p> 
<p>2. 信息标记的三种类型：</p> 
<p style="text-align:center;"></p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>信息标记</td><td>标记形式</td><td>说明</td></tr><tr><td>XML</td><td>&lt;name&gt;...&lt;/name&gt;,&lt;name/&gt;,&lt;!--注释--&gt;</td><td>最早的通用信息标记语言，可扩展性好，但繁琐</td></tr><tr><td>JSON</td><td>键值对，由嵌套表达所属关系</td><td>信息有类型，适合程序处理（js），较XML更简洁</td></tr><tr><td>YAML</td><td> <p>无类型键值对，由缩进表达所属关系，-表示并列关系，#表示注释，</p> <p>|表示整块数据</p> </td><td>信息无类型，文本信息比例高，可读性好</td></tr></tbody></table> 
<hr> 
<p>3.基于bs4库的HTML内容遍历</p> 
<p>HTML以标签树的形似存在，即标签对及其所属关系，遍历方式可分为<strong>下行遍历、上行遍历、平行遍历</strong></p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>遍历类型</td><td style="width:124px;">属性</td><td style="width:259px;">说明</td></tr><tr><td colspan="1" rowspan="3">下行遍历</td><td style="width:124px;">.contents</td><td style="width:259px;">子节点列表（下一代）</td></tr><tr><td style="width:124px;">.children</td><td style="width:259px;">子节点，<strong>迭代类型</strong>（下一代）</td></tr><tr><td style="width:124px;">.descendants</td><td style="width:259px;">所有子孙节点，<strong>迭代类型</strong></td></tr><tr><td colspan="1" rowspan="2">上行遍历</td><td style="width:124px;">.parent</td><td style="width:259px;">父节点标签</td></tr><tr><td style="width:124px;">.parents</td><td style="width:259px;">所有先辈标签，<strong>迭代类型,包括该标签</strong></td></tr><tr><td colspan="1" rowspan="4">平行遍历</td><td style="width:124px;">.next_sibling</td><td style="width:259px;">返回按照html文本顺序的下一个平行节点标签</td></tr><tr><td style="width:124px;">.previous_sibling</td><td style="width:259px;">返回按照html文本顺序的上一个平行节点标签</td></tr><tr><td style="width:124px;">.next_siblings</td><td style="width:259px;">返回按照html文本顺序的后续所有平行节点标签，迭代类型</td></tr><tr><td style="width:124px;">.previous_siblingss</td><td style="width:259px;">返回按照html文本顺序的前续所有平行节点标签，迭代类型</td></tr></tbody></table> 
<p>迭代类型：可直接遍历</p> 
<blockquote> 
 <p style="text-align:center;">for children in soup.a.children</p> 
 <p style="text-align:center;">print(children)</p> 
</blockquote> 
<hr> 
<p>4.soup.prettify()</p> 
<p>为html文本&lt;&gt;及其内容自动增加‘\n’，使结果可读性更强</p> 
<p>注：Python 3.x默认支持utf-8编码，可解析中文无障碍</p> 
<hr> 
<p>5.信息提取</p> 
<p>方式一：解析（XML，JSON，YAML）的标记形式→提取标记对应的信息</p> 
<p style="text-align:center;">繁琐，慢，但信息解析准确</p> 
<p>方式二：无视标记，直接搜索，即对信息的文本使用查找函数（拿到任务后可以先在源代码处手动 搜索一下）</p> 
<p style="text-align:center;">准确性与文本内容相关，但很快，过程简洁</p> 
<p>方法三（融合）：先解析，遍历需要的标签，然后小范围搜索</p> 
<blockquote> 
 <p>html内容查找方法：</p> 
 <p>&lt;&gt;.find_all(name,attrs,recursive,string,**kwargs)#返回列表类型，存储查找到的结果</p> 
 <p>名字、属性、子孙、字符串等检索，可扩展</p> 
 <table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>方法</td><td>说明</td></tr><tr><td>&lt;&gt;.find()</td><td>搜索且只返回第一个结果，参数同上</td></tr><tr><td>&lt;&gt;.find_parents()</td><td>在先辈节点中搜索，返回列表类型</td></tr><tr><td>&lt;&gt;.find_parent()</td><td>在先辈节点中搜索，返回一个结果</td></tr><tr><td>&lt;&gt;.find_next_siblings()</td><td>在后续平行节点中搜索，返回列表类型</td></tr><tr><td>&lt;&gt;.find_next_sibling()</td><td>在后续平行节点中搜索，返回一个结果</td></tr><tr><td>&lt;&gt;.find_previous_siblings()</td><td>在前续平行节点中搜索，返回列表类型</td></tr><tr><td>&lt;&gt;.find_previous_sibling()</td><td>在前续平行节点中搜索，返回一个结果</td></tr></tbody></table> 
 <p></p> 
</blockquote> 
<h2 id="%E5%9B%9B%E3%80%81%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F"><strong>四、正则表达式</strong></h2> 
<p>正则表达式是用来简洁表示<strong>一组字符串</strong>的表达式，即通用的字符串表达框架。</p> 
<p>主要应用于字符串匹配中。</p> 
<p>正则表达式的语法：<strong>字符+操作符</strong></p> 
<p>使用方式：导入re包，赋值<strong>r‘正则表达式’</strong>→原生字符串类型，其中的\不表示转义</p> 
<hr> 
<p>正则表达式的操作符</p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>操作符</td><td>说明</td></tr><tr><td>.</td><td>表示任意单个字符</td></tr><tr><td>[]</td><td>字符集，对单个字符的取值范围</td></tr><tr><td>[^]</td><td>字符集，对单个字符给出排除范围</td></tr><tr><td>*</td><td>前一字符的0或无限次扩展/最小匹配</td></tr><tr><td>+</td><td>前一字符的1或无限次扩展/最小匹配</td></tr><tr><td>？</td><td>前一字符的0或1次扩展/最小匹配</td></tr><tr><td>{m,n}</td><td>前一字符扩展m至n次（包含n）/最小匹配</td></tr><tr><td>{m}</td><td>前一字符扩展m次</td></tr><tr><td>|</td><td>左右表达式中的r任一个</td></tr><tr><td>^</td><td>匹配字符串开头</td></tr><tr><td>$</td><td>匹配字符串结尾</td></tr><tr><td>()</td><td>分组标记，内部只能使用|操作符</td></tr><tr><td>\d</td><td>数字，等价于[0-9]</td></tr><tr><td>\D</td><td>数字，等价于[^0-9]</td></tr><tr><td>\w</td><td>单词字符，等价于[A-Za-z0-9]</td></tr><tr><td>\b</td><td>匹配空字符串，只能在单词的开始和结尾</td></tr><tr><td>\B</td><td>匹配空字符串，但不能在开头和结尾</td></tr></tbody></table> 
<hr> 
<p>Re库的主要功能函数</p> 
<p>首先，将正则表达式编译的正则表达式对象</p> 
<p style="text-align:center;"><strong>regex=re.compile(正则表达式,flags=0)</strong></p> 
<p>对regex调用功能函数（常用）</p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>函数</td><td>说明</td></tr><tr><td>regex.search()</td><td>在一个字符中搜索匹配regex的第一个位置，返回match对象</td></tr><tr><td>regex.match()</td><td>从一个字符的开始匹配regex，返回match对象</td></tr><tr><td>regex.findall()</td><td>搜索字符串，以列表类型返回全部可以匹配的字符串</td></tr><tr><td>regex.split()</td><td>将一个字符串按照正则表达式进行分割，返回列表类型</td></tr><tr><td> <p>regex.finditer()</p> </td><td>搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素都是match对象</td></tr><tr><td>regex.sub()</td><td>在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</td></tr></tbody></table> 
<hr> 
<p>Re库的Match对象</p> 
<p>match对象是一次匹配的结果包含匹配的很多信息：</p> 
<p>        match=re.search(r'[1-9]\d{5}'，'BIT  100081')#返回BIT  100081中匹配上'[1-9]\d{5}'的部分</p> 
<p></p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td rowspan="4">方法</td><td>match.group(0)</td><td>获取匹配后的字符串</td></tr><tr><td>match.start()</td><td>匹配字符串在str中的开始位置</td></tr><tr><td>match.end()</td><td>匹配字符串在str中的结束位置</td></tr><tr><td>match.apan()</td><td>返回（.strat(),.end())</td></tr><tr><td colspan="1" rowspan="4">属性</td><td>match.string</td><td>待匹配文本（BIT  100081）</td></tr><tr><td>match.re</td><td>待匹配正则表达式（re.complie('[1-9]\d{5}'）</td></tr><tr><td>match.pos</td><td>匹配结果在str中的开始位置</td></tr><tr><td>match.endpos</td><td>匹配结果在str中的结束位置</td></tr></tbody></table> 
<p></p> 
<p>匹配：贪婪匹配和最小匹配（由于正则表达式中有无限次扩展形式引出）</p> 
<p>贪婪匹配：输出匹配<strong>最长</strong>的字符串</p> 
<p>最小匹配：输出匹配<strong>最短</strong>的字符串（在有扩展功能的操作符后加？）</p> 
<h2 id="%E4%BA%94%E3%80%81%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%88%E4%BD%9B%E7%B3%BB%E6%9B%B4%E6%96%B0...)">五、项目实战（佛系更新...)</h2> 
<p>简单项目1-10</p> 
<p>较复杂项目</p> 
<p>本阶段在爬虫的目标信息获取上需要下重点</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/63c6d2d0d5b6121988d807b4d25d727f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">微信小程序获取用户信息</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/76a944fb54e027ad22cb27957ce40213/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">实体类中Date 时间格式</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>