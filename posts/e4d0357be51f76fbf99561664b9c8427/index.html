<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习常见回归分支算法逐步分析，各种回归之间的优缺点，适用场景，举例演示 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习常见回归分支算法逐步分析，各种回归之间的优缺点，适用场景，举例演示" />
<meta property="og:description" content="文章目录 1、线性回归（Linear Regression）1.1 优点1.2 缺点1.3 适用场景1.4 图例说明 2、多项式回归（Polynomial Regression）2.1 优点2.2 缺点2.3 适用场景2.4 图例说明 3、决策树回归（Decision Tree Regression）3.1 优点3.2 缺点3.3 适用场景 4、随机森林回归（Random Forest Regression）4.1 优点4.2 缺点4.3 适用场景 5、逻辑斯蒂回归（Logistic Regression）5.1 优点5.2 缺点5.3 适用场景 6、弹性网络回归（Elastic Net Regression）6.1 优点6.2 缺点6.3 适用场景 7、岭回归（Ridge Regression）7.1 优点7.2 缺点7.3 适用场景 8、Lasso回归（Lasso Regression）8.1 优点8.2 缺点8.3 适用场景 回归的概念：回归算法是一种用于预测连续数值输出的监督学习算法，可以根据输入特征预测一个或多个目标变量。它有多个分支，每个分支都有其独特的优缺点。下面是深度学习中几类回归变种： 1、线性回归（Linear Regression） 线性回归算法可以说是回归算法里面最简单的一种。
1.1 优点 简单且易于解释。计算效率高，适用于大规模数据集。在特征与目标之间存在线性关系时效果良好。 1.2 缺点 无法处理非线性关系。对于一些异常值，无法做到拟合曲线。对异常值敏感。需要满足线性回归假设（如线性关系、残差正态分布等）。 1.3 适用场景 适用场景：预测数值型目标，建立输入特征和输出之间的线性关系。
案例：预测房价。根据房屋特征（面积、卧室数量等），建立线性关系来估计房价。
1.4 图例说明 代码：
import matplotlib.pyplot as plt import numpy as np # 设置中文显示 plt." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/e4d0357be51f76fbf99561664b9c8427/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-02T22:21:12+08:00" />
<meta property="article:modified_time" content="2023-12-02T22:21:12+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习常见回归分支算法逐步分析，各种回归之间的优缺点，适用场景，举例演示</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1Linear_Regression_2" rel="nofollow">1、线性回归（Linear Regression）</a></li><li><ul><li><a href="#11__4" rel="nofollow">1.1 优点</a></li><li><a href="#12__8" rel="nofollow">1.2 缺点</a></li><li><a href="#13__12" rel="nofollow">1.3 适用场景</a></li><li><a href="#14__20" rel="nofollow">1.4 图例说明</a></li></ul> 
  </li><li><a href="#2Polynomial_Regression_132" rel="nofollow">2、多项式回归（Polynomial Regression）</a></li><li><ul><li><a href="#21__133" rel="nofollow">2.1 优点</a></li><li><a href="#22__136" rel="nofollow">2.2 缺点</a></li><li><a href="#23__139" rel="nofollow">2.3 适用场景</a></li><li><a href="#24__142" rel="nofollow">2.4 图例说明</a></li></ul> 
  </li><li><a href="#3Decision_Tree_Regression_194" rel="nofollow">3、决策树回归（Decision Tree Regression）</a></li><li><ul><li><a href="#31__196" rel="nofollow">3.1 优点</a></li><li><a href="#32__200" rel="nofollow">3.2 缺点</a></li><li><a href="#33__204" rel="nofollow">3.3 适用场景</a></li></ul> 
  </li><li><a href="#4Random_Forest_Regression_207" rel="nofollow">4、随机森林回归（Random Forest Regression）</a></li><li><ul><li><a href="#41__208" rel="nofollow">4.1 优点</a></li><li><a href="#42__211" rel="nofollow">4.2 缺点</a></li><li><a href="#43__214" rel="nofollow">4.3 适用场景</a></li></ul> 
  </li><li><a href="#5Logistic_Regression_217" rel="nofollow">5、逻辑斯蒂回归（Logistic Regression）</a></li><li><ul><li><a href="#51__218" rel="nofollow">5.1 优点</a></li><li><a href="#52__221" rel="nofollow">5.2 缺点</a></li><li><a href="#53__224" rel="nofollow">5.3 适用场景</a></li></ul> 
  </li><li><a href="#6Elastic_Net_Regression_227" rel="nofollow">6、弹性网络回归（Elastic Net Regression）</a></li><li><ul><li><a href="#61__228" rel="nofollow">6.1 优点</a></li><li><a href="#62__231" rel="nofollow">6.2 缺点</a></li><li><a href="#63__233" rel="nofollow">6.3 适用场景</a></li></ul> 
  </li><li><a href="#7Ridge_Regression_236" rel="nofollow">7、岭回归（Ridge Regression）</a></li><li><ul><li><a href="#71__237" rel="nofollow">7.1 优点</a></li><li><a href="#72__240" rel="nofollow">7.2 缺点</a></li><li><a href="#73__243" rel="nofollow">7.3 适用场景</a></li></ul> 
  </li><li><a href="#8LassoLasso_Regression_246" rel="nofollow">8、Lasso回归（Lasso Regression）</a></li><li><ul><li><a href="#81__247" rel="nofollow">8.1 优点</a></li><li><a href="#82__250" rel="nofollow">8.2 缺点</a></li><li><a href="#83__253" rel="nofollow">8.3 适用场景</a></li></ul> 
 </li></ul> 
</div> 
<br>  回归的概念：回归算法是一种用于预测连续数值输出的监督学习算法，可以根据输入特征预测一个或多个目标变量。它有多个分支，每个分支都有其独特的优缺点。下面是深度学习中几类回归变种： 
<p></p> 
<h2><a id="1Linear_Regression_2"></a>1、线性回归（Linear Regression）</h2> 
<p>线性回归算法可以说是回归算法里面最简单的一种。</p> 
<h3><a id="11__4"></a>1.1 优点</h3> 
<ul><li>简单且易于解释。</li><li>计算效率高，适用于大规模数据集。</li><li>在特征与目标之间存在线性关系时效果良好。</li></ul> 
<h3><a id="12__8"></a>1.2 缺点</h3> 
<ul><li>无法处理非线性关系。对于一些异常值，无法做到拟合曲线。</li><li>对异常值敏感。</li><li>需要满足线性回归假设（如线性关系、残差正态分布等）。</li></ul> 
<h3><a id="13__12"></a>1.3 适用场景</h3> 
<p>适用场景：预测数值型目标，建立输入特征和输出之间的线性关系。<br> 案例：预测房价。根据房屋特征（面积、卧室数量等），建立线性关系来估计房价。</p> 
<p><img src="https://images2.imgbox.com/23/02/kTyJi1l2_o.png" alt="在这里插入图片描述" width="640"><br> <img src="https://images2.imgbox.com/80/72/b7mixpu8_o.png" alt="在这里插入图片描述" width="640"></p> 
<h3><a id="14__20"></a>1.4 图例说明</h3> 
<p>代码：</p> 
<pre><code class="prism language-bash"><span class="token function">import</span> matplotlib.pyplot as plt
<span class="token function">import</span> numpy as np

<span class="token comment"># 设置中文显示</span>
plt.rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>
plt.rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> False

<span class="token comment"># 数据</span>
area <span class="token operator">=</span> np.array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">50</span>, <span class="token number">75</span>, <span class="token number">100</span>, <span class="token number">120</span>, <span class="token number">150</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
price <span class="token operator">=</span> np.array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">120</span>, <span class="token number">180</span>, <span class="token number">220</span>, <span class="token number">250</span>, <span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 执行线性回归</span>
coefficients <span class="token operator">=</span> np.polyfit<span class="token punctuation">(</span>area, price, <span class="token number">1</span><span class="token punctuation">)</span>
m, b <span class="token operator">=</span> coefficients

<span class="token comment"># 创建预测模型</span>
predict_model <span class="token operator">=</span> np.poly1d<span class="token punctuation">(</span>coefficients<span class="token punctuation">)</span>

<span class="token comment"># 生成预测值</span>
predicted_price <span class="token operator">=</span> predict_model<span class="token punctuation">(</span>area<span class="token punctuation">)</span>

<span class="token comment"># 绘制原始数据点</span>
plt.scatter<span class="token punctuation">(</span>area, price, <span class="token assign-left variable">label</span><span class="token operator">=</span><span class="token string">'实际数据点'</span><span class="token punctuation">)</span>

<span class="token comment"># 绘制线性回归线</span>
plt.plot<span class="token punctuation">(</span>area, predicted_price, <span class="token assign-left variable">label</span><span class="token operator">=</span>f<span class="token string">'线性回归: y = {m:.2f}x + {b:.2f}'</span>, <span class="token assign-left variable">color</span><span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>

<span class="token comment"># 添加标签和图例</span>
plt.xlabel<span class="token punctuation">(</span><span class="token string">'房屋面积（平方米）'</span><span class="token punctuation">)</span>
plt.ylabel<span class="token punctuation">(</span><span class="token string">'价格（万元）'</span><span class="token punctuation">)</span>
plt.title<span class="token punctuation">(</span><span class="token string">'线性回归'</span><span class="token punctuation">)</span>
plt.legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 显示图形</span>
plt.show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>生成对应图像：<br> <img src="https://images2.imgbox.com/af/ec/STFA7S3b_o.png" alt="在这里插入图片描述"><br> <strong>深度学习中的线性回归</strong><br> 代码：</p> 
<pre><code class="prism language-bash"><span class="token function">import</span> torch
<span class="token function">import</span> torch.nn as nn
<span class="token function">import</span> torch.optim as optim
<span class="token function">import</span> numpy as np
<span class="token function">import</span> matplotlib.pyplot as plt

<span class="token comment"># 设置中文显示</span>
plt.rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>
plt.rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> False

<span class="token comment"># 生成模拟数据</span>
np.random.seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> <span class="token number">2</span> * np.random.rand<span class="token punctuation">(</span><span class="token number">100</span>, <span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> <span class="token number">4</span> + <span class="token number">3</span> * X + np.random.randn<span class="token punctuation">(</span><span class="token number">100</span>, <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 转换为PyTorch的Tensor</span>
X_tensor <span class="token operator">=</span> torch.from_numpy<span class="token punctuation">(</span>X<span class="token punctuation">)</span>.float<span class="token punctuation">(</span><span class="token punctuation">)</span>
y_tensor <span class="token operator">=</span> torch.from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">)</span>.float<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 定义线性回归模型</span>
class LinearRegressionModel<span class="token punctuation">(</span>nn.Module<span class="token punctuation">)</span>:
    def __init__<span class="token punctuation">(</span>self, input_size, output_size<span class="token punctuation">)</span>:
        super<span class="token punctuation">(</span>LinearRegressionModel, self<span class="token punctuation">)</span>.__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self.linear <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span>input_size, output_size<span class="token punctuation">)</span>

    def forward<span class="token punctuation">(</span>self, x<span class="token punctuation">)</span>:
        <span class="token builtin class-name">return</span> self.linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 实例化模型</span>
input_size <span class="token operator">=</span> <span class="token number">1</span>
output_size <span class="token operator">=</span> <span class="token number">1</span>
model <span class="token operator">=</span> LinearRegressionModel<span class="token punctuation">(</span>input_size, output_size<span class="token punctuation">)</span>

<span class="token comment"># 定义损失函数和优化器</span>
criterion <span class="token operator">=</span> nn.MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim.SGD<span class="token punctuation">(</span>model.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
num_epochs <span class="token operator">=</span> <span class="token number">100</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">epoch</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span>:
    <span class="token comment"># Forward pass</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>X_tensor<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs, y_tensor<span class="token punctuation">)</span>

    <span class="token comment"># Backward pass and optimization</span>
    optimizer.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer.step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 打印训练过程中的损失</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch+1<span class="token punctuation">)</span> % <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span>:
        print<span class="token punctuation">(</span>f<span class="token string">'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}'</span><span class="token punctuation">)</span>

<span class="token comment"># 绘制模型预测结果和真实数据</span>
predicted <span class="token operator">=</span> model<span class="token punctuation">(</span>X_tensor<span class="token punctuation">)</span>.detach<span class="token punctuation">(</span><span class="token punctuation">)</span>.numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt.scatter<span class="token punctuation">(</span>X, y, <span class="token assign-left variable">label</span><span class="token operator">=</span><span class="token string">'实际数据点'</span><span class="token punctuation">)</span>
plt.plot<span class="token punctuation">(</span>X, predicted, <span class="token assign-left variable">label</span><span class="token operator">=</span><span class="token string">'模型预测'</span>, <span class="token assign-left variable">color</span><span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>
plt.xlabel<span class="token punctuation">(</span><span class="token string">'房屋面积（平方米）'</span><span class="token punctuation">)</span>
plt.ylabel<span class="token punctuation">(</span><span class="token string">'价格（万元）'</span><span class="token punctuation">)</span>
plt.title<span class="token punctuation">(</span><span class="token string">'线性回归'</span><span class="token punctuation">)</span>
plt.legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt.show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>生成对应的图像：<br> <img src="https://images2.imgbox.com/fa/07/P4dWuEIz_o.png" alt="在这里插入图片描述"><br> 是不是看着比简单的回归复杂很多，深度模型解决的回归问题还要比这复杂得多。</p> 
<h2><a id="2Polynomial_Regression_132"></a>2、多项式回归（Polynomial Regression）</h2> 
<h3><a id="21__133"></a>2.1 优点</h3> 
<ul><li>可以捕捉特征和目标之间的非线性关系。</li><li>相对简单实现。</li></ul> 
<h3><a id="22__136"></a>2.2 缺点</h3> 
<ul><li>可能会过度拟合数据，特别是高阶多项式。</li><li>需要选择适当的多项式阶数。</li></ul> 
<h3><a id="23__139"></a>2.3 适用场景</h3> 
<p>适用场景：处理非线性关系，通过添加多项式特征来拟合曲线。<br> 案例：预测股票价格。使用多项式回归来拟合价格与时间之间的非线性关系。</p> 
<h3><a id="24__142"></a>2.4 图例说明</h3> 
<p>代码：</p> 
<pre><code class="prism language-bash"><span class="token function">import</span> numpy as np
<span class="token function">import</span> matplotlib.pyplot as plt
from sklearn.linear_model <span class="token function">import</span> LinearRegression
from sklearn.preprocessing <span class="token function">import</span> PolynomialFeatures
from sklearn.metrics <span class="token function">import</span> mean_squared_error

<span class="token comment"># 设置中文显示</span>
plt.rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>
plt.rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> False

<span class="token comment"># 生成模拟数据</span>
np.random.seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> <span class="token number">2</span> * np.random.rand<span class="token punctuation">(</span><span class="token number">100</span>, <span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> <span class="token number">4</span> + <span class="token number">3</span> * X + np.random.randn<span class="token punctuation">(</span><span class="token number">100</span>, <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 选择多项式次数</span>
degree <span class="token operator">=</span> <span class="token number">2</span>

<span class="token comment"># 构建设计矩阵</span>
poly_features <span class="token operator">=</span> PolynomialFeatures<span class="token punctuation">(</span>degree<span class="token operator">=</span>degree, <span class="token assign-left variable">include_bias</span><span class="token operator">=</span>False<span class="token punctuation">)</span>
X_poly <span class="token operator">=</span> poly_features.fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment"># 使用线性回归拟合多项式特征</span>
lin_reg <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
lin_reg.fit<span class="token punctuation">(</span>X_poly, y<span class="token punctuation">)</span>

<span class="token comment"># 预测</span>
X_new <span class="token operator">=</span> np.linspace<span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">2</span>, <span class="token number">100</span><span class="token punctuation">)</span>.reshape<span class="token punctuation">(</span>-1, <span class="token number">1</span><span class="token punctuation">)</span>
X_new_poly <span class="token operator">=</span> poly_features.transform<span class="token punctuation">(</span>X_new<span class="token punctuation">)</span>
y_new <span class="token operator">=</span> lin_reg.predict<span class="token punctuation">(</span>X_new_poly<span class="token punctuation">)</span>

<span class="token comment"># 绘制结果</span>
plt.scatter<span class="token punctuation">(</span>X, y, <span class="token assign-left variable">label</span><span class="token operator">=</span><span class="token string">'True data'</span><span class="token punctuation">)</span>
plt.plot<span class="token punctuation">(</span>X_new, y_new, <span class="token string">'r-'</span>, <span class="token assign-left variable">label</span><span class="token operator">=</span><span class="token string">'Predictions'</span>, <span class="token assign-left variable">linewidth</span><span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
plt.xlabel<span class="token punctuation">(</span><span class="token string">'X'</span><span class="token punctuation">)</span>
plt.ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>
plt.title<span class="token punctuation">(</span><span class="token string">'多项式线性回归'</span><span class="token punctuation">)</span>
plt.legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt.show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 评估模型</span>
y_pred <span class="token operator">=</span> lin_reg.predict<span class="token punctuation">(</span>X_poly<span class="token punctuation">)</span>
mse <span class="token operator">=</span> mean_squared_error<span class="token punctuation">(</span>y, y_pred<span class="token punctuation">)</span>
print<span class="token punctuation">(</span>f<span class="token string">'Mean Squared Error: {mse:.4f}'</span><span class="token punctuation">)</span>
</code></pre> 
<p>生成对应图像：<br> <img src="https://images2.imgbox.com/16/c2/EXi1Niz4_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3Decision_Tree_Regression_194"></a>3、决策树回归（Decision Tree Regression）</h2> 
<h3><a id="31__196"></a>3.1 优点</h3> 
<ul><li>能够处理非线性关系。</li><li>不需要对数据进行特征缩放。</li><li>结果易于可视化和解释。</li></ul> 
<h3><a id="32__200"></a>3.2 缺点</h3> 
<ul><li>容易过拟合。树越深，越可能发生过拟合现象。</li><li>对数据中的噪声敏感。</li><li>不稳定，小的数据变化可能导致不同的树结构。</li></ul> 
<h3><a id="33__204"></a>3.3 适用场景</h3> 
<p>适用场景：适用于非线性数据，创建树状结构进行回归预测。<br> 案例：天气预测。基于多个天气因素，预测温度。</p> 
<h2><a id="4Random_Forest_Regression_207"></a>4、随机森林回归（Random Forest Regression）</h2> 
<h3><a id="41__208"></a>4.1 优点</h3> 
<ul><li>降低了决策树回归的过拟合风险。</li><li>能够处理高维数据。</li></ul> 
<h3><a id="42__211"></a>4.2 缺点</h3> 
<ul><li>失去了部分可解释性。</li><li>难以调整模型参数。</li></ul> 
<h3><a id="43__214"></a>4.3 适用场景</h3> 
<p>适用场景：用于回归任务，具有高度的鲁棒性。<br> 案例：股票价格预测。使用多个随机森林树来预测未来的股票价格。</p> 
<h2><a id="5Logistic_Regression_217"></a>5、逻辑斯蒂回归（Logistic Regression）</h2> 
<h3><a id="51__218"></a>5.1 优点</h3> 
<ul><li>用于二分类问题，广泛应用于分类任务。</li><li>输出结果可以解释为概率。</li></ul> 
<h3><a id="52__221"></a>5.2 缺点</h3> 
<ul><li>仅适用于二分类问题。这是它的优点，也是它的缺点。</li><li>对于复杂的非线性问题效果可能不佳。对线性问题解答较好。</li></ul> 
<h3><a id="53__224"></a>5.3 适用场景</h3> 
<p>适用场景：用于二分类或多分类任务，预测概率分布。<br> 案例：垃圾邮件分类。根据邮件内容来判断是否是垃圾邮件。</p> 
<h2><a id="6Elastic_Net_Regression_227"></a>6、弹性网络回归（Elastic Net Regression）</h2> 
<h3><a id="61__228"></a>6.1 优点</h3> 
<ul><li>综合了岭回归和Lasso回归的优点。</li><li>可以应对多重共线性和特征选择。</li></ul> 
<h3><a id="62__231"></a>6.2 缺点</h3> 
<ul><li>需要调整两个正则化参数。</li></ul> 
<h3><a id="63__233"></a>6.3 适用场景</h3> 
<p>适用场景：结合了 Ridge 和 Lasso 的优点，适用于高维数据和特征选择。<br> 案例：医学诊断。处理具有大量特征的患者数据，选择最相关的特征。</p> 
<h2><a id="7Ridge_Regression_236"></a>7、岭回归（Ridge Regression）</h2> 
<h3><a id="71__237"></a>7.1 优点</h3> 
<ul><li>可以解决多重共线性问题。</li><li>对异常值不敏感。</li></ul> 
<h3><a id="72__240"></a>7.2 缺点</h3> 
<ul><li>不适用于特征选择，所有特征都会被考虑。</li><li>参数需要调整。</li></ul> 
<h3><a id="73__243"></a>7.3 适用场景</h3> 
<p>适用场景：处理多重共线性问题，添加L2正则化以防止过拟合。<br> 案例：预测学生成绩。处理多个高度相关的特征，如学习时间、家庭支持等。</p> 
<h2><a id="8LassoLasso_Regression_246"></a>8、Lasso回归（Lasso Regression）</h2> 
<h3><a id="81__247"></a>8.1 优点</h3> 
<ul><li>可以用于特征选择，趋向于将不重要的特征的系数推到零。</li><li>可以解决多重共线性问题。</li></ul> 
<h3><a id="82__250"></a>8.2 缺点</h3> 
<ul><li>对于高维数据，可能会选择较少的特征。</li><li>需要调整正则化参数。</li></ul> 
<h3><a id="83__253"></a>8.3 适用场景</h3> 
<p>适用场景：用于特征选择和稀疏性，通过L1正则化将一些特征的权重设为零。<br> 案例：预测产品销量。确定哪些产品特征对销售额的影响最大。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/141491c73409326af9a42ad580c49548/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【NeurIPS 2023】PromptIR: Prompting for All-in-One Blind Image Restoration</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9907a929a45a49dd7c2149654ddf2b27/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Timestamps are unset in a packet for stream X.This is deprecated and will stop working in the future</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>