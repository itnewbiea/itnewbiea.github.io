<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>1、传统神经网络和卷积神经网络 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="1、传统神经网络和卷积神经网络" />
<meta property="og:description" content="传统神经网络和卷积神经网络 1、神经网络分类2、传统神经网络层次结构3、**卷积**神经网络的层次结构及其作用3.1其他特点 1、神经网络分类 根据矩阵运算划分
卷积神经网络：点积矩阵卷积运算（多维）；卷积神经层由多个特征面构成，每一个特征面则是由很多个神经元构成。核代表参数w
传统神经网络：叉积矩阵乘法运算（一维）；每层由排成一列的神经元构成；神经元：每个神经元代表矩阵的一个列向量Xi，神经元连线代表系数W。每一个像素值，都是一个神经元，每个神经元代表了一个特征。
2、传统神经网络层次结构 输入层：的每个神经元代表了一个特征
隐藏层：特征提取
输出层：输出层个数代表了分类标签的个数
3、卷积神经网络的层次结构及其作用 多通道输入，多卷积核，输出的通道数=卷积核的个数。
输入层-&gt;卷积层-&gt;激活层-&gt;池化层-&gt;全连接层
数据输入层：对原始数据进行初步处理，使卷积神经网络能有更好的效果
卷积层：提取特征（矩阵大小个数都变化）；卷积核遍历图片上每一个像素点
激活层：计算结果通过一个激活函数加一个非线性的关系，使能逼近任何函数。
池化层：数据压缩，提取主要特征，降低网络复杂度；不改变矩阵的深度，缩小矩阵，减少网络的参数（矩阵变小，个数不变）
光栅化(Rasterization)：为了与传统的多层感知器MLP全连接，把上一层的所有Feature Map的每个像素依次展开，排成一列。某些情况下这一层可以省去。
全连接层：分类器角色，将特征映射到样本标记空间，本质是矩阵变换。将特征图拉成一维向量，将每个特征点作为一个神经元进行分类任务。把所有局部特征结合变成全局特征，用来计算最后每一类的得分。
3.1其他特点 1、卷积结构可以减少深层网络占用的内存量，其中三个关键操作——局部感受野、权值共享、池化层，有效的减少了网络的参数个数，缓解了模型的过拟合问题。
2、填充padding
为了使卷积操作后能得到满意的输出图片尺寸，经常会使用padding对输入进行填充操作。默认在图片周围填充0。使卷积核对边缘信息的处理不止处理一次，对边缘信息的提取更加充分了，减少边缘信息丢失。
3、感受视野
网络越深，感受视野越大，检测目标越大。底层网络感受视野小，检测小目标。
增大感受视野：可以用空洞卷积、spp、上下采样融合、网络深度" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/809bc9356aefd85b6a67a2bf2dc4260d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-15T10:49:31+08:00" />
<meta property="article:modified_time" content="2023-04-15T10:49:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">1、传统神经网络和卷积神经网络</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>传统神经网络和卷积神经网络</h4> 
 <ul><li><a href="#1_2" rel="nofollow">1、神经网络分类</a></li><li><a href="#2_8" rel="nofollow">2、传统神经网络层次结构</a></li><li><a href="#3_16" rel="nofollow">3、**卷积**神经网络的层次结构及其作用</a></li><li><ul><li><a href="#31_34" rel="nofollow">3.1其他特点</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="1_2"></a>1、神经网络分类</h2> 
<p>根据<strong>矩阵运算</strong>划分<br> <strong>卷积神经网络</strong>：点积矩阵卷积运算（多维）；卷积神经层由多个特征面构成，每一个特征面则是由很多个神经元构成。核代表参数w<br> <strong>传统神经网络</strong>：叉积矩阵乘法运算（一维）；每层由排成一列的神经元构成；神经元：每个神经元代表矩阵的一个列向量Xi，神经元连线代表系数W。每一个像素值，都是一个神经元，每个神经元代表了一个特征。</p> 
<h2><a id="2_8"></a>2、传统神经网络层次结构</h2> 
<p>输入层：的每个神经元代表了一个特征<br> 隐藏层：特征提取<br> 输出层：输出层个数代表了分类标签的个数<br> <img src="https://images2.imgbox.com/20/81/0sSb0Ugk_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3_16"></a>3、<strong>卷积</strong>神经网络的层次结构及其作用</h2> 
<p>多通道输入，多卷积核，输出的通道数=卷积核的个数。<br> 输入层-&gt;卷积层-&gt;激活层-&gt;池化层-&gt;全连接层</p> 
<p>数据输入层：对原始数据进行初步处理，使卷积神经网络能有更好的效果</p> 
<p>卷积层：提取特征（矩阵大小个数都变化）；卷积核遍历图片上每一个像素点</p> 
<p>激活层：计算结果通过一个激活函数加一个非线性的关系，使能逼近任何函数。</p> 
<p>池化层：数据压缩，提取主要特征，降低网络复杂度；不改变矩阵的深度，缩小矩阵，减少网络的参数（矩阵变小，个数不变）</p> 
<p>光栅化(Rasterization)：为了与传统的多层感知器MLP全连接，把上一层的所有Feature Map的每个像素依次展开，排成一列。某些情况下这一层可以省去。</p> 
<p>全连接层：分类器角色，将特征映射到样本标记空间，本质是矩阵变换。将特征图拉成一维向量，将每个特征点作为一个神经元进行分类任务。把所有局部特征结合变成全局特征，用来计算最后每一类的得分。</p> 
<p><img src="https://images2.imgbox.com/a1/e4/9p68TGXF_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="31_34"></a>3.1其他特点</h3> 
<p>1、卷积结构可以减少深层网络占用的内存量，其中三个关键操作——局部感<strong>受野、权值共享、池化层</strong>，有效的减少了网络的参数个数，缓解了模型的过拟合问题。</p> 
<p>2、填充padding<br> 为了使卷积操作后能得到满意的输出图片尺寸，经常会使用padding对输入进行填充操作。默认在图片周围填充0。使卷积核对边缘信息的处理不止处理一次，对边缘信息的提取更加充分了，减少边缘信息丢失。<br> <img src="https://images2.imgbox.com/3a/79/Ib31bEbj_o.png" alt="在这里插入图片描述"></p> 
<p>3、感受视野<br> 网络越深，感受视野越大，检测目标越大。底层网络感受视野小，检测小目标。<br> 增大感受视野：可以用空洞卷积、spp、上下采样融合、网络深度</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b2312a2004a274e03b9daa808f254dd7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Windows系统安装WSL，并安装docker服务</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2f2ab0d55ec3abe48dbbfc52a4df2698/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Nopepad&#43;&#43;使用教程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>