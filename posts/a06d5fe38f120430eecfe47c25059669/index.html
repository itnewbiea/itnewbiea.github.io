<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Swin Transformer对CNN的降维打击 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Swin Transformer对CNN的降维打击" />
<meta property="og:description" content="一、前言 一张图告诉你Transformer现在是多么的强！几乎包揽了ADE20K语义分割的前几名！
该文章详细解读Swin-transformer的相关内容以及高明之处。看完学不会，你在评论区打我！CNN已然在计算机视觉领域取得了革命性的成果，拥有着不可撼动的地位。Transformer最初用于NLP领域，但Transformer凭借其强大的特征表征能力，已经在cv领域杀出了一条血路。
paper链接：https://arxiv.org/pdf/2103.14030.pdf
代码链接：https://github.com/microsoft/Swin-Transformer
二、Swin Transformer 2.1 背景 Transformer最开始用于NLP领域，但其强大的表征能力让cv领域的研究人员垂涎欲滴。然而从NLP转为cv领域，存在两个天然的问题。
1.相较于文本，图像中像素的分辨率更高2.图像的视觉实体尺寸之间差异很大 传统Transformer（例如transformer、ViT等）尽管有强大的特征表达能力，但其巨大计算量的问题让人望而却步。与传统Transformer不同的是，Swin-Transformer解决了Transformer一直饱受诟病的计算量问题。那么，Swin-Transformer是如何解决的计算量问题呢？让我们继续往下看吧。
2.2 Architecture概况 学习swin transformer之前，我们首先需要熟知以下几个概念：
Resolution：假设一张图像的分辨率为224x224，这里所说的224就是像素。Patch：所谓的Patch就是由多少个像素点构成的，假设一个patch的size为4x4，则这个patch包含16个像素点。Window：window的size是由patch决定的，而不是由像素点，假设window的size为7x7，则该window包含49个patch，而不是49个像素点。 在对swin-transformer网络进行讲解之前，我们首先需要明确一点：无论是transformer还是swin-transformer结构，都不会改变输入的形状，换句话说，输入是什么样，经过transformer或swin-transformer后，输出跟输入的形状是相同的。
一般而言，我拿到一篇论文之后，会首先分析每个块的输入输出是怎样的，先从整体上对网络结构把握，然后在慢慢的细化。我们首先来梳理一下swin-transformer每个块的输入输出。
stageLayersizeinput image224x224x3patch partition224/4 x 224/4 x 4x4x31linear embedding224/4 x 224/4 x 961swin transformer224/4 x 224/4 x 962patch merging224/8 x 224/8 x 1922swin transformer224/8 x 224/8 x 1923patch merging224/16 x 224/16 x 1923swin transformer224/16 x 224/16 x 1924patch merging224/32 x 224/32 x 3844swin transformer224/32 x 224/32 x 384 从结构图中可以看到，swin-transformer网络结构主要包括以下层：
1.Patch Partition：将输入图像划分为若干个patch2.Linear Embedding：将输入图像映射要任意维度（论文中记为C，即C=96）3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/a06d5fe38f120430eecfe47c25059669/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-15T21:48:43+08:00" />
<meta property="article:modified_time" content="2021-11-15T21:48:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Swin Transformer对CNN的降维打击</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_0"></a>一、前言</h3> 
<p>一张图告诉你Transformer现在是多么的强！几乎包揽了ADE20K语义分割的前几名！<br> <img src="https://images2.imgbox.com/30/8f/qybwEmIY_o.png" alt="在这里插入图片描述"><br> 该文章详细解读Swin-transformer的相关内容以及高明之处。看完学不会，你在评论区打我！CNN已然在计算机视觉领域取得了革命性的成果，拥有着不可撼动的地位。Transformer最初用于NLP领域，但Transformer凭借其强大的特征表征能力，已经在cv领域杀出了一条血路。<br> paper链接：<a href="https://arxiv.org/pdf/2103.14030.pdf" rel="nofollow">https://arxiv.org/pdf/2103.14030.pdf</a><br> 代码链接：<a href="https://github.com/microsoft/Swin-Transformer">https://github.com/microsoft/Swin-Transformer<br> </a></p> 
<h3><a id="Swin_Transformer_8"></a>二、Swin Transformer</h3> 
<h4><a id="21__9"></a>2.1 背景</h4> 
<p>Transformer最开始用于NLP领域，但其强大的表征能力让cv领域的研究人员垂涎欲滴。然而从NLP转为cv领域，存在两个天然的问题。</p> 
<ul><li>1.相较于文本，图像中像素的分辨率更高</li><li>2.图像的视觉实体尺寸之间差异很大</li></ul> 
<p>传统Transformer（例如transformer、ViT等）尽管有强大的特征表达能力，但其巨大计算量的问题让人望而却步。与传统Transformer不同的是，Swin-Transformer解决了Transformer一直饱受诟病的计算量问题。那么，Swin-Transformer是如何解决的计算量问题呢？让我们继续往下看吧。</p> 
<h4><a id="22_Architecture_15"></a>2.2 Architecture概况</h4> 
<p>学习swin transformer之前，我们首先需要熟知以下几个概念：</p> 
<ul><li>Resolution：假设一张图像的分辨率为224x224，这里所说的224就是像素。</li><li>Patch：所谓的Patch就是由多少个像素点构成的，假设一个patch的size为4x4，则这个patch包含16个像素点。</li><li>Window：window的size是由patch决定的，而不是由像素点，假设window的size为7x7，则该window包含49个patch，而不是49个像素点。</li></ul> 
<p>在对swin-transformer网络进行讲解之前，我们首先需要明确一点：无论是transformer还是swin-transformer结构，都不会改变输入的形状，换句话说，输入是什么样，经过transformer或swin-transformer后，输出跟输入的形状是相同的。<br> 一般而言，我拿到一篇论文之后，会首先分析每个块的输入输出是怎样的，先从整体上对网络结构把握，然后在慢慢的细化。我们首先来梳理一下swin-transformer每个块的输入输出。<br> <img src="https://images2.imgbox.com/8e/5e/z2f4VnaN_o.png" alt="在这里插入图片描述"></p> 
<table><thead><tr><th>stage</th><th>Layer</th><th>size</th></tr></thead><tbody><tr><td></td><td>input image</td><td>224x224x3</td></tr><tr><td></td><td>patch partition</td><td>224/4 x 224/4 x 4x4x3</td></tr><tr><td>1</td><td>linear embedding</td><td>224/4 x 224/4 x 96</td></tr><tr><td>1</td><td>swin transformer</td><td>224/4 x 224/4 x 96</td></tr><tr><td>2</td><td>patch merging</td><td>224/8 x 224/8 x 192</td></tr><tr><td>2</td><td>swin transformer</td><td>224/8 x 224/8 x 192</td></tr><tr><td>3</td><td>patch merging</td><td>224/16 x 224/16 x 192</td></tr><tr><td>3</td><td>swin transformer</td><td>224/16 x 224/16 x 192</td></tr><tr><td>4</td><td>patch merging</td><td>224/32 x 224/32 x 384</td></tr><tr><td>4</td><td>swin transformer</td><td>224/32 x 224/32 x 384</td></tr></tbody></table> 
<p>从结构图中可以看到，swin-transformer网络结构主要包括以下层：</p> 
<ul><li>1.Patch Partition：将输入图像划分为若干个patch</li><li>2.Linear Embedding：将输入图像映射要任意维度（论文中记为C，即C=96）</li><li>3.Patch Merging：降低分辨率，扩大感受野，获得多层次的特征信息，类似于CNN中的pool层</li><li>4.swin transformer：特征提取及特征表征</li></ul> 
<h4><a id="23_swintransformer_42"></a>2.3 swin-transformer结构解析</h4> 
<p>到这里我们已经大致了解swin-transformer网络的基本结构，接下来，跟着我一块揭开Swin-transformer的真面目吧。一个swin-transformer block由两个连续的swin-transformer结构组成，两个结构不同之处在于：第一个结构中使用的是在一个window中计算self-attention，记为W-MSA；第二个结构中使用的是shifted window技术，记为SW-MSA。 在这一章节中，我们重点介绍swin-transformer是如何在一个window中进行self-attention计算的。<br> <img src="https://images2.imgbox.com/cd/3b/ocV5meCV_o.png" alt="在这里插入图片描述"><br> 假设我们将window size设置为4，则一个window中包含4x4个Patch，如下图中的Layer l的不重叠窗口划分结果。但只在window中进行self-attention计算，使得各个windows之间缺乏信息的交互，这限制了swin-transformer的特征表达能力。<br> 为此，swin-transformer的作者提出了top-left的窗口移位方式，如下图中Layer l+1所示。但这样的window移位方式增加了window的数量（从2x2-&gt;3x3），增加了2.25倍，且window之间的size也不尽相同，这导致无法进行并行计算。<br> <img src="https://images2.imgbox.com/d9/4e/oAT2Hbby_o.png" alt="在这里插入图片描述"><br> 基于上述两个原因，作者提出了shifted window技术，这也是整篇文章的核心所在。那么shifted window的过程是怎样的呢？</p> 
<h4><a id="24_shifted_window_49"></a>2.4 shifted window</h4> 
<p>假设input image的size为224x224,window的size为7x7，patch size为4X4，那么input image包含224/4 x 224/4个patch（56x56），如下图中的第一张图。我们将其划分为不重叠的window，每个window包含7x7个patch，如下图中的第2张图。接下来，我们将整张图像沿主对角线方向移位(floor(M/2),floor(M/2))个patch，这里的M代表window的size，则本例中移位(3,3)个patch，如第3张图所示。移位后，可以看到，一个window包含4个不同window的部分，如第4张图所示（蓝色网格线）。<br> <img src="https://images2.imgbox.com/17/58/qifA3oa1_o.png" alt="在这里插入图片描述"><br> 我们假设移位后的图像是如下图所示的。我们分别对不同的区域进行编码，为什么要进行编码呢？这是因为我们对一个window中不同区域Patch进行self-attention计算没有任何意义。例如，区域3和区域4在原图中就是两个不相邻的区域，本身之间没有任何的联系。那么，swin-transformer是如何实现一个window中只有相同区域才进行self-attention计算的呢？<br> <img src="https://images2.imgbox.com/9e/f9/EsTEQyK9_o.png" alt="在这里插入图片描述"><br> 我们以右下角4个均不同的区域为案例进行演示。为简洁，我们将右下角的一个window进行简化，由原来的49个patch简化为4个patch，但过程是相同的。<br> <img src="https://images2.imgbox.com/53/7b/wrvljrVw_o.png" alt="在这里插入图片描述"><br> 首先我们根据patch的数量建立一个相关矩阵，本例中patch的数量为4，则建立一个4x4的矩阵，然后将x和y进行相减，相减后，相同区域的结果为0，不同区域的结果我们将其置为负无穷，得到一个mask矩阵，然后与计算得到的attention矩阵进行相加，这样便实现了相同区域进行self-attention计算。</p> 
<h4><a id="25_Relative_position_bias_58"></a>2.5 Relative position bias</h4> 
<p><img src="https://images2.imgbox.com/24/1d/F8eaKLrc_o.png" alt="在这里插入图片描述"><br> 公式中的B即为相对位置信息。那么相对位置信息是如何计算的呢？我们假设有p1、p2、p3、p4四个patch，分别以p1、p2、p3、p4为原点，计算其余patch相对于原点的偏移量，如表1所示。计算完毕后，我们会发现有以下2个问题：</p> 
<ul><li>1.相对位置信息中出现负数</li><li>2.(0,1)和（1,0）虽然是2个不同的相对位置信息，但是它们相加的总偏移量相等。<br> 为了解决以上2个问题，论文作者做了如下操作：</li><li>1.为了方便后续计算，每个坐标的位置都加上偏移量，使其从0开始，避免负数的出现。</li><li>2.对0维度进行乘法变换，论文中是对0维度的数值乘以(2M-1)。</li><li>3.将0维度和1维度的数值进行相加，得到一个index值。</li><li>4.根据index的值，映射到权重矩阵中得到相应的权重值。</li><li>5.将attention矩阵与权重矩阵进行相加。<br> <img src="https://images2.imgbox.com/8c/1b/HLcUEgyH_o.png" alt="在这里插入图片描述"></li></ul> 
<h4><a id="26__70"></a>2.6 循环窗口移动技术是如何实现的</h4> 
<p>其实原理很简单，就是使用了torch.roll()这个方法，关于方法的解释及代码如下，大家可以了解一下。<br> <img src="https://images2.imgbox.com/e3/94/7d7q08un_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/38/2e/TfOcOY6b_o.png" alt=""><br> <img src="https://images2.imgbox.com/e7/4b/AKn3O75d_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f5d11f1cad226881b82791479ca88f77/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C语言排序函数qsort用法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8ec8bf4cabd5afac54095f2812a5ded4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">面试官：说说你对装饰者模式的理解？应用场景？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>