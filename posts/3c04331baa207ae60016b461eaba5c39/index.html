<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大创项目推荐 深度学习OCR中文识别 - opencv python - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="大创项目推荐 深度学习OCR中文识别 - opencv python" />
<meta property="og:description" content="文章目录 0 前言1 课题背景2 实现效果3 文本区域检测网络-CTPN4 文本识别网络-CRNN5 最后 0 前言 🔥 优质竞赛项目系列，今天要分享的是
🚩 **基于深度学习OCR中文识别系统 **
该项目较为新颖，适合作为竞赛课题方向，学长非常推荐！
🥇学长这里给一个题目综合评分(每项满分5分)
难度系数：3分工作量：3分创新点：4分 🧿 更多资料, 项目分享：
https://gitee.com/dancheng-senior/postgraduate
1 课题背景 在日常生产生活中有大量的文档资料以图片、PDF的方式留存，随着时间推移 往往难以检索和归类 ，文字识别（Optical Character
Recognition，OCR ）是将图片、文档影像上的文字内容快速识别成为可编辑的文本的技术。
高性能文档OCR识别系统是基于深度学习技术，综合运用Tensorflow、CNN、Caffe
等多种深度学习训练框架，基于千万级大规模文字样本集训练完成的OCR引擎，与传统的模式识别的技术相比，深度学习技术支持更低质量的分辨率、抗干扰能力更强、适用的场景更复杂，文字的识别率更高。
本项目基于Tensorflow、keras/pytorch实现对自然场景的文字检测及OCR中文文字识别。
2 实现效果 公式检测
纯文字识别
3 文本区域检测网络-CTPN 对于复杂场景的文字识别，首先要定位文字的位置，即文字检测。
简介
CTPN是在ECCV
2016提出的一种文字检测算法。CTPN结合CNN与LSTM深度网络，能有效的检测出复杂场景的横向分布的文字，效果如图1，是目前比较好的文字检测算法。由于CTPN是从Faster
RCNN改进而来，本文默认读者熟悉CNN原理和Faster RCNN网络结构。
相关代码
​
def main(argv): pycaffe_dir = os.path.dirname(__file__) parser = argparse.ArgumentParser() # Required arguments: input and output. parser.add_argument( &#34;input_file&#34;, help=&#34;Input txt/csv filename. If .txt, must be list of filenames." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/3c04331baa207ae60016b461eaba5c39/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-25T16:43:50+08:00" />
<meta property="article:modified_time" content="2023-12-25T16:43:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大创项目推荐 深度学习OCR中文识别 - opencv python</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#0__2" rel="nofollow">0 前言</a></li><li><a href="#1__20" rel="nofollow">1 课题背景</a></li><li><a href="#2__30" rel="nofollow">2 实现效果</a></li><li><a href="#3_CTPN_38" rel="nofollow">3 文本区域检测网络-CTPN</a></li><li><a href="#4_CRNN_197" rel="nofollow">4 文本识别网络-CRNN</a></li><li><a href="#5__309" rel="nofollow">5 最后</a></li></ul> 
</div> 
<p></p> 
<h2><a id="0__2"></a>0 前言</h2> 
<p>🔥 优质竞赛项目系列，今天要分享的是</p> 
<p>🚩 **基于深度学习OCR中文识别系统 **</p> 
<p>该项目较为新颖，适合作为竞赛课题方向，学长非常推荐！</p> 
<p>🥇学长这里给一个题目综合评分(每项满分5分)</p> 
<ul><li>难度系数：3分</li><li>工作量：3分</li><li>创新点：4分</li></ul> 
<p>🧿 <strong>更多资料, 项目分享：</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p> 
<h2><a id="1__20"></a>1 课题背景</h2> 
<p>在日常生产生活中有大量的文档资料以图片、PDF的方式留存，随着时间推移 往往难以检索和归类 ，文字识别（Optical Character<br> Recognition，OCR ）是将图片、文档影像上的文字内容快速识别成为可编辑的文本的技术。</p> 
<p>高性能文档OCR识别系统是基于深度学习技术，综合运用Tensorflow、CNN、Caffe<br> 等多种深度学习训练框架，基于千万级大规模文字样本集训练完成的OCR引擎，与传统的模式识别的技术相比，深度学习技术支持更低质量的分辨率、抗干扰能力更强、适用的场景更复杂，文字的识别率更高。</p> 
<p>本项目基于Tensorflow、keras/pytorch实现对自然场景的文字检测及OCR中文文字识别。</p> 
<h2><a id="2__30"></a>2 实现效果</h2> 
<p><strong>公式检测</strong><br> <img src="https://images2.imgbox.com/9e/98/r9qF7nBm_o.png" alt="在这里插入图片描述"><br> <strong>纯文字识别</strong></p> 
<p><img src="https://images2.imgbox.com/88/8e/JwwMPYzg_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3_CTPN_38"></a>3 文本区域检测网络-CTPN</h2> 
<p>对于复杂场景的文字识别，首先要定位文字的位置，即文字检测。</p> 
<p><strong>简介</strong><br> CTPN是在ECCV<br> 2016提出的一种文字检测算法。CTPN结合CNN与LSTM深度网络，能有效的检测出复杂场景的横向分布的文字，效果如图1，是目前比较好的文字检测算法。由于CTPN是从Faster<br> RCNN改进而来，本文默认读者熟悉CNN原理和Faster RCNN网络结构。<br> <img src="https://images2.imgbox.com/57/52/W9KQDRPO_o.png" alt="在这里插入图片描述"><br> <strong>相关代码</strong></p> 
<p>​</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span><span class="token punctuation">:</span>
    pycaffe_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span>

    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># Required arguments: input and output.</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"input_file"</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span>"Input txt<span class="token operator">/</span>csv filename<span class="token punctuation">.</span> If <span class="token punctuation">.</span>txt<span class="token punctuation">,</span> must be <span class="token builtin">list</span> of filenames<span class="token punctuation">.</span>\
        If <span class="token punctuation">.</span>csv<span class="token punctuation">,</span> must be comma<span class="token operator">-</span>separated <span class="token builtin">file</span> <span class="token keyword">with</span> header\
        <span class="token string">'filename, xmin, ymin, xmax, ymax'</span>"
    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"output_file"</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"Output h5/csv filename. Format depends on extension."</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># Optional arguments.</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--model_def"</span><span class="token punctuation">,</span>
        default<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>pycaffe_dir<span class="token punctuation">,</span>
                <span class="token string">"../models/bvlc_reference_caffenet/deploy.prototxt.prototxt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"Model definition file."</span>
    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--pretrained_model"</span><span class="token punctuation">,</span>
        default<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>pycaffe_dir<span class="token punctuation">,</span>
                <span class="token string">"../models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"Trained model weights file."</span>
    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--crop_mode"</span><span class="token punctuation">,</span>
        default<span class="token operator">=</span><span class="token string">"selective_search"</span><span class="token punctuation">,</span>
        choices<span class="token operator">=</span>CROP_MODES<span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"How to generate windows for detection."</span>
    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--gpu"</span><span class="token punctuation">,</span>
        action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"Switch for gpu computation."</span>
    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--mean_file"</span><span class="token punctuation">,</span>
        default<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>pycaffe_dir<span class="token punctuation">,</span>
                             <span class="token string">'caffe/imagenet/ilsvrc_2012_mean.npy'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"Data set image mean of H x W x K dimensions (numpy array). "</span> <span class="token operator">+</span>
             <span class="token string">"Set to '' for no mean subtraction."</span>
    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--input_scale"</span><span class="token punctuation">,</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"Multiply input features by this scale to finish preprocessing."</span>
    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--raw_scale"</span><span class="token punctuation">,</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span>
        default<span class="token operator">=</span><span class="token number">255.0</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"Multiply raw input by this scale before preprocessing."</span>
    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--channel_swap"</span><span class="token punctuation">,</span>
        default<span class="token operator">=</span><span class="token string">'2,1,0'</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"Order to permute input channels. The default converts "</span> <span class="token operator">+</span>
             <span class="token string">"RGB -&gt; BGR since BGR is the Caffe default by way of OpenCV."</span>

    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--context_pad"</span><span class="token punctuation">,</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>
        default<span class="token operator">=</span><span class="token string">'16'</span><span class="token punctuation">,</span>
        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"Amount of surrounding context to collect in input window."</span>
    <span class="token punctuation">)</span>
    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

    mean<span class="token punctuation">,</span> channel_swap <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>mean_file<span class="token punctuation">:</span>
        mean <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">.</span>mean_file<span class="token punctuation">)</span>
        <span class="token keyword">if</span> mean<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            mean <span class="token operator">=</span> mean<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>channel_swap<span class="token punctuation">:</span>
        channel_swap <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> args<span class="token punctuation">.</span>channel_swap<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>gpu<span class="token punctuation">:</span>
        caffe<span class="token punctuation">.</span>set_mode_gpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"GPU mode"</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        caffe<span class="token punctuation">.</span>set_mode_cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"CPU mode"</span><span class="token punctuation">)</span>

    <span class="token comment"># Make detector.</span>
    detector <span class="token operator">=</span> caffe<span class="token punctuation">.</span>Detector<span class="token punctuation">(</span>args<span class="token punctuation">.</span>model_def<span class="token punctuation">,</span> args<span class="token punctuation">.</span>pretrained_model<span class="token punctuation">,</span> mean<span class="token operator">=</span>mean<span class="token punctuation">,</span>
            input_scale<span class="token operator">=</span>args<span class="token punctuation">.</span>input_scale<span class="token punctuation">,</span> raw_scale<span class="token operator">=</span>args<span class="token punctuation">.</span>raw_scale<span class="token punctuation">,</span>
            channel_swap<span class="token operator">=</span>channel_swap<span class="token punctuation">,</span>
            context_pad<span class="token operator">=</span>args<span class="token punctuation">.</span>context_pad<span class="token punctuation">)</span>

    <span class="token comment"># Load input.</span>
    t <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loading input..."</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>input_file<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'txt'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>input_file<span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            inputs <span class="token operator">=</span> <span class="token punctuation">[</span>_<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>input_file<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'csv'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>args<span class="token punctuation">.</span>input_file<span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'filename'</span><span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        inputs<span class="token punctuation">.</span>set_index<span class="token punctuation">(</span><span class="token string">'filename'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> Exception<span class="token punctuation">(</span><span class="token string">"Unknown input file type: not in txt or csv."</span><span class="token punctuation">)</span>

    <span class="token comment"># Detect.</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>crop_mode <span class="token operator">==</span> <span class="token string">'list'</span><span class="token punctuation">:</span>
        <span class="token comment"># Unpack sequence of (image filename, windows).</span>
        images_windows <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">(</span>ix<span class="token punctuation">,</span> inputs<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>index <span class="token operator">==</span> ix<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span>COORD_COLS<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span>
            <span class="token keyword">for</span> ix <span class="token keyword">in</span> inputs<span class="token punctuation">.</span>index<span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
        detections <span class="token operator">=</span> detector<span class="token punctuation">.</span>detect_windows<span class="token punctuation">(</span>images_windows<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        detections <span class="token operator">=</span> detector<span class="token punctuation">.</span>detect_selective_search<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Processed {} windows in {:.3f} s."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>detections<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                     time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> t<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># Collect into dataframe with labeled fields.</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>detections<span class="token punctuation">)</span>
    df<span class="token punctuation">.</span>set_index<span class="token punctuation">(</span><span class="token string">'filename'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    df<span class="token punctuation">[</span>COORD_COLS<span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>
        data<span class="token operator">=</span>np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'window'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> index<span class="token operator">=</span>df<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>COORD_COLS<span class="token punctuation">)</span>
    <span class="token keyword">del</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'window'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># Save results.</span>
    t <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>output_file<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'csv'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># csv</span>
        <span class="token comment"># Enumerate the class probabilities.</span>
        class_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'class{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>NUM_OUTPUT<span class="token punctuation">)</span><span class="token punctuation">]</span>
        df<span class="token punctuation">[</span>class_cols<span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>
            data<span class="token operator">=</span>np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'feat'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> index<span class="token operator">=</span>df<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>class_cols<span class="token punctuation">)</span>
        df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>args<span class="token punctuation">.</span>output_file<span class="token punctuation">,</span> cols<span class="token operator">=</span>COORD_COLS <span class="token operator">+</span> class_cols<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token comment"># h5</span>
        df<span class="token punctuation">.</span>to_hdf<span class="token punctuation">(</span>args<span class="token punctuation">.</span>output_file<span class="token punctuation">,</span> <span class="token string">'df'</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'w'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Saved to {} in {:.3f} s."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>output_file<span class="token punctuation">,</span>
                                            time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> t<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>CTPN网络结构</strong><br> <img src="https://images2.imgbox.com/b2/48/8caW7gwN_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="4_CRNN_197"></a>4 文本识别网络-CRNN</h2> 
<p><strong>CRNN 介绍</strong><br> CRNN 全称为 Convolutional Recurrent Neural Network，主要用于端到端地对不定长的文本序列进行识别，不用</p> 
<p><img src="https://images2.imgbox.com/da/b9/z3OGbFe1_o.png" alt="图来自文章：一文读懂CRNN+CTC文字识别"></p> 
<p>整个CRNN网络结构包含三部分，从下到上依次为：</p> 
<ol><li>CNN（卷积层），使用深度CNN，对输入图像提取特征，得到特征图；</li><li>RNN（循环层），使用双向RNN（BLSTM）对特征序列进行预测，对序列中的每个特征向量进行学习，并输出预测标签（真实值）分布；</li><li>CTC loss（转录层），使用 CTC 损失，把从循环层获取的一系列标签分布转换成最终的标签序列。</li></ol> 
<p><strong>CNN</strong><br> 卷积层的结构图：<br> <img src="https://images2.imgbox.com/c5/76/uDryN9xc_o.png" alt="在这里插入图片描述"></p> 
<p>这里有一个很精彩的改动，一共有四个最大池化层，但是最后两个池化层的窗口尺寸由 2x2 改为 1x2，也就是图片的高度减半了四次（除以 2^4<br> ），而宽度则只减半了两次（除以2^2），这是因为文本图像多数都是高较小而宽较长，所以其feature<br> map也是这种高小宽长的矩形形状，如果使用1×2的池化窗口可以尽量保证不丢失在宽度方向的信息，更适合英文字母识别（比如区分i和l）。</p> 
<p>CRNN 还引入了BatchNormalization模块，加速模型收敛，缩短训练过程。</p> 
<p>输入图像为灰度图像（单通道）；高度为32，这是固定的，图片通过 CNN<br> 后，高度就变为1，这点很重要；宽度为160，宽度也可以为其他的值，但需要统一，所以输入CNN的数据尺寸为 (channel, height,<br> width)=(1, 32, 160)。</p> 
<p>CNN的输出尺寸为 (512, 1, 40)。即 CNN 最后得到512个特征图，每个特征图的高度为1，宽度为40。</p> 
<p><strong>Map-to-Sequence</strong><br> 我们是不能直接把 CNN 得到的特征图送入 RNN 进行训练的，需要进行一些调整，根据特征图提取 RNN 需要的特征向量序列。</p> 
<p><img src="https://images2.imgbox.com/bd/aa/4Z2E1Zwn_o.png" alt="在这里插入图片描述"></p> 
<p>现在需要从 CNN 模型产生的特征图中提取特征向量序列，每一个特征向量（如上图中的一个红色框）在特征图上按列从左到右生成，每一列包含512维特征，这意味着第<br> i 个特征向量是所有的特征图第 i 列像素的连接，这些特征向量就构成一个序列。</p> 
<p>由于卷积层，最大池化层和激活函数在局部区域上执行，因此它们是平移不变的。因此，特征图的每列（即一个特征向量）对应于原始图像的一个矩形区域（称为感受野），并且这些矩形区域与特征图上从左到右的相应列具有相同的顺序。特征序列中的每个向量关联一个感受野。</p> 
<p>如下图所示：<br> <img src="https://images2.imgbox.com/4c/3b/tRHOscjW_o.png" alt="在这里插入图片描述"></p> 
<p>这些特征向量序列就作为循环层的输入，每个特征向量作为 RNN 在一个时间步（time step）的输入。</p> 
<p><strong>RNN</strong><br> 因为 RNN 有梯度消失的问题，不能获取更多上下文信息，所以 CRNN 中使用的是 LSTM，LSTM<br> 的特殊设计允许它捕获长距离依赖，不了解的话可以看一下这篇文章 对RNN和LSTM的理解。</p> 
<p>LSTM<br> 是单向的，它只使用过去的信息。然而，在基于图像的序列中，两个方向的上下文是相互有用且互补的。将两个LSTM，一个向前和一个向后组合到一个双向LSTM中。此外，可以堆叠多层双向LSTM，深层结构允许比浅层抽象更高层次的抽象。</p> 
<p>这里采用的是两层各256单元的双向 LSTM 网络：<br> <img src="https://images2.imgbox.com/cb/ba/m9Bv4xz1_o.png" alt="在这里插入图片描述"></p> 
<p>通过上面一步，我们得到了40个特征向量，每个特征向量长度为512，在 LSTM 中一个时间步就传入一个特征向量进行分</p> 
<p>我们知道一个特征向量就相当于原图中的一个小矩形区域，RNN<br> 的目标就是预测这个矩形区域为哪个字符，即根据输入的特征向量，进行预测，得到所有字符的softmax概率分布，这是一个长度为字符类别数的向量，作为CTC层的输入。</p> 
<p>因为每个时间步都会有一个输入特征向量 x^T ，输出一个所有字符的概率分布 y^T ，所以输出为 40 个长度为字符类别数的向量构成的后验概率矩阵。</p> 
<p>如下图所示：<br> <img src="https://images2.imgbox.com/90/f7/7A0NvQCU_o.png" alt="在这里插入图片描述"></p> 
<p>然后将这个后验概率矩阵传入转录层。<br> <strong>CTC loss</strong><br> 这算是 CRNN 最难的地方，这一层为转录层，转录是将 RNN<br> 对每个特征向量所做的预测转换成标签序列的过程。数学上，转录是根据每帧预测找到具有最高概率组合的标签序列。</p> 
<p>端到端OCR识别的难点在于怎么处理不定长序列对齐的问题！OCR可建模为时序依赖的文本图像问题，然后使用CTC（Connectionist Temporal<br> Classification, CTC）的损失函数来对 CNN 和 RNN 进行端到端的联合训练。</p> 
<p><strong>相关代码</strong></p> 
<p>​</p> 
<pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputdata<span class="token punctuation">,</span> name<span class="token punctuation">,</span> reuse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Main routine to construct the network
        :param inputdata:
        :param name:
        :param reuse:
        :return:
        """</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span>name_or_scope<span class="token operator">=</span>name<span class="token punctuation">,</span> reuse<span class="token operator">=</span>reuse<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># centerlized data</span>
            inputdata <span class="token operator">=</span> tf<span class="token punctuation">.</span>divide<span class="token punctuation">(</span>inputdata<span class="token punctuation">,</span> <span class="token number">255.0</span><span class="token punctuation">)</span>
            <span class="token comment">#1.特征提取阶段</span>
            <span class="token comment"># first apply the cnn feature extraction stage</span>
            cnn_out <span class="token operator">=</span> self<span class="token punctuation">.</span>_feature_sequence_extraction<span class="token punctuation">(</span>
                inputdata<span class="token operator">=</span>inputdata<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'feature_extraction_module'</span>
            <span class="token punctuation">)</span>
            <span class="token comment">#2.第二步，  batch*1*25*512  变成 batch * 25 * 512</span>
            <span class="token comment"># second apply the map to sequence stage</span>
            sequence <span class="token operator">=</span> self<span class="token punctuation">.</span>_map_to_sequence<span class="token punctuation">(</span>
                inputdata<span class="token operator">=</span>cnn_out<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'map_to_sequence_module'</span>
            <span class="token punctuation">)</span>
            <span class="token comment">#第三步，应用序列标签阶段</span>
            <span class="token comment"># third apply the sequence label stage</span>
            <span class="token comment"># net_out width, batch, n_classes</span>
            <span class="token comment"># raw_pred   width, batch, 1</span>
            net_out<span class="token punctuation">,</span> raw_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>_sequence_label<span class="token punctuation">(</span>
                inputdata<span class="token operator">=</span>sequence<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'sequence_rnn_module'</span>
            <span class="token punctuation">)</span>

        <span class="token keyword">return</span> net_out
</code></pre> 
<p>​</p> 
<h2><a id="5__309"></a>5 最后</h2> 
<p>🧿 <strong>更多资料, 项目分享：</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/426665856b50f5410b809cf1b41a21c7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【案例】简单的账号短信登录</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fcc43993e3dbf2c4c0be781d1ddc0e0d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">React Native 从类组件到函数组件</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>