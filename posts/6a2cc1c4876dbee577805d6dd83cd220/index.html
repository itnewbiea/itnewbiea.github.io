<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>K近邻分类算法 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="K近邻分类算法" />
<meta property="og:description" content="K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。
下面以比较著名的鸾尾花（Iris）数据集举例，讲解K近邻算法
首先我们先导入数据
from sklearn.datasets import load_iris iris = load_iris() print(iris.data.shape) print(iris.data) 可以看到Iris数据集共有150朵鸾尾花的样本，因为没有测试数据，所以我们随机采用其中75%的数据作为训练数据，采用剩余的25%的数据作为测试数据
下面对Iris数据集进行分割
from sklearn.cross_validation import train_test_split X_train,X_test,Y_train,Y_test = train_test_split(iris.data,iris.target,test_size=0.25,random_state=33) 分割完成后，到了训练部分，这里我们使用K近邻分类器对鸾尾花的数据进行类别预测
from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier ss = StandardScaler() X_train = ss.fit_transform(X_train) X_test = ss.transform(X_test) knc = KNeighborsClassifier() knc.fit(X_train,Y_train) Y_predict = knc.predict(X_test) 将预测结果存在Y_predict中
最后我们使用模型自带的评估函数对K近邻分类器在鸾尾花数据上的预测性能进行评估
可以看到，K近邻分类器对38条鸾尾花测试样本的准确性约为89.47%，平均精确率、召回率以及F1指标分别为0.92、0.89、0.90.
K近邻算法模型没有参数训练过程，也就是说，该模型并没有通过任何学习算法分析训练数据，而是只是根据测试样本在训练数据的分布直接做出分类决策。因此，K近邻属于无参数模型中非常简单的一种。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/6a2cc1c4876dbee577805d6dd83cd220/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-09-19T15:59:25+08:00" />
<meta property="article:modified_time" content="2018-09-19T15:59:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">K近邻分类算法</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。<br> 下面以比较著名的鸾尾花（Iris）数据集举例，讲解K近邻算法<br> 首先我们先导入数据</p> 
<pre><code>from sklearn.datasets import load_iris
iris = load_iris()
print(iris.data.shape)
print(iris.data)
</code></pre> 
<p><img src="https://images2.imgbox.com/23/af/CK5blep0_o.png" alt="在这里插入图片描述"><br> 可以看到Iris数据集共有150朵鸾尾花的样本，因为没有测试数据，所以我们随机采用其中75%的数据作为训练数据，采用剩余的25%的数据作为测试数据<br> 下面对Iris数据集进行分割</p> 
<pre><code>from sklearn.cross_validation import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(iris.data,iris.target,test_size=0.25,random_state=33)
</code></pre> 
<p>分割完成后，到了训练部分，这里我们使用K近邻分类器对鸾尾花的数据进行类别预测</p> 
<pre><code>from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

ss = StandardScaler()
X_train = ss.fit_transform(X_train)
X_test = ss.transform(X_test)

knc = KNeighborsClassifier()
knc.fit(X_train,Y_train)
Y_predict = knc.predict(X_test)
</code></pre> 
<p>将预测结果存在Y_predict中<br> <img src="https://images2.imgbox.com/6b/03/7YO8fiHp_o.png" alt="在这里插入图片描述"><br> 最后我们使用模型自带的评估函数对K近邻分类器在鸾尾花数据上的预测性能进行评估<br> <img src="https://images2.imgbox.com/45/36/rdUMwRME_o.png" alt=""><br> <img src="https://images2.imgbox.com/bc/f7/bOBMVnaH_o.png" alt=""><br> 可以看到，K近邻分类器对38条鸾尾花测试样本的准确性约为89.47%，平均精确率、召回率以及F1指标分别为0.92、0.89、0.90.</p> 
<p>K近邻算法模型没有参数训练过程，也就是说，该模型并没有通过任何学习算法分析训练数据，而是只是根据测试样本在训练数据的分布直接做出分类决策。因此，K近邻属于无参数模型中非常简单的一种。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b710ecba74e81431398b121964b8259c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">升级safari 12版本，easyconnectplugin插件等不能使用解决办法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0e89b366f69c728ea5d0bba51ea613ef/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">HttpRunner 使用注意点</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>