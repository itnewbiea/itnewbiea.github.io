<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>YOLOV5超参数设置与数据增强解析 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="YOLOV5超参数设置与数据增强解析" />
<meta property="og:description" content="1、YOLOV5的超参数配置文件介绍 YOLOv5有大约30个超参数用于各种训练设置。它们在*xml中定义。/data目录下的Yaml文件。更好的初始猜测将产生更好的最终结果，因此在进化之前正确地初始化这些值是很重要的。如果有疑问，只需使用缺省值，这些缺省值是为YOLOv5 COCO训练从头优化的。
YOLOv5的超参文件见data/hyp.finetune.yaml（适用VOC数据集）或者hyo.scrach.yaml（适用COCO数据集）文件
1、yolov5/data/hyps/hyp.scratch-low.yaml(YOLOv5 COCO训练从头优化，数据增强低) # Hyperparameters for low-augmentation COCO training from scratch # python train.py --batch 64 --cfg yolov5n6.yaml --weights &#39;&#39; --data coco.yaml --img 640 --epochs 300 --linear # See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials lr0: 0.01 # initial learning rate (SGD=1E-2, Adam=1E-3) 初始学习速率 lrf: 0.01 # final OneCycleLR learning rate (lr0 * lrf) ，最终OneCycleLR学习率 momentum: 0.937 # SGD momentum/Adam beta1 weight_decay: 0.0005 # optimizer weight decay 5e-4 ,权重衰变 warmup_epochs: 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/b5c8607c8d03f1a562cc47136808069f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-30T15:14:42+08:00" />
<meta property="article:modified_time" content="2022-06-30T15:14:42+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">YOLOV5超参数设置与数据增强解析</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="1YOLOV5_0"></a>1、YOLOV5的超参数配置文件介绍</h3> 
<p>YOLOv5有大约30个超参数用于各种训练设置。它们在*xml中定义。/data目录下的Yaml文件。更好的初始猜测将产生更好的最终结果，因此在进化之前正确地初始化这些值是很重要的。如果有疑问，只需使用缺省值，这些缺省值是为YOLOv5 COCO训练从头优化的。</p> 
<blockquote> 
 <p>YOLOv5的超参文件见data/hyp.finetune.yaml（适用VOC数据集）或者hyo.scrach.yaml（适用COCO数据集）文件</p> 
</blockquote> 
<h4><a id="1yolov5datahypshypscratchlowyamlYOLOv5_COCO_5"></a>1、yolov5/data/hyps/hyp.scratch-low.yaml(YOLOv5 COCO训练从头优化，数据增强低)</h4> 
<pre><code class="prism language-bash"><span class="token comment"># Hyperparameters for low-augmentation COCO training from scratch </span>
 <span class="token comment"># python train.py --batch 64 --cfg yolov5n6.yaml --weights '' --data coco.yaml --img 640 --epochs 300 --linear </span>
 <span class="token comment"># See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials </span>
  
 lr0: <span class="token number">0.01</span>  <span class="token comment"># initial learning rate (SGD=1E-2, Adam=1E-3) 初始学习速率</span>
 lrf: <span class="token number">0.01</span>  <span class="token comment"># final OneCycleLR learning rate (lr0 * lrf) ，最终OneCycleLR学习率</span>
 momentum: <span class="token number">0.937</span>  <span class="token comment"># SGD momentum/Adam beta1 </span>
 weight_decay: <span class="token number">0.0005</span>  <span class="token comment"># optimizer weight decay 5e-4 ,权重衰变</span>
 warmup_epochs: <span class="token number">3.0</span>  <span class="token comment"># warmup epochs (fractions ok) 学习率热身epoch</span>
 warmup_momentum: <span class="token number">0.8</span>  <span class="token comment"># warmup initial momentum 学习率热身初始动量</span>
 warmup_bias_lr: <span class="token number">0.1</span>  <span class="token comment"># warmup initial bias lr 学习率热身偏执学习率</span>
 box: <span class="token number">0.05</span>  <span class="token comment"># box loss gain </span>
 cls: <span class="token number">0.5</span>  <span class="token comment"># cls loss gain </span>
 cls_pw: <span class="token number">1.0</span>  <span class="token comment"># cls BCELoss positive_weight </span>
 obj: <span class="token number">1.0</span>  <span class="token comment"># obj loss gain (scale with pixels) </span>
 obj_pw: <span class="token number">1.0</span>  <span class="token comment"># obj BCELoss positive_weight </span>
 iou_t: <span class="token number">0.20</span>  <span class="token comment"># IoU training threshold </span>
 anchor_t: <span class="token number">4.0</span>  <span class="token comment"># anchor-multiple threshold </span>
 <span class="token comment"># anchors: 3  # anchors per output layer (0 to ignore) </span>
 fl_gamma: <span class="token number">0.0</span>  <span class="token comment"># focal loss gamma (efficientDet default gamma=1.5) </span>
 <span class="token comment">#颜色亮度,色调(Hue)、饱和度(Saturation)</span>
 hsv_h: <span class="token number">0.015</span>  <span class="token comment"># image HSV-Hue augmentation (fraction) </span>
 hsv_s: <span class="token number">0.7</span>  <span class="token comment"># image HSV-Saturation augmentation (fraction) </span>
 hsv_v: <span class="token number">0.4</span>  <span class="token comment"># image HSV-Value augmentation (fraction) </span>
 <span class="token comment">#图像旋转</span>
 degrees: <span class="token number">0.0</span>  <span class="token comment"># image rotation (+/- deg) </span>
 <span class="token comment">#图像平移</span>
 translate: <span class="token number">0.1</span>  <span class="token comment"># image translation (+/- fraction) </span>
 <span class="token comment">##图像仿射变换的缩放比例</span>
 scale: <span class="token number">0.5</span>  <span class="token comment"># image scale (+/- gain) </span>
 <span class="token comment">#设置裁剪的仿射矩阵系数</span>
 shear: <span class="token number">0.0</span>  <span class="token comment"># image shear (+/- deg) </span>
 <span class="token comment">#透视变换</span>
 perspective: <span class="token number">0.0</span>  <span class="token comment"># image perspective (+/- fraction), range 0-0.001 ,range 0-0.001 0.0：仿射变换，&gt;0为透视变换</span>
 flipud: <span class="token number">0.0</span>  <span class="token comment"># image flip up-down (probability) </span>
 fliplr: <span class="token number">0.5</span>  <span class="token comment"># image flip left-right (probability) </span>
 mosaic: <span class="token number">1.0</span>  <span class="token comment"># image mosaic (probability) </span>
 mixup: <span class="token number">0.0</span>  <span class="token comment"># image mixup (probability) #在mosaic启用时，才可以启用</span>
 copy_paste: <span class="token number">0.0</span>  <span class="token comment"># segment copy-paste (probability),在mosaic启用时，才可以启用 </span>
</code></pre> 
<h4><a id="2yolov5datahypshypscratchmdeiayaml_47"></a>2、yolov5/data/hyps/hyp.scratch-mdeia.yaml（数据增强中）</h4> 
<pre><code class="prism language-bash"><span class="token comment"># YOLOv5 🚀 by Ultralytics, GPL-3.0 license</span>
<span class="token comment"># Hyperparameters for medium-augmentation COCO training from scratch</span>
<span class="token comment"># python train.py --batch 32 --cfg yolov5m6.yaml --weights '' --data coco.yaml --img 1280 --epochs 300</span>
<span class="token comment"># See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials</span>

lr0: <span class="token number">0.01</span>  <span class="token comment"># initial learning rate (SGD=1E-2, Adam=1E-3)</span>
lrf: <span class="token number">0.1</span>  <span class="token comment"># final OneCycleLR learning rate (lr0 * lrf)</span>
momentum: <span class="token number">0.937</span>  <span class="token comment"># SGD momentum/Adam beta1</span>
weight_decay: <span class="token number">0.0005</span>  <span class="token comment"># optimizer weight decay 5e-4</span>
warmup_epochs: <span class="token number">3.0</span>  <span class="token comment"># warmup epochs (fractions ok)</span>
warmup_momentum: <span class="token number">0.8</span>  <span class="token comment"># warmup initial momentum</span>
warmup_bias_lr: <span class="token number">0.1</span>  <span class="token comment"># warmup initial bias lr</span>
box: <span class="token number">0.05</span>  <span class="token comment"># box loss gain</span>
cls: <span class="token number">0.3</span>  <span class="token comment"># cls loss gain</span>
cls_pw: <span class="token number">1.0</span>  <span class="token comment"># cls BCELoss positive_weight</span>
obj: <span class="token number">0.7</span>  <span class="token comment"># obj loss gain (scale with pixels)</span>
obj_pw: <span class="token number">1.0</span>  <span class="token comment"># obj BCELoss positive_weight</span>
iou_t: <span class="token number">0.20</span>  <span class="token comment"># IoU training threshold</span>
anchor_t: <span class="token number">4.0</span>  <span class="token comment"># anchor-multiple threshold</span>
<span class="token comment"># anchors: 3  # anchors per output layer (0 to ignore)</span>
fl_gamma: <span class="token number">0.0</span>  <span class="token comment"># focal loss gamma (efficientDet default gamma=1.5)</span>
hsv_h: <span class="token number">0.015</span>  <span class="token comment"># image HSV-Hue augmentation (fraction)</span>
hsv_s: <span class="token number">0.7</span>  <span class="token comment"># image HSV-Saturation augmentation (fraction)</span>
hsv_v: <span class="token number">0.4</span>  <span class="token comment"># image HSV-Value augmentation (fraction)</span>
degrees: <span class="token number">0.0</span>  <span class="token comment"># image rotation (+/- deg)</span>
translate: <span class="token number">0.1</span>  <span class="token comment"># image translation (+/- fraction)</span>
scale: <span class="token number">0.9</span>  <span class="token comment"># image scale (+/- gain)</span>
shear: <span class="token number">0.0</span>  <span class="token comment"># image shear (+/- deg)</span>
perspective: <span class="token number">0.0</span>  <span class="token comment"># image perspective (+/- fraction), range 0-0.001</span>
flipud: <span class="token number">0.0</span>  <span class="token comment"># image flip up-down (probability)</span>
fliplr: <span class="token number">0.5</span>  <span class="token comment"># image flip left-right (probability)</span>
mosaic: <span class="token number">1.0</span>  <span class="token comment"># image mosaic (probability)</span>
mixup: <span class="token number">0.1</span>  <span class="token comment"># image mixup (probability)</span>
copy_paste: <span class="token number">0.0</span>  <span class="token comment"># segment copy-paste (probability)</span>
</code></pre> 
<h4><a id="3hypscratchhighyaml_84"></a>3、hyp.scratch-high.yaml（数据增强高）</h4> 
<pre><code class="prism language-bash"><span class="token comment"># YOLOv5 🚀 by Ultralytics, GPL-3.0 license</span>
<span class="token comment"># Hyperparameters for high-augmentation COCO training from scratch</span>
<span class="token comment"># python train.py --batch 32 --cfg yolov5m6.yaml --weights '' --data coco.yaml --img 1280 --epochs 300</span>
<span class="token comment"># See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials</span>

lr0: <span class="token number">0.01</span>  <span class="token comment"># initial learning rate (SGD=1E-2, Adam=1E-3)</span>
lrf: <span class="token number">0.1</span>  <span class="token comment"># final OneCycleLR learning rate (lr0 * lrf)</span>
momentum: <span class="token number">0.937</span>  <span class="token comment"># SGD momentum/Adam beta1</span>
weight_decay: <span class="token number">0.0005</span>  <span class="token comment"># optimizer weight decay 5e-4</span>
warmup_epochs: <span class="token number">3.0</span>  <span class="token comment"># warmup epochs (fractions ok)</span>
warmup_momentum: <span class="token number">0.8</span>  <span class="token comment"># warmup initial momentum</span>
warmup_bias_lr: <span class="token number">0.1</span>  <span class="token comment"># warmup initial bias lr</span>
box: <span class="token number">0.05</span>  <span class="token comment"># box loss gain</span>
cls: <span class="token number">0.3</span>  <span class="token comment"># cls loss gain</span>
cls_pw: <span class="token number">1.0</span>  <span class="token comment"># cls BCELoss positive_weight</span>
obj: <span class="token number">0.7</span>  <span class="token comment"># obj loss gain (scale with pixels)</span>
obj_pw: <span class="token number">1.0</span>  <span class="token comment"># obj BCELoss positive_weight</span>
iou_t: <span class="token number">0.20</span>  <span class="token comment"># IoU training threshold</span>
anchor_t: <span class="token number">4.0</span>  <span class="token comment"># anchor-multiple threshold</span>
<span class="token comment"># anchors: 3  # anchors per output layer (0 to ignore)</span>
fl_gamma: <span class="token number">0.0</span>  <span class="token comment"># focal loss gamma (efficientDet default gamma=1.5)</span>
hsv_h: <span class="token number">0.015</span>  <span class="token comment"># image HSV-Hue augmentation (fraction)</span>
hsv_s: <span class="token number">0.7</span>  <span class="token comment"># image HSV-Saturation augmentation (fraction)</span>
hsv_v: <span class="token number">0.4</span>  <span class="token comment"># image HSV-Value augmentation (fraction)</span>
degrees: <span class="token number">0.0</span>  <span class="token comment"># image rotation (+/- deg)</span>
translate: <span class="token number">0.1</span>  <span class="token comment"># image translation (+/- fraction)</span>
scale: <span class="token number">0.9</span>  <span class="token comment"># image scale (+/- gain)</span>
shear: <span class="token number">0.0</span>  <span class="token comment"># image shear (+/- deg)</span>
perspective: <span class="token number">0.0</span>  <span class="token comment"># image perspective (+/- fraction), range 0-0.001</span>
flipud: <span class="token number">0.0</span>  <span class="token comment"># image flip up-down (probability)</span>
fliplr: <span class="token number">0.5</span>  <span class="token comment"># image flip left-right (probability)</span>
mosaic: <span class="token number">1.0</span>  <span class="token comment"># image mosaic (probability)</span>
mixup: <span class="token number">0.1</span>  <span class="token comment"># image mixup (probability)</span>
copy_paste: <span class="token number">0.1</span>  <span class="token comment"># segment copy-paste (probability)</span>
</code></pre> 
<h3><a id="2OneCycleLR_121"></a>2、OneCycleLR学习率</h3> 
<p>根据“OneCycleLR学习率”策略，设置各参数组的学习率。1cycle策略将学习率从初始学习率退火到最大学习率，然后从最大学习率退火到远低于初始学习率的最小学习率。<a href="https://click.endnote.com/viewer?doi=10.48550/arxiv.1708.07120&amp;token=WzIyOTQ5NjcsIjEwLjQ4NTUwL2FyeGl2LjE3MDguMDcxMjAiXQ.TRjqjx-UC_VFt1UnLxwEA0OMTYA" rel="nofollow">论文地址</a></p> 
<h3><a id="3Warmup_123"></a>3、Warmup</h3> 
<p>warmup是一种学习率优化方法，最早出现在resnet论文中，在模型训练初期选用较小的学习率，训练一段时间之后（10epoch 或者 10000steps）使用预设的学习率进行训练</p> 
<p>为什么使用</p> 
<blockquote> 
 <p>模型训练初期，权重随机化，对数据的理解为0，在第一个epoch中，模型会根据输入的数据进行快速的调参，此时如果采用较大的学习率，有很大的可能使模型学偏，后续需要更多的轮次才能拉回来</p> 
</blockquote> 
<blockquote> 
 <p>当模型训练一段时间之后，对数据有一定的先验知识，此时使用较大的学习率模型不容易学偏，可以使用较大的学习率加速训练。</p> 
</blockquote> 
<blockquote> 
 <p>当模型使用较大的学习率训练一段时间之后，模型的分布相对比较稳定，此时不宜从数据中再学到新的特点，如果继续使用较大的学习率会破坏模型的稳定性，而使用较小的学习率更获得最优。</p> 
</blockquote> 
<p>Pytorch内部并没有warmup的接口，为此需要使用第三方包<a href="https://github.com/Tony-Y/pytorch_warmup">pytorch_warmup </a>，可以使用命令pip install pytorch_warmup进行安装</p> 
<h4><a id="1_136"></a>1、当学习率计划使用全局迭代数时，未调优的线性预热可以这样使用:</h4> 
<pre><code class="prism language-bash"><span class="token function">import</span> torch
<span class="token function">import</span> pytorch_warmup as warmup

optimizer <span class="token operator">=</span> torch.optim.AdamW<span class="token punctuation">(</span>params, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.001</span>, <span class="token assign-left variable">betas</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.9</span>, <span class="token number">0.999</span><span class="token punctuation">)</span>, <span class="token assign-left variable">weight_decay</span><span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
num_steps <span class="token operator">=</span> len<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span> * num_epochs
lr_scheduler <span class="token operator">=</span> torch.optim.lr_scheduler.CosineAnnealingLR<span class="token punctuation">(</span>optimizer, <span class="token assign-left variable">T_max</span><span class="token operator">=</span>num_steps<span class="token punctuation">)</span>
warmup_scheduler <span class="token operator">=</span> warmup.UntunedLinearWarmup<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">epoch</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span>,num_epochs+1<span class="token punctuation">)</span>:
    <span class="token keyword">for</span> <span class="token for-or-select variable">batch</span> <span class="token keyword">in</span> dataloader:
        optimizer.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> <span class="token punctuation">..</span>.
        loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer.step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        with warmup_scheduler.dampening<span class="token punctuation">(</span><span class="token punctuation">)</span>:
            lr_scheduler.step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="2PyTorch_140with_155"></a>2、如果你想使用PyTorch 1.4.0或更高版本支持的学习率调度“链接”，你可以简单地给出一组with语句的学习率调度程序代码:</h4> 
<pre><code class="prism language-bash">lr_scheduler1 <span class="token operator">=</span> torch.optim.lr_scheduler.ExponentialLR<span class="token punctuation">(</span>optimizer, <span class="token assign-left variable">gamma</span><span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>
lr_scheduler2 <span class="token operator">=</span> torch.optim.lr_scheduler.StepLR<span class="token punctuation">(</span>optimizer, <span class="token assign-left variable">step_size</span><span class="token operator">=</span><span class="token number">3</span>, <span class="token assign-left variable">gamma</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
warmup_scheduler <span class="token operator">=</span> warmup.UntunedLinearWarmup<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">epoch</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span>,num_epochs+1<span class="token punctuation">)</span>:
    <span class="token keyword">for</span> <span class="token for-or-select variable">batch</span> <span class="token keyword">in</span> dataloader:
        <span class="token punctuation">..</span>.
        optimizer.step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        with warmup_scheduler.dampening<span class="token punctuation">(</span><span class="token punctuation">)</span>:
            lr_scheduler1.step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            lr_scheduler2.step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="3epoch_169"></a>3、当学习率计划使用epoch号时，预热计划可以这样使用:</h4> 
<pre><code class="prism language-bash">lr_scheduler <span class="token operator">=</span> torch.optim.lr_scheduler.MultiStepLR<span class="token punctuation">(</span>optimizer, <span class="token assign-left variable">milestones</span><span class="token operator">=</span><span class="token punctuation">[</span>num_epochs//3<span class="token punctuation">]</span>, <span class="token assign-left variable">gamma</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
warmup_scheduler <span class="token operator">=</span> warmup.UntunedLinearWarmup<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">epoch</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span>,num_epochs+1<span class="token punctuation">)</span>:
    <span class="token keyword">for</span> iter, batch <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>:
        optimizer.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> <span class="token punctuation">..</span>.
        loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer.step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> iter <span class="token operator">&lt;</span> len<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>-1:
            with warmup_scheduler.dampening<span class="token punctuation">(</span><span class="token punctuation">)</span>:
                pass
    with warmup_scheduler.dampening<span class="token punctuation">(</span><span class="token punctuation">)</span>:
        lr_scheduler.step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="4Warmup_Schedules_186"></a>4、Warmup Schedules</h4> 
<h5><a id="1Manual_Warmup_187"></a>1、Manual Warmup</h5> 
<p>预热因子w(t)取决于预热期，必须手动指定线性预热和指数预热。</p> 
<h6><a id="1_Linear_189"></a>1、 Linear</h6> 
<pre><code class="prism language-bash">w<span class="token punctuation">(</span>t<span class="token punctuation">)</span> <span class="token operator">=</span> min<span class="token punctuation">(</span><span class="token number">1</span>, t / warmup_period<span class="token punctuation">)</span>
warmup_scheduler <span class="token operator">=</span> warmup.LinearWarmup<span class="token punctuation">(</span>optimizer, <span class="token assign-left variable">warmup_period</span><span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">)</span>
</code></pre> 
<h6><a id="2_Exponential_195"></a>2、 Exponential</h6> 
<pre><code class="prism language-bash">warmup_period <span class="token operator">=</span> <span class="token number">1</span> / <span class="token punctuation">(</span><span class="token number">1</span> - beta2<span class="token punctuation">)</span>

warmup_scheduler <span class="token operator">=</span> warmup.UntunedExponentialWarmup<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
</code></pre> 
<h6><a id="3_RAdam_Warmup_203"></a>3、 RAdam Warmup</h6> 
<p>The warmup factor depends on Adam’s beta2 parameter for RAdamWarmup. Please see the original paper for the details.</p> 
<pre><code class="prism language-bash">warmup_scheduler <span class="token operator">=</span> warmup.RAdamWarmup<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
</code></pre> 
<h6><a id="4_Apexs_Adam_209"></a>4、 Apex’s Adam</h6> 
<p>The Apex library provides an Adam optimizer tuned for CUDA devices, <a href="https://nvidia.github.io/apex/optimizers.html#apex.optimizers.FusedAdam" rel="nofollow">FusedAdam</a>. The FusedAdam optimizer can be used with the warmup schedulers. For example:</p> 
<pre><code class="prism language-bash">optimizer <span class="token operator">=</span> apex.optimizers.FusedAdam<span class="token punctuation">(</span>params, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.001</span>, <span class="token assign-left variable">betas</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.9</span>, <span class="token number">0.999</span><span class="token punctuation">)</span>, <span class="token assign-left variable">weight_decay</span><span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
lr_scheduler <span class="token operator">=</span> torch.optim.lr_scheduler.CosineAnnealingLR<span class="token punctuation">(</span>optimizer, <span class="token assign-left variable">T_max</span><span class="token operator">=</span>num_steps<span class="token punctuation">)</span>
warmup_scheduler <span class="token operator">=</span> warmup.UntunedLinearWarmup<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="4YOLOV5yolov5v6utilsdatasetspy_217"></a>4、YOLOV5数据增强（yolov5-v6\utils\datasets.py）</h3> 
<p><a href="https://click.endnote.com/viewer?doi=10.48550/arxiv.1708.07120&amp;token=WzIyOTQ5NjcsIjEwLjQ4NTUwL2FyeGl2LjE3MDguMDcxMjAiXQ.TRjqjx-UC_VFt1UnLxwEA0OMTYA" rel="nofollow">目标检测 YOLOv5 - 数据增强</a><br> <a href="https://blog.csdn.net/weixin_43694096/article/details/124741952">Yolov5(v6.1)数据增强方式解析</a><br> 一旦训练开始，您可以在train_batch*.jpg图像中查看增强策略的效果。这些图像将在你的火车日志目录中，通常是yolov5/runs/train/exp:<br> train_batch0.jpg shows train batch 0 mosaics and labels:<br> <img src="https://images2.imgbox.com/02/f4/LYt1mR0I_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b5/63/ZGKPRUg0_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/98/ce/QOsnmNmx_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="5_YOLOv5Albumentations_226"></a>5、 YOLOv5集成Albumentations，添加新的数据增强方法</h3> 
<blockquote> 
 <p>To use albumentations simply pip install -U albumentations and then update the augmentation pipeline as you see fit in the new Albumentations class in yolov5/utils/augmentations.py. Note these Albumentations operations run in addition to the YOLOv5 hyperparameter augmentations, i.e. defined in hyp.scratch.yaml.</p> 
</blockquote> 
<p>Here’s an example that <strong>applies Blur, MedianBlur and ToGray albumentations in addition to the YOLOv5 hyperparameter augmentations normally applied to your training mosaics</strong> 😃</p> 
<pre><code class="prism language-bash">class Albumentations:
    <span class="token comment"># YOLOv5 Albumentations class (optional, used if package is installed)</span>
    def __init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>:
        self.transform <span class="token operator">=</span> None
        try:
            <span class="token function">import</span> albumentations as A
            check_version<span class="token punctuation">(</span>A.__version__, <span class="token string">'1.0.3'</span><span class="token punctuation">)</span>  <span class="token comment"># version requirement</span>

            self.transform <span class="token operator">=</span> A.Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
                A.Blur<span class="token punctuation">(</span>blur_limit<span class="token operator">=</span><span class="token number">50</span>, <span class="token assign-left variable">p</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>,
                A.MedianBlur<span class="token punctuation">(</span>blur_limit<span class="token operator">=</span><span class="token number">51</span>, <span class="token assign-left variable">p</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>,
                A.ToGray<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">]</span>,
                <span class="token assign-left variable">bbox_params</span><span class="token operator">=</span>A.BboxParams<span class="token punctuation">(</span>format<span class="token operator">=</span><span class="token string">'yolo'</span>, <span class="token assign-left variable">label_fields</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'class_labels'</span><span class="token punctuation">]</span><span class="token punctuation">))</span>

            logging.info<span class="token punctuation">(</span>colorstr<span class="token punctuation">(</span><span class="token string">'albumentations: '</span><span class="token punctuation">)</span> + <span class="token string">', '</span>.join<span class="token punctuation">(</span>f<span class="token string">'{x}'</span> <span class="token keyword">for</span> <span class="token for-or-select variable">x</span> <span class="token keyword">in</span> self.transform.transforms<span class="token punctuation">))</span>
        except ImportError:  <span class="token comment"># package not installed, skip</span>
            pass
        except Exception as e:
            logging.info<span class="token punctuation">(</span>colorstr<span class="token punctuation">(</span><span class="token string">'albumentations: '</span><span class="token punctuation">)</span> + f<span class="token string">'{e}'</span><span class="token punctuation">)</span>

    def __call__<span class="token punctuation">(</span>self, im, labels, <span class="token assign-left variable">p</span><span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>:
        <span class="token keyword">if</span> self.transform and random.random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> p:
            new <span class="token operator">=</span> self.transform<span class="token punctuation">(</span>image<span class="token operator">=</span>im, <span class="token assign-left variable">bboxes</span><span class="token operator">=</span>labels<span class="token punctuation">[</span>:, <span class="token number">1</span>:<span class="token punctuation">]</span>, <span class="token assign-left variable">class_labels</span><span class="token operator">=</span>labels<span class="token punctuation">[</span>:, <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># transformed</span>
            im, labels <span class="token operator">=</span> new<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span>, np.array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>c, *b<span class="token punctuation">]</span> <span class="token keyword">for</span> c, b <span class="token keyword">in</span> zip<span class="token punctuation">(</span>new<span class="token punctuation">[</span><span class="token string">'class_labels'</span><span class="token punctuation">]</span>, new<span class="token punctuation">[</span><span class="token string">'bboxes'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token builtin class-name">return</span> im, labels
</code></pre> 
<p><img src="https://images2.imgbox.com/89/f0/aDHJI0x9_o.png" alt="在这里插入图片描述"><br> ##您可以在YOLOv5数据加载器中集成额外的Albumentations增强功能:<br> 在YOLOv5数据加载器中插入albumentaugment功能的最佳位置是这里:</p> 
<pre><code class="prism language-bash"><span class="token keyword">if</span> self.augment: 
     <span class="token comment"># Augment imagespace </span>
     <span class="token keyword">if</span> not mosaic: 
         img, labels <span class="token operator">=</span> random_perspective<span class="token punctuation">(</span>img, labels, 
                                          <span class="token assign-left variable">degrees</span><span class="token operator">=</span>hyp<span class="token punctuation">[</span><span class="token string">'degrees'</span><span class="token punctuation">]</span>, 
                                          <span class="token assign-left variable">translate</span><span class="token operator">=</span>hyp<span class="token punctuation">[</span><span class="token string">'translate'</span><span class="token punctuation">]</span>, 
                                          <span class="token assign-left variable">scale</span><span class="token operator">=</span>hyp<span class="token punctuation">[</span><span class="token string">'scale'</span><span class="token punctuation">]</span>, 
                                          <span class="token assign-left variable">shear</span><span class="token operator">=</span>hyp<span class="token punctuation">[</span><span class="token string">'shear'</span><span class="token punctuation">]</span>, 
                                          <span class="token assign-left variable">perspective</span><span class="token operator">=</span>hyp<span class="token punctuation">[</span><span class="token string">'perspective'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
  
     <span class="token comment"># Augment colorspace </span>
     augment_hsv<span class="token punctuation">(</span>img, <span class="token assign-left variable">hgain</span><span class="token operator">=</span>hyp<span class="token punctuation">[</span><span class="token string">'hsv_h'</span><span class="token punctuation">]</span>, <span class="token assign-left variable">sgain</span><span class="token operator">=</span>hyp<span class="token punctuation">[</span><span class="token string">'hsv_s'</span><span class="token punctuation">]</span>, <span class="token assign-left variable">vgain</span><span class="token operator">=</span>hyp<span class="token punctuation">[</span><span class="token string">'hsv_v'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
  
     <span class="token comment"># Apply cutouts </span>
     <span class="token comment"># if random.random() &lt; 0.9: </span>
     <span class="token comment">#     labels = cutout(img, labels) </span>
</code></pre> 
<p>其中img为图像，label为边框标签。请注意，您添加的任何albuments增强都将是对超参数文件中定义的现有自动YOLOv5增强的补充:</p> 
<h3><a id="6_282"></a>6、定义评估指标</h3> 
<p>健康是我们追求的价值最大化。在YOLOv5中，我们将默认适应度函数定义为指标的加权组合:mAP@0.5占权重的10%，mAP@0.5:0.95占剩余的90%，没有Precision P和Recall R。您可以根据自己的需要进行调整，或者使用默认的适合度定义(推荐)。</p> 
<pre><code class="prism language-bash">yolov5/utils/metrics.py

Lines <span class="token number">12</span> to <span class="token number">16</span> <span class="token keyword">in</span> 4103ce9

 def fitness<span class="token punctuation">(</span>x<span class="token punctuation">)</span>: 
     <span class="token comment"># Model fitness as a weighted combination of metrics </span>
     w <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.0</span>, <span class="token number">0.0</span>, <span class="token number">0.1</span>, <span class="token number">0.9</span><span class="token punctuation">]</span>  <span class="token comment"># weights for [P, R, mAP@0.5, mAP@0.5:0.95] </span>
     <span class="token builtin class-name">return</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span>:, :4<span class="token punctuation">]</span> * w<span class="token punctuation">)</span>.sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> 
</code></pre> 
<h3><a id="7_Evolve_295"></a>7、 Evolve（模型参数更新进化）</h3> 
<pre><code class="prism language-bash"><span class="token comment"># Single-GPU</span>
python train.py --epochs <span class="token number">10</span> --data coco128.yaml --weights yolov5s.pt --cache --evolve

<span class="token comment"># Multi-GPU</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token number">4</span> <span class="token number">5</span> <span class="token number">6</span> <span class="token number">7</span><span class="token punctuation">;</span> <span class="token keyword">do</span>
  <span class="token function">sleep</span> <span class="token variable"><span class="token variable">$(</span><span class="token function">expr</span> <span class="token number">30</span> <span class="token punctuation">\</span>* $i<span class="token variable">)</span></span> <span class="token operator">&amp;&amp;</span>  <span class="token comment"># 30-second delay (optional)</span>
  <span class="token builtin class-name">echo</span> <span class="token string">'Starting GPU '</span><span class="token variable">$i</span><span class="token string">'...'</span> <span class="token operator">&amp;&amp;</span>
  <span class="token function">nohup</span> python train.py --epochs <span class="token number">10</span> --data coco128.yaml --weights yolov5s.pt --cache --device <span class="token variable">$i</span> --evolve <span class="token operator">&gt;</span> evolve_gpu_<span class="token variable">$i</span>.log <span class="token operator">&amp;</span>
<span class="token keyword">done</span>

<span class="token comment"># Multi-GPU bash-while (not recommended)</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token number">4</span> <span class="token number">5</span> <span class="token number">6</span> <span class="token number">7</span><span class="token punctuation">;</span> <span class="token keyword">do</span>
  <span class="token function">sleep</span> <span class="token variable"><span class="token variable">$(</span><span class="token function">expr</span> <span class="token number">30</span> <span class="token punctuation">\</span>* $i<span class="token variable">)</span></span> <span class="token operator">&amp;&amp;</span>  <span class="token comment"># 30-second delay (optional)</span>
  <span class="token builtin class-name">echo</span> <span class="token string">'Starting GPU '</span><span class="token variable">$i</span><span class="token string">'...'</span> <span class="token operator">&amp;&amp;</span>
  <span class="token string">"<span class="token variable"><span class="token variable">$(</span><span class="token keyword">while</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token keyword">do</span> <span class="token function">nohup</span> python train.py<span class="token punctuation">..</span>. --device $i --evolve <span class="token number">1</span> <span class="token operator">&gt;</span> evolve_gpu_$i.log<span class="token punctuation">;</span> <span class="token keyword">done</span><span class="token variable">)</span></span>"</span> <span class="token operator">&amp;</span>
<span class="token keyword">done</span>
</code></pre> 
<pre><code class="prism language-bash"><span class="token comment"># YOLOv5 Hyperparameter Evolution Results</span>
<span class="token comment"># Best generation: 287</span>
<span class="token comment"># Last generation: 300</span>
<span class="token comment">#    metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss</span>
<span class="token comment">#              0.54634,              0.55625,              0.58201,              0.33665,             0.056451,             0.042892,             0.013441</span>

lr0: <span class="token number">0.01</span>  <span class="token comment"># initial learning rate (SGD=1E-2, Adam=1E-3)</span>
lrf: <span class="token number">0.2</span>  <span class="token comment"># final OneCycleLR learning rate (lr0 * lrf)</span>
momentum: <span class="token number">0.937</span>  <span class="token comment"># SGD momentum/Adam beta1</span>
weight_decay: <span class="token number">0.0005</span>  <span class="token comment"># optimizer weight decay 5e-4</span>
warmup_epochs: <span class="token number">3.0</span>  <span class="token comment"># warmup epochs (fractions ok)</span>
warmup_momentum: <span class="token number">0.8</span>  <span class="token comment"># warmup initial momentum</span>
warmup_bias_lr: <span class="token number">0.1</span>  <span class="token comment"># warmup initial bias lr</span>
box: <span class="token number">0.05</span>  <span class="token comment"># box loss gain</span>
cls: <span class="token number">0.5</span>  <span class="token comment"># cls loss gain</span>
cls_pw: <span class="token number">1.0</span>  <span class="token comment"># cls BCELoss positive_weight</span>
obj: <span class="token number">1.0</span>  <span class="token comment"># obj loss gain (scale with pixels)</span>
obj_pw: <span class="token number">1.0</span>  <span class="token comment"># obj BCELoss positive_weight</span>
iou_t: <span class="token number">0.20</span>  <span class="token comment"># IoU training threshold</span>
anchor_t: <span class="token number">4.0</span>  <span class="token comment"># anchor-multiple threshold</span>
<span class="token comment"># anchors: 3  # anchors per output layer (0 to ignore)</span>
fl_gamma: <span class="token number">0.0</span>  <span class="token comment"># focal loss gamma (efficientDet default gamma=1.5)</span>
hsv_h: <span class="token number">0.015</span>  <span class="token comment"># image HSV-Hue augmentation (fraction)</span>
hsv_s: <span class="token number">0.7</span>  <span class="token comment"># image HSV-Saturation augmentation (fraction)</span>
hsv_v: <span class="token number">0.4</span>  <span class="token comment"># image HSV-Value augmentation (fraction)</span>
degrees: <span class="token number">0.0</span>  <span class="token comment"># image rotation (+/- deg)</span>
translate: <span class="token number">0.1</span>  <span class="token comment"># image translation (+/- fraction)</span>
scale: <span class="token number">0.5</span>  <span class="token comment"># image scale (+/- gain)</span>
shear: <span class="token number">0.0</span>  <span class="token comment"># image shear (+/- deg)</span>
perspective: <span class="token number">0.0</span>  <span class="token comment"># image perspective (+/- fraction), range 0-0.001</span>
flipud: <span class="token number">0.0</span>  <span class="token comment"># image flip up-down (probability)</span>
fliplr: <span class="token number">0.5</span>  <span class="token comment"># image flip left-right (probability)</span>
mosaic: <span class="token number">1.0</span>  <span class="token comment"># image mosaic (probability)</span>
mixup: <span class="token number">0.0</span>  <span class="token comment"># image mixup (probability)</span>
copy_paste: <span class="token number">0.0</span>  <span class="token comment"># segment copy-paste (probability)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/9a/fe/Xbk6ftUy_o.png" alt="在这里插入图片描述"><br> 我们建议至少300代的进化才能获得最好的结果。请注意，进化通常是昂贵和耗时的，因为基本场景要训练数百次，可能需要数百或数千个GPU小时。</p> 
<h3><a id="8__357"></a>8、 超参数可视化</h3> 
<p>evolve.csv is plotted as evolve.png by utils.plots.plot_evolve() after evolution finishes with one subplot per hyperparameter showing fitness (y axis) vs hyperparameter values (x axis). Yellow indicates higher concentrations. Vertical distributions indicate that a parameter has been disabled and does not mutate. This is user selectable in the meta dictionary in train.py, and is useful for fixing parameters and preventing them from evolving.<br> <img src="https://images2.imgbox.com/a8/5c/Usk6XVZZ_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/908992362ff0a11683123a860579aec6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ArcGIS api for JavaScript - 发布一个GIS线上图层</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f91ab643665b34c27d2cb016de728401/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">video 标签 autoplay 实现自动播放</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>