<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python爬虫代码分享：获取小说的内容 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python爬虫代码分享：获取小说的内容" />
<meta property="og:description" content="Python爬虫代码是一种自动化程序，可以通过向网站发送HTTP请求来获取内容，并对其进行解析、提取和存储。本文中，分享了一份从小说网站获取小说内容的Python爬虫代码。该代码可以自动批量下载小说，将每章节的内容保存到txt文档中。
# - - - - 小说爬虫程序 - - - - # 从biquge获取小说内容，将内容写入txt文档中。 # 打开biquge主页，将对应小说的网址复制到Python中即可 import re import os import requests # biquge小说主页的网址 novel_url = &#34;https://www.biqudu.net/13_13453/&#34; # 读取页面并解码为utf-8格式 novel_page = requests.get(novel_url).content.decode(&#34;UTF-8&#34;) # 取出biquge网址 url_array = novel_url.split(&#39;/&#39;) url_array.remove(url_array[3]) base_url = url_array[0] &#43; &#34;//&#34; &#43; url_array[2] &#43; &#34;/&#34; # 获取小说标题 title_regex = re.compile(r&#39;&lt;h1&gt;(.&#43;)&lt;/h1&gt;&#39;) title = title_regex.findall(novel_page)[0].center(23, &#39;=&#39;) print(title) # 文件名称为小说的标题加上.txt后缀 file_name = title_regex.findall(novel_page)[0] &#43; &#34;.txt&#34; # 获取小说目录 chapter_regex = re.compile(r&#39;&lt;a href=&#34;/(.&#43;\.html)&#34;&gt;(.&#43;)&lt;/a&gt;&#39;) chapter_raw = chapter_regex." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/aabe49af91604374e463f3ca72bc82b8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-11T00:17:18+08:00" />
<meta property="article:modified_time" content="2023-05-11T00:17:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python爬虫代码分享：获取小说的内容</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>        Python爬虫代码是一种自动化程序，可以通过向网站发送HTTP请求来获取内容，并对其进行解析、提取和存储。本文中，分享了一份从小说网站获取小说内容的Python爬虫代码。该代码可以自动批量下载小说，将每章节的内容保存到txt文档中。</p> 
<pre><code class="language-python"># - - - - 小说爬虫程序 - - - -
# 从biquge获取小说内容，将内容写入txt文档中。 
# 打开biquge主页，将对应小说的网址复制到Python中即可

import re
import os
import requests

# biquge小说主页的网址
novel_url = "https://www.biqudu.net/13_13453/"

# 读取页面并解码为utf-8格式
novel_page = requests.get(novel_url).content.decode("UTF-8")

# 取出biquge网址
url_array = novel_url.split('/')
url_array.remove(url_array[3])
base_url = url_array[0] + "//" + url_array[2] + "/"

# 获取小说标题
title_regex = re.compile(r'&lt;h1&gt;(.+)&lt;/h1&gt;')      
title = title_regex.findall(novel_page)[0].center(23, '=')
print(title)

# 文件名称为小说的标题加上.txt后缀
file_name = title_regex.findall(novel_page)[0] + ".txt"   

# 获取小说目录
chapter_regex = re.compile(r'&lt;a href="/(.+\.html)"&gt;(.+)&lt;/a&gt;')
chapter_raw = chapter_regex.findall(novel_page)
chapter_list = [(i[1], base_url + i[0]) for i in chapter_raw]
print("目录已加载完毕!")

# 获取每一个章节的内容
content_regex = re.compile(r'&lt;div id="content"&gt;(.+)&lt;script&gt;chaptererror', re.S)  
newline_regex = re.compile(r"&lt;br/&gt;&lt;br/&gt;\u3000\u3000")

# 判断路径下是否存在对应的文件
is_exist = os.path.isfile(file_name)  

if is_exist:
    os.remove(file_name)    #移除存在的文件，防止后续字符写到前面的文件

with open(file_name, "a") as f:
    for chapter in chapter_list:
        print("开始下载---&gt;", chapter[0])
        print("章节网址---&gt;,", chapter[1])
        chapter_page = requests.get(chapter[1]).content.decode("UTF-8")
        chapter_content = content_regex.findall(chapter_page)[0]
        chapter_content = newline_regex.sub('', chapter_content)
        chapter_content = chapter_content.replace("&lt;script&gt;readx();&lt;/script&gt;", "") 
        chapter_content = chapter_content.replace("\r\n", "")
        chapter_content = chapter_content.replace("。”", "”")
        chapter_content = chapter_content.lstrip()
        f.write(chapter[0])
        f.write("\n\n")
        nrlArray = chapter_content.split('。')
        for sentence in nrlArray:
            f.write("  " + sentence)
            f.write("\n\n")
        f.write("\n\n")

print("下载完毕！")</code></pre> 
<p>该代码主要实现了以下功能：</p> 
<ol><li> <p>获取小说的标题和章节目录 通过正则表达式编写匹配规则，可以获取小说的标题和章节目录。对于不同的小说网站，需要根据网站源代码中的标签和结构进行调整，以保证能够正确地提取信息。</p> </li><li> <p>下载每个章节的内容并写入文件 使用requests库向小说网站发送HTTP请求，获取每个章节的内容，并通过正则表达式进行解析和提取。最后将每个章节的标题和内容写入txt文档中。在写入之前，需要先进行一些文本清洗工作，例如去除多余的HTML标签、空格、回车等。</p> </li></ol> 
<p>此外，该代码还具有以下特点：</p> 
<ul><li>支持断点续传：在下载过程中，如果出现意外中断，下次执行代码时会从上一次中断的位置继续下载。</li><li>可扩展性强：只需根据不同的小说网站进行适当的修改，就能够批量下载其他小说。</li></ul> 
<p>总之，Python爬虫代码是一种非常强大的工具，可以帮助我们自动化地获取和处理数据。但需要注意的是，爬取网站内容可能涉及到版权等法律问题，应该遵守相关规定并谨慎使用</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9ae9e00c306f942b80cdf26df8d26863/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">elementplus全局美化滚动条vue</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9fad494ce011a38bbcaa0b1004effd6e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">EndNote导入文献出现带有大括号{}乱码的解决办法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>