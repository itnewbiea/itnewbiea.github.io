<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>GRU实现时间序列预测(PyTorch版) - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="GRU实现时间序列预测(PyTorch版)" />
<meta property="og:description" content="💥项目专栏：【深度学习时间序列预测案例】零基础入门经典深度学习时间序列预测项目实战（附代码&#43;数据集&#43;原理介绍）
文章目录 前言一、基于PyTorch搭建GRU模型实现风速时间序列预测二、时序数据集的制作三、数据归一化四、数据集加载器五、搭建GRU模型六、定义模型、损失函数、优化器七、模型训练八、可视化结果完整源码 前言 👑 最近很多订阅了🔥《深度学习100例》🔥的用户私信咨询基于深度学习实现时间序列的相关问题，为了能更清晰的说明，所以建立了本专栏专门记录基于深度学习的时间序列预测方法，帮助广大零基础用户达到轻松入门。
👑 本专栏适用人群：🚨🚨🚨深度学习初学者，刚刚接触时间序列的用户群体，专栏将具体讲解如何快速搭建深度学习模型用自己的数据集实现时间序列预测，快速让新手小白能够对基于深度学习方法进行时间序列预测有个基本的框架认识。
👑 本专栏整理了《深度学习时间序列预测案例》，内包含了各种不同的基于深度学习模型的时间序列预测方法，例如LSTM、GRU、CNN（一维卷积、二维卷积）、LSTM-CNN、BiLSTM、Self-Attention、LSTM-Attention、Transformer等经典模型，💥💥💥包含项目原理以及源码，每一个项目实例都附带有完整的代码&#43;数据集。
正在更新中~ ✨
🚨 我的项目环境：
平台：Windows10语言环境：python3.7编译器：PyCharmPyTorch版本：1.11.0 💥 项目专栏：【深度学习时间序列预测案例】零基础入门经典深度学习时间序列预测项目实战（附代码&#43;数据集&#43;原理介绍）
一、基于PyTorch搭建GRU模型实现风速时间序列预测 高精度、可靠的风速预报是气象学家面临的挑战。由对流风暴引起的强风，造成相当大的破坏(大规模森林破坏、停电、建筑物/房屋损坏等)。雷暴、龙卷风以及大冰雹、强风等对流事件是有可能扰乱日常生活的自然灾害，特别是在有利于对流启动的复杂地形上。即使是普通的对流事件也会产生强风，造成致命和昂贵的损失。因此，风速预测是一项重要的工作。
本篇文章我们采用了经典的循环神经网络 GRU 来对我们的时序数据建模处理，作为该专栏的第一篇文章，本篇将💎 详细介绍项目的每个实现部分以及细节处理，帮助新手小白快速建立起如何处理时序数据的框架。
二、时序数据集的制作 对于实现时间序列预测，我们使用的原始数据集往往不能够直接送入模型，需要进行预处理，这里说的预处理并不是处理空值、归一化这种处理方式，而是基于原始数据构建模型需要的时序数据集。
为了介绍什么是时序数据集，我们举个例子：
假设我们的原始数据如下：
第一列为时间刻度，代表每个样本的时间，第二列则为建模数据，由于数据集中只有一列特征，所以 WIND 既是输入的特征，又是模型的输出（预测值），由于是时序预测，那么我们就需要基于以前时间发生的数据来预测未来的数据。
DATE	WIND	1961-01-01	13.67 1961-01-02	11.50 1961-01-03	11.25 1961-01-04	8.63 1961-01-05	11.92 如果我们设置 timestep 为2的话（timestep就是时间窗口，用户滑动制作时序数据），那么我们将会产生如下的时序样本：
T1	T2 target 13.67	11.50	11.25 11.50	11.25	8.63 11.25	8.63	11.92 其中 T1 代表前2天的数据，T2代表前1天的数据，该数据维度为【3，2】，代表3个时序样本，2天数据（也就是timestep的值），这里发现时序数据集相对于原始数据集少了2个，这是因为前2个样本没有以前数据的参照，只有从第3个样本开始，他才有前两天的数据，所以我们的时序数据集的个数应该是 len(data)-timestep 个。
这个时序数据集的意思就是利用前2天的风速去预测未来1天的风速，所以我们需要基于原始数据来提取出这种的数据集，进而送入模型进行训练，我们可以根据我们的业务需求来调整 timestep 的大小，有些任务可能定为24，这个意思就是利用前24个样本去预测未来的样本，这种一般时间周期为24小时，这个数据集是针对单特征输入的，也就是整个数据中只有一个特征 WIND，这里说的一个特征是原始特征，也就是每天（每个样本）的特征维度。
如果每天的特征存在多个，这就是多变量输入，其实制作方法是一样的，只不过相对于单特征多了一个维度，举例：
DATE	WIND	TEMPERATURE	RAIN 1961-01-01	13." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/3c60485a49598d7e1574df748d13f515/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-24T20:22:35+08:00" />
<meta property="article:modified_time" content="2023-04-24T20:22:35+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GRU实现时间序列预测(PyTorch版)</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/92/e9/AfE5bQY8_o.jpg" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>💥项目专栏：<a href="https://weibaohang.blog.csdn.net/article/details/128585814" rel="nofollow">【深度学习时间序列预测案例】零基础入门经典深度学习时间序列预测项目实战（附代码+数据集+原理介绍）</a></p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_8" rel="nofollow">前言</a></li><li><a href="#PyTorchGRU_28" rel="nofollow">一、基于PyTorch搭建GRU模型实现风速时间序列预测</a></li><li><a href="#_33" rel="nofollow">二、时序数据集的制作</a></li><li><a href="#_129" rel="nofollow">三、数据归一化</a></li><li><a href="#_147" rel="nofollow">四、数据集加载器</a></li><li><a href="#GRU_177" rel="nofollow">五、搭建GRU模型</a></li><li><a href="#_304" rel="nofollow">六、定义模型、损失函数、优化器</a></li><li><a href="#_328" rel="nofollow">七、模型训练</a></li><li><a href="#_396" rel="nofollow">八、可视化结果</a></li><li><a href="#_427" rel="nofollow">完整源码</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_8"></a>前言</h2> 
<ul><li> <p>👑 最近很多订阅了🔥<code>《深度学习100例》</code>🔥的用户私信咨询基于深度学习实现时间序列的相关问题，为了能更清晰的说明，所以建立了本专栏<code>专门记录基于深度学习的时间序列预测方法</code>，帮助广大零基础用户达到轻松入门。</p> </li><li> <p>👑 本专栏适用人群：🚨🚨🚨<code>深度学习初学者</code>，<code>刚刚接触时间序列的用户群体</code>，专栏将具体讲解如何快速搭建深度学习模型用自己的数据集实现时间序列预测，<code>快速让新手小白能够对基于深度学习方法进行时间序列预测有个基本的框架认识</code>。</p> </li><li> <p>👑 本专栏整理了<code>《深度学习时间序列预测案例》</code>，内包含了各种不同的基于深度学习模型的时间序列预测方法，例如<code>LSTM、GRU、CNN（一维卷积、二维卷积）、LSTM-CNN、BiLSTM、Self-Attention、LSTM-Attention、Transformer等经典模型</code>，💥💥💥包含项目原理以及源码，每一个项目实例都附带有<code>完整的代码+数据集</code>。</p> </li></ul> 
<p>正在更新中~ ✨</p> 
<p>🚨 我的项目环境：</p> 
<ul><li>平台：Windows10</li><li>语言环境：python3.7</li><li>编译器：PyCharm</li><li>PyTorch版本：1.11.0</li></ul> 
<p>💥 项目专栏：<a href="https://weibaohang.blog.csdn.net/article/details/128585814" rel="nofollow">【深度学习时间序列预测案例】零基础入门经典深度学习时间序列预测项目实战（附代码+数据集+原理介绍）</a></p> 
<hr> 
<h2><a id="PyTorchGRU_28"></a>一、基于PyTorch搭建GRU模型实现风速时间序列预测</h2> 
<p>高精度、可靠的风速预报是气象学家面临的挑战。由对流风暴引起的强风，造成相当大的破坏(大规模森林破坏、停电、建筑物/房屋损坏等)。雷暴、龙卷风以及大冰雹、强风等对流事件是有可能扰乱日常生活的自然灾害，特别是在有利于对流启动的复杂地形上。即使是普通的对流事件也会产生强风，造成致命和昂贵的损失。因此，风速预测是一项重要的工作。</p> 
<p>本篇文章我们采用了经典的循环神经网络 <code>GRU</code> 来对我们的时序数据建模处理，作为该专栏的第一篇文章，本篇将💎 <code>详细介绍项目的每个实现部分以及细节处理，帮助新手小白快速建立起如何处理时序数据的框架</code>。</p> 
<h2><a id="_33"></a>二、时序数据集的制作</h2> 
<p>对于实现时间序列预测，我们使用的原始数据集往往不能够直接送入模型，需要进行预处理，这里说的预处理并不是处理空值、归一化这种处理方式，而是基于原始数据构建模型需要的时序数据集。</p> 
<p>为了介绍什么是时序数据集，我们举个例子：</p> 
<p>假设我们的原始数据如下：</p> 
<p>第一列为时间刻度，代表每个样本的时间，第二列则为建模数据，由于数据集中只有一列特征，所以 <code>WIND</code> 既是输入的特征，又是模型的输出（预测值），由于是时序预测，那么我们就需要基于以前时间发生的数据来预测未来的数据。</p> 
<pre><code>DATE		WIND						
1961-01-01	13.67
1961-01-02	11.50
1961-01-03	11.25
1961-01-04	8.63
1961-01-05	11.92
</code></pre> 
<p>如果我们设置 <code>timestep</code> 为2的话（timestep就是时间窗口，用户滑动制作时序数据），那么我们将会产生如下的时序样本：</p> 
<pre><code>T1		T2 		target
13.67	11.50	11.25
11.50	11.25	8.63
11.25	8.63	11.92
</code></pre> 
<p>其中 T1 代表前2天的数据，T2代表前1天的数据，该数据维度为【3，2】，代表3个时序样本，2天数据（也就是timestep的值），这里发现时序数据集相对于原始数据集少了2个，这是因为前2个样本没有以前数据的参照，只有从第3个样本开始，他才有前两天的数据，所以我们的时序数据集的个数应该是 <code>len(data)-timestep</code> 个。</p> 
<p>这个时序数据集的意思就是利用前2天的风速去预测未来1天的风速，所以我们需要基于原始数据来提取出这种的数据集，进而送入模型进行训练，我们可以根据我们的业务需求来调整 <code>timestep</code> 的大小，有些任务可能定为24，这个意思就是利用前24个样本去预测未来的样本，这种一般时间周期为24小时，这个数据集是针对单特征输入的，也就是整个数据中只有一个特征 <code>WIND</code>，这里说的一个特征是原始特征，也就是每天（每个样本）的特征维度。</p> 
<p>如果每天的特征存在多个，这就是多变量输入，其实制作方法是一样的，只不过相对于单特征多了一个维度，举例：</p> 
<pre><code>DATE		WIND		TEMPERATURE		RAIN
1961-01-01	13.67		12				134
1961-01-02	11.50		18				234
1961-01-03	11.25		13				157
1961-01-04	8.63		27				192
1961-01-05	11.92		5				260
</code></pre> 
<p>这个数据集中每天的特征维度为3，分别是 <code>风速</code>、<code>温度</code>、<code>降雨</code>，也就是用三个维度的向量来表示每个样本数据，假设我们的 <code>timestep</code> 还是2的话，我们的时序数据集如下：</p> 
<pre><code>T1					T2 					target
[13.67，12，134]	[11.50，18，234]	11.25
[11.50，18，234]	[11.25，13，157]	8.63
[11.25，13，157]	[8.63，27，192]		11.92
</code></pre> 
<p>与上面一维的数据一样，只不过多变量的数据维度会多一维，原来T1、T2对应每个位置是一个标量（一个数字），现在是用一个向量表示（将每天的样本特征封装到一个列表里），此时的数据维度为【3，2，3】。</p> 
<ul><li>第一个维度的值代表时序数据集的样本数</li><li>第二个维度代表窗口大小timestep</li><li>第三个维度代表每天的特征数</li></ul> 
<p>如果熟悉NLP的朋友，应该很容易理解，第二个维度相当于 <code>seq_len</code> ，也就是序列长度（一句话词的个数），第三个维度相当于 <code>feature_size</code> ，也就是每个词的向量编码长度。</p> 
<p>例如我爱你中国这句话就有5个词，所以 <code>seq_len=5</code>，如果我们用一个嵌入向量来表示每个词（假设为10）即 <code>feature_size=10</code>，这时我们就可以用一个【5，10】的矩阵来表示这句话，5个词，每个词向量的大小为10，如果我们有多句话，就可以在第一个位置添加一个维度，代表样本数。</p> 
<p>此处的时序数据和NLP文本方式同理，对于新手小白可能不好理解，不过没有关系。</p> 
<p>接下来就到了到底如何基于原始数据获得时序数据集呢，接下来基于本项目给出代码示例：</p> 
<pre><code class="prism language-python"><span class="token comment"># 形成训练数据，例如12345789 12-3、23-4、34-5</span>
<span class="token keyword">def</span> <span class="token function">split_data</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> timestep<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dataX <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 保存X</span>
    dataY <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 保存Y</span>

    <span class="token comment"># 将整个窗口的数据保存到X中，将未来一天保存到Y中</span>
    <span class="token keyword">for</span> index <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token operator">-</span> timestep<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dataX<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">[</span>index<span class="token punctuation">:</span> index <span class="token operator">+</span> timestep<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        dataY<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">[</span>index <span class="token operator">+</span> timestep<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    dataX <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>dataX<span class="token punctuation">)</span>
    dataY <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>dataY<span class="token punctuation">)</span>

    <span class="token comment"># 获取训练集大小</span>
    train_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> dataX<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 划分训练集、测试集</span>
    x_train <span class="token operator">=</span> dataX<span class="token punctuation">[</span><span class="token punctuation">:</span> train_size<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> timestep<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>
    y_train <span class="token operator">=</span> dataY<span class="token punctuation">[</span><span class="token punctuation">:</span> train_size<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    x_test <span class="token operator">=</span> dataX<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> timestep<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>
    y_test <span class="token operator">=</span> dataY<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token punctuation">[</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">]</span>
</code></pre> 
<p>本项目使用的数据集是风速预测数据集，特征共有8列，但本专栏只是初探，所以只使用了 <code>WIND</code> 这一列特征，也就单输入，关于数据集的介绍可以查看本专栏的该篇文章 <a href="https://blog.csdn.net/m0_47256162/article/details/128585962?spm=1001.2014.3001.5501">深度学习时间序列预测项目案例数据集介绍</a> 。</p> 
<p>有兴趣的小伙伴可以去Github上去下载第三方库采用掉包来处理数据，本代码是采用自己实现方式。</p> 
<h2><a id="_129"></a>三、数据归一化</h2> 
<p>数据的 <code>归一化和标准化</code> 是特征缩放(feature scaling)的方法，是数据预处理的关键步骤。不同评价指标往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据归一化/标准化处理，以解决数据指标之间的可比性。原始数据经过数据归一化/标准化处理后，<code>各指标处于同一数量级</code>，适合进行综合对比评价。</p> 
<p>常见的归一化方式有：<code>Min-Max</code>、<code>Z-Score</code>、<code>L2范数归一化</code>等等，对于本项目使用的是 <code>MIn-Max</code> 归一化，他会将所有的数据缩放到 <code>0-1</code> 区间，对于该操作可以手动实现，代码如下：</p> 
<pre><code class="prism language-python"><span class="token punctuation">(</span>df <span class="token operator">-</span> df<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>df<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> df<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>也可以使用 <code>sklearn</code> 中提供的 <code>MinMaxScaler()</code> 函数实现，代码如下：</p> 
<pre><code class="prism language-python">scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> scaler_model<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>有兴趣的小伙伴可以多多尝试不同的归一化方式，可以参照这篇文章进行尝试 <a href="https://www.jianshu.com/p/95a8f035c86c" rel="nofollow">归一化 （Normalization）、标准化 （Standardization）和中心化/零均值化 （Zero-centered）</a> 。</p> 
<h2><a id="_147"></a>四、数据集加载器</h2> 
<p>上面已经处理好了数据，获得了模型的输入数据，但是对于PyTorch的输入需要是Tensor类型数据，所以此时需要将上面获得的numpy.array类型数据转成Tensor类型数据。</p> 
<pre><code class="prism language-python">x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> split_data<span class="token punctuation">(</span>data<span class="token punctuation">,</span> config<span class="token punctuation">.</span>timestep<span class="token punctuation">,</span> config<span class="token punctuation">.</span>input_size<span class="token punctuation">)</span>

<span class="token comment"># 将数据转为tensor</span>
x_train_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
y_train_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
x_test_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
y_test_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
</code></pre> 
<p>现在数据集已经全部转成了Tensor类型数据，此时已经可以直接喂入模型进行使用，但是我们常常使用数据加载器，数据集如果小直接使用Tensor也都OK，但是如果我们的数据集过大，如果不适用数据加载器直接加载到内存中会导致内存爆炸，所以要分批次一点点加载数据。</p> 
<pre><code class="prism language-python"><span class="token comment"># 形成训练数据集</span>
train_data <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_train_tensor<span class="token punctuation">,</span> y_train_tensor<span class="token punctuation">)</span>
test_data <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_test_tensor<span class="token punctuation">,</span> y_test_tensor<span class="token punctuation">)</span>

<span class="token comment"># 将数据加载成迭代器</span>
train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>
                                           config<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
                                           <span class="token boolean">False</span><span class="token punctuation">)</span>

test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span>
                                          config<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
                                          <span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="GRU_177"></a>五、搭建GRU模型</h2> 
<p>接下来就到了该项目的重中之重，构建我们的深度学习模型，本项目使用的模型是经典的循环神经网络GRU，由于此专栏注重实战讲解，所以关于GRU模型的原理词处就不赘述了，有兴趣的小伙伴可以去百度进行了解，这里你只需要知道GRU是一个深度学习模型，能够处理时序数据，获取时间维度上的关联信息。</p> 
<p><code>该图为PyTorch官方文档给出的GRU模型解释：</code></p> 
<p><img src="https://images2.imgbox.com/42/ae/1UwVZkgz_o.png" alt="在这里插入图片描述"></p> 
<p>为了能够使用GRU搭建模型处理我们的时序数据，我们需要GRU模型的输入和输出是什么，对于初学者了解这个很重要，它能够快速帮助我们在自己的数据集上调试运行。</p> 
<p><code>该图为GRU模型的参数：</code></p> 
<p><img src="https://images2.imgbox.com/4d/f8/neQOVUlg_o.png" alt="在这里插入图片描述"></p> 
<ul><li>input_size：每个时间点的特征维度，就是对应上面我们说的每天的特征维度是3还是1</li><li>hidden_size：GRU内部隐层的维度大小</li><li>num_layers：GRU的层数，默认为1</li><li>bias：是否在隐层中添加偏置bias，默认为True</li><li>batch_first：如果设置为True，GRU的输入第一个维度为批次大小，也就是【batch_size，seq_len，feature_size】，如果为False，则模型的输入Tensor的维度为【seq_len，batch_size，feature_size】，默认为False</li><li>dropout：是否采用dropout</li><li>bidirectional：是否采用双向GRU模型，默认单向为False</li></ul> 
<p><code>该图为GRU模型的输入：</code></p> 
<p><img src="https://images2.imgbox.com/35/41/eXLmTpGn_o.png" alt="在这里插入图片描述"></p> 
<p>GRU的模型输入Tensor的维度为【batch_size，seq_len，feature_size】，其实也可以是【seq_len，batch_size，feature_size】，但是我们常常将批次大小作为第一个维度传入，容易理解，本项目采用的输入维度为第一种方式，批次为先。</p> 
<p>此处有小伙伴会存在一个问题，模型的输入还有一个 <code>h_0</code> 作为输入，如果了解GRU原理的同学就可以知道这个输入变量是干嘛的，就是模型初始的隐层状态，对于这个变量可传可不传，如果不传则默认为0，有兴趣了解这个参数到底传入还是不传入可以参考这篇文章 <a href="https://blog.csdn.net/weixin_39518984/article/details/109548739">对LSTM中每个batch都初始化隐含层的理解</a> ，本项目传入的隐层状态是传入的，但是传入的参数是以0进行填充，和默认不传入一致，只是为了让小伙伴了解这个参数是怎么传入的。</p> 
<pre><code class="prism language-python"><span class="token keyword">if</span> hidden <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
	h_0 <span class="token operator">=</span> x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>new<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    h_0 <span class="token operator">=</span> hidden
output<span class="token punctuation">,</span> h_0 <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h_0<span class="token punctuation">)</span>
</code></pre> 
<p><code>该图为GRU模型的输出：</code></p> 
<p><img src="https://images2.imgbox.com/9f/58/EUYq2fsT_o.png" alt="在这里插入图片描述"><br> GRU模型的输出有两个，一个输出的是模型的最终输出，也就是我们想要的输出，另外一个输出是模型的隐藏状态，对于本项目来说我们并不需要他。</p> 
<p>对于这两个输出的维度一定要知道，首先是我们需要的输出 <code>output</code>，该输出的维度为【batch_size，seq_len，D * hidden_size】，此处的D就是我们是否采用双向GRU，如果设置 <code>bidirectional=True</code>，则D=2，否则D=1，<code>hidden_size</code> 就是GRU中间隐层的维度大小。</p> 
<p>对于<code>h_n</code>的输出我们简答了解一下就好，因为我们不会对他进行处理。</p> 
<p>为了能够理解GRU的输入和输出，举个例子说明：</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

output<span class="token punctuation">,</span> h_0 <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre> 
<p>我们定义了输入向量，该向量的维度为【32，5，3】，分别代表【批次大小，时间片，特征大小】，用语言叙述就是32个样本，然后用5天的数据去未来1天的数据，每天的特征维度为3。</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>h_0<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>我们可以看到 <code>output</code> 的输出维度为【batch_size，seq_len，D * hidden_size】，由于我们的GRU是单向的，所以D=1。</p> 
<p>如果设置为双向：</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

output<span class="token punctuation">,</span> h_0 <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>接下来就到了使用PyTorch搭建GRU模型，代码如下：</p> 
<pre><code class="prism language-python"><span class="token comment"># 定义GRU网络</span>
<span class="token keyword">class</span> <span class="token class-name">GRU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> feature_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GRU<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size  <span class="token comment"># 隐层大小</span>
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers  <span class="token comment"># gru层数</span>
        <span class="token comment"># feature_size为特征维度，就是每个时间点对应的特征数量，这里为1</span>
        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>feature_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> hidden<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># 获取批次大小</span>
        
        <span class="token comment"># 初始化隐层状态</span>
        <span class="token keyword">if</span> hidden <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            h_0 <span class="token operator">=</span> x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>new<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            h_0 <span class="token operator">=</span> hidden
            
        <span class="token comment"># GRU运算</span>
        output<span class="token punctuation">,</span> h_0 <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h_0<span class="token punctuation">)</span>
        
        <span class="token comment"># 获取GRU输出的维度信息</span>
        batch_size<span class="token punctuation">,</span> timestep<span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> output<span class="token punctuation">.</span>shape  
            
        <span class="token comment"># 将output变成 batch_size * timestep, hidden_dim</span>
        output <span class="token operator">=</span> output<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        
        <span class="token comment"># 全连接层</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>output<span class="token punctuation">)</span>  <span class="token comment"># 形状为batch_size * timestep, 1</span>
        
        <span class="token comment"># 转换维度，用于输出</span>
        output <span class="token operator">=</span> output<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>timestep<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 我们只需要返回最后一个时间片的数据即可</span>
        <span class="token keyword">return</span> output<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre> 
<p>本项目的模型采用的是GRU+全连接层，有小伙伴可能有一个问题就是搭建模型的过程中有句代码就是 <code>output = output.reshape(timestep, batch_size, -1)</code>，它的目的就是将我们的输出数据的第一个维度变成时间片。</p> 
<p>如果我们设置 <code>timestep=5</code>，那么我们的 <code>output</code> 的输出就为【5，32，1】，作为模型输出我们只需要最后一个时间片的数据作为输出即可，因为GRU是处理时序数据的，最后一个时间片包含了前面所有时间片的信息（T1，T2…）。</p> 
<p>感兴趣的小伙伴可以尝试不返回最后一个时间片的数据作为输出，可以将每个时间片的数据池化再进行输出（例如将每个时间片的数据取平均、取最大等操作），也就是将5个【32，1】维度的张量取平均再进行输出，不过这样会提高运算时间，至于模型效果会不会提高，需要自己在自己的数据集上面尝试，希望小伙伴初学时可以多多尝试。</p> 
<h2><a id="_304"></a>六、定义模型、损失函数、优化器</h2> 
<p>为了训练数据，首先定义GRU模型，然后再定义对应的损失函数，由于我们这里是风速预测，显然是个回归问题，所以采用回归问题常用的 <code>MESLoss()</code>，如果可以的话，可以自定义损失函数，针对自己的项目需求定义对应的损失函数。</p> 
<p>对于优化器来讲，使用的也是目前常用的 <code>Adam</code> 优化器，对于新手来讲也可以多多尝试其它的优化器，比如 <code>SGD</code>、<code>RMSprop</code>等，对于优化器的选择，可以参考这篇文章 <a href="https://zhuanlan.zhihu.com/p/527908842" rel="nofollow">Pytorch 30种优化器总结</a> 。</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> GRU<span class="token punctuation">(</span>config<span class="token punctuation">.</span>feature_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> config<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span>  <span class="token comment"># 定义GRU网络</span>
loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 定义损失函数</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>  <span class="token comment"># 定义优化器</span>
</code></pre> 
<p>在定义优化器的同时，我们需要将模型的参数传入，可以通过 <code>model.parameters()</code> 获得，如果模型中有些层不需要训练，我们可以将参数冻结，这时使用优化器训练模型时，该层参数就不会被修改，实现该目的可以使用以下函数：</p> 
<pre><code class="prism language-python"><span class="token comment"># 冻结模型参数</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>
</code></pre> 
<p>另外多说一点，有些复杂的模型需要定义多个优化器，也就是模型中不同的层或者参数需要使用不同的优化策略进行优化，例如本项目中我们的模型包含了GRU层和全连接层，我们可以定义 <code>optimizer_gru = torch.optim.Adam()</code> 和 <code>optimizer_fc = torch.optim.RMSprop()</code>，这时两个层可以使用不同的学习率或者权重衰减方式进行训练，但这是后话， 对于新手不需要搞这么复杂，用一个优化器训练模型即可，如果有能力可以自己尝试以下，使用多个优化器来训练自己的模型。</p> 
<p>另外一点，如果我们需要进行权重衰减，可以在定义优化器的同时传入 <code>weight_decay</code> ，有兴趣的同学可以参考这篇文章进行了解 <a href="https://blog.csdn.net/qq_51491920/article/details/125537434">权重衰退</a> 。</p> 
<h2><a id="_328"></a>七、模型训练</h2> 
<p>下面代码是相对标准的模型训练框架，涵盖训练集和测试集的验证，该部分用户可以自己DIY设计，比如统计相关的指标信息（整体损失、epoch损失等）或者打印信息等，这些都可以按照自己的喜好进行调整。</p> 
<p>对于模型验证部分，添不添加都OK，但是一般我们是会加上的，因为防止过拟合，让模型有更好的泛化性、鲁棒性，模型训练完成需要在测试集上进行验证，如果损失下降，则保留此轮训练的模型。</p> 
<pre><code class="prism language-python"><span class="token comment"># 模型训练</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    running_loss <span class="token operator">=</span> <span class="token number">0</span>
    train_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>  <span class="token comment"># 形成进度条</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_bar<span class="token punctuation">:</span>
        x_train<span class="token punctuation">,</span> y_train <span class="token operator">=</span> data  <span class="token comment"># 解包迭代器中的X和Y</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        y_train_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>y_train_pred<span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_bar<span class="token punctuation">.</span>desc <span class="token operator">=</span> <span class="token string">"train epoch[{}/{}] loss:{:.3f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                                                                 config<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span>
                                                                 loss<span class="token punctuation">)</span>

    <span class="token comment"># 模型验证</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    test_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        test_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>
        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_bar<span class="token punctuation">:</span>
            x_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> data
            y_test_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
            test_loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>y_test_pred<span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> test_loss <span class="token operator">&lt;</span> config<span class="token punctuation">.</span>best_loss<span class="token punctuation">:</span>
        config<span class="token punctuation">.</span>best_loss <span class="token operator">=</span> test_loss
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span>
</code></pre> 
<p>上述代码理解相对简单，就不多赘述了，有同学会好奇 <code>train_bar = tqdm(train_loader)</code> 这句代码是做什么的，对于模型训练来将不是必须的，他只是用来形成进度条的，帮助用户了解当前模型的训练进度，效果如下：</p> 
<pre><code class="prism language-python">train epoch<span class="token punctuation">[</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.017</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">01</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">83</span><span class="token punctuation">.</span>10it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">360</span><span class="token punctuation">.</span>01it<span class="token operator">/</span>s<span class="token punctuation">]</span>
train epoch<span class="token punctuation">[</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.014</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">02</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">.</span>06it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">404</span><span class="token punctuation">.</span>49it<span class="token operator">/</span>s<span class="token punctuation">]</span>
train epoch<span class="token punctuation">[</span><span class="token number">3</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.014</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">01</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">.</span>92it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">276</span><span class="token punctuation">.</span>92it<span class="token operator">/</span>s<span class="token punctuation">]</span>
train epoch<span class="token punctuation">[</span><span class="token number">4</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.014</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">01</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">.</span>16it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">375</span><span class="token punctuation">.</span>53it<span class="token operator">/</span>s<span class="token punctuation">]</span>
train epoch<span class="token punctuation">[</span><span class="token number">5</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.014</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">01</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">77</span><span class="token punctuation">.</span>95it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">399</span><span class="token punctuation">.</span>98it<span class="token operator">/</span>s<span class="token punctuation">]</span>
train epoch<span class="token punctuation">[</span><span class="token number">6</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.014</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">01</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">.</span>74it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">404</span><span class="token punctuation">.</span>50it<span class="token operator">/</span>s<span class="token punctuation">]</span>
train epoch<span class="token punctuation">[</span><span class="token number">7</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.014</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">01</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">72</span><span class="token punctuation">.</span>54it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">370</span><span class="token punctuation">.</span>81it<span class="token operator">/</span>s<span class="token punctuation">]</span>
train epoch<span class="token punctuation">[</span><span class="token number">8</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.014</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">02</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">.</span>67it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">237</span><span class="token punctuation">.</span>74it<span class="token operator">/</span>s<span class="token punctuation">]</span>
train epoch<span class="token punctuation">[</span><span class="token number">9</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.014</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">02</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">.</span>72it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">303</span><span class="token punctuation">.</span>73it<span class="token operator">/</span>s<span class="token punctuation">]</span>
train epoch<span class="token punctuation">[</span><span class="token number">10</span><span class="token operator">/</span><span class="token number">10</span><span class="token punctuation">]</span> loss<span class="token punctuation">:</span><span class="token number">0.014</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">141</span><span class="token operator">/</span><span class="token number">141</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">02</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">.</span>28it<span class="token operator">/</span>s<span class="token punctuation">]</span>
<span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>█████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">36</span><span class="token operator">/</span><span class="token number">36</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">292</span><span class="token punctuation">.</span>70it<span class="token operator">/</span>s<span class="token punctuation">]</span>
Finished Training
</code></pre> 
<p>对于模型损失的指标，用户可以手动保存，就是将每轮的损失值保存到列表中或者其它处理，也可以掉包来实现，在pytorch中有个 <code>meter</code> 库可以实现这个目的，有兴趣的同学可以参考这篇文章 <a href="https://blog.csdn.net/m0_47256162/article/details/127848579">pytorch中meter.ClassErrorMeter()使用方法</a> 。</p> 
<h2><a id="_396"></a>八、可视化结果</h2> 
<p>为了查看模型的训练效果，我们采用可视化的方式来对比真实值和预测值的差距，对于绘图，我们采用了经典的可视化库 <code>matplotlib</code> ，可视化代码如下：</p> 
<pre><code class="prism language-python"><span class="token comment"># 绘制结果</span>
plot_size <span class="token operator">=</span> <span class="token number">200</span> <span class="token comment"># 绘制前200个样本</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span><span class="token punctuation">(</span>model<span class="token punctuation">(</span>x_train_tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> plot_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"b"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>y_train_tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> plot_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

y_test_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_test_tensor<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>y_test_pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> plot_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"b"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>y_test_tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> plot_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>解释下上述代码，首先定义了 <code>plot_size</code> ，这个变量是用来绘制样本数的，因为我们的数据集中存在几千个样本，如果全部绘制，会导致曲线过于拥挤，为了更好的观察拟合效果，所以只绘制其中一小部分。</p> 
<p>还有一处需要说明的是 <code>scaler.inverse_transform()</code> ，由于我们的数据集在训练之前进行了归一化，所以在绘制曲线时需要将预测结果进行反归一化，恢复到原来的量纲区间。</p> 
<p><code>训练集效果：</code></p> 
<p><img src="https://images2.imgbox.com/92/43/IKl1dFKx_o.png" alt="在这里插入图片描述"></p> 
<p><code>测试集效果：</code></p> 
<p><img src="https://images2.imgbox.com/ad/b5/rBvE8tYQ_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_427"></a>完整源码</h2> 
<p>注意🚨🚨🚨：由于是针对于新手小白入门的系列专栏，所以代码并没有采用开发大型项目的方式，而是python单文件实现，这样能够帮助新人一键复制调试运行，不需要理解复杂的项目构造，另外一点就是由于是帮助新人理解时间序列预测基本过程，所以源码仅包含了时间序列预测的基本框架结构，有些地方实现略有简陋，有能力的小伙伴可以根据自己的能力在此基础上进行修改，例如尝试更深层次的模型结构，尝试更多的参数，以及进行分文件编写（模型训练、模型测试、定义模型、绘制图像）达到项目开发流程。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> tushare <span class="token keyword">as</span> ts
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span class="token punctuation">,</span> MinMaxScaler
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> TensorDataset
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm

<span class="token keyword">class</span> <span class="token class-name">Config</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    data_path <span class="token operator">=</span> <span class="token string">'./data/wind_dataset.csv'</span>
    timestep <span class="token operator">=</span> <span class="token number">1</span>  <span class="token comment"># 时间步长，就是利用多少时间窗口</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span>  <span class="token comment"># 批次大小</span>
    feature_size <span class="token operator">=</span> <span class="token number">1</span>  <span class="token comment"># 每个步长对应的特征数量，这里只使用1维，每天的风速</span>
    hidden_size <span class="token operator">=</span> <span class="token number">256</span>  <span class="token comment"># 隐层大小</span>
    output_size <span class="token operator">=</span> <span class="token number">1</span>  <span class="token comment"># 由于是单输出任务，最终输出层大小为1，预测未来1天风速</span>
    num_layers <span class="token operator">=</span> <span class="token number">2</span>  <span class="token comment"># gru的层数</span>
    epochs <span class="token operator">=</span> <span class="token number">10</span> <span class="token comment"># 迭代轮数</span>
    best_loss <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment"># 记录损失</span>
    learning_rate <span class="token operator">=</span> <span class="token number">0.0003</span> <span class="token comment"># 学习率</span>
    model_name <span class="token operator">=</span> <span class="token string">'gru'</span> <span class="token comment"># 模型名称</span>
    save_path <span class="token operator">=</span> <span class="token string">'./{}.pth'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>model_name<span class="token punctuation">)</span> <span class="token comment"># 最优模型保存路径</span>

config <span class="token operator">=</span> Config<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 1.加载时间序列数据</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>config<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> index_col <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>


<span class="token comment"># 2.将数据进行标准化</span>
scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
scaler_model <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> scaler_model<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'WIND'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 形成训练数据，例如12345789 12-3456789</span>
<span class="token keyword">def</span> <span class="token function">split_data</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> timestep<span class="token punctuation">,</span> feature_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dataX <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 保存X</span>
    dataY <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 保存Y</span>

    <span class="token comment"># 将整个窗口的数据保存到X中，将未来一天保存到Y中</span>
    <span class="token keyword">for</span> index <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token operator">-</span> timestep<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dataX<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">[</span>index<span class="token punctuation">:</span> index <span class="token operator">+</span> timestep<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        dataY<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">[</span>index <span class="token operator">+</span> timestep<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    dataX <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>dataX<span class="token punctuation">)</span>
    dataY <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>dataY<span class="token punctuation">)</span>

    <span class="token comment"># 获取训练集大小</span>
    train_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> dataX<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 划分训练集、测试集</span>
    x_train <span class="token operator">=</span> dataX<span class="token punctuation">[</span><span class="token punctuation">:</span> train_size<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> timestep<span class="token punctuation">,</span> feature_size<span class="token punctuation">)</span>
    y_train <span class="token operator">=</span> dataY<span class="token punctuation">[</span><span class="token punctuation">:</span> train_size<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    x_test <span class="token operator">=</span> dataX<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> timestep<span class="token punctuation">,</span> feature_size<span class="token punctuation">)</span>
    y_test <span class="token operator">=</span> dataY<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token punctuation">[</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">]</span>

<span class="token comment"># 3.获取训练数据   x_train: 170000,30,1   y_train:170000,7,1</span>
x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> split_data<span class="token punctuation">(</span>data<span class="token punctuation">,</span> config<span class="token punctuation">.</span>timestep<span class="token punctuation">,</span> config<span class="token punctuation">.</span>feature_size<span class="token punctuation">)</span>

<span class="token comment"># 4.将数据转为tensor</span>
x_train_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
y_train_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
x_test_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
y_test_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 5.形成训练数据集</span>
train_data <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_train_tensor<span class="token punctuation">,</span> y_train_tensor<span class="token punctuation">)</span>
test_data <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_test_tensor<span class="token punctuation">,</span> y_test_tensor<span class="token punctuation">)</span>

<span class="token comment"># 6.将数据加载成迭代器</span>
train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>
                                           config<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
                                           <span class="token boolean">False</span><span class="token punctuation">)</span>

test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span>
                                          config<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
                                          <span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># 7.定义GRU网络</span>
<span class="token keyword">class</span> <span class="token class-name">GRU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> feature_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GRU<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size  <span class="token comment"># 隐层大小</span>
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers  <span class="token comment"># gru层数</span>
        <span class="token comment"># feature_size为特征维度，就是每个时间点对应的特征数量，这里为1</span>
        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>feature_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> hidden<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># 获取批次大小</span>
        
        <span class="token comment"># 初始化隐层状态</span>
        <span class="token keyword">if</span> hidden <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            h_0 <span class="token operator">=</span> x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>new<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            h_0 <span class="token operator">=</span> hidden
            
        <span class="token comment"># GRU运算</span>
        output<span class="token punctuation">,</span> h_0 <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h_0<span class="token punctuation">)</span>
        
        <span class="token comment"># 获取GRU输出的维度信息</span>
        batch_size<span class="token punctuation">,</span> timestep<span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> output<span class="token punctuation">.</span>shape  
            
        <span class="token comment"># 将output变成 batch_size * timestep, hidden_dim</span>
        output <span class="token operator">=</span> output<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        
        <span class="token comment"># 全连接层</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>output<span class="token punctuation">)</span>  <span class="token comment"># 形状为batch_size * timestep, 1</span>
        
        <span class="token comment"># 转换维度，用于输出</span>
        output <span class="token operator">=</span> output<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>timestep<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 我们只需要返回最后一个时间片的数据即可</span>
        <span class="token keyword">return</span> output<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

model <span class="token operator">=</span> GRU<span class="token punctuation">(</span>config<span class="token punctuation">.</span>feature_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> config<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span>  <span class="token comment"># 定义GRU网络</span>
loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 定义损失函数</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>  <span class="token comment"># 定义优化器</span>

<span class="token comment"># 8.模型训练</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    running_loss <span class="token operator">=</span> <span class="token number">0</span>
    train_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>  <span class="token comment"># 形成进度条</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_bar<span class="token punctuation">:</span>
        x_train<span class="token punctuation">,</span> y_train <span class="token operator">=</span> data  <span class="token comment"># 解包迭代器中的X和Y</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        y_train_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>y_train_pred<span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_bar<span class="token punctuation">.</span>desc <span class="token operator">=</span> <span class="token string">"train epoch[{}/{}] loss:{:.3f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                                                                 config<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span>
                                                                 loss<span class="token punctuation">)</span>

    <span class="token comment"># 模型验证</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    test_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        test_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>
        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_bar<span class="token punctuation">:</span>
            x_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> data
            y_test_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
            test_loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>y_test_pred<span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> test_loss <span class="token operator">&lt;</span> config<span class="token punctuation">.</span>best_loss<span class="token punctuation">:</span>
        config<span class="token punctuation">.</span>best_loss <span class="token operator">=</span> test_loss
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span>

<span class="token comment"># 9.绘制结果</span>
plot_size <span class="token operator">=</span> <span class="token number">200</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span><span class="token punctuation">(</span>model<span class="token punctuation">(</span>x_train_tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> plot_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"b"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>y_train_tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> plot_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

y_test_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_test_tensor<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>y_test_pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> plot_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"b"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>y_test_tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> plot_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/cccecc5fd53c4ae05ede0ecc33f33a8c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">控制台输出vue实例</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/eb0283157af7a372481f07d99b1983cd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">pandas中对df进行多条件筛选</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>