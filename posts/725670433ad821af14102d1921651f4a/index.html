<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>斯坦福大学-自然语言处理入门 笔记 第七课 情感分析（sentiment analysis） - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="斯坦福大学-自然语言处理入门 笔记 第七课 情感分析（sentiment analysis）" />
<meta property="og:description" content="一、情感分析简述 情感分析（sentiment analysis），又叫意见抽取（opinion extraction），意见挖掘（opinion mining）,情感挖掘（sentiment mining）以及主观分析（subjectivity analysis）。
情感分析的应用领域非常广泛
情感分析是对态度的研究，具体可以分解为：
按照复杂程度，可以把情感分类分为三类 简单任务：判断文本的任务是消极的还是积极的更复杂：把对文本的态度按1-5打分进阶：研究来源（source）、对象（target）以及复杂的态度类型 二、一个基本算法 1、一个情感分类任务 判断IMDB的电影评论是积极的还是消极的数据：Polarity Data 2.0 http://www.cs.cornell.edu/people/pabo/movie-review-data基本步骤 分词（tokenizaiton）特征抽取利用分类模型分类（朴素贝叶斯，SVM，MaxEnt) 2、情感分词（tokenizaiton）问题 处理HTML和XML的标记Twitter的标记（名字，tags）大写（保留全部大写的单词）电话和日期表情（下面是一些正则表达）
一些有用的代码
http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py 3、特征抽取 否定的抽取： I didn‘ t like this movie vs I really like this movie 解决方案：在否定词和接下来的标点之间的每个词都加上NOT_,形如下面
抽取哪些单词？ 只使用形容词还是使用全部单词？ 全部的单词表现更好，至少在这个数据集上是这样 4、分类：二值化（binarized (Boolean feature)）多元朴素贝叶斯 基本思想：主要针对情感（或者可能是其他文本分类领域）。单词是否出现比单词出现的频率更为重要，所以这个算法的特别之处在于对出现的单词都记为1。具体算法和朴素贝叶斯一致，唯一的变动是在计算P（w|c）的时候，先删除每篇文档里的重复的单词，只保留一个。
这种算法会比原来的朴素贝叶斯效果更好（这个算法和Mutivariate Bernoulli Naive Bayes是不一样的，后者在文本问题上效果不好)也可以使用其他的改进：log(freq(w))(单词的count取对数以后就会小很多） 5、交叉检验（cross-validation） 把数据集分成十份fold（每一份中类别比例相同）对每一份（fold），选择这一份作为临时的测试集，在另外九份上训练模型，并在测试集上计算模型效果。给出十份效果的平均数 6、评论难以分类的原因 三、情感词典（sentiment Lexicons） 1、一些可用的情感词典 根据相关的研究，我们发现除了sentiword，其他情感词典的相似度都很高。
2、 分析IMDB中每个词的极性（polarity） 比较单词和电影打分之间的相关性，考虑到可比性，计算的公式如下：
3、逻辑否定词 根据pott的研究，更多的否定词会出现在消极情绪中
四、情感词典训练 1、利用半监督学习词典 使用少量的信息，包括一些标注的样本和一些人工建立的模式（pattern），通过bootstrap的方法来训练词典。
2、Hatzivassiloglou和Mckeown的算法（用于单词词典的构造） 关键思想：用and相连的两个词，极性相同；用but相连的两个词，则反之。第一步：标记种子集（seed set） 1336个形容词，657个正向词，679个负向词 第二步：利用关键思想拓展种子集
第三步：利用监督分类算法计算单词对的极性相似程度（polarity similarity），结果如下图。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/725670433ad821af14102d1921651f4a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-10-17T19:23:13+08:00" />
<meta property="article:modified_time" content="2018-10-17T19:23:13+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">斯坦福大学-自然语言处理入门 笔记 第七课 情感分析（sentiment analysis）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>一、情感分析简述</h2> 
<p>情感分析（sentiment analysis），又叫意见抽取（opinion extraction），意见挖掘（opinion mining）,情感挖掘（sentiment mining）以及主观分析（subjectivity analysis）。</p> 
<ul><li>情感分析的应用领域非常广泛<br> <img src="https://images2.imgbox.com/dc/ef/yUCuky0d_o.png" alt="在这里插入图片描述"></li><li>情感分析是对态度的研究，具体可以分解为：<br> <img src="https://images2.imgbox.com/29/da/lZOYXTrJ_o.png" alt="在这里插入图片描述"></li><li>按照复杂程度，可以把情感分类分为三类 
  <ul><li>简单任务：判断文本的任务是消极的还是积极的</li><li>更复杂：把对文本的态度按1-5打分</li><li>进阶：研究来源（source）、对象（target）以及复杂的态度类型</li></ul> </li></ul> 
<h2><a id="_10"></a>二、一个基本算法</h2> 
<h3><a id="1_11"></a>1、一个情感分类任务</h3> 
<ul><li>判断IMDB的电影评论是积极的还是消极的</li><li>数据：Polarity Data 2.0 <a href="http://www.cs.cornell.edu/people/pabo/movie-review-data" rel="nofollow">http://www.cs.cornell.edu/people/pabo/movie-review-data</a></li><li>基本步骤 
  <ul><li>分词（tokenizaiton）</li><li>特征抽取</li><li>利用分类模型分类（朴素贝叶斯，SVM，MaxEnt)</li></ul> </li></ul> 
<h3><a id="2tokenizaiton_18"></a>2、情感分词（tokenizaiton）问题</h3> 
<ul><li>处理HTML和XML的标记</li><li>Twitter的标记（名字，tags）</li><li>大写（保留全部大写的单词）</li><li>电话和日期</li><li>表情（下面是一些正则表达）<br> <img src="https://images2.imgbox.com/2d/f6/w0xyBNHQ_o.png" alt="在这里插入图片描述"></li><li>一些有用的代码<br> <a href="http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py" rel="nofollow">http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py</a></li></ul> 
<h3><a id="3_27"></a>3、特征抽取</h3> 
<ul><li>否定的抽取： I didn‘ t like this movie vs I really like this movie 
  <ul><li>解决方案：在否定词和接下来的标点之间的每个词都加上NOT_,形如下面<br> <img src="https://images2.imgbox.com/d5/1f/8ikcjCTN_o.png" alt="在这里插入图片描述"></li></ul> </li><li>抽取哪些单词？ 
  <ul><li>只使用形容词</li><li>还是使用全部单词？ 
    <ul><li>全部的单词表现更好，至少在这个数据集上是这样</li></ul> </li></ul> </li></ul> 
<h3><a id="4binarized_Boolean_feature_35"></a>4、分类：二值化（binarized (Boolean feature)）多元朴素贝叶斯</h3> 
<ul><li>基本思想：主要针对情感（或者可能是其他文本分类领域）。单词是否出现比单词出现的频率更为重要，所以这个算法的特别之处在于对出现的单词都记为1。</li><li>具体算法和朴素贝叶斯一致，唯一的变动是在计算P（w|c）的时候，先删除每篇文档里的重复的单词，只保留一个。<br> <img src="https://images2.imgbox.com/97/6e/UORRSXwu_o.png" alt="在这里插入图片描述"></li><li>这种算法会比原来的朴素贝叶斯效果更好（这个算法和Mutivariate Bernoulli Naive Bayes是不一样的，后者在文本问题上效果不好)</li><li>也可以使用其他的改进：log(freq(w))(单词的count取对数以后就会小很多）</li></ul> 
<h3><a id="5crossvalidation_41"></a>5、交叉检验（cross-validation）</h3> 
<ul><li>把数据集分成十份fold（每一份中类别比例相同）</li><li>对每一份（fold），选择这一份作为临时的测试集，在另外九份上训练模型，并在测试集上计算模型效果。</li><li>给出十份效果的平均数</li></ul> 
<h3><a id="6_45"></a>6、评论难以分类的原因</h3> 
<p><img src="https://images2.imgbox.com/91/8e/F3nAyavW_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b3/3d/oD6IegfT_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="sentiment_Lexicons_48"></a>三、情感词典（sentiment Lexicons）</h2> 
<h3><a id="1_49"></a>1、一些可用的情感词典</h3> 
<p><img src="https://images2.imgbox.com/ef/54/ztRYSlgM_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/47/ef/uRCcsjmI_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/76/f1/zbtE4vhC_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/9c/c1/pVpfDRgM_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/09/2a/PDjbnf7n_o.png" alt="在这里插入图片描述"></p> 
<ul><li>根据相关的研究，我们发现除了sentiword，其他情感词典的相似度都很高。<br> <img src="https://images2.imgbox.com/88/15/JnYUMnJv_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="2_IMDBpolarity_57"></a>2、 分析IMDB中每个词的极性（polarity）</h3> 
<p>比较单词和电影打分之间的相关性，考虑到可比性，计算的公式如下：<br> <img src="https://images2.imgbox.com/8c/5a/ELREBmt2_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a7/2c/ef5Nlklk_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="3_61"></a>3、逻辑否定词</h3> 
<p>根据pott的研究，更多的否定词会出现在消极情绪中<br> <img src="https://images2.imgbox.com/c3/c8/jT3QanG1_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_64"></a>四、情感词典训练</h2> 
<h3><a id="1_65"></a>1、利用半监督学习词典</h3> 
<p>使用少量的信息，包括一些标注的样本和一些人工建立的模式（pattern），通过bootstrap的方法来训练词典。</p> 
<h3><a id="2HatzivassiloglouMckeown_67"></a>2、Hatzivassiloglou和Mckeown的算法（用于单词词典的构造）</h3> 
<ul><li>关键思想：用and相连的两个词，极性相同；用but相连的两个词，则反之。</li><li>第一步：标记种子集（seed set） 
  <ul><li>1336个形容词，657个正向词，679个负向词</li></ul> </li><li>第二步：利用关键思想拓展种子集<br> <img src="https://images2.imgbox.com/4e/24/HKykx18U_o.png" alt="在这里插入图片描述"></li><li>第三步：利用监督分类算法计算单词对的极性相似程度（polarity similarity），结果如下图。<br> <img src="https://images2.imgbox.com/d6/e2/qsXPzRPr_o.png" alt="在这里插入图片描述"></li><li>第四步：利用聚类方法把图分为两个部分<br> <img src="https://images2.imgbox.com/a7/77/5HtDNmdR_o.png" alt="在这里插入图片描述"></li><li>最终的结果：确实会出现不准确的情况<br> <img src="https://images2.imgbox.com/61/9b/Npnq9Pi6_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="3Turney_79"></a>3、Turney算法（用于词组词典的构造）</h3> 
<ul><li>第一步：根据下面的规则，抽取两字词组<br> <img src="https://images2.imgbox.com/e5/61/Pl4GSbqn_o.png" alt="在这里插入图片描述"></li><li>第二步：学习每个词组的词性 
  <ul><li>基本思想：积极词组会和“excellent”更多的一起出现；消极词组会和“poor”更多的一起出现</li><li>度量一起出现的指标：PMI（pointwise mutual information)，表示x和y同时出现的概率，比上他们如果独立的时候同时出现的概率。<br> <img src="https://images2.imgbox.com/0e/ed/C7kAKykT_o.png" alt="在这里插入图片描述"> 
    <ul><li>两个单词之间的PMI可以写成如下的形式：<br> <img src="https://images2.imgbox.com/e9/08/LiiTA7V3_o.png" alt="在这里插入图片描述"></li><li>具体到概率的计算如下：P(word)是word出现的次数/总单词数，P（word1，word2）是word1和word2同时出现的次数/总单词数的平方<br> <img src="https://images2.imgbox.com/2e/b2/BNaqjlVn_o.png" alt="在这里插入图片描述"></li><li>极性的度量=和excellent的PMI-和poor的PMI<br> <img src="https://images2.imgbox.com/c4/ad/JHkTudmu_o.png" alt="在这里插入图片描述"></li></ul> </li></ul> </li><li>例子<br> <img src="https://images2.imgbox.com/17/6b/1Lp5eyg1_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/61/48/ROyFrMxG_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="4wordnet_95"></a>4、使用wordnet学习极性</h3> 
<ul><li>wordnet：线上分类词典（thesaurus）</li><li>种子词：积极（good），消极（terrible）</li><li>找同义词和反义词 
  <ul><li>积极方面：加入积极的同义词（well）和消极的反义词</li><li>消极方面：加入消极的同义词（awful）和积极的反义词（evil）</li></ul> </li></ul> 
<h3><a id="5_101"></a>5、训练词典的总结</h3> 
<ul><li>优点 
  <ul><li>有领域针对性（demain-specific）</li><li>可以有更多单词，因此更稳健</li></ul> </li><li>主要解决思想 
  <ul><li>开始找一系列种子词（good，bad）</li><li>找到其他有相同词性的词（利用and/but，利用在同一篇文档中附近出现的单词，利用wordnet的同义词和反义词）</li></ul> </li></ul> 
<h2><a id="_108"></a>五、其他情感任务</h2> 
<h3><a id="1aspecttargetattribute_109"></a>1、研究情感的方面（aspect）、对象（target）以及态度（attribute）</h3> 
<ul><li>如何选取方面（aspect）？ 
  <ul><li>有些可以事先确定，比如我们要研究酒店的话，方面就是食物、交通、设备等等</li><li>有些则利用出现的频率和规则确定 
    <ul><li>找到在评论中经常出现的词组（fish tacos）</li><li>利用一些规则进行筛选，比如在情感词后面出现的词，比如great fish tacos可以提取fish tacos</li></ul> </li></ul> </li><li>接下来，进行有监督学习 
  <ul><li>对一小部分的语料进行关于方面（aspect）的人工标注</li><li>训练一个分类器，将其他没标注的句子分到对应的方面（aspect）中</li></ul> </li><li>步骤图示<br> <img src="https://images2.imgbox.com/8b/7f/iaV9T4aB_o.png" alt="在这里插入图片描述"></li><li>训练结果<br> <img src="https://images2.imgbox.com/af/eb/MokKyjtL_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="2_122"></a>2、不均衡类别问题</h3> 
<ul><li>基本模型假设类别的频率是均衡的，但是在现实生活中的大部分问题，类别都是不均衡的（类别发生的概率是不一样的）</li><li>非均衡问题的评价标准：用准确率不适合来进行评价，应该使用F值</li><li>严重的非均衡问题甚至会降低分类表现</li><li>两个常见的解决方案 
  <ul><li>训练样本重抽样：随机欠拟合</li><li>代价损失函数：svm，当对较少的类错误分类的时候会进行惩罚</li></ul> </li></ul> 
<h3><a id="3_129"></a>3、七星问题的处理</h3> 
<ul><li>转化为二分类问题</li><li>用线性或者有序回归，或者是特定的模型，比如metric labeling</li></ul> 
<h3><a id="4sentiment_132"></a>4、关于情绪（sentiment)的总结</h3> 
<ul><li>通常会构建分类或者是回归模型</li><li>特征构建上的一些要点 
  <ul><li>否定（negation）是很重要的</li><li>使用所有的单词（朴素贝叶斯）做特征，在某些任务中表现很好</li><li>在其他任务中，使用单词的子集会更好 
    <ul><li>手工建立的极性词典</li><li>种子和半监督方法生成词典</li></ul> </li></ul> </li></ul> 
<h3><a id="5_140"></a>5、除了态度以外，还可以进行其他类型的分析</h3> 
<p><img src="https://images2.imgbox.com/93/f4/R2PMHGGw_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b5/31/tGZlambE_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/9b/2c/jydFMS8X_o.png" alt="在这里插入图片描述"></p> 
<p>，</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/59aa0eb10c949c8acba365a3c6205dd9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C#.NET调用jar包（java环境配置及ikvm安装）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bc9022f53a85b240a121b5a832010752/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Jupyter notebook 查看Markdown .md文件</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>