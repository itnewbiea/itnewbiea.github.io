<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>一文读懂「AI Agent」智能体 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="一文读懂「AI Agent」智能体" />
<meta property="og:description" content="资料： 1. 🔥报告： https://download.csdn.net/download/Julialove102123/88707927 2. 💡简单介绍视频：强推👍🏻Zomi酱的 AI Agent视频介绍 3. ⭐️简单介绍PDF： https://download.csdn.net/download/Julialove102123/88710873 一、什么是AI Agent？ 定义：智能体agent是通过传感器感知环境（收集信息）并通过执行器作用于该环境（采取行动）的事物
大语言模型和 AI Agent 的区别
1. 在于 AI Agent 可以独立思考并做出行动，和 RPA 的区别在于它能够处理未知环境信息。ChatGPT 诞生后，AI 从真正意义上具备了和人类进行多轮对话的能力，并且能针对相应问题给出具体回答与建议。随后各个领域的“Copilot”推出，如 Microsoft 365 Copilot、GitHub Copilot、Adobe Firefly 等，让 AI 成为了办公、代码、设计等场景的“智能副驾驶”。
2. 大模型与人类之间的交互是基于 prompt 实现的，用户prompt 是否清晰明确会影响大模型回答的效果，例如 ChatGPT 和这些 Copilot 都需要明确任务才能得到有用的回答。而 AI Agent 的工作仅需给定一个目标，它就能够针对目标独立思考并做出行动，它会根据给定任务详细拆解出每一步的计划步骤，依靠来自外界的反馈和自主思考，自己给自己创建 prompt，来实现目标。如果说 Copilot 是“副驾驶”，那么 Agent 则可以算得上一个初级的“主驾驶”。和传统的 RPA 相比，RPA 只能在给定的情况条件下，根据程序内预设好的流程来进行工作的处理，在出现大量未知信息、难以预测的环境中时，RPA 是无法进行工作的，AIAgent 则可以通过和环境进行交互，感知信息并做出对应的思考和行动。
二、Agent结构 AI AGENT = LLM（核心控制器，构建核心能力）&#43; 规划能力 &#43; 记忆 &#43; 工具。其中基座模型能力至关重要。
2.1 规划Planning Chain-of-Thought 推理只是作为静态黑盒，它没有用外部知识，所以在推理过程中会出现事实幻想(fact hallucination)和错误传递(error propagation)的问题。ReAct 克服了在思维链推理中的幻觉和错误传播问题，通过与简单的维基百科API交互，生成类 似于人的任务解决型轨迹，解释性进一步增强。 1）Chain of thought 2）Self Reflection 自我反思(Self-reflection)允许 Agent 通过完善以往行动决策和纠正以往错误来迭代改进。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/124784822ca8a2f783cdb73b6a6c569f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-06T14:57:34+08:00" />
<meta property="article:modified_time" content="2024-01-06T14:57:34+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">一文读懂「AI Agent」智能体</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <div>
   资料： 
 </div> 
 <div>
   1. 🔥报告： 
  <a href="https://download.csdn.net/download/Julialove102123/88707927" title="https://download.csdn.net/download/Julialove102123/88707927">https://download.csdn.net/download/Julialove102123/88707927</a> 
 </div> 
 <div>
   2. 💡简单介绍视频：强推👍🏻Zomi酱的 
  <a href="https://space.bilibili.com/517221395/channel/collectiondetail?sid=1860427" rel="nofollow" title="AI Agent视频介绍">AI Agent视频介绍</a> 
 </div> 
 <div>
   3. ⭐️简单介绍PDF： 
  <a href="https://download.csdn.net/download/Julialove102123/88710873" title="https://download.csdn.net/download/Julialove102123/88710873">https://download.csdn.net/download/Julialove102123/88710873</a> 
 </div> 
</blockquote> 
<h2><img alt="" height="1200" src="https://images2.imgbox.com/78/ca/4m5VUjTf_o.png" width="1200"></h2> 
<h2>一、什么是AI Agent？</h2> 
<p><img alt="" height="403" src="https://images2.imgbox.com/7f/eb/YyJql62s_o.png" width="1200"></p> 
<p><strong>定义</strong>：智能体agent是通过传感器感知环境（收集信息）并通过执行器作用于该环境（采取行动）的事物</p> 
<p><strong>大语言模型和 AI Agent 的区别</strong></p> 
<p>1. 在于 AI Agent 可以独立思考并做出行动，和 RPA 的区别在于它能够处理未知环境信息。ChatGPT 诞生后，AI 从真正意义上具备了和人类进行多轮对话的能力，并且能针对相应问题给出具体回答与建议。随后各个领域的“Copilot”推出，如 Microsoft 365 Copilot、GitHub Copilot、Adobe Firefly 等，让 AI 成为了办公、代码、设计等场景的“智能副驾驶”。</p> 
<p>2. 大模型与人类之间的交互是基于 prompt 实现的，用户prompt 是否清晰明确会影响大模型回答的效果，例如 ChatGPT 和这些 Copilot 都需要明确任务才能得到有用的回答。而 AI Agent 的工作仅需给定一个目标，它就能够针对目标独立思考并做出行动，它会根据给定任务详细拆解出每一步的计划步骤，依靠来自外界的反馈和自主思考，自己给自己创建 prompt，来实现目标。如果说 Copilot 是“副驾驶”，那么 Agent 则可以算得上一个初级的“主驾驶”。和传统的 RPA 相比，RPA 只能在给定的情况条件下，根据程序内预设好的流程来进行工作的处理，在出现大量未知信息、难以预测的环境中时，RPA 是无法进行工作的，AIAgent 则可以通过和环境进行交互，感知信息并做出对应的思考和行动。</p> 
<h2><strong>二、Agent结构</strong></h2> 
<p>AI AGENT = LLM（核心控制器，构建核心能力）+ 规划能力 + 记忆 + 工具。其中基座模型能力至关重要。</p> 
<p></p> 
<p><img alt="" height="768" src="https://images2.imgbox.com/57/21/ztUrOwNy_o.png" width="1200"></p> 
<p><img alt="" height="914" src="https://images2.imgbox.com/46/48/LnO9j9J1_o.png" width="1200"></p> 
<h3>2.1 规划Planning</h3> 
<p><img alt="" height="720" src="https://images2.imgbox.com/17/a0/qAIAXgxb_o.png" width="1200"></p> 
<ul><li>Chain-of-Thought 推理只是作为静态黑盒，它没有用外部知识，所以在推理过程中会出现事实幻想(fact hallucination)和错误传递(error propagation)的问题。</li><li>ReAct 克服了在思维链推理中的幻觉和错误传播问题，通过与简单的维基百科API交互，生成类 似于人的任务解决型轨迹，解释性进一步增强。</li></ul> 
<h4>1）Chain of thought</h4> 
<p><img alt="" height="474" src="https://images2.imgbox.com/cb/ca/YzsaYOlx_o.png" width="1200"></p> 
<p><img alt="" height="762" src="https://images2.imgbox.com/3d/33/Is2VwKGu_o.png" width="1200"></p> 
<p><img alt="" height="762" src="https://images2.imgbox.com/99/78/aLOUFdnm_o.png" width="1200"></p> 
<p class="img-center"><img alt="" height="593" src="https://images2.imgbox.com/3c/36/ZGb2K4hD_o.png" width="1200"></p> 
<h4>2）Self Reflection</h4> 
<p>自我反思(Self-reflection)允许 Agent 通过完善以往行动决策和纠正以往错误来迭代改进。</p> 
<ol><li> <p><strong>Re Act</strong>：将动作空间扩展为任务特定的「离散动作和语言空间的组合」，将推理和动作集成在LLM 中。离散动作使 LLM 能够与环境交互，而语言空间促使 LLM 以自然语言生成推理轨迹;</p> </li></ol> 
<blockquote> 
 <p>Thought: ... Action: ... Observation: ... ... (Repeated many times)</p> 
</blockquote> 
<p><img alt="" height="718" src="https://images2.imgbox.com/b1/59/1UoEn64i_o.png" width="1200"></p> 
<p><img alt="" height="846" src="https://images2.imgbox.com/59/da/8KYVOXKc_o.png" width="1200"></p> 
<p><img alt="" height="758" src="https://images2.imgbox.com/b6/07/CoCD0IBd_o.png" width="1200"></p> 
<p><strong>2. Self-ask</strong>：Self-ask是一种follow-up的使用范式，仅仅包含 follow-up, immediate answer步骤，至于 follow-up多少个 step，完全由 Agent 自己决定。</p> 
<p><img alt="" height="676" src="https://images2.imgbox.com/f3/ef/pKS7A4N4_o.png" width="1200"></p> 
<p class="img-center"><img alt="" height="418" src="https://images2.imgbox.com/51/da/8Un2Wccb_o.png" width="300"></p> 
<h3>2.2 记忆Memory</h3> 
<p><img alt="" height="630" src="https://images2.imgbox.com/bb/76/PluK1MOa_o.png" width="1200"></p> 
<p><img alt="" height="728" src="https://images2.imgbox.com/61/05/1436wDfq_o.png" width="1200"></p> 
<ul><li>感知记忆(Sensory Memory)：记忆早期阶段，在原始刺激结束后保持对感官信息(视觉、听觉)的印象。特点:持续时间短，子类包括图像记忆(视觉)、回声记忆(听觉)和触摸记忆(触感)。</li><li>短期记忆(STM，Sort-term Memory)：短期记忆存储目前所知道的信息，以及执行复杂认知任务(如学习和推理)所需要的信息。 特点:短期记忆持续时间较短(1~2 周)</li><li>长期记忆(Long-termMemory，LTM)：将信息长时间存储，从几天到几十年不等。 
  <ul><li> <p>显式记忆(Explicit)：对事件的记忆，可以有意识地回忆起来的记忆，如记得小时候我喜欢吃奶瓶;</p> </li><li> <p>隐式记忆(Implicit)：无意识的记忆，涉及自主执行的技能和惯例，如黄老师傅学会开车;</p> </li></ul></li></ul> 
<p class="img-center"><img alt="" height="470" src="https://images2.imgbox.com/8b/aa/fcW3hLKD_o.png" width="1024"></p> 
<p></p> 
<h3>2.3 工具Tools</h3> 
<p class="img-center"><img alt="" height="818" src="https://images2.imgbox.com/74/9b/gFdsuCgn_o.png" width="1200"></p> 
<h2><img alt="" height="848" src="https://images2.imgbox.com/ac/2e/AQJiEeKB_o.png" width="1200"></h2> 
<p><img alt="" height="374" src="https://images2.imgbox.com/c2/97/bwidM2s9_o.png" width="1200"></p> 
<p><img alt="" height="734" src="https://images2.imgbox.com/1f/27/g7Qx9sl5_o.png" width="1200"></p> 
<h2>二、两大发展方向</h2> 
<p><img alt="" height="434" src="https://images2.imgbox.com/d6/2b/oqFsH7P0_o.png" width="1200"></p> 
<p>基于LLM开发的AI AGENT应用情况，将目前AI AGENT划分为两大类：</p> 
<ul><li>自主智能体（Self Reflection）：力图实现复杂流程自动化。当给定自主智能体一个目标时，它们能自行创建任务、完成任务、创建新任务、重新确定任务列表的优先级、完成新的首要任务，并不断重复这个过程，直到完成目标。准确度要求高，因而更需要外部工具辅助减少大模型不确定性的负面影响。</li><li>智能体模拟（Task Decomposition），力图更加拟人可信。分为强调情感情商的智能体以及强调交互的智能体，后者往往是在多智能体环境中，可能涌现出超越设计者规划的场景和能力，大模型生成的不确定性反而成为优势，多样性使其有望成为AIGC重要组成部分。</li></ul> 
<p><img alt="" height="552" src="https://images2.imgbox.com/6f/6c/UgVZKcsZ_o.png" width="1200">​</p> 
<h2>三、Agent 智能体的应用</h2> 
<h3>3.1 按应用领域</h3> 
<p class="img-center"><img alt="" height="885" src="https://images2.imgbox.com/a0/1e/epxAKxz6_o.png" width="1000"></p> 
<h3>3.2 按技术分类</h3> 
<p>（1）Simulations Agent：模拟智能体，在模拟器中包括一个 and/or 多个 Agent 相互作用。</p> 
<blockquote> 
 <p>Simulation Agent 包括一个/多个 Agents 相互作用。模拟 Agent 通常包括两个主要组件: 1. 长期记忆 2. 模拟环境</p> 
</blockquote> 
<p><img alt="" height="808" src="https://images2.imgbox.com/85/65/UFWiFTIT_o.png" width="1200"></p> 
<p><img alt="" height="840" src="https://images2.imgbox.com/79/6a/YfUINPw8_o.png" width="1200"></p> 
<p><img alt="" height="918" src="https://images2.imgbox.com/fb/ca/CrwEpkIm_o.png" width="1200"></p> 
<p>（2）Automatic Agent：自动化智能体，给定一个 and/or 多个长期目标，独立执行这些目标。这些应用程序结合了工具使用和长期内存。 典型的有AutoGPT，BabyAGI。</p> 
<p><img alt="" height="896" src="https://images2.imgbox.com/cc/f1/V52XzYcA_o.png" width="1200"></p> 
<p><img alt="" height="842" src="https://images2.imgbox.com/d8/ac/QWfxdzzy_o.png" width="1200"></p> 
<p>AutoGPT流程：</p> 
<ol><li> <p>任务定义:通过 Name、Role、Goals，组成 Prompt</p> </li><li> <p>理解任务:对下发的Prompt，ChatGP T通过大模型对语义内容理解</p> </li><li> <p>生成方案: ChatGP T 输出详细的 Step-by-Step 解决方案</p> </li><li> <p>生成指令:LLM 根据规划 Plan 生成可执行的操作或指令</p> </li><li> <p>执行指令:通过访问外部资源或调用ChatGP T完成任务</p> </li><li> <p>输出结果:指令操作完成后，系统返回执行结果</p> </li><li> <p>评估结果: AI 会评估结果以确定是否达到预期目标或是否需要进一步完善</p> </li></ol> 
<p><img alt="" height="964" src="https://images2.imgbox.com/a9/34/a70YZYWY_o.png" width="1200"></p> 
<ul><li>AgentGPT 基于 Langchain 和 OpenAI 基础构建 AI Agent。可以通过浏览器或个人计算机中创建、 配置和部署自主 AI 代理。</li><li>AgentGPT 允许配置和部署自治 AI 代理。命名自己的自定义 AI，让它开始实现任何可以想象的 目标。它将尝试通过思考要做的任务、执行它们并从结果中学习来达到目标。</li></ul> 
<p>（3）Multimodal Agent：多模态智能体，不仅可以处理纯文本的信息，还可以拓展到多模态来完成图像，语音，视频的交互。典型的应用有Visual ChatGPT，AssistGPT，HuggingGPT。</p> 
<p><img alt="" height="956" src="https://images2.imgbox.com/59/6f/VmfO9u3j_o.png" width="1200"></p> 
<ul><li>HuggingGPT 把 LLM 作为一个 Agent，用于管理和组织 Huggingface 上的模型(文生图、图生文、 目标检测等模型)，LLM 首先会根据用户的请求规划一个任务清单，然后给每个任务指派一个 HuggingFace 模型，AI 模型执行完以后，LLM收集结果并返回给用户。</li></ul> 
<p><img alt="" height="954" src="https://images2.imgbox.com/b7/f0/vIKZERSe_o.png" width="1200"></p> 
<p><img alt="" height="948" src="https://images2.imgbox.com/71/b4/hwRDQi6H_o.png" width="1200"></p> 
<h2>四、困难和挑战</h2> 
<p>局限性I：效率</p> 
<ol><li> <p>执行效率:Agent 作为执行者，需要运行多次和与外界进行交互，LLMs 消耗资源很大，因此导致 Agen ts 运行效率不会太高。</p> </li><li> <p>探索效率:通过 Agent 自行探索并完成整个解决过程仍然比较繁琐耗时，Agent 也很容易把问题复杂 化。考虑到 LLM 调用的成本，要在实际场景落地使用也还需要在这方面做不少优化。一种方式可能是 像 AutoGPT 那样可以中途引入人工的判断干预和反馈输入。</p> </li></ol> 
<p>局限性II：依赖 LLM<br> • 依赖LLM:Agent 所有的衍生技术都严重依赖于 LLMs 基础能力(OpenAI GPT4 API)，所以一个 Agents 的好坏，需要看该 LLMs 的训练 or 微调学习是否到位。</p> 
<ol><li> <p>动作有效性。评估过程中， LLMs 并不总是在遵循指令。即 LLMs 预期输出并不总是处于环境可以接受 的输入空间中。如 1)LLMs 没有理解指令，因此没有输出动作;2)LLMs 输出动作，却是错误或不完 整。所以如何确保动作有效，是一个需要改进的方向。</p> </li><li> <p>长上下文。开源模型的上下文长度(如2k tokens)会极大地影响交互任务中的表现，有些任务需要较 长的指令和反馈，可能超过上下文长度，导致模型忽略有用信息。</p> </li><li> <p>多轮一致性，不稳定性。部分任务需要多轮对话，每轮对话简短。会导致 LLMs 在多轮对话中丢失自 我角色(如输出道歉并表示无法回答)。在多轮对话 or 任务中保持一致性，是一个具有挑战性的工作。</p> </li></ol> 
<p>局限性III：训练方式和效果</p> 
<ol><li>•记忆召回：如果只是做简单的 embedding 相似性召回，很容易发现召回的结果不是很好。这里应该也有不少可以改进的空间，Generative Agents 里对于记忆的更细致的处理，LlamaIndex 中 对于 index 结构的设计也有很多可以选择与调优的地方。</li><li>错误累积：实际上 AI Agent 总体表现并没有那么惊艳，网上 or 论文给出的很多例子都都是经过精挑细算。真正可能会因为前面一些步骤出现偏差，后续的执行步骤逐渐越跑越远。很重要 的问题可能还是任务规划 Planning and 执行 Action，外部工具利用等方面的高质量训练数据相 对匮乏。这或许是 OpenAI 自己做 Tools plugin 体系的原因之一。</li></ol> 
<p>总结：未来发展的最终目标是实现通用AGI。</p> 
<blockquote> 
 <p>Pre-training or Fine-tuning 阶段实现 Language Agent 与利用 Prompt engineering 实现 Language agent，属于两个完全不同的研发路径，虽然从表面上看起来，都在做language agent。</p> 
 <ol><li> <p>Google DeepMind 创建的时候主攻 Autonomous Agents，如 AlphaGo、AlphaStat 等。</p> </li><li> <p>OpenAI 主攻从预训练到 RLHF 的 Autonomous Agents，如发布从 GPT1 到 GPT4 。</p> </li></ol> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/841379966058ad1e04e2ee32b79681d7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">二手买卖、废品回收小程序 在app.json中声明permission scope.userLocation字段 教程说明</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/69517ba93d3c46310d09b2fbccd4f9a5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python项目分享 基于Django的智慧校园考试系统</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>