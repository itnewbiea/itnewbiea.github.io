<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>利用Pandas进行高效网络数据获取 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="利用Pandas进行高效网络数据获取" />
<meta property="og:description" content="利用Pandas进行高效网络数据获取 背景： ​ 最近看到一篇关于使用Pandas模块进行爬虫的文章，觉得很有趣，这里为大家详细说明。
基础铺垫： ​ pd.read_html pandas 库中的一个函数，用于从 HTML 页面中读取表格数据并返回一个包含 DataFrame 对象的列表。那么说明是表格数据呢，就是table标签的，如下图！
​ 我们可以使用XPath快速判断当前页面是否具有使用Pandas进行爬虫的前提条件。
​ pd.read_html(io, match=‘.&#43;’, flavor=None, header=None, index_col=None, skiprows=None, attrs=None, parse_dates=False, thousands=‘,’, encoding=None, decimal=‘.’, converters=None, na_values=None, keep_default_na=True, displayed_only=True)
参数说明：
io: 接受的输入数据，可以是一个 HTML 字符串、一个 URL、一个文件路径或一个文件对象。match (可选): 一个正则表达式，用于匹配要提取的表格的 HTML 属性。flavor (可选): 解析器的名称，例如 &#39;html5lib&#39;、&#39;lxml&#39;、&#39;html.parser&#39; 等。其他参数：例如 header、index_col、skiprows 等参数用于控制读取表格数据的方式和格式。 案例实战： pd.read_html 函数会尝试从输入数据中提取所有的表格，并返回一个包含 DataFrame 对象的列表，就是一个列表里存在多个dataframe类型，每个 DataFrame 对象对应一个表格。
import pandas as pd # 从 HTML 页面中读取表格数据 url = &#39;https://vip.stock.finance.sina.com.cn/q/go.php/vFinanceAnalyze/kind/profit/index.phtml?p=1&#39; tables = pd.read_html(url) print(tables,type(tables),len(tables)) # 选择第一个表格的 DataFrame 对象 df = tables[0] # 打印 DataFrame print(&#39;---------------------------------------&#39;) print(df,type(df)) ​ 那么如果爬取多页呢？ 写个for循环，然后使用concat拼接起来，不会拼接的看一下我不久前写的博客。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/87b8e14b7b9e948531631ea69035a5f4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-29T21:11:43+08:00" />
<meta property="article:modified_time" content="2023-12-29T21:11:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">利用Pandas进行高效网络数据获取</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="Pandas_0"></a>利用Pandas进行高效网络数据获取</h3> 
<h4><a id="_2"></a>背景：</h4> 
<p>​ 最近看到一篇关于使用Pandas模块进行爬虫的文章，觉得很有趣，这里为大家详细说明。</p> 
<h4><a id="_6"></a>基础铺垫：</h4> 
<p>​ <code> pd.read_html</code> pandas 库中的一个函数，用于从 HTML 页面中读取表格数据并返回一个包含 DataFrame 对象的列表。那么说明是表格数据呢，就是<code>table</code>标签的，如下图！</p> 
<p>​ 我们可以使用XPath快速判断当前页面是否具有使用Pandas进行爬虫的前提条件。</p> 
<p><img src="https://images2.imgbox.com/22/65/YIoxMGeT_o.png" alt="在这里插入图片描述"></p> 
<p>​ <code>pd.read_htm</code>l(io, match=‘.+’, flavor=None, header=None, index_col=None, skiprows=None, attrs=None, parse_dates=False, thousands=‘,’, encoding=None, decimal=‘.’, converters=None, na_values=None, keep_default_na=True, displayed_only=True)</p> 
<p>参数说明：</p> 
<ul><li><code>io</code>: 接受的输入数据，可以是一个 HTML 字符串、一个 URL、一个文件路径或一个文件对象。</li><li><code>match</code> (可选): 一个正则表达式，用于匹配要提取的表格的 HTML 属性。</li><li><code>flavor</code> (可选): 解析器的名称，例如 <code>'html5lib'</code>、<code>'lxml'</code>、<code>'html.parser'</code> 等。</li><li>其他参数：例如 <code>header</code>、<code>index_col</code>、<code>skiprows</code> 等参数用于控制读取表格数据的方式和格式。</li></ul> 
<h4><a id="_24"></a>案例实战：</h4> 
<p><code> pd.read_html</code> 函数会尝试从输入数据中提取所有的表格，并返回一个包含 DataFrame 对象的列表，就是一个列表里存在多个dataframe类型，每个 DataFrame 对象对应一个表格。</p> 
<pre><code class="prism language-py"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment"># 从 HTML 页面中读取表格数据</span>
url <span class="token operator">=</span> <span class="token string">'https://vip.stock.finance.sina.com.cn/q/go.php/vFinanceAnalyze/kind/profit/index.phtml?p=1'</span>
tables <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_html<span class="token punctuation">(</span>url<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>tables<span class="token punctuation">,</span><span class="token builtin">type</span><span class="token punctuation">(</span>tables<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>tables<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 选择第一个表格的 DataFrame 对象</span>
df <span class="token operator">=</span> tables<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token comment"># 打印 DataFrame</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'---------------------------------------'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span><span class="token builtin">type</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/0b/1f/mNxlMRwx_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/48/66/5rNF8Xvc_o.png" alt="在这里插入图片描述"></p> 
<p>​ 那么如果爬取多页呢？ 写个for循环，然后使用concat拼接起来，不会拼接的看一下我不久前写的博客。</p> 
<pre><code class="prism language-py"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

data_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    url <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'https://vip.stock.finance.sina.com.cn/q/go.php/vFinanceAnalyze/kind/profit/index.phtml?p=</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_html<span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># 这里注意提取 返回的是一个列表</span>
    data_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token comment"># 每一个data都是一个dataframe类型</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"个数为"</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 合并数据</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>data_list<span class="token punctuation">,</span>ignore_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 保存到本地 </span>
df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"profit.csv"</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
<p>看一下结果：</p> 
<p><img src="https://images2.imgbox.com/6d/79/HUNvPcBA_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/0b/7e/D7fyiI0G_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_75"></a>细节问题：</h4> 
<p>这里还要注意一个问题，有的时候还要设置一下编码，可能爬下来的是乱码，如下：</p> 
<p><img src="https://images2.imgbox.com/57/5a/ceYNYoT5_o.png" alt="在这里插入图片描述"></p> 
<p>设置一下编码方式即可。</p> 
<pre><code class="prism language-py">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_html<span class="token punctuation">(</span>url<span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>如果大家想深层了解为什么有的时候需要设置，有的时候不需要设置，你要需要看这个响应回来的编码格式。</p> 
<p><img src="https://images2.imgbox.com/f3/48/xz1HHUlN_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/a7/f2/3t3kpflC_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_97"></a>温馨提示：</h4> 
<p>​ 本文提供的内容仅供学习和研究目的，请在合法和道德的框架内使用所获取的知识和技巧。在进行网络爬虫活动时，请遵守相关法律法规，并尊重网站的使用条款和隐私政策。确保在进行任何爬取操作之前获得合适的授权，并确保不会给目标网站或他人造成不必要的干扰或损害。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/63442fca9c5115767f00648efa5ff068/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">electron-builder 打包exe后白屏</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8b0d01f55ba68687d92cedf5f9a828e9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">常见的Transformers（二）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>