<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Pytorch中contiguous()函数理解 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Pytorch中contiguous()函数理解" />
<meta property="og:description" content="引言 在pytorch中，只有很少几个操作是不改变tensor的内容本身，而只是重新定义下标与元素的对应关系的。换句话说，这种操作不进行数据拷贝和数据的改变，变的是元数据。
会改变元数据的操作是：
narrow()view()expand()transpose() 在使用transpose()进行转置操作时，pytorch并不会创建新的、转置后的tensor，而是修改了tensor中的一些属性（也就是元数据），使得此时的offset和stride是与转置tensor相对应的。转置的tensor和原tensor的内存是共享的！ transpose()后改变元数据，代码示例： x = torch.randn(3, 2) y = torch.transpose(x, 0, 1) print(&#34;修改前：&#34;) print(&#34;x-&#34;, x) print(&#34;y-&#34;, y) print(&#34;\n修改后：&#34;) y[0, 0] = 11 print(&#34;x-&#34;, x) print(&#34;y-&#34;, y) 运行结果：
修改前： x- tensor([[-0.5670, -1.0277], [ 0.1981, -1.2250], [ 0.8494, -1.4234]]) y- tensor([[-0.5670, 0.1981, 0.8494], [-1.0277, -1.2250, -1.4234]]) 修改后： x- tensor([[11.0000, -1.0277], [ 0.1981, -1.2250], [ 0.8494, -1.4234]]) y- tensor([[11.0000, 0.1981, 0.8494], [-1.0277, -1.2250, -1.4234]]) 可以看到，改变了y的元素的值的同时，x的元素的值也发生了变化。
因此可以说，x是contiguous的，但y不是（因为内部数据不是通常的布局方式）。注意不要被contiguous的字面意思“连续的”误解，tensor中数据还是在内存中一块区域里，只是布局的问题！
为什么这么说：因为，y里面数据布局的方式和从头开始创建一个常规的tensor布局的方式是不一样的。这个可能只是python中之前常用的浅拷贝，y还是指向x变量所处的位置，只是说记录了transpose这个变化的布局。
使用contiguous() 如果想要断开这两个变量之间的依赖（x本身是contiguous的），就要使用contiguous()针对x进行变化，感觉上就是我们认为的深拷贝。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/bea868078eac7ebde47ca4f1919057dd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-08-23T11:13:31+08:00" />
<meta property="article:modified_time" content="2020-08-23T11:13:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Pytorch中contiguous()函数理解</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 id="main-toc">引言</h3> 
<blockquote> 
 <p>在pytorch中，只有很少几个操作是<strong>不改变tensor的内容本身</strong>，而只是<strong>重新定义下标与元素的对应关系</strong>的。换句话说，这种操作不进行数据拷贝和数据的改变，变的是<strong>元数据</strong>。</p> 
</blockquote> 
<p>会改变元数据的操作是：</p> 
<ul><li>narrow()</li><li>view()</li><li>expand()</li><li>transpose() </li></ul> 
<p style="text-indent:33px;">在使用<code>transpose()</code>进行转置操作时，pytorch并不会创建新的、转置后的tensor，而是修改了tensor中的一些属性（也就是元数据），使得此时的offset和stride是与转置tensor相对应的。转置的tensor和原tensor的内存是共享的！  </p> 
<p><strong><code>transpose()后改变元数据，</code>代码示例： </strong></p> 
<pre><code class="language-python">x = torch.randn(3, 2)
y = torch.transpose(x, 0, 1)
print("修改前：")
print("x-", x)
print("y-", y)

print("\n修改后：")
y[0, 0] = 11
print("x-", x)
print("y-", y)</code></pre> 
<p><strong> 运行结果：</strong></p> 
<pre><code>修改前：
x- tensor([[-0.5670, -1.0277],
           [ 0.1981, -1.2250],
           [ 0.8494, -1.4234]])
y- tensor([[-0.5670,  0.1981,  0.8494],
           [-1.0277, -1.2250, -1.4234]])

修改后：
x- tensor([[11.0000, -1.0277],
           [ 0.1981, -1.2250],
           [ 0.8494, -1.4234]])
y- tensor([[11.0000,  0.1981,  0.8494],
           [-1.0277, -1.2250, -1.4234]])</code></pre> 
<p>可以看到，<strong>改变了y的元素的值的同时，x的元素的值也发生了变化</strong>。</p> 
<p style="text-indent:33px;">因此可以说，<strong>x是contiguous的</strong>，但<strong>y不是</strong>（因为内部数据不是通常的布局方式）。注意不要被contiguous的字面意思“连续的”误解，tensor中数据还是在内存中一块区域里，只是<strong>布局</strong>的问题！</p> 
<p style="text-indent:33px;">为什么这么说：因为，<strong>y里面数据布局的方式和从头开始创建一个常规的tensor布局的方式是不一样的。</strong>这个<strong>可能只是python中之前常用的浅拷贝</strong>，<strong>y还是指向x变量所处的位置，只是说记录了transpose这个变化的布局。</strong></p> 
<hr> 
<h3 id="%E4%BD%BF%E7%94%A8contiguous()%C2%A0">使用contiguous() </h3> 
<p style="text-indent:33px;">如果想要<strong>断开</strong>这两个<strong>变量之间的依赖</strong>（x本身是contiguous的），就要<strong>使用contiguous()针对x进行变化</strong>，<strong>感觉上就是我们认为的深拷贝</strong>。</p> 
<p> 当<strong>调用contiguous()时</strong>，<strong>会强制拷贝一份tensor</strong>，让它的布局和从头创建的一模一样，<strong>但是两个tensor完全没有联系</strong>。</p> 
<p><strong> 代码示例：</strong></p> 
<pre><code class="language-python">x = torch.randn(3, 2)
y = torch.transpose(x, 0, 1).contiguous()
print("修改前：")
print("x-", x)
print("y-", y)

print("\n修改后：")
y[0, 0] = 11
print("x-", x)
print("y-", y)</code></pre> 
<p><strong>运行结果： </strong></p> 
<pre><code>修改前：
x- tensor([[ 0.9730,  0.8559],
           [ 1.6064,  1.4375],
           [-1.0905,  1.0690]])
y- tensor([[ 0.9730,  1.6064, -1.0905],
           [ 0.8559,  1.4375,  1.0690]])

修改后：
x- tensor([[ 0.9730,  0.8559],
           [ 1.6064,  1.4375],
           [-1.0905,  1.0690]])
y- tensor([[11.0000,  1.6064, -1.0905],
           [ 0.8559,  1.4375,  1.0690]])</code></pre> 
<p> 可以看到，当<strong>对y使用了.contiguous()</strong>后，<strong>改变y的值时，x没有任何影响</strong>！</p> 
<hr> 
<h3 id="%E5%90%8E%E8%AE%B0%C2%A0">后记 </h3> 
<p> 一般来说这一点不用太担心，当遇到<strong>需要调用contiguous()的地方</strong>，运行时会提示你：</p> 
<pre><code>RuntimeError: input is not contiguous</code></pre> 
<p> <strong>这时候只需要在该变量后面加上.contiguous()就可以了！</strong></p> 
<hr> 
<h3 id="%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99%EF%BC%9A">参考资料：</h3> 
<blockquote> 
 <p><a href="" rel="nofollow">https://blog.csdn.net/gdymind/article/details/82662502</a></p> 
 <p><a href="" rel="nofollow">https://www.jianshu.com/p/7e72cc1ab7a0</a></p> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ad25acda4b2e487dfddba435f8273950/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">什么是RabbitMq?其原理？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/50346aa06a8323609931cdb1a52643ed/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vscode中的C语言scanf卡在编译过程的解决办法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>