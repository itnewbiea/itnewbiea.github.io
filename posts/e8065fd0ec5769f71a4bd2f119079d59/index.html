<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>开源预训练框架 MMPRETRAIN官方文档（概览、环境安装与验证、基础用户指南） - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="开源预训练框架 MMPRETRAIN官方文档（概览、环境安装与验证、基础用户指南）" />
<meta property="og:description" content="MMPretrain是全新升级的开源预训练框架。它已着手提供多个强大的预训练骨干网并支持不同的预训练策略。MMPretrain 源自著名的开源项目 MMClassification 和MMSelfSup，并开发了许多令人兴奋的新功能。目前，预训练阶段对于视觉识别至关重要。凭借丰富而强大的预训练模型，我们目前有能力改进各种下游视觉任务。
我们代码库的主要目标是成为一个易于访问且用户友好的库，并简化研究和工程。我们详细介绍了 MMPretrain 不同部分的属性和设计。
1、MMPretrain 实践路线图 为了帮助用户快速使用 MMPretrain，我们建议遵循我们为库创建的实践路线图：
（1）对于想要尝试 MMPretrain 的用户，我们建议阅读入门 部分以了解环境设置。 （2）对于基本使用，我们建议用户参考用户指南，以利用各种算法来获取预训练模型并评估其在下游任务中的性能。 （3）对于那些希望自定义自己的算法的人，我们提供了 高级指南，其中包括修改代码的提示和规则。 （4）要找到您想要的预训练模型，用户可以查看ModelZoo，它总结了各种主干和预训练方法以及不同算法的介绍。 （5）此外，我们还提供分析和可视化工具来帮助诊断算法。 2、环境配置安装 1、 先决条件 在本节中，我们将演示如何使用 PyTorch 准备环境。
MMPretrain 适用于 Linux、Windows 和 macOS。它需要 Python 3.7&#43;、CUDA 10.2&#43; 和 PyTorch 1.8&#43;。
2、安装 创建conda环境并激活。 conda create --name mmpretrain python=3.8 -y #创建环境 conda activate mmpretrain #激活环境 conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch #安装 PyTorch and torchvision (官方) #如果网不好，可以这样安装 pip3 install torch==1.8.2&#43;cu102 torchvision==0.9.2&#43;cu102 torchaudio===0.8.2 -f https://download." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/e8065fd0ec5769f71a4bd2f119079d59/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-27T14:54:56+08:00" />
<meta property="article:modified_time" content="2023-07-27T14:54:56+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">开源预训练框架 MMPRETRAIN官方文档（概览、环境安装与验证、基础用户指南）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>MMPretrain是全新升级的开源预训练框架。它已着手提供多个强大的预训练骨干网并支持不同的预训练策略。MMPretrain 源自著名的开源项目 MMClassification 和MMSelfSup，并开发了许多令人兴奋的新功能。目前，预训练阶段对于视觉识别至关重要。凭借丰富而强大的预训练模型，我们目前有能力改进各种下游视觉任务。</p> 
<p>我们代码库的主要目标是成为一个易于访问且用户友好的库，并简化研究和工程。我们详细介绍了 MMPretrain 不同部分的属性和设计。</p> 
<h3><a id="1MMPretrain__3"></a>1、MMPretrain 实践路线图</h3> 
<p><img src="https://images2.imgbox.com/70/11/XGXJtzj6_o.png" alt="在这里插入图片描述"></p> 
<p>为了帮助用户快速使用 MMPretrain，我们建议遵循我们为库创建的实践路线图：</p> 
<h4><a id="1_MMPretrain___8"></a>（1）对于想要尝试 MMPretrain 的用户，我们建议阅读入门 部分以了解环境设置。</h4> 
<h4><a id="2_9"></a>（2）对于基本使用，我们建议用户参考用户指南，以利用各种算法来获取预训练模型并评估其在下游任务中的性能。</h4> 
<h4><a id="3__11"></a>（3）对于那些希望自定义自己的算法的人，我们提供了 高级指南，其中包括修改代码的提示和规则。</h4> 
<h4><a id="4ModelZoo_13"></a>（4）要找到您想要的预训练模型，用户可以查看ModelZoo，它总结了各种主干和预训练方法以及不同算法的介绍。</h4> 
<h4><a id="5_15"></a>（5）此外，我们还提供分析和可视化工具来帮助诊断算法。</h4> 
<h3><a id="2_16"></a>2、环境配置安装</h3> 
<h4><a id="1__17"></a>1、 先决条件</h4> 
<p>在本节中，我们将演示如何使用 PyTorch 准备环境。<br> MMPretrain 适用于 Linux、Windows 和 macOS。它需要 Python 3.7+、CUDA 10.2+ 和 PyTorch 1.8+。</p> 
<h4><a id="2_20"></a>2、安装</h4> 
<pre><code class="prism language-bash">创建conda环境并激活。
conda create <span class="token parameter variable">--name</span> mmpretrain <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.8</span> <span class="token parameter variable">-y</span>  <span class="token comment">#创建环境</span>
conda activate mmpretrain   <span class="token comment">#激活环境            </span>
</code></pre> 
<pre><code class="prism language-bash">conda <span class="token function">install</span> pytorch torchvision torchaudio <span class="token assign-left variable">cudatoolkit</span><span class="token operator">=</span><span class="token number">10.2</span> <span class="token parameter variable">-c</span> pytorch  <span class="token comment">#安装 PyTorch and torchvision (官方)</span>

<span class="token comment">#如果网不好，可以这样安装</span>
pip3 <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">1.8</span>.2+cu102 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.9</span>.2+cu102 <span class="token assign-left variable">torchaudio</span><span class="token operator">==</span><span class="token operator">=</span><span class="token number">0.8</span>.2 <span class="token parameter variable">-f</span> https://download.pytorch.org/whl/lts/1.8/torch_lts.html  <span class="token parameter variable">-i</span> http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com

<span class="token comment">#验证是否安装成功</span>

<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token function">import</span> torchvision
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token function">import</span> torch
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> import.__version__
  File <span class="token string">"&lt;stdin&gt;"</span>, line <span class="token number">1</span>
    import.__version__
          ^
SyntaxError: invalid syntax
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> torch.__version__
<span class="token string">'1.8.2+cu102'</span>
</code></pre> 
<h4><a id="3_mmpretrain_46"></a>3、从源安装 mmpretrain</h4> 
<p>在这种情况下，从源安装 mmpretrain：</p> 
<pre><code class="prism language-bash"><span class="token function">git</span> clone https://github.com/open-mmlab/mmpretrain.git
<span class="token builtin class-name">cd</span> mmpretrain
pip <span class="token function">install</span> <span class="token parameter variable">-U</span> openmim <span class="token operator">&amp;&amp;</span> mim <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token builtin class-name">.</span>  <span class="token parameter variable">-f</span> https://download.pytorch.org/whl/lts/1.8/torch_lts.html  <span class="token parameter variable">-i</span> http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com
</code></pre> 
<pre><code class="prism language-bash"><span class="token function">git</span> clone https://github.com/open-mmlab/mmpretrain.git
<span class="token builtin class-name">cd</span> mmpretrain
pip <span class="token function">install</span> <span class="token parameter variable">-U</span> openmim  <span class="token parameter variable">-f</span> https://download.pytorch.org/whl/lts/1.8/torch_lts.html  <span class="token parameter variable">-i</span> http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com
mim <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token builtin class-name">.</span>
</code></pre> 
<p>"-e"意味着以可编辑模式安装项目，因此对代码所做的任何本地修改都会生效，无需重新安装。<br> <img src="https://images2.imgbox.com/b7/18/bzdxxFc4_o.png" alt="在这里插入图片描述"><br> 安装多模态支持（可选）<br> MMPretrain 中的多模态模型需要额外的依赖项。要安装这些依赖项，您可以[multimodal]在安装过程中添加。例如：</p> 
<pre><code class="prism language-bash"><span class="token comment"># Install from source</span>
mim <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token string">".[multimodal]"</span>

<span class="token comment"># Install as a Python package</span>
mim <span class="token function">install</span> <span class="token string">"mmpretrain[multimodal]&gt;=1.0.0rc8"</span>
</code></pre> 
<h3><a id="3_74"></a>3、验证安装</h3> 
<p>为了验证 MMPretrain 是否安装正确，我们提供了一些示例代码来运行推理演示。<br> 选项（a）。如果从源安装 mmpretrain，只需运行以下命令：</p> 
<pre><code class="prism language-bash">python demo/image_demo.py demo/demo.JPEG resnet18_8xb32_in1k <span class="token parameter variable">--device</span> cpu
</code></pre> 
<p>您将在终端中看到输出结果字典，包括pred_label,pred_score和pred_class<br> <img src="https://images2.imgbox.com/e9/a9/6eba4hlR_o.png" alt="在这里插入图片描述"><br> 选项（b）。如果将 mmpretrain 安装为 python 包，请打开 python 解释器并复制并粘贴以下代码。</p> 
<pre><code class="prism language-bash">from mmpretrain <span class="token function">import</span> get_model, inference_model

model <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token string">'resnet18_8xb32_in1k'</span>, <span class="token assign-left variable">device</span><span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span>  <span class="token comment"># or device='cuda:0'</span>
inference_model<span class="token punctuation">(</span>model, <span class="token string">'demo/demo.JPEG'</span><span class="token punctuation">)</span>
</code></pre> 
<p>您将看到打印的字典，包括预测的标签、分数和类别名称。</p> 
<h4><a id="_95"></a>注意</h4> 
<p>这resnet18_8xb32_in1k是模型名称，您可以使用它mmpretrain.list_models来探索所有模型，或在模型动物园摘要中搜索它们。</p> 
<h3><a id="3_99"></a>3、了解配置</h3> 
<p>为了管理深度学习实验中的各种配置，我们使用一种配置文件来记录所有这些配置。该配置系统采用模块化和继承设计，更多详细信息可以参考 MMEngine 的教程。</p> 
<p>通常，我们使用Python文件作为配置文件。所有的配置文件都放在该configs文件夹下，目录结构如下：</p> 
<pre><code class="prism language-bash">MMPretrain/
    ├── configs/
    │   ├── _base_/                       <span class="token comment"># primitive configuration folder，基本配置文件夹</span>
    │   │   ├── datasets/                      <span class="token comment"># primitive datasets，基本数据集</span>
    │   │   ├── models/                        <span class="token comment"># primitive models，基本模型</span>
    │   │   ├── schedules/                     <span class="token comment"># primitive schedules，基本学习率</span>
    │   │   └── default_runtime.py             <span class="token comment"># primitive runtime setting，基本运行设置</span>
    │   ├── beit/                         <span class="token comment"># BEiT Algorithms Folder，BEiT</span>
    │   ├── mae/                          <span class="token comment"># MAE Algorithms Folder，MAE 算法文件夹</span>
    │   ├── mocov2/                       <span class="token comment"># MoCoV2 Algorithms Folder，MoCoV2算法文件夹</span>
    │   ├── resnet/                       <span class="token comment"># ResNet Algorithms Folder</span>
    │   ├── swin_transformer/             <span class="token comment"># Swin Algorithms Folder</span>
    │   ├── vision_transformer/           <span class="token comment"># ViT Algorithms Folder</span>
    │   ├── <span class="token punctuation">..</span>.
    └── <span class="token punctuation">..</span>.
</code></pre> 
<p>如果您想检查配置文件，可以运行以查看完整的配置。</p> 
<pre><code class="prism language-bash">python tools/misc/print_config.py /<span class="token environment constant">PATH</span>/TO/CONFIG
</code></pre> 
<p>本文主要讲解配置文件的结构，以及如何在现有配置文件的基础上进行修改。我们以ResNet50配置文件为例，逐行解释。</p> 
<h4><a id="1_129"></a>1、配置结构</h4> 
<p>文件夹中有四种基本组件文件configs/<em>base</em>，分别是：<br> models<br> datasets<br> schedules<br> runtime</p> 
<p>我们将文件夹中的所有配置文件_base_称为原始配置文件。您可以通过继承一些原始配置文件轻松构建训练配置文件。<br> 为了便于理解，我们以ResNet50 配置文件为例，并对每一行进行注释。</p> 
<pre><code class="prism language-bash">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>                                    <span class="token comment"># This config file will inherit all config files in `_base_`.</span>
    <span class="token string">'../_base_/models/resnet50.py'</span>,           <span class="token comment"># model settings</span>
    <span class="token string">'../_base_/datasets/imagenet_bs32.py'</span>,    <span class="token comment"># data settings</span>
    <span class="token string">'../_base_/schedules/imagenet_bs256.py'</span>,  <span class="token comment"># schedule settings</span>
    <span class="token string">'../_base_/default_runtime.py'</span>            <span class="token comment"># runtime settings</span>
<span class="token punctuation">]</span>
</code></pre> 
<h5><a id="1_146"></a>1、模型设置</h5> 
<p>这个原始配置文件包含一个 dict 变量model，主要包含<strong>网络结构和损失函数等信息</strong>：</p> 
<h6><a id="type_148"></a><strong>type：</strong></h6> 
<p>要构建的模型类型，我们支持多种任务。<br> 对于图像分类任务，通常ImageClassifier可以在<a href="https://mmpretrain.readthedocs.io/en/latest/api/models.html#module-mmpretrain.models.classifiers" rel="nofollow">API 文档</a>中找到更多详细信息。<br> 对于自监督学习，有好几种SelfSupervisors，比如such as MoCoV2, BEiT, MAE,等等，你可以在API文档中找到更多详细信息。<br> 对于图像检索任务，通常ImageToImageRetriever，可以在API 文档中找到更多详细信息。</p> 
<p>通常，我们使用该type字段来指定组件的类，并使用其他字段来传递该类的初始化参数。<a href="https://mmengine.readthedocs.io/en/latest/advanced_tutorials/registry.html" rel="nofollow">注册表教程</a>对此进行了详细描述。</p> 
<p>这里我们以 的 config 字段ImageClassifier为例，对初始化参数进行说明如下：</p> 
<h6><a id="backbone_158"></a><strong>backbone：</strong></h6> 
<p>主干的设置。主干网络是提取输入特征的主要网络，如ResNet、Swin Transformer、Vision Transformer等。所有可用的主干网络都可以<a href="https://mmpretrain.readthedocs.io/en/latest/api/models.html#module-mmpretrain.models.backbones" rel="nofollow">在API 文档</a>中找到。<br> 对于自监督学习，一些主干被重新实现，您可以在API 文档中找到更多详细信息。</p> 
<h6><a id="neck_161"></a><strong>neck：</strong></h6> 
<p>颈部的设置。颈部是连接backbone和头部的中间模块，就像GlobalAveragePooling。所有可用的颈部都可以在API 文档中找到。</p> 
<h6><a id="head_164"></a><strong>head：</strong></h6> 
<p>任务头的设置。头部是执行指定任务的与任务相关的组件，例如图像分类或自监督训练。所有可用的头都可以在API 文档中找到。</p> 
<h6><a id="loss_167"></a><strong>loss：</strong></h6> 
<p>要优化的损失函数，如CrossEntropyLoss、LabelSmoothLoss等。所有可用的损失都可以在API 文档PixelReconstructionLoss中找到。</p> 
<h6><a id="data_preprocessor_170"></a><strong>data_preprocessor：</strong></h6> 
<p>模型前向处理的组件，用于预处理输入。请<a href="https://mmpretrain.readthedocs.io/en/latest/api/data_process.html#module-mmpretrain.models.utils.data_preprocessor" rel="nofollow">参阅文档了解更多详细信息</a>。</p> 
<h6><a id="train_cfg__ImageClassifier_173"></a><strong>train_cfg ImageClassifier</strong>：</h6> 
<p>训练时的额外设置。在 中ImageClassifier，我们主要使用它来指定批量增强设置，例如Mixup和CutMix。。<a href="https://mmpretrain.readthedocs.io/en/latest/api/data_process.html#module-mmpretrain.models.utils.batch_augments" rel="nofollow">请参阅文档了解更多详细信息</a></p> 
<p>以下是 ResNet50 配置文件的模型原始配置configs/<em>base</em>/models/resnet50.py：</p> 
<pre><code class="prism language-bash">model <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'ImageClassifier'</span>,     <span class="token comment"># The type of the main model (here is for image classification task).主要模型的类型(这里是针对图像分类任务的)。</span>
    <span class="token assign-left variable">backbone</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'ResNet'</span>,          <span class="token comment"># The type of the backbone module.</span>
        <span class="token comment"># All fields except `type` come from the __init__ method of class `ResNet`</span>
        <span class="token comment"># and you can find them from https://mmpretrain.readthedocs.io/en/latest/api/generated/mmpretrain.models.backbones.ResNet.html,#除了' type '之外的所有字段都来自' ResNet '类的__init__方法,你可以从</span>
        <span class="token assign-left variable">depth</span><span class="token operator">=</span><span class="token number">50</span>,
        <span class="token assign-left variable">num_stages</span><span class="token operator">=</span><span class="token number">4</span>,
        <span class="token assign-left variable">out_indices</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span>, <span class="token punctuation">)</span>,
        <span class="token assign-left variable">frozen_stages</span><span class="token operator">=</span>-1,
        <span class="token assign-left variable">style</span><span class="token operator">=</span><span class="token string">'pytorch'</span><span class="token punctuation">)</span>,
    <span class="token assign-left variable">neck</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'GlobalAveragePooling'</span><span class="token punctuation">)</span>,    <span class="token comment"># The type of the neck module.</span>
    <span class="token assign-left variable">head</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'LinearClsHead'</span>,     <span class="token comment"># The type of the classification head module.</span>
        <span class="token comment"># All fields except `type` come from the __init__ method of class `LinearClsHead`除了' type '之外的所有字段都来自' linearclhead '类的__init__方法</span>
        <span class="token comment"># and you can find them from https://mmpretrain.readthedocs.io/en/latest/api/generated/mmpretrain.models.heads.LinearClsHead.html</span>
        <span class="token assign-left variable">num_classes</span><span class="token operator">=</span><span class="token number">1000</span>,
        <span class="token assign-left variable">in_channels</span><span class="token operator">=</span><span class="token number">2048</span>,
        <span class="token assign-left variable">loss</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'CrossEntropyLoss'</span>, <span class="token assign-left variable">loss_weight</span><span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>,
    <span class="token punctuation">))</span>
</code></pre> 
<pre><code class="prism language-bash">CLASSmmpretrain.models.backbones.ResNet<span class="token punctuation">(</span>depth, <span class="token assign-left variable">in_channels</span><span class="token operator">=</span><span class="token number">3</span>, <span class="token assign-left variable">stem_channels</span><span class="token operator">=</span><span class="token number">64</span>, <span class="token assign-left variable">base_channels</span><span class="token operator">=</span><span class="token number">64</span>, <span class="token assign-left variable">expansion</span><span class="token operator">=</span>None, <span class="token assign-left variable">num_stages</span><span class="token operator">=</span><span class="token number">4</span>, <span class="token assign-left variable">strides</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">2</span>, <span class="token number">2</span>, <span class="token number">2</span><span class="token punctuation">)</span>, <span class="token assign-left variable">dilations</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">)</span>, <span class="token assign-left variable">out_indices</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span>,<span class="token punctuation">)</span>, <span class="token assign-left variable">style</span><span class="token operator">=</span><span class="token string">'pytorch'</span>, <span class="token assign-left variable">deep_stem</span><span class="token operator">=</span>False, <span class="token assign-left variable">avg_down</span><span class="token operator">=</span>False, <span class="token assign-left variable">frozen_stages</span><span class="token operator">=</span>-1, <span class="token assign-left variable">conv_cfg</span><span class="token operator">=</span>None, <span class="token assign-left variable">norm_cfg</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'requires_grad'</span><span class="token builtin class-name">:</span> True, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'BN'</span><span class="token punctuation">}</span>, <span class="token assign-left variable">norm_eval</span><span class="token operator">=</span>False, <span class="token assign-left variable">with_cp</span><span class="token operator">=</span>False, <span class="token assign-left variable">zero_init_residual</span><span class="token operator">=</span>True, <span class="token assign-left variable">init_cfg</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'Kaiming'</span>, <span class="token string">'layer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'Conv2d'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>, <span class="token punctuation">{<!-- --></span><span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'Constant'</span>, <span class="token string">'val'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'layer'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'_BatchNorm'</span>, <span class="token string">'GroupNorm'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span>, <span class="token assign-left variable">drop_path_rate</span><span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-bash">CLASSmmpretrain.models.heads.LinearClsHead<span class="token punctuation">(</span>num_classes, in_channels, <span class="token assign-left variable">init_cfg</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'layer'</span><span class="token builtin class-name">:</span> <span class="token string">'Linear'</span>, <span class="token string">'std'</span><span class="token builtin class-name">:</span> <span class="token number">0.01</span>, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">'Normal'</span><span class="token punctuation">}</span>, **kwargs<span class="token punctuation">)</span>
</code></pre> 
<h5><a id="2_209"></a>2、数据设置</h5> 
<p>这个原始配置文件包含构建数据加载器和评估器的信息：</p> 
<h6><a id="data_preprocessor_212"></a>data_preprocessor：</h6> 
<p>模型输入预处理配置，与此相同，model.data_preprocessor但优先级较低。</p> 
<h6><a id="train_evaluator__val_evaluator__test_evaluator_215"></a>train_evaluator | val_evaluator | test_evaluator：</h6> 
<p>要构建评估器或指标，请参阅教程。</p> 
<h6><a id="train_dataloader__val_dataloader__test_dataloader_218"></a>train_dataloader | val_dataloader | test_dataloader：</h6> 
<p>数据加载器的设置</p> 
<h6><a id="batch_sizeGPU_221"></a>batch_size：每个GPU的批量大小。</h6> 
<h6><a id="num_workersGPUworker_223"></a>num_workers：每个GPU获取数据的worker数量。</h6> 
<h6><a id="sampler_225"></a>sampler：采样器的设置。</h6> 
<h6><a id="persistent_workers_227"></a>persistent_workers：完成一个纪元后是否继续工作。</h6> 
<h6><a id="dataset_229"></a>dataset：数据集的设置。</h6> 
<p>####### type：数据集的类型，我们支持CustomDataset，ImageNet还有很多其他数据集，参考文档。</p> 
<p>####### pipeline：数据转换管道。您可以在本教程中了解如何设计管道。</p> 
<p>以下是ResNet50配置中的数据原语配置configs/<em>base</em>/datasets/imagenet_bs32.py：</p> 
<pre><code class="prism language-bash">dataset_type <span class="token operator">=</span> <span class="token string">'ImageNet'</span>,训练样本的数据类型
<span class="token comment"># preprocessing configuration</span>
data_preprocessor <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token comment"># Input image data channels in 'RGB' order</span>
    <span class="token assign-left variable">mean</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span>, <span class="token number">116.28</span>, <span class="token number">103.53</span><span class="token punctuation">]</span>,    <span class="token comment"># Input image normalized channel mean in RGB order</span>
    <span class="token assign-left variable">std</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span>, <span class="token number">57.12</span>, <span class="token number">57.375</span><span class="token punctuation">]</span>,       <span class="token comment"># Input image normalized channel std in RGB order</span>
    <span class="token assign-left variable">to_rgb</span><span class="token operator">=</span>True,                       <span class="token comment"># Whether to flip the channel from BGR to RGB or RGB to BGR</span>
<span class="token punctuation">)</span>

train_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span>
    dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span>,     <span class="token comment"># read image</span>
    dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'RandomResizedCrop'</span>, <span class="token assign-left variable">scale</span><span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">)</span>,     <span class="token comment"># Random scaling and cropping，随机缩放和裁剪</span>
    dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'RandomFlip'</span>, <span class="token assign-left variable">prob</span><span class="token operator">=</span><span class="token number">0.5</span>, <span class="token assign-left variable">direction</span><span class="token operator">=</span><span class="token string">'horizontal'</span><span class="token punctuation">)</span>,   <span class="token comment"># random horizontal flip</span>
    dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'PackInputs'</span><span class="token punctuation">)</span>,         <span class="token comment"># prepare images and labels，准备图片和标签</span>
<span class="token punctuation">]</span>

test_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span>
    dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span>,     <span class="token comment"># read image</span>
    dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'ResizeEdge'</span>, <span class="token assign-left variable">scale</span><span class="token operator">=</span><span class="token number">256</span>, <span class="token assign-left variable">edge</span><span class="token operator">=</span><span class="token string">'short'</span><span class="token punctuation">)</span>,  <span class="token comment"># Scale the short side to 256，将短边缩放到256</span>
    dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'CenterCrop'</span>, <span class="token assign-left variable">crop_size</span><span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">)</span>,     <span class="token comment"># center crop</span>
    dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'PackInputs'</span><span class="token punctuation">)</span>,                 <span class="token comment"># prepare images and labels</span>
<span class="token punctuation">]</span>

<span class="token comment"># Construct training set dataloader</span>
train_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">batch_size</span><span class="token operator">=</span><span class="token number">32</span>,                     <span class="token comment"># batchsize per GPU</span>
    <span class="token assign-left variable">num_workers</span><span class="token operator">=</span><span class="token number">5</span>,                     <span class="token comment"># Number of workers to fetch data per GPU，每个GPU获取数据的工作线程数</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>                      <span class="token comment"># training dataset</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span>dataset_type,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span><span class="token string">'data/imagenet'</span>,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">'meta/train.txt'</span>,
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'train'</span>,
        <span class="token assign-left variable">pipeline</span><span class="token operator">=</span>train_pipeline<span class="token punctuation">)</span>,
    <span class="token assign-left variable">sampler</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'DefaultSampler'</span>, <span class="token assign-left variable">shuffle</span><span class="token operator">=</span>True<span class="token punctuation">)</span>,   <span class="token comment"># default sampler，默认的取样器</span>
    <span class="token assign-left variable">persistent_workers</span><span class="token operator">=</span>True,                             <span class="token comment"># Whether to keep the process, can shorten the preparation time of each epoch，是否保留流程，可以缩短每个epoch的准备时间</span>
<span class="token punctuation">)</span>

<span class="token comment"># Construct the validation set dataloader</span>
val_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">batch_size</span><span class="token operator">=</span><span class="token number">32</span>,
    <span class="token assign-left variable">num_workers</span><span class="token operator">=</span><span class="token number">5</span>,
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span>dataset_type,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span><span class="token string">'data/imagenet'</span>,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">'meta/val.txt'</span>,
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'val'</span>,
        <span class="token assign-left variable">pipeline</span><span class="token operator">=</span>test_pipeline<span class="token punctuation">)</span>,
    <span class="token assign-left variable">sampler</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'DefaultSampler'</span>, <span class="token assign-left variable">shuffle</span><span class="token operator">=</span>False<span class="token punctuation">)</span>,
    <span class="token assign-left variable">persistent_workers</span><span class="token operator">=</span>True,
<span class="token punctuation">)</span>
<span class="token comment"># The settings of the evaluation metrics for validation. We use the top1 and top5 accuracy here.用于验证的评估度量的设置。我们在这里使用top1和top5的精度</span>
val_evaluator <span class="token operator">=</span> dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'Accuracy'</span>, <span class="token assign-left variable">topk</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">5</span><span class="token punctuation">))</span>

test_dataloader <span class="token operator">=</span> val_dataloader  <span class="token comment"># The settings of the dataloader for the test dataset, which is the same as val_dataloader</span>
test_evaluator <span class="token operator">=</span> val_evaluator    <span class="token comment"># The settings of the evaluation metrics for test, which is the same as val_evaluator</span>
</code></pre> 
<h5><a id="3_294"></a>3、日程设置</h5> 
<p>这个原始配置文件主要包含<strong>训练策略设置以及训练、验证和测试循环的设置</strong>：</p> 
<h6><a id="optim_wrapperhttpsmmenginereadthedocsioenlatesttutorialsoptim_wrapperhtml_297"></a>optim_wrapper：优化器包装器的设置。<a href="https://mmengine.readthedocs.io/en/latest/tutorials/optim_wrapper.html" rel="nofollow">我们使用优化器包装器来定制优化过程</a>。</h6> 
<h6><a id="optimizerpytorchMMEngine_299"></a>optimizer：支持所有pytorch优化器，参考相关MMEngine文档。</h6> 
<h6><a id="paramwise_cfg_300"></a>paramwise_cfg：根据参数类型或名称设置不同的优化参数，请参考相关学习策略文档。</h6> 
<h6><a id="accumulative_counts_302"></a>accumulative_counts：经过多次后退而不是一次后退来优化参数。您可以使用它通过小批量来模拟大批量。</h6> 
<h6><a id="param_scheduler_304"></a>param_scheduler：优化器参数策略。</h6> 
<p>您可以使用它来指定训练期间的学习率和动量曲线。有关更多详细信息，<a href="https://mmengine.readthedocs.io/en/latest/tutorials/param_scheduler.html" rel="nofollow">请参阅MMEngine 中的文档。</a></p> 
<h6><a id="train_cfg__val_cfg__test_cfgMMEngine_307"></a>train_cfg | val_cfg | test_cfg：训练、验证和测试循环的设置，请参考相关MMEngine文档。</h6> 
<p>以下是ResNet50配置中的schedule原语配置configs/<em>base</em>/datasets/imagenet_bs32.py：</p> 
<pre><code class="prism language-bash">optim_wrapper <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token comment"># Use SGD optimizer to optimize parameters.</span>
    <span class="token assign-left variable">optimizer</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'SGD'</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.1</span>, <span class="token assign-left variable">momentum</span><span class="token operator">=</span><span class="token number">0.9</span>, <span class="token assign-left variable">weight_decay</span><span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">))</span>

<span class="token comment"># The tuning strategy of the learning rate.学习率的调整策略</span>
<span class="token comment"># The 'MultiStepLR' means to use multiple steps policy to schedule the learning rate (LR).“MultiStepLR”是指使用多步策略来调度学习率</span>
param_scheduler <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'MultiStepLR'</span>, <span class="token assign-left variable">by_epoch</span><span class="token operator">=</span>True, <span class="token assign-left variable">milestones</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">30</span>, <span class="token number">60</span>, <span class="token number">90</span><span class="token punctuation">]</span>, <span class="token assign-left variable">gamma</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>

<span class="token comment"># Training configuration, iterate 100 epochs, and perform validation after every training epoch.</span>
<span class="token comment"># 'by_epoch=True' means to use `EpochBaseTrainLoop`, 'by_epoch=False' means to use IterBaseTrainLoop.</span>
train_cfg <span class="token operator">=</span> dict<span class="token punctuation">(</span>by_epoch<span class="token operator">=</span>True, <span class="token assign-left variable">max_epochs</span><span class="token operator">=</span><span class="token number">100</span>, <span class="token assign-left variable">val_interval</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># Use the default val loop settings.</span>
val_cfg <span class="token operator">=</span> dict<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Use the default test loop settings.</span>
test_cfg <span class="token operator">=</span> dict<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># This schedule is for the total batch size 256.此计划适用于总批大小为256的批</span>
<span class="token comment"># If you use a different total batch size, like 512 and enable auto learning rate scaling.如果您使用不同的总批大小，如512，并启用自动学习率缩放。</span>
<span class="token comment"># We will scale up the learning rate to 2 times.我们将把学习率提高到2倍。</span>
auto_scale_lr <span class="token operator">=</span> dict<span class="token punctuation">(</span>base_batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="4_336"></a>4、运行时设置</h5> 
<p>这部分主要包括保存<strong>检查点策略、日志配置、训练参数、断点权重路径、工作目录等</strong>。<br> 这是几乎所有配置都使用的运行时原始配置文件“configs/ base /default_runtime.py” ：</p> 
<pre><code class="prism language-bash"><span class="token comment"># defaults to use registries in mmpretrain，默认在mmpretrain中使用注册表</span>
default_scope <span class="token operator">=</span> <span class="token string">'mmpretrain'</span>

<span class="token comment"># configure default hooks</span>
default_hooks <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token comment"># record the time of every iteration.，记录每次迭代的时间</span>
    <span class="token assign-left variable">timer</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'IterTimerHook'</span><span class="token punctuation">)</span>,

    <span class="token comment"># print log every 100 iterations.</span>
    <span class="token assign-left variable">logger</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'LoggerHook'</span>, <span class="token assign-left variable">interval</span><span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>,

    <span class="token comment"># enable the parameter scheduler.启用参数调度程序</span>
    <span class="token assign-left variable">param_scheduler</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'ParamSchedulerHook'</span><span class="token punctuation">)</span>,

    <span class="token comment"># save checkpoint per epoch.</span>
    <span class="token assign-left variable">checkpoint</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'CheckpointHook'</span>, <span class="token assign-left variable">interval</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>,

    <span class="token comment"># set sampler seed in a distributed environment.在分布式环境中设置采样器种子</span>
    <span class="token assign-left variable">sampler_seed</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'DistSamplerSeedHook'</span><span class="token punctuation">)</span>,

    <span class="token comment"># validation results visualization, set True to enable it.</span>
    <span class="token assign-left variable">visualization</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'VisualizationHook'</span>, <span class="token assign-left variable">enable</span><span class="token operator">=</span>False<span class="token punctuation">)</span>,
<span class="token punctuation">)</span>

<span class="token comment"># configure environment</span>
env_cfg <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token comment"># whether to enable cudnn benchmark，是否开启cudnn基准</span>
    <span class="token assign-left variable">cudnn_benchmark</span><span class="token operator">=</span>False,

    <span class="token comment"># set multi-process parameters，设置多进程参数</span>
    <span class="token assign-left variable">mp_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>mp_start_method<span class="token operator">=</span><span class="token string">'fork'</span>, <span class="token assign-left variable">opencv_num_threads</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>,

    <span class="token comment"># set distributed parameters，设置分布参数</span>
    <span class="token assign-left variable">dist_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">)</span>,
<span class="token punctuation">)</span>

<span class="token comment"># set visualizer</span>
vis_backends <span class="token operator">=</span> <span class="token punctuation">[</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'LocalVisBackend'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># use local HDD backend</span>
visualizer <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'UniversalVisualizer'</span>, <span class="token assign-left variable">vis_backends</span><span class="token operator">=</span>vis_backends, <span class="token assign-left variable">name</span><span class="token operator">=</span><span class="token string">'visualizer'</span><span class="token punctuation">)</span>

<span class="token comment"># set log level</span>
log_level <span class="token operator">=</span> <span class="token string">'INFO'</span>

<span class="token comment"># load from which checkpoint</span>
load_from <span class="token operator">=</span> None

<span class="token comment"># whether to resume training from the loaded checkpoint</span>
resume <span class="token operator">=</span> False
</code></pre> 
<h4><a id="2_391"></a>2、继承和修改配置文件</h4> 
<p>为了便于理解，我们建议贡献者继承现有的配置文件。但不要滥用继承权。<strong>通常，对于所有配置文件，我们建议最大继承级别为 3。</strong></p> 
<p>例如，如果您的配置文件是基于ResNet并进行了一些其他修改，您可以首先通过指定_base_ =‘./resnet50_8xb32_in1k.py’（相对于您的配置文件的路径）来继承基本的ResNet结构、数据集和其他训练设置，然后修改配置文件。一个更具体的例子，现在我们想要使用configs/resnet/resnet50_8xb32_in1k.py中的几乎所有配置，<strong>但是</strong>使用CutMix训练批次增强<strong>并将训练时期数从100 更改为 300，修改何时衰减学习率，并修改数据集路径</strong>，您可以创建一个新的configs/resnet/resnet50_8xb32-300e_in1k.py配置文件 ，内容如下：</p> 
<pre><code class="prism language-bash"><span class="token comment"># create this file under 'configs/resnet/' folder</span>
_base_ <span class="token operator">=</span> <span class="token string">'./resnet50_8xb32_in1k.py'</span>

<span class="token comment"># using CutMix batch augment</span>
model <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">train_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">augments</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'CutMix'</span>, <span class="token assign-left variable">alpha</span><span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token comment">#增加了数据增强</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># trains more epochs</span>
train_cfg <span class="token operator">=</span> dict<span class="token punctuation">(</span>max_epochs<span class="token operator">=</span><span class="token number">300</span>, <span class="token assign-left variable">val_interval</span><span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># Train for 300 epochs, evaluate every 10 epochs</span>
param_scheduler <span class="token operator">=</span> dict<span class="token punctuation">(</span>step<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">150</span>, <span class="token number">200</span>, <span class="token number">250</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># The learning rate adjustment has also changed</span>

<span class="token comment"># Use your own dataset directory</span>
train_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>data_root<span class="token operator">=</span><span class="token string">'mydata/imagenet/train'</span><span class="token punctuation">)</span>,
<span class="token punctuation">)</span>
val_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">batch_size</span><span class="token operator">=</span><span class="token number">64</span>,                  <span class="token comment"># No back-propagation during validation, larger batch size can be used</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>data_root<span class="token operator">=</span><span class="token string">'mydata/imagenet/val'</span><span class="token punctuation">)</span>,
<span class="token punctuation">)</span>
test_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">batch_size</span><span class="token operator">=</span><span class="token number">64</span>,                  <span class="token comment"># No back-propagation during test, larger batch size can be used</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>data_root<span class="token operator">=</span><span class="token string">'mydata/imagenet/val'</span><span class="token punctuation">)</span>,
<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="3_423"></a>3、修改命令中的配置</h4> 
<p>当您使用脚本“tools/train.py”或“tools/test.py”提交任务或使用其他一些工具时，它们可以通过指定参数直接修改所使用的配置文件的内容–cfg-options。</p> 
<p>更新字典链的配置键。</p> 
<p>可以按照原始配置中字典键的顺序指定配置选项。例如，将模型主干中的所有 BN 模块更改为模式。</p> 
<pre><code class="prism language-bash">--cfg-options <span class="token assign-left variable">model.backbone.norm_eval</span><span class="token operator">=</span>False
</code></pre> 
<p>更新配置列表中的密钥。</p> 
<p>一些配置字典在您的配置中组成一个列表。例如，训练管道data.train.pipeline通常是一个列表，例如。如果您想在管道中更改为，您可以指定。</p> 
<pre><code class="prism language-bash"><span class="token punctuation">[</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span>, dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'TopDownRandomFlip'</span>, <span class="token assign-left variable">flip_prob</span><span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>, <span class="token punctuation">..</span>.<span class="token punctuation">]</span>
</code></pre> 
<p>更新列表/元组的值。</p> 
<p>如果要更新的值是列表或元组。例如，配置文件通常设置. 如果您想更改该字段，您可以指定。请注意，引号“对于支持列表/元组数据类型是必需的，并且指定值的引号内不允许有空格。</p> 
<pre><code class="prism language-bash">val_evaluator <span class="token operator">=</span> dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'Accuracy'</span>, <span class="token assign-left variable">topk</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">5</span><span class="token punctuation">))</span>
--cfg-options <span class="token assign-left variable">val_evaluator.topk</span><span class="token operator">=</span><span class="token string">"(1,3)"</span>
</code></pre> 
<h4><a id="4_451"></a>4、现有模型的推理</h4> 
<p>本教程将展示如何使用以下API：</p> 
<p>list_models：列出 MMPreTrain 中可用的模型名称。<br> get_model：从模型名称或模型配置中获取模型。<br> inference_model：用相应的推理器推理模型。<br> 这是快速入门的快捷方式，对于高级用法，请直接使用下面的推理器。</p> 
<p>推理者：<br> ImageClassificationInferencer：对给定图像进行图像分类。<br> ImageRetrievalInferencer：从给定图像集上的给定图像执行图像到图像检索。<br> ImageCaptionInferencer：在给定图像上生成标题。<br> VisualQuestionAnsweringInferencer：根据给定的图片回答问题。<br> VisualGroundingInferencer：从给定图像的描述中找到一个对象。<br> TextToImageRetrievalInferencer：根据给定图像集的给定描述执行文本到图像检索。<br> ImageToTextRetrievalInferencer：从给定图像对一系列文本执行图像到文本检索。<br> NLVRInferencer：对给定的图像对和文本执行自然语言视觉推理。<br> FeatureExtractor：通过视觉主干从图像文件中提取特征。</p> 
<h5><a id="_469"></a>列出可用型号</h5> 
<p>列出 MMPreTrain 中的所有模型。</p> 
<pre><code class="prism language-bash">from mmpretrain <span class="token function">import</span> list_models
list_models<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>list_models支持Unix文件名模式匹配，可以使用*** * **来匹配任何字符。</p> 
<pre><code class="prism language-bash">from mmpretrain <span class="token function">import</span> list_models
list_models<span class="token punctuation">(</span><span class="token string">"*convnext-b*21k"</span><span class="token punctuation">)</span>
</code></pre> 
<p>您可以使用list_models推理器的方法来获取相应任务的可用模型。</p> 
<pre><code class="prism language-bash">from mmpretrain <span class="token function">import</span> ImageCaptionInferencer
ImageCaptionInferencer.list_models<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="Get_a_model_487"></a>Get a model</h5> 
<p>you can use get_model get the model.</p> 
<pre><code class="prism language-bash">from mmpretrain <span class="token function">import</span> get_model

model <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token string">"convnext-base_in21k-pre_3rdparty_in1k"</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token string">"convnext-base_in21k-pre_3rdparty_in1k"</span>, <span class="token assign-left variable">pretrained</span><span class="token operator">=</span>True<span class="token punctuation">)</span>

model <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token string">"convnext-base_in21k-pre_3rdparty_in1k"</span>, <span class="token assign-left variable">pretrained</span><span class="token operator">=</span><span class="token string">"your_local_checkpoint_path"</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token string">"convnext-base_in21k-pre_3rdparty_in1k"</span>, <span class="token assign-left variable">head</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">))</span>

model_headless <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token string">"resnet18_8xb32_in1k"</span>, <span class="token assign-left variable">head</span><span class="token operator">=</span>None, <span class="token assign-left variable">neck</span><span class="token operator">=</span>None, <span class="token assign-left variable">backbone</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>out_indices<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">2</span>, <span class="token number">3</span><span class="token punctuation">))</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-bash"><span class="token function">import</span> torch
from mmpretrain <span class="token function">import</span> get_model
model <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token string">'convnext-base_in21k-pre_3rdparty_in1k'</span>, <span class="token assign-left variable">pretrained</span><span class="token operator">=</span>True<span class="token punctuation">)</span>
x <span class="token operator">=</span> torch.rand<span class="token variable"><span class="token punctuation">((</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">))</span></span>
y <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
print<span class="token punctuation">(</span>type<span class="token punctuation">(</span>y<span class="token punctuation">)</span>, y.shape<span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_512"></a>对给定图像的推理</h5> 
<p>以下是通过 ResNet-50 预训练分类模型推断图像的示例。</p> 
<pre><code class="prism language-bash">from mmpretrain <span class="token function">import</span> inference_model
image <span class="token operator">=</span> <span class="token string">'https://github.com/open-mmlab/mmpretrain/raw/main/demo/demo.JPEG'</span>
<span class="token comment"># If you have no graphical interface, please set `show=False`</span>
result <span class="token operator">=</span> inference_model<span class="token punctuation">(</span><span class="token string">'resnet50_8xb32_in1k'</span>, image, <span class="token assign-left variable">show</span><span class="token operator">=</span>True<span class="token punctuation">)</span>
print<span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">'pred_class'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>该inference_modelAPI仅用于演示，不能保留模型实例或对多个样本进行推理。您可以使用推理器进行多次调用。</p> 
<pre><code class="prism language-bash">from mmpretrain <span class="token function">import</span> ImageClassificationInferencer
image <span class="token operator">=</span> <span class="token string">'https://github.com/open-mmlab/mmpretrain/raw/main/demo/demo.JPEG'</span>
inferencer <span class="token operator">=</span> ImageClassificationInferencer<span class="token punctuation">(</span><span class="token string">'resnet50_8xb32_in1k'</span><span class="token punctuation">)</span>
<span class="token comment"># Note that the inferencer output is a list of result even if the input is a single sample.</span>
result <span class="token operator">=</span> inferencer<span class="token punctuation">(</span><span class="token string">'https://github.com/open-mmlab/mmpretrain/raw/main/demo/demo.JPEG'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
print<span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">'pred_class'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># You can also use is for multiple images.</span>
image_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'demo/demo.JPEG'</span>, <span class="token string">'demo/bird.JPEG'</span><span class="token punctuation">]</span> * <span class="token number">16</span>
results <span class="token operator">=</span> inferencer<span class="token punctuation">(</span>image_list, <span class="token assign-left variable">batch_size</span><span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span>len<span class="token punctuation">(</span>results<span class="token punctuation">))</span>
print<span class="token punctuation">(</span>results<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'pred_class'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>通常，每个样本的结果都是一个字典。例如，图像分类结果是一个包含pred_label、pred_score、的字典，pred_scores如下pred_class</p> 
<pre><code class="prism language-bash"><span class="token punctuation">{<!-- --></span>
    <span class="token string">"pred_label"</span><span class="token builtin class-name">:</span> <span class="token number">65</span>,
    <span class="token string">"pred_score"</span><span class="token builtin class-name">:</span> <span class="token number">0.6649366617202759</span>,
    <span class="token string">"pred_class"</span><span class="token builtin class-name">:</span><span class="token string">"sea snake"</span>,
    <span class="token string">"pred_scores"</span><span class="token builtin class-name">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">..</span>., <span class="token number">0.6649366617202759</span>, <span class="token punctuation">..</span>.<span class="token punctuation">]</span>, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>float32<span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>您可以通过参数配置推理器，例如，使用您自己的配置文件和检查点通过 CUDA 推理图像。</p> 
<pre><code class="prism language-bash">from mmpretrain <span class="token function">import</span> ImageClassificationInferencer
image <span class="token operator">=</span> <span class="token string">'https://github.com/open-mmlab/mmpretrain/raw/main/demo/demo.JPEG'</span>
config <span class="token operator">=</span> <span class="token string">'configs/resnet/resnet50_8xb32_in1k.py'</span>
checkpoint <span class="token operator">=</span> <span class="token string">'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth'</span>
inferencer <span class="token operator">=</span> ImageClassificationInferencer<span class="token punctuation">(</span>model<span class="token operator">=</span>config, <span class="token assign-left variable">pretrained</span><span class="token operator">=</span>checkpoint, <span class="token assign-left variable">device</span><span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> inferencer<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
print<span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">'pred_class'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_Gradio__558"></a>通过 Gradio 演示进行推理</h5> 
<p>我们还为所有支持的任务提供了渐变演示，您可以在projects/gradio_demo/launch.py​​ 中找到它。<br> gradio请先安装。pip install -U gradio</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> <span class="token string">"gradio&gt;=3.31.0"</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/b0/32/IualJKwX_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="_567"></a>从图像中提取特征</h5> 
<p>FeatureExtractor与model.extract_feat 相比，是直接从图像文件中提取特征，而不是使用一批张量。总之， model.extract_feat的输入是torch.Tensor， FeatureExtractor的输入是图像。</p> 
<pre><code class="prism language-bash">from mmpretrain <span class="token function">import</span> FeatureExtractor, get_model
model <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token string">'resnet50_8xb32_in1k'</span>, <span class="token assign-left variable">backbone</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>out_indices<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">1</span>, <span class="token number">2</span>, <span class="token number">3</span><span class="token punctuation">))</span><span class="token punctuation">)</span>
extractor <span class="token operator">=</span> FeatureExtractor<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
features <span class="token operator">=</span> extractor<span class="token punctuation">(</span><span class="token string">'https://github.com/open-mmlab/mmpretrain/raw/main/demo/demo.JPEG'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>.shape, features<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>.shape, features<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>.shape, features<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>.shape
</code></pre> 
<h4><a id="5_576"></a>5、模型训练</h4> 
<p>在本教程中，我们将介绍如何使用 MMPretrain 中提供的脚本来启动训练任务。如果您需要，我们还提供了一些有关如何使用自定义数据集进行预训练 以及如何使用自定义数据集进行微调的练习示例。</p> 
<h5><a id="_579"></a>使用您的电脑进行训练</h5> 
<p>您可以使用tools/train.py它在具有 CPU 和可选 GPU 的单台机器上训练模型。</p> 
<p>以下是该脚本的完整用法：</p> 
<pre><code class="prism language-bash">python tools/train.py <span class="token variable">${CONFIG_FILE}</span> <span class="token punctuation">[</span>ARGS<span class="token punctuation">]</span>
</code></pre> 
<p>默认情况下，MMPretrain 更喜欢 GPU 而不是 CPU。如果你想在CPU上训练模型，请将CUDA_VISIBLE_DEVICES其清空或设置为-1以使GPU对程序不可见。</p> 
<pre><code class="prism language-bash"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span>-1 python tools/train.py <span class="token variable">${CONFIG_FILE}</span> <span class="token punctuation">[</span>ARGS<span class="token punctuation">]</span>
</code></pre> 
<p>CONFIG_FILE 配置文件的路径。</p> 
<p>–work-dir WORK_DIR 保存日志和检查点的目标文件夹。默认为 .config 下的配置文件同名的文件夹./work_dirs。</p> 
<p>–resume [RESUME] 恢复训练。如果指定路径，则从该路径恢复，如果不指定，则尝试从最新的检查点自动恢复。</p> 
<p>–amp 启用自动混合精度训练。</p> 
<p>–no-validate 不建议。在训练期间禁用检查点评估。</p> 
<p>–auto-scale-lr 根据实际批量大小和原始批量大小自动缩放学习率。</p> 
<p>–no-pin-memory 是否禁用pin_memory数据加载器中的选项。</p> 
<p>–no-persistent-workers 是否禁用persistent_workers数据加载器中的选项。</p> 
<p>–cfg-options CFG_OPTIONS 覆盖已使用配置中的一些设置，xxx=yyy 格式的键值对将合并到配置文件中。如果要覆盖的值是列表，则其形式应为key=“[a,b]“或key=a,b。该参数还允许嵌套列表/元组值，例如key=”[(a,b),(c,d)]”。请注意，引号是必需的，并且不允许有空格。</p> 
<p>–launcher {none,pytorch,slurm,mpi}，作业启动器的选项。</p> 
<h5><a id="_GPU__611"></a>使用多个 GPU 进行训练</h5> 
<p>我们提供了一个 shell 脚本来启动多 GPU 任务torch.distributed.launch。</p> 
<pre><code class="prism language-bash"><span class="token function">bash</span> ./tools/dist_train.sh <span class="token variable">${CONFIG_FILE}</span> <span class="token variable">${GPU_NUM}</span> <span class="token punctuation">[</span>PY_ARGS<span class="token punctuation">]</span>
</code></pre> 
<p>您还可以通过环境变量指定启动器的额外参数。例如，通过以下命令将启动器的通信端口更改为29666：</p> 
<pre><code class="prism language-bash"><span class="token assign-left variable">PORT</span><span class="token operator">=</span><span class="token number">29666</span> <span class="token function">bash</span> ./tools/dist_train.sh <span class="token variable">${CONFIG_FILE}</span> <span class="token variable">${GPU_NUM}</span> <span class="token punctuation">[</span>PY_ARGS<span class="token punctuation">]</span>
</code></pre> 
<p>如果您想启动多个训练作业并使用不同的GPU，您可以通过指定不同的端口和可见设备来启动它们。</p> 
<pre><code class="prism language-bash"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span>,2,3 <span class="token assign-left variable">PORT</span><span class="token operator">=</span><span class="token number">29500</span> <span class="token function">bash</span> ./tools/dist_train.sh <span class="token variable">${CONFIG_FILE1}</span> <span class="token number">4</span> <span class="token punctuation">[</span>PY_ARGS<span class="token punctuation">]</span>
<span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">4,5</span>,6,7 <span class="token assign-left variable">PORT</span><span class="token operator">=</span><span class="token number">29501</span> <span class="token function">bash</span> ./tools/dist_train.sh <span class="token variable">${CONFIG_FILE2}</span> <span class="token number">4</span> <span class="token punctuation">[</span>PY_ARGS<span class="token punctuation">]</span>
</code></pre> 
<h5><a id="_628"></a>如何使用自定义数据集进行预训练</h5> 
<p>在本教程中，我们提供了一个练习示例以及一些有关如何在您自己的数据集上进行训练的技巧。<br> 在 MMPretrain 中，我们支持CustomDataset（类似于ImageFolderin torchvision），可以直接读取指定文件夹内的图像。<strong>您只需准备自定义数据集的路径信息并编辑config即可</strong>。</p> 
<h6><a id="_1__631"></a>第 1 步：准备数据集</h6> 
<p>按照准备数据集准备数据集。数据集的根文件夹可以是这样的data/custom_dataset/。<br> 在这里，我们假设您想要进行无监督训练，并使用子文件夹格式CustomDataset将数据集组织为：<br> data/custom_dataset/<br> ├── sample1.png<br> ├── sample2.png<br> ├── sample3.png<br> ├── sample4.png<br> └── …</p> 
<h6><a id="_2_640"></a>步骤 2：选择一个配置作为模板</h6> 
<p>在这里，我们想以此configs/mae/mae_vit-base-p16_8xb512-amp-coslr-300e_in1k.py为例。我们首先将此配置文件复制到同一文件夹并将其重命名为 mae_vit-base-p16_8xb512-amp-coslr-300e_custom.py.<br> 该配置的内容是：</p> 
<pre><code class="prism language-bash">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'../_base_/models/mae_vit-base-p16.py'</span>,
    <span class="token string">'../_base_/datasets/imagenet_bs512_mae.py'</span>,
    <span class="token string">'../_base_/default_runtime.py'</span>,
<span class="token punctuation">]</span>

<span class="token comment"># optimizer wrapper</span>
optim_wrapper <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'AmpOptimWrapper'</span>,
    <span class="token assign-left variable">loss_scale</span><span class="token operator">=</span><span class="token string">'dynamic'</span>,
    <span class="token assign-left variable">optimizer</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'AdamW'</span>,
        <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">1</span>.5e-4 * <span class="token number">4096</span> / <span class="token number">256</span>,
        <span class="token assign-left variable">betas</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.9</span>, <span class="token number">0.95</span><span class="token punctuation">)</span>,
        <span class="token assign-left variable">weight_decay</span><span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span>,
    <span class="token assign-left variable">paramwise_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">custom_keys</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
            <span class="token string">'ln'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>,
            <span class="token string">'bias'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>,
            <span class="token string">'pos_embed'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0</span>.<span class="token punctuation">)</span>,
            <span class="token string">'mask_token'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0</span>.<span class="token punctuation">)</span>,
            <span class="token string">'cls_token'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0</span>.<span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">))</span>

<span class="token comment"># learning rate scheduler</span>
param_scheduler <span class="token operator">=</span> <span class="token punctuation">[</span>
    dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'LinearLR'</span>,
        <span class="token assign-left variable">start_factor</span><span class="token operator">=</span><span class="token number">0.0001</span>,
        <span class="token assign-left variable">by_epoch</span><span class="token operator">=</span>True,
        <span class="token assign-left variable">begin</span><span class="token operator">=</span><span class="token number">0</span>,
        <span class="token assign-left variable">end</span><span class="token operator">=</span><span class="token number">40</span>,
        <span class="token assign-left variable">convert_to_iter_based</span><span class="token operator">=</span>True<span class="token punctuation">)</span>,
    dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CosineAnnealingLR'</span>,
        <span class="token assign-left variable">T_max</span><span class="token operator">=</span><span class="token number">260</span>,
        <span class="token assign-left variable">by_epoch</span><span class="token operator">=</span>True,
        <span class="token assign-left variable">begin</span><span class="token operator">=</span><span class="token number">40</span>,
        <span class="token assign-left variable">end</span><span class="token operator">=</span><span class="token number">300</span>,
        <span class="token assign-left variable">convert_to_iter_based</span><span class="token operator">=</span>True<span class="token punctuation">)</span>
<span class="token punctuation">]</span>

<span class="token comment"># runtime settings</span>
train_cfg <span class="token operator">=</span> dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'EpochBasedTrainLoop'</span>, <span class="token assign-left variable">max_epochs</span><span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span>
default_hooks <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token comment"># only keeps the latest 3 checkpoints</span>
    <span class="token assign-left variable">checkpoint</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'CheckpointHook'</span>, <span class="token assign-left variable">interval</span><span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">max_keep_ckpts</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">))</span>

randomness <span class="token operator">=</span> dict<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span>, <span class="token assign-left variable">diff_rank_seed</span><span class="token operator">=</span>True<span class="token punctuation">)</span>

<span class="token comment"># auto resume</span>
resume <span class="token operator">=</span> True

<span class="token comment"># NOTE: `auto_scale_lr` is for automatically scaling LR</span>
<span class="token comment"># based on the actual training batch size.</span>
auto_scale_lr <span class="token operator">=</span> dict<span class="token punctuation">(</span>base_batch_size<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">)</span>
</code></pre> 
<h6><a id="3_702"></a>步骤3：编辑数据集相关配置</h6> 
<p>将type数据集设置覆盖为’CustomDataset’<br> data_root将数据集设置覆盖为data/custom_dataset.<br> 将数据集设置覆盖ann_file为空字符串，因为我们假设您使用的是子文件夹格式CustomDataset。<br> 将数据集设置覆盖data_prefix为空字符串，因为我们在 下使用整个数据集data_root，并且您不需要将样本拆分为不同的子集并设置data_prefix.<br> 修改后的配置将类似于：</p> 
<pre><code class="prism language-bash">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'../_base_/models/mae_vit-base-p16.py'</span>,
    <span class="token string">'../_base_/datasets/imagenet_bs512_mae.py'</span>,
    <span class="token string">'../_base_/default_runtime.py'</span>,
<span class="token punctuation">]</span>

<span class="token comment"># &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Override dataset settings here &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span>
train_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CustomDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span><span class="token string">'data/custom_dataset/'</span>,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">''</span>,       <span class="token comment"># We assume you are using the sub-folder format without ann_file,我们假设您使用的是没有ann_file的子文件夹格式</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">''</span>,    <span class="token comment"># The `data_root` is the data_prefix directly.</span>
        <span class="token assign-left variable">with_label</span><span class="token operator">=</span>False,
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token comment"># &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span>

<span class="token comment"># optimizer wrapper</span>
optim_wrapper <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'AmpOptimWrapper'</span>,
    <span class="token assign-left variable">loss_scale</span><span class="token operator">=</span><span class="token string">'dynamic'</span>,
    <span class="token assign-left variable">optimizer</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'AdamW'</span>,
        <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">1</span>.5e-4 * <span class="token number">4096</span> / <span class="token number">256</span>,
        <span class="token assign-left variable">betas</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.9</span>, <span class="token number">0.95</span><span class="token punctuation">)</span>,
        <span class="token assign-left variable">weight_decay</span><span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span>,
    <span class="token assign-left variable">paramwise_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">custom_keys</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
            <span class="token string">'ln'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>,
            <span class="token string">'bias'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>,
            <span class="token string">'pos_embed'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0</span>.<span class="token punctuation">)</span>,
            <span class="token string">'mask_token'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0</span>.<span class="token punctuation">)</span>,
            <span class="token string">'cls_token'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0</span>.<span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">))</span>

<span class="token comment"># learning rate scheduler</span>
param_scheduler <span class="token operator">=</span> <span class="token punctuation">[</span>
    dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'LinearLR'</span>,
        <span class="token assign-left variable">start_factor</span><span class="token operator">=</span><span class="token number">0.0001</span>,
        <span class="token assign-left variable">by_epoch</span><span class="token operator">=</span>True,
        <span class="token assign-left variable">begin</span><span class="token operator">=</span><span class="token number">0</span>,
        <span class="token assign-left variable">end</span><span class="token operator">=</span><span class="token number">40</span>,
        <span class="token assign-left variable">convert_to_iter_based</span><span class="token operator">=</span>True<span class="token punctuation">)</span>,
    dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CosineAnnealingLR'</span>,
        <span class="token assign-left variable">T_max</span><span class="token operator">=</span><span class="token number">260</span>,
        <span class="token assign-left variable">by_epoch</span><span class="token operator">=</span>True,
        <span class="token assign-left variable">begin</span><span class="token operator">=</span><span class="token number">40</span>,
        <span class="token assign-left variable">end</span><span class="token operator">=</span><span class="token number">300</span>,
        <span class="token assign-left variable">convert_to_iter_based</span><span class="token operator">=</span>True<span class="token punctuation">)</span>
<span class="token punctuation">]</span>

<span class="token comment"># runtime settings</span>
train_cfg <span class="token operator">=</span> dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'EpochBasedTrainLoop'</span>, <span class="token assign-left variable">max_epochs</span><span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span>
default_hooks <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token comment"># only keeps the latest 3 checkpoints</span>
    <span class="token assign-left variable">checkpoint</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'CheckpointHook'</span>, <span class="token assign-left variable">interval</span><span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">max_keep_ckpts</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">))</span>

randomness <span class="token operator">=</span> dict<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span>, <span class="token assign-left variable">diff_rank_seed</span><span class="token operator">=</span>True<span class="token punctuation">)</span>

<span class="token comment"># auto resume</span>
resume <span class="token operator">=</span> True

<span class="token comment"># NOTE: `auto_scale_lr` is for automatically scaling LR</span>
<span class="token comment"># based on the actual training batch size.</span>
auto_scale_lr <span class="token operator">=</span> dict<span class="token punctuation">(</span>base_batch_size<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">)</span>
</code></pre> 
<p>通过使用编辑后的配置文件，您可以在自定义数据集上使用 MAE 算法训练自监督模型。</p> 
<p>遵循上述想法，我们还提供了如何在 COCO 数据集上训练 MAE 的示例。编辑后的文件将是这样的</p> 
<pre><code class="prism language-bash">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'../_base_/models/mae_vit-base-p16.py'</span>,
    <span class="token string">'../_base_/datasets/imagenet_mae.py'</span>,
    <span class="token string">'../_base_/default_runtime.py'</span>,
<span class="token punctuation">]</span>

<span class="token comment"># &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Override dataset settings here &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span>
train_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'mmdet.CocoDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span><span class="token string">'data/coco/'</span>,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">'annotations/instances_train2017.json'</span>,  <span class="token comment"># Only for loading images, and the labels won't be used.</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>img<span class="token operator">=</span><span class="token string">'train2017/'</span><span class="token punctuation">)</span>,
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token comment"># &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span>

<span class="token comment"># optimizer wrapper</span>
optim_wrapper <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'AmpOptimWrapper'</span>,
    <span class="token assign-left variable">loss_scale</span><span class="token operator">=</span><span class="token string">'dynamic'</span>,
    <span class="token assign-left variable">optimizer</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'AdamW'</span>,
        <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">1</span>.5e-4 * <span class="token number">4096</span> / <span class="token number">256</span>,
        <span class="token assign-left variable">betas</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.9</span>, <span class="token number">0.95</span><span class="token punctuation">)</span>,
        <span class="token assign-left variable">weight_decay</span><span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span>,
    <span class="token assign-left variable">paramwise_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">custom_keys</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
            <span class="token string">'ln'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>,
            <span class="token string">'bias'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>,
            <span class="token string">'pos_embed'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0</span>.<span class="token punctuation">)</span>,
            <span class="token string">'mask_token'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0</span>.<span class="token punctuation">)</span>,
            <span class="token string">'cls_token'</span><span class="token builtin class-name">:</span> dict<span class="token punctuation">(</span>decay_mult<span class="token operator">=</span><span class="token number">0</span>.<span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">))</span>

<span class="token comment"># learning rate scheduler</span>
param_scheduler <span class="token operator">=</span> <span class="token punctuation">[</span>
    dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'LinearLR'</span>,
        <span class="token assign-left variable">start_factor</span><span class="token operator">=</span><span class="token number">0.0001</span>,
        <span class="token assign-left variable">by_epoch</span><span class="token operator">=</span>True,
        <span class="token assign-left variable">begin</span><span class="token operator">=</span><span class="token number">0</span>,
        <span class="token assign-left variable">end</span><span class="token operator">=</span><span class="token number">40</span>,
        <span class="token assign-left variable">convert_to_iter_based</span><span class="token operator">=</span>True<span class="token punctuation">)</span>,
    dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CosineAnnealingLR'</span>,
        <span class="token assign-left variable">T_max</span><span class="token operator">=</span><span class="token number">260</span>,
        <span class="token assign-left variable">by_epoch</span><span class="token operator">=</span>True,
        <span class="token assign-left variable">begin</span><span class="token operator">=</span><span class="token number">40</span>,
        <span class="token assign-left variable">end</span><span class="token operator">=</span><span class="token number">300</span>,
        <span class="token assign-left variable">convert_to_iter_based</span><span class="token operator">=</span>True<span class="token punctuation">)</span>
<span class="token punctuation">]</span>

<span class="token comment"># runtime settings</span>
train_cfg <span class="token operator">=</span> dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'EpochBasedTrainLoop'</span>, <span class="token assign-left variable">max_epochs</span><span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span>
default_hooks <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token comment"># only keeps the latest 3 checkpoints</span>
    <span class="token assign-left variable">checkpoint</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'CheckpointHook'</span>, <span class="token assign-left variable">interval</span><span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">max_keep_ckpts</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">))</span>

randomness <span class="token operator">=</span> dict<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span>, <span class="token assign-left variable">diff_rank_seed</span><span class="token operator">=</span>True<span class="token punctuation">)</span>

<span class="token comment"># auto resume</span>
resume <span class="token operator">=</span> True

<span class="token comment"># NOTE: `auto_scale_lr` is for automatically scaling LR</span>
<span class="token comment"># based on the actual training batch size.</span>
auto_scale_lr <span class="token operator">=</span> dict<span class="token punctuation">(</span>base_batch_size<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_852"></a>如何使用自定义数据集进行预训练</h5> 
<h6><a id="_1__853"></a>第 1 步：准备数据集</h6> 
<p>按照准备数据集准备数据集。数据集的根文件夹可以是这样的data/custom_dataset/。<br> 在这里，我们假设您想要进行<strong>监督图像分类训练</strong>，并使用子文件夹格式 CustomDataset将数据集组织为<br> data/custom_dataset/<br> ├── train<br> │ ├── class_x<br> │ │ ├── x_1.png<br> │ │ ├── x_2.png<br> │ │ ├── x_3.png<br> │ │ └── …<br> │ ├── class_y<br> │ └── …<br> └── test<br> ├── class_x<br> │ ├── test_x_1.png<br> │ ├── test_x_2.png<br> │ ├── test_x_3.png<br> │ └── …<br> ├── class_y<br> └── …</p> 
<h6><a id="_2_873"></a>步骤 2：选择一个配置作为模板</h6> 
<p>在这里，我们想以此configs/resnet/resnet50_8xb32_in1k.py为例。我们首先将此配置文件复制到同一文件夹并将其重命名为resnet50_8xb32-ft_custom.py.</p> 
<pre><code class="prism language-bash">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'../_base_/models/resnet50.py'</span>,           <span class="token comment"># model settings</span>
    <span class="token string">'../_base_/datasets/imagenet_bs32.py'</span>,    <span class="token comment"># data settings</span>
    <span class="token string">'../_base_/schedules/imagenet_bs256.py'</span>,  <span class="token comment"># schedule settings</span>
    <span class="token string">'../_base_/default_runtime.py'</span>,           <span class="token comment"># runtime settings</span>
<span class="token punctuation">]</span>
</code></pre> 
<h6><a id="_3_884"></a>步骤 3：编辑模型设置</h6> 
<p>在微调模型时，通常我们希望<strong>加载预先训练的主干权重并从头开始训练新的分类头</strong>。</p> 
<p>要加载预训练的主干网，我们需要更改主干网的初始化配置并使用Pretrained初始化函数。此外，在init_cfg 中 ，我们用来prefix='backbone’告诉初始化函数检查点中需要加载的子模块的前缀。</p> 
<p>例如，backbone这里的意思是加载backbone子模块。这里我们使用在线检查点，它会在训练期间自动下载，您也可以手动下载模型并使用本地路径。然后我们需要根据新数据集的类号来修改头部，<strong>只需更改num_classes头部即可</strong>。</p> 
<p>当新数据集很小并且与预训练数据集共享域时，我们可能希望<strong>冻结主干的前几个阶段的参数</strong>，这将有助于网络保持从预训练数据集中提取低级信息的能力模型。在 MMPretrain 中，**您可以简单地通过参数指定要冻结的阶段数frozen_stages。**例如，要冻结前两个阶段的参数，只需使用以下配置：<br> frozen_stages到目前为止，并非所有骨干都支持这一论点。请检查 文档 以确认您的主干是否支持它。</p> 
<pre><code class="prism language-bash">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'../_base_/models/resnet50.py'</span>,           <span class="token comment"># model settings</span>
    <span class="token string">'../_base_/datasets/imagenet_bs32.py'</span>,    <span class="token comment"># data settings</span>
    <span class="token string">'../_base_/schedules/imagenet_bs256.py'</span>,  <span class="token comment"># schedule settings</span>
    <span class="token string">'../_base_/default_runtime.py'</span>,           <span class="token comment"># runtime settings</span>
<span class="token punctuation">]</span>

<span class="token comment"># &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Override model settings here &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span>
model <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">backbone</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">frozen_stages</span><span class="token operator">=</span><span class="token number">2</span>,
        <span class="token assign-left variable">init_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
            <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'Pretrained'</span>,
            <span class="token assign-left variable">checkpoint</span><span class="token operator">=</span><span class="token string">'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth'</span>,
            <span class="token assign-left variable">prefix</span><span class="token operator">=</span><span class="token string">'backbone'</span>,
        <span class="token punctuation">))</span>,
    <span class="token assign-left variable">head</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>,
<span class="token punctuation">)</span>
<span class="token comment"># &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span>
</code></pre> 
<p>这里我们只需要设置我们想要修改的部分配置，因为继承的配置将被合并并得到整个配置。</p> 
<h6><a id="_4_915"></a>步骤 4：编辑数据集设置</h6> 
<p>为了对新数据集进行微调，我们需要覆盖一些数据集设置，例如数据集类型、数据管道等。</p> 
<pre><code class="prism language-bash">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'../_base_/models/resnet50.py'</span>,           <span class="token comment"># model settings</span>
    <span class="token string">'../_base_/datasets/imagenet_bs32.py'</span>,    <span class="token comment"># data settings</span>
    <span class="token string">'../_base_/schedules/imagenet_bs256.py'</span>,  <span class="token comment"># schedule settings</span>
    <span class="token string">'../_base_/default_runtime.py'</span>,           <span class="token comment"># runtime settings</span>
<span class="token punctuation">]</span>

<span class="token comment"># model settings</span>
model <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">backbone</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">frozen_stages</span><span class="token operator">=</span><span class="token number">2</span>,
        <span class="token assign-left variable">init_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
            <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'Pretrained'</span>,
            <span class="token assign-left variable">checkpoint</span><span class="token operator">=</span><span class="token string">'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth'</span>,
            <span class="token assign-left variable">prefix</span><span class="token operator">=</span><span class="token string">'backbone'</span>,
        <span class="token punctuation">))</span>,
    <span class="token assign-left variable">head</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>,
<span class="token punctuation">)</span>

<span class="token comment"># &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Override data settings here &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span>
data_root <span class="token operator">=</span> <span class="token string">'data/custom_dataset'</span>
train_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CustomDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span>data_root,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">''</span>,       <span class="token comment"># We assume you are using the sub-folder format without ann_file</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'train'</span>,
    <span class="token punctuation">))</span>
val_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CustomDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span>data_root,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">''</span>,       <span class="token comment"># We assume you are using the sub-folder format without ann_file</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'test'</span>,
    <span class="token punctuation">))</span>
test_dataloader <span class="token operator">=</span> val_dataloader
<span class="token comment"># &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span>
</code></pre> 
<h6><a id="_5_957"></a>步骤 5：编辑计划设置（可选）</h6> 
<p>微调超参数与默认计划不同。它通常需要较小的学习率和更快的衰减调度器时期。</p> 
<pre><code class="prism language-bash">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'../_base_/models/resnet50.py'</span>,           <span class="token comment"># model settings</span>
    <span class="token string">'../_base_/datasets/imagenet_bs32.py'</span>,    <span class="token comment"># data settings</span>
    <span class="token string">'../_base_/schedules/imagenet_bs256.py'</span>,  <span class="token comment"># schedule settings</span>
    <span class="token string">'../_base_/default_runtime.py'</span>,           <span class="token comment"># runtime settings</span>
<span class="token punctuation">]</span>

<span class="token comment"># model settings</span>
model <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">backbone</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">frozen_stages</span><span class="token operator">=</span><span class="token number">2</span>,
        <span class="token assign-left variable">init_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
            <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'Pretrained'</span>,
            <span class="token assign-left variable">checkpoint</span><span class="token operator">=</span><span class="token string">'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth'</span>,
            <span class="token assign-left variable">prefix</span><span class="token operator">=</span><span class="token string">'backbone'</span>,
        <span class="token punctuation">))</span>,
    <span class="token assign-left variable">head</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>,
<span class="token punctuation">)</span>

<span class="token comment"># data settings</span>
data_root <span class="token operator">=</span> <span class="token string">'data/custom_dataset'</span>
train_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CustomDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span>data_root,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">''</span>,       <span class="token comment"># We assume you are using the sub-folder format without ann_file</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'train'</span>,
    <span class="token punctuation">))</span>
val_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CustomDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span>data_root,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">''</span>,       <span class="token comment"># We assume you are using the sub-folder format without ann_file</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'test'</span>,
    <span class="token punctuation">))</span>
test_dataloader <span class="token operator">=</span> val_dataloader

<span class="token comment"># &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Override schedule settings here &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span>
<span class="token comment"># optimizer hyper-parameters</span>
optim_wrapper <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">optimizer</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'SGD'</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.01</span>, <span class="token assign-left variable">momentum</span><span class="token operator">=</span><span class="token number">0.9</span>, <span class="token assign-left variable">weight_decay</span><span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">))</span>
<span class="token comment"># learning policy</span>
param_scheduler <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'MultiStepLR'</span>, <span class="token assign-left variable">by_epoch</span><span class="token operator">=</span>True, <span class="token assign-left variable">milestones</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">]</span>, <span class="token assign-left variable">gamma</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
<span class="token comment"># &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span>
</code></pre> 
<h6><a id="_6__1007"></a>步骤 6 开始训练</h6> 
<p>现在，我们已经完成了配置文件的微调，如下：</p> 
<pre><code class="prism language-bash">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'../_base_/models/resnet50.py'</span>,           <span class="token comment"># model settings</span>
    <span class="token string">'../_base_/datasets/imagenet_bs32.py'</span>,    <span class="token comment"># data settings</span>
    <span class="token string">'../_base_/schedules/imagenet_bs256.py'</span>,  <span class="token comment"># schedule settings</span>
    <span class="token string">'../_base_/default_runtime.py'</span>,           <span class="token comment"># runtime settings</span>
<span class="token punctuation">]</span>

<span class="token comment"># model settings</span>
model <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">backbone</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">frozen_stages</span><span class="token operator">=</span><span class="token number">2</span>,
        <span class="token assign-left variable">init_cfg</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
            <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'Pretrained'</span>,
            <span class="token assign-left variable">checkpoint</span><span class="token operator">=</span><span class="token string">'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth'</span>,
            <span class="token assign-left variable">prefix</span><span class="token operator">=</span><span class="token string">'backbone'</span>,
        <span class="token punctuation">))</span>,
    <span class="token assign-left variable">head</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>,
<span class="token punctuation">)</span>

<span class="token comment"># data settings</span>
data_root <span class="token operator">=</span> <span class="token string">'data/custom_dataset'</span>
train_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CustomDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span>data_root,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">''</span>,       <span class="token comment"># We assume you are using the sub-folder format without ann_file</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'train'</span>,
    <span class="token punctuation">))</span>
val_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CustomDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span>data_root,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">''</span>,       <span class="token comment"># We assume you are using the sub-folder format without ann_file</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'test'</span>,
    <span class="token punctuation">))</span>
test_dataloader <span class="token operator">=</span> val_dataloader

<span class="token comment"># schedule settings</span>
optim_wrapper <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">optimizer</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'SGD'</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.01</span>, <span class="token assign-left variable">momentum</span><span class="token operator">=</span><span class="token number">0.9</span>, <span class="token assign-left variable">weight_decay</span><span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">))</span>
param_scheduler <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'MultiStepLR'</span>, <span class="token assign-left variable">by_epoch</span><span class="token operator">=</span>True, <span class="token assign-left variable">milestones</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">]</span>, <span class="token assign-left variable">gamma</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
</code></pre> 
<p>这里我们使用计算机上的 8 个 GPU 通过以下命令来训练模型：</p> 
<pre><code class="prism language-bash"><span class="token function">bash</span> tools/dist_train.sh configs/resnet/resnet50_8xb32-ft_custom.py <span class="token number">8</span>
</code></pre> 
<p>此外，您可以仅使用一个 GPU 通过以下命令来训练模型：</p> 
<pre><code class="prism language-bash">python tools/train.py configs/resnet/resnet50_8xb32-ft_custom.py
</code></pre> 
<p>但是等等，如果使用一个 GPU，则需要更改一个重要的配置。我们需要更改数据集配置如下：</p> 
<pre><code class="prism language-bash">data_root <span class="token operator">=</span> <span class="token string">'data/custom_dataset'</span>
train_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">batch_size</span><span class="token operator">=</span><span class="token number">256</span>,
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CustomDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span>data_root,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">''</span>,       <span class="token comment"># We assume you are using the sub-folder format without ann_file</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'train'</span>,
    <span class="token punctuation">))</span>
val_dataloader <span class="token operator">=</span> dict<span class="token punctuation">(</span>
    <span class="token assign-left variable">dataset</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>
        <span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token string">'CustomDataset'</span>,
        <span class="token assign-left variable">data_root</span><span class="token operator">=</span>data_root,
        <span class="token assign-left variable">ann_file</span><span class="token operator">=</span><span class="token string">''</span>,       <span class="token comment"># We assume you are using the sub-folder format without ann_file</span>
        <span class="token assign-left variable">data_prefix</span><span class="token operator">=</span><span class="token string">'test'</span>,
    <span class="token punctuation">))</span>
test_dataloader <span class="token operator">=</span> val_dataloader
</code></pre> 
<p>这是因为我们的训练计划的批量大小为 256。如果使用 8 个 GPU，只需batch_size=32在每个 GPU 的基本配置文件中使用配置，总批量大小将为 256。但是如果使用 1 个 GPU，则需要更改它手动调整至 256 以匹配训练计划。</p> 
<p>然而，更大的批量大小需要更大的 GPU 内存，这里有几个简单的技巧来节省 GPU 内存：<br> 启用自动混合精度训练。</p> 
<pre><code class="prism language-bash">python tools/train.py configs/resnet/resnet50_8xb32-ft_custom.py <span class="token parameter variable">--amp</span>
</code></pre> 
<p>使用较小的批量大小（例如batch_size=32代替 256），并启用自动学习率缩放。</p> 
<pre><code class="prism language-bash">python tools/train.py configs/resnet/resnet50_8xb32-ft_custom.py --auto-scale-lr
</code></pre> 
<p>auto_scale_lr.base_batch_size自动学习率缩放将根据实际批量大小和（您可以在基本配置中找到它 configs/<em>base</em>/schedules/imagenet_bs256.py）调整学习率</p> 
<h4><a id="6_1100"></a>6、模型测试</h4> 
<p>对于图像分类任务和图像检索任务，您可以在训练后测试您的模型。</p> 
<h5><a id="_1102"></a>使用您的电脑进行测试</h5> 
<p>您可以tools/test.py在具有 CPU 和可选 GPU 的单台计算机上测试模型。<br> 以下是该脚本的完整用法：</p> 
<pre><code class="prism language-bash">python tools/test.py <span class="token variable">${CONFIG_FILE}</span> <span class="token variable">${CHECKPOINT_FILE}</span> <span class="token punctuation">[</span>ARGS<span class="token punctuation">]</span>
</code></pre> 
<p>默认情况下，MMPretrain 更喜欢 GPU 而不是 CPU。如果你想在CPU上测试模型，请将CUDA_VISIBLE_DEVICES其清空或设置为-1以使GPU对程序不可见。</p> 
<pre><code class="prism language-bash"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span>-1 python tools/test.py <span class="token variable">${CONFIG_FILE}</span> <span class="token variable">${CHECKPOINT_FILE}</span> <span class="token punctuation">[</span>ARGS<span class="token punctuation">]</span>
</code></pre> 
<p>CONFIG_FILE 配置文件的路径。</p> 
<p>CHECKPOINT_FILE 检查点文件的路径（可以是http链接，您可以在此处找到检查点）。<br> –work-dir WORK_DIR 保存包含评估指标的文件的目录。<br> –out OUT 包含测试结果的文件的保存路径。<br> –out-item OUT_ITEM 指定测试结果文件的内容，可以是“pred”或“metrics”。如果是“pred”，则保存模型的输出以供离线评估。如果是“metrics”，则保存评估指标。默认为“pred”。<br> –cfg-options CFG_OPTIONS 覆盖已使用配置中的一些设置，xxx=yyy 格式的键值对将合并到配置文件中。如果要覆盖的值是列表，则其形式应为key=“[a,b]“或key=a,b。该参数还允许嵌套列表/元组值，例如key=”[(a,b),(c,d)]”。请注意，引号是必需的，并且不允许有空格。</p> 
<p>–show-dir SHOW_DIR 保存结果可视化图像的目录。<br> –show 在窗口中可视化预测结果。</p> 
<p>–interval INTERVAL 要可视化的样本间隔。</p> 
<p>–wait-time WAIT_TIME 每个窗口的显示时间（以秒为单位）。默认为 1。<br> –no-pin-memory 是否禁用pin_memory数据加载器中的选项。</p> 
<p>–tta 是否启用（TTA）。如果配置文件具有tta_pipeline和tta_model字段，请使用它们来确定 TTA 转换以及如何合并 TTA 结果。否则，通过平均分类分数来使用翻转 TTA。<br> –launcher {none,pytorch,slurm,mpi}，作业启动器的选项。</p> 
<h5><a id="_GPU__1133"></a>使用多个 GPU 进行测试</h5> 
<pre><code class="prism language-bash"><span class="token function">bash</span> ./tools/dist_test.sh <span class="token variable">${CONFIG_FILE}</span> <span class="token variable">${CHECKPOINT_FILE}</span> <span class="token variable">${GPU_NUM}</span> <span class="token punctuation">[</span>PY_ARGS<span class="token punctuation">]</span>
</code></pre> 
<h4><a id="7_1138"></a>7、下游任务</h4> 
<h5><a id="_1139"></a>检测</h5> 
<p>对于检测任务，请使用 MMDetection。首先，确保你已经安装了MIM，它也是 OpenMMLab 的一个项目。</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> openmim
mim <span class="token function">install</span> <span class="token string">'mmdet&gt;=3.0.0rc0'</span>
</code></pre> 
<p>训练<br> 安装后，您可以通过简单的命令运行MMDetection。</p> 
<pre><code class="prism language-bash"><span class="token comment"># distributed version</span>
<span class="token function">bash</span> tools/benchmarks/mmdetection/mim_dist_train_c4.sh <span class="token variable">${CONFIG}</span> <span class="token variable">${PRETRAIN}</span> <span class="token variable">${GPUS}</span>
<span class="token function">bash</span> tools/benchmarks/mmdetection/mim_dist_train_fpn.sh <span class="token variable">${CONFIG}</span> <span class="token variable">${PRETRAIN}</span> <span class="token variable">${GPUS}</span>

<span class="token comment"># slurm version</span>
<span class="token function">bash</span> tools/benchmarks/mmdetection/mim_slurm_train_c4.sh <span class="token variable">${PARTITION}</span> <span class="token variable">${CONFIG}</span> <span class="token variable">${PRETRAIN}</span>
<span class="token function">bash</span> tools/benchmarks/mmdetection/mim_slurm_train_fpn.sh <span class="token variable">${PARTITION}</span> <span class="token variable">${CONFIG}</span> <span class="token variable">${PRETRAIN}</span>
</code></pre> 
<p>${CONFIG}：直接使用MMDetection中的配置文件路径。对于某些算法，我们还有一些修改过的配置文件，可以在benchmarks相应算法文件夹下的文件夹中找到。您还可以从头开始编写配置文件。<br> ${PRETRAIN}：预训练的模型文件。<br> ${GPUS}：您要用于训练的 GPU 数量。我们默认采用 8 个 GPU 来执行检测任务。</p> 
<pre><code class="prism language-bash"><span class="token function">bash</span> ./tools/benchmarks/mmdetection/mim_dist_train_c4.sh <span class="token punctuation">\</span>
  configs/byol/benchmarks/mask-rcnn_r50-c4_ms-1x_coco.py <span class="token punctuation">\</span>
  https://download.openmmlab.com/mmselfsup/1.x/byol/byol_resnet50_16xb256-coslr-200e_in1k/byol_resnet50_16xb256-coslr-200e_in1k_20220825-de817331.pth <span class="token number">8</span>
</code></pre> 
<p>测试<br> 训练后，您还可以运行以下命令来测试您的模型。</p> 
<pre><code class="prism language-bash"><span class="token comment"># distributed version</span>
<span class="token function">bash</span> tools/benchmarks/mmdetection/mim_dist_test.sh <span class="token variable">${CONFIG}</span> <span class="token variable">${CHECKPOINT}</span> <span class="token variable">${GPUS}</span>

<span class="token comment"># slurm version</span>
<span class="token function">bash</span> tools/benchmarks/mmdetection/mim_slurm_test.sh <span class="token variable">${PARTITION}</span> <span class="token variable">${CONFIG}</span> <span class="token variable">${CHECKPOINT}</span>
</code></pre> 
<p>${CONFIG}：直接使用MMDetection中的配置文件名。对于某些算法，我们还有一些修改过的配置文件，可以在benchmarks相应算法文件夹下的文件夹中找到。您还可以从头开始编写配置文件。</p> 
<p>${CHECKPOINT}：您要测试的微调检测模型。</p> 
<p>${GPUS}：您要用于测试的 GPU 数量。我们默认采用 8 个 GPU 来执行检测任务。</p> 
<pre><code class="prism language-bash"><span class="token function">bash</span> ./tools/benchmarks/mmdetection/mim_dist_test.sh <span class="token punctuation">\</span>
configs/byol/benchmarks/mask-rcnn_r50_fpn_ms-1x_coco.py <span class="token punctuation">\</span>
https://download.openmmlab.com/mmselfsup/1.x/byol/byol_resnet50_16xb256-coslr-200e_in1k/byol_resnet50_16xb256-coslr-200e_in1k_20220825-de817331.pth <span class="token number">8</span>
</code></pre> 
<h5><a id="_1188"></a>分割</h5> 
<p>对于语义分割任务，我们使用 MMSegmentation。首先，确保你已经安装了MIM，它也是 OpenMMLab 的一个项目。</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> openmim
mim <span class="token function">install</span> <span class="token string">'mmsegmentation&gt;=1.0.0rc0'</span>
</code></pre> 
<p>模型训练<br> 安装后，您可以使用简单的命令运行 MMSegmentation。</p> 
<pre><code class="prism language-bash"><span class="token comment"># distributed version</span>
<span class="token function">bash</span> tools/benchmarks/mmsegmentation/mim_dist_train.sh <span class="token variable">${CONFIG}</span> <span class="token variable">${PRETRAIN}</span> <span class="token variable">${GPUS}</span>

<span class="token comment"># slurm version</span>
<span class="token function">bash</span> tools/benchmarks/mmsegmentation/mim_slurm_train.sh <span class="token variable">${PARTITION}</span> <span class="token variable">${CONFIG}</span> <span class="token variable">${PRETRAIN}</span>
</code></pre> 
<p>${CONFIG}：直接使用MMSegmentation中的配置文件路径。对于某些算法，我们还有一些修改过的配置文件，可以在benchmarks相应算法文件夹下的文件夹中找到。您还可以从头开始编写配置文件。<br> ${PRETRAIN}：预训练的模型文件。<br> ${GPUS}：您要用于训练的 GPU 数量。我们默认采用 4 个 GPU 来执行分割任务。</p> 
<pre><code class="prism language-bash"><span class="token function">bash</span> ./tools/benchmarks/mmsegmentation/mim_dist_train.sh <span class="token punctuation">\</span>
configs/benchmarks/mmsegmentation/voc12aug/fcn_r50-d8_4xb4-20k_voc12aug-512x512.py <span class="token punctuation">\</span>
https://download.openmmlab.com/mmselfsup/1.x/byol/byol_resnet50_16xb256-coslr-200e_in1k/byol_resnet50_16xb256-coslr-200e_in1k_20220825-de817331.pth <span class="token number">4</span>
</code></pre> 
<p>模型测试<br> 训练后，您还可以运行以下命令来测试您的模型。</p> 
<pre><code class="prism language-bash"><span class="token comment"># distributed version</span>
<span class="token function">bash</span> tools/benchmarks/mmsegmentation/mim_dist_test.sh <span class="token variable">${CONFIG}</span> <span class="token variable">${CHECKPOINT}</span> <span class="token variable">${GPUS}</span>

<span class="token comment"># slurm version</span>
<span class="token function">bash</span> tools/benchmarks/mmsegmentation/mim_slurm_test.sh <span class="token variable">${PARTITION}</span> <span class="token variable">${CONFIG}</span> <span class="token variable">${CHECKPOINT}</span>
</code></pre> 
<p>${CONFIG}：直接使用MMSegmentation中的配置文件名。对于某些算法，我们还有一些修改过的配置文件，可以在benchmarks相应算法文件夹下的文件夹中找到。您还可以从头开始编写配置文件。</p> 
<p>${CHECKPOINT}：您要测试的微调分割模型。</p> 
<p>${GPUS}：您要用于测试的 GPU 数量。我们默认采用 4 个 GPU 来执行分割任务。</p> 
<pre><code class="prism language-bash"><span class="token function">bash</span> ./tools/benchmarks/mmsegmentation/mim_dist_test.sh  fcn_r50-d8_4xb4-20k_voc12aug-512x512.py <span class="token punctuation">\</span>
https://download.openmmlab.com/mmselfsup/1.x/byol/byol_resnet50_16xb256-coslr-200e_in1k/byol_resnet50_16xb256-coslr-200e_in1k_20220825-de817331.pth <span class="token number">4</span>
</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bbafe8408e9c7fb9d570ae5805bbd682/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">一大波涨姿势的小众网站，带你解锁新大陆！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/eec108c045a938c92f2a559785ef9deb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">oracle 游标(cursor)＆＆记录集(record)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>