<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>《ImageNet Classification with Deep Convolutional Neural Networks》论文研读及AlexNet代码实现 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="《ImageNet Classification with Deep Convolutional Neural Networks》论文研读及AlexNet代码实现" />
<meta property="og:description" content="这篇补充了上篇的代码实现，可直接参见第二部分。
《ImageNet Classification with Deep Convolutional Neural Networks》基于深度卷积神经网络的Image分类
ImageNet：是一个图片分类数据集，分成1000类，每类大约1000多张图片
用到的技术：图像增强(两种方法)、ReLU、Dropout
第一部分：论文解读 0、摘要 （写法不怎么好）
第一步：告诉我们干了什么事情：我们训练了一个大型的深度卷积神经网络，将LSVRC-2010竞赛中的ImageNet 120万张高分辨率图像分类到1000个不同的类别。第二步：结果：在测试数据上，top-1的错误率是37.5%，top-5的错误率为17.0%，这大大优于之前的最先进水平。（2010年的竞赛给了测试集）该神经网络有6000万个参数和65万个神经元，由5个卷积层组成，其中一些是最大池化层，还有三个全连接层，最后是1000路的softmax。为了使训练更快，采用GPU。为了减少全连接层的过拟合，采用名为“dropout”的正则化方法。参加了LSVRC-2012比赛，2012年没有给测试集，我们的模型top-5错误率为15.3%，第二名的错误率为26.2%。表示我们的模型比第二名的模型好了很多。 1、序言 有了足够的计算和足够的数据，对于需要集成许多不同的、嘈杂的线索的复杂任务，学习胜过编程。（训练很重要）反向传播很重要。整个网络的分类性能取决于每个连接上的权重值。错误的结论：随机初始权重学习神经网络太难了。可以学习：但是要大量的标记数据和大量的计算。 现在无监督学习的发展，可以在无标记数据里学到想要的知识，例如GAN。
2、引言 本文干了什么：提出了一个物体识别方法。为了提高方法的性能：要大的数据集，学习更大的模型，还要防止过拟合。 过拟合（使用正则化）是深度学习的一个分支，重点是网络架构，网络架构很好的话正则化也没有那么重要。
本文提出的模型：CNNs，广度深度同样重要，CNNs的连接和参数要少很多，并且更容易训练，理论上的性能只是略差。（自己写论文的时候不能只说自己的东西很好）但是CNNs不好训练：用GPU训练，并且ImageNet够大，过拟合也不会太严重。 本文具体贡献如下：
训练了一个最大的CNNs，有着最好的准确率。但是现在看来AlexNet是小网络。编写了一个高度优化的二维卷积的GPU实现，以及CNNs固有的功能。一些新的不寻常的功能（在第四节中详细介绍），提高了性能、减少了训练时间。采用了以下有效的技术来防止过拟合（在第五节中详细介绍）。 最终的网络：
5个卷积层、3个全连接层。在GPU上进行训练。 文章说深度似乎很重要：我们去除任何的卷积层，都会导致性能下降。这个说法现在看来似乎不太对，深度和宽度同样重要，即使去掉一层，参数调好也能达到同样的效果。
3、数据集 使用的数据集：
使用ImageNet的一个子集，1000个类别，每个类别1000张图片。大约有120万张训练图像，5万张验证图像和15万张测试图像。 图像预处理：
预处理：仅仅做了剪裁，没有做任何的特征提取方法：最后要将图像下采样成256×256。先将短边缩放至256，长边不够256的话拉成256，长边够256的话从图像中裁剪出中央的256×256块。所以我们在像素的（居中）原始RGB值上训练我们的网络（没有抽取抽取特征，直接在原始的pixels上，原始的RGB上训练网络） 这个预处理很重要！现在绝大多数都采用原始的RGB图像，采用end to end，原始的图片，原始的文本直接放进去，不做任何的特征提取，神经网络直接做出来。这是在当时一个很重要的创新点，但是这篇文章没有细说。
4、架构 五个卷积层、三个全连接层 4.1 Rectified Linear Unit nonlinearity(非线性激活ReLU) 非线性激活一般方法是：Tanh或sigmoid。（当时用的几乎都是这两个，现在也用，ReLU用的比较多）
从图上就可以看出来走的很慢，该文章用ReLU激活函数：小于0的为0，大于0的是本身。
本文使用ReLU是因为tanh(X)慢，ReLU快。现在看来也没有快多少，但还是用ReLU，因为简单。
实验结果：
4.2 Training on multiple GPUs 在多个GPU上进行训练 我们自己训练肯定不会多个GPU，大型人工智能机构的肯定会。这里就略过。
4.3 Local response normalization LRN归一化 对局部神经元的活动创建了竞争机制，使得其中相应较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力，但是现在不用了。
-因为ReLU不像tanh、sigmoid有值域区间，所以在ReLU后面做一个normalization，本篇文章就是LRN。
4.4 池化层 对传统的pooling有一定的改动。采用了重叠的最大池化，此前的CNNs中普遍使用平均池化，采用最大池化，避免了平均池化的模糊化效果；并且重叠和覆盖，提升了特征的丰富性。
传统的pooling：stride=2，z=2，无重叠，为以下这种情况：
走两步，发现没有重叠。
本文的pooling：stride=2，z=3，有重叠，为以下这种情况：
走两步，可以看到是有重叠的。
本文使用的s=3，z=2，使得top-1和top-5的错误率分别降低了0.4%和0.3%，池化层不改变通道数，采取这种方法对过拟合也有一定的缓解。
4.5 整体架构 前五个是卷积层，后三个是全连接层。最后一个全连接层的输入被送入一个1000路的softmax，产生1000个类别标签的分布。二、四、五卷积层的内核只与前一层中位于同一GPU的内核图相连。第三层卷积层的神经元与第二层的所有内核图相连。全连接层的神经元与上一层的所有神经元相连。LRN加在第一层、第二层卷积层后。最大池化层在LRN后面和第五层卷积层后。ReLU用在每个卷积层和全连接层后。 第一层卷积层：卷积层、ReLU、LRN、最大池化层" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/273423a18ee1c8b1b69a3c683ea36503/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-28T12:30:02+08:00" />
<meta property="article:modified_time" content="2022-10-28T12:30:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">《ImageNet Classification with Deep Convolutional Neural Networks》论文研读及AlexNet代码实现</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>这篇补充了上篇的代码实现，可直接参见第二部分。</p> 
<blockquote> 
 <p>《ImageNet Classification with Deep Convolutional Neural Networks》基于深度卷积神经网络的Image分类<br> ImageNet：是一个图片分类数据集，分成1000类，每类大约1000多张图片<br> 用到的技术：图像增强(两种方法)、ReLU、Dropout</p> 
</blockquote> 
<h2><a id="_6"></a>第一部分：论文解读</h2> 
<h2><a id="0_7"></a>0、摘要</h2> 
<p>（写法不怎么好）</p> 
<ul><li>第一步：<font color="red">告诉我们干了什么事情：</font>我们训练了一个大型的深度卷积神经网络，将LSVRC-2010竞赛中的ImageNet 120万张高分辨率图像分类到1000个不同的类别。</li><li>第二步：<font color="red">结果：</font>在测试数据上，top-1的错误率是37.5%，top-5的错误率为17.0%，这大大优于之前的最先进水平。（2010年的竞赛给了测试集）</li><li>该神经网络有6000万个参数和65万个神经元，由5个卷积层组成，其中一些是最大池化层，还有三个全连接层，最后是1000路的softmax。</li><li>为了使训练更快，采用GPU。</li><li>为了减少全连接层的过拟合，采用名为“dropout”的正则化方法。</li><li>参加了LSVRC-2012比赛，2012年没有给测试集，我们的模型top-5错误率为15.3%，第二名的错误率为26.2%。表示我们的模型比第二名的模型好了很多。</li></ul> 
<h2><a id="1_16"></a>1、序言</h2> 
<ul><li>有了足够的计算和足够的数据，对于需要集成许多不同的、嘈杂的线索的复杂任务，学习胜过编程。<font color="red">（训练很重要）</font></li><li>反向传播很重要。整个网络的分类性能取决于每个连接上的权重值。</li><li>错误的结论：随机初始权重学习神经网络太难了。</li><li>可以学习：但是要大量的标记数据和大量的计算。</li></ul> 
<blockquote> 
 <p>现在无监督学习的发展，可以在无标记数据里学到想要的知识，例如GAN。</p> 
</blockquote> 
<h2><a id="2_27"></a>2、引言</h2> 
<ul><li>本文干了什么：提出了一个物体识别方法。</li><li>为了提高方法的性能：要大的数据集，学习更大的模型，还要防止过拟合。</li></ul> 
<blockquote> 
 <p>过拟合（使用正则化）是深度学习的一个分支，重点是网络架构，网络架构很好的话正则化也没有那么重要。</p> 
</blockquote> 
<ul><li>本文提出的模型：CNNs，广度深度同样重要，CNNs的连接和参数要少很多，并且更容易训练，理论上的性能只是略差。（自己写论文的时候不能只说自己的东西很好）</li><li>但是CNNs不好训练：用GPU训练，并且ImageNet够大，过拟合也不会太严重。</li></ul> 
<p>本文具体贡献如下：</p> 
<ul><li>训练了一个最大的CNNs，有着最好的准确率。但是现在看来AlexNet是小网络。</li><li>编写了一个高度优化的二维卷积的GPU实现，以及CNNs固有的功能。</li><li>一些新的不寻常的功能（在第四节中详细介绍），提高了性能、减少了训练时间。</li><li>采用了以下有效的技术来防止过拟合（在第五节中详细介绍）。</li></ul> 
<p>最终的网络：</p> 
<ul><li>5个卷积层、3个全连接层。在GPU上进行训练。</li></ul> 
<blockquote> 
 <p>文章说深度似乎很重要：我们去除任何的卷积层，都会导致性能下降。这个说法现在看来似乎不太对，深度和宽度同样重要，即使去掉一层，参数调好也能达到同样的效果。</p> 
</blockquote> 
<h2><a id="3_50"></a>3、数据集</h2> 
<p>使用的数据集：</p> 
<ul><li>使用ImageNet的一个子集，1000个类别，每个类别1000张图片。大约有120万张训练图像，5万张验证图像和15万张测试图像。</li></ul> 
<p>图像预处理：</p> 
<ul><li>预处理：仅仅做了剪裁，没有做任何的特征提取</li><li>方法：最后要将图像下采样成256×256。先将短边缩放至256，长边不够256的话拉成256，长边够256的话从图像中裁剪出中央的256×256块。所以我们在像素的（居中）原始RGB值上训练我们的网络（没有抽取抽取特征，直接在原始的pixels上，原始的RGB上训练网络）</li></ul> 
<blockquote> 
 <p>这个预处理很重要！现在绝大多数都采用原始的RGB图像，采用end to end，原始的图片，原始的文本直接放进去，不做任何的特征提取，神经网络直接做出来。这是在当时一个很重要的创新点，但是这篇文章没有细说。</p> 
</blockquote> 
<h2><a id="4_63"></a>4、架构</h2> 
<ul><li>五个卷积层、三个全连接层</li></ul> 
<h4><a id="41_Rectified_Linear_Unit_nonlinearityReLU_67"></a>4.1 Rectified Linear Unit nonlinearity(非线性激活ReLU)</h4> 
<p>非线性激活一般方法是：Tanh或sigmoid。（当时用的几乎都是这两个，现在也用，ReLU用的比较多）<br> <img src="https://images2.imgbox.com/e7/ce/sTXbJi95_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/2c/54/ea0MxopH_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/62/94/KLuHoSZq_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/66/11/wi6pLP7o_o.png" alt="在这里插入图片描述"><br> 从图上就可以看出来走的很慢，该文章用ReLU激活函数：小于0的为0，大于0的是本身。<br> <img src="https://images2.imgbox.com/00/04/04cedj1G_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b5/bc/gonG8kTq_o.png" alt="在这里插入图片描述"><br> 本文使用ReLU是因为tanh(X)慢，ReLU快。<font color="red">现在看来也没有快多少，但还是用ReLU，因为简单。</font><br> 实验结果：<br> <img src="https://images2.imgbox.com/01/50/Gj7rPKkT_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="42_Training_on_multiple_GPUs_GPU_80"></a>4.2 Training on multiple GPUs 在多个GPU上进行训练</h4> 
<p>我们自己训练肯定不会多个GPU，大型人工智能机构的肯定会。这里就略过。</p> 
<h4><a id="43_Local_response_normalization_LRN_83"></a>4.3 Local response normalization LRN归一化</h4> 
<p>对局部神经元的活动创建了竞争机制，使得其中相应较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力，但是现在不用了。</p> 
<p>-因为ReLU不像tanh、sigmoid有值域区间，所以在ReLU后面做一个normalization，本篇文章就是LRN。</p> 
<h4><a id="44__88"></a>4.4 池化层</h4> 
<p>对传统的pooling有一定的改动。<font color="red">采用了重叠的最大池化，此前的CNNs中普遍使用平均池化，采用最大池化，避免了平均池化的模糊化效果；并且重叠和覆盖，提升了特征的丰富性。</font></p> 
<ul><li> <p>传统的pooling：stride=2，z=2，无重叠，为以下这种情况：<br> <img src="https://images2.imgbox.com/11/13/SHrihonU_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/16/12/5sRgNSAt_o.png" alt="在这里插入图片描述"><br> 走两步，发现没有重叠。</p> </li><li> <p>本文的pooling：stride=2，z=3，有重叠，为以下这种情况：<br> <img src="https://images2.imgbox.com/78/a8/kXBBag2M_o.png" alt="在这里插入图片描述"><br> 走两步，可以看到是有重叠的。<br> <img src="https://images2.imgbox.com/0d/d7/oaORg1yf_o.png" alt="在这里插入图片描述"><br> 本文使用的s=3，z=2，使得top-1和top-5的错误率分别降低了0.4%和0.3%，池化层不改变通道数，采取这种方法对过拟合也有一定的缓解。</p> </li></ul> 
<h4><a id="45__101"></a>4.5 整体架构</h4> 
<ul><li>前五个是卷积层，后三个是全连接层。最后一个全连接层的输入被送入一个1000路的softmax，产生1000个类别标签的分布。</li><li>二、四、五卷积层的内核只与前一层中位于同一GPU的内核图相连。</li><li>第三层卷积层的神经元与第二层的所有内核图相连。</li><li>全连接层的神经元与上一层的所有神经元相连。</li><li>LRN加在第一层、第二层卷积层后。</li><li>最大池化层在LRN后面和第五层卷积层后。</li><li>ReLU用在每个卷积层和全连接层后。</li></ul> 
<p>第一层卷积层：卷积层、ReLU、LRN、最大池化层</p> 
<ul><li>卷积核：96个11×11×3的卷积核。</li><li>图像大小：227×227×3的输入图像。</li><li>stride：(4,4)。</li></ul> 
<p>第二层卷积层：卷积层、ReLU、LRN、最大池化层</p> 
<ul><li>卷积核：256个5×5×48的卷积核。</li><li>与第一层的输出（LRN和池化）相连。</li></ul> 
<p>第三层卷积层：卷积层、ReLU</p> 
<ul><li>卷积核：384个3×3×256的卷积核。</li><li>与第二层的输出（LRN和池化）相连。</li></ul> 
<p>第四层卷积层：卷积层、ReLU</p> 
<ul><li>卷积核：384个3×3×192的内核</li></ul> 
<p>第五层卷积层：卷积层、ReLU、最大池化层</p> 
<ul><li>256个3×3×192的内核</li></ul> 
<p>全连接层每个有4096个神经元。</p> 
<blockquote> 
 <p>长为4096的向量能够很好的抓住语义信息，如果两张图片4096向量很近的话，这两个图片可能就是同一个物体的图片。<br> 一个图片，通过模型，把他压缩成4096的向量，这个向量把中间的语义信息都能表示起来（很像感受野），变成机器能懂得一个东西。机器用来做搜索、做分类、做什么事情都可以。<br> 前面的原始数据，不管是图片、文字，还是语音、视频，通过中间的模型，最后压缩成一个向量，这个向量，机器能够去识别，能够识别的话，就可以在上面做各种各样的事情。</p> 
</blockquote> 
<p>模型架构：<br> <img src="https://images2.imgbox.com/d6/da/YEAj4xIB_o.png" alt="在这里插入图片描述"><br> 现在已经不这么写了！第二部分代码实现展示现在怎么写。</p> 
<h2><a id="5__145"></a>5 减少过拟合</h2> 
<p>本文提供了两种减少过拟合的方式。</p> 
<h4><a id="51_147"></a>5.1数据增强（数据扩充）</h4> 
<p>说我们的数据增强都是在CPU上计算的，因此是无计算的。现在都放在GPU上进行计算。</p> 
<h6><a id="_149"></a>第一种方式：增加图片数量</h6> 
<ul><li>人为进行数据扩充</li><li>训练集：随机的在256×256的图像上扣一块227×227的图像，再水平翻转。<font color="red">相当于增加了2*(256-227)^2的数据量。</font></li><li>测试集：随机的在256×256的图像上扣五块227×227的图像，再水平翻转。（十个），对他们进行预测并对10次结果求均值。</li></ul> 
<h6><a id="PCA_154"></a>第二种方式：PCA加一些高斯扰动</h6> 
<ul><li>改变训练图像中的RGB通道的强度（颜色会有一些改变）。</li><li>我们对整个ImageNet训练集的RGB像素值的集合进行PCA主成分分析。在每张训练图像中，我们添加所发现的主成分的倍数，其大小与相应的特征值乘以从高斯中抽取的mean为0，std为0.1的随机变量相乘。</li><li>对主成分做一个（0，0.1）的高斯扰动（标准差为0.1），对颜色光照做了变换，添加了一些噪声，错误率下降了1%。</li><li>得到了一个重要属性，物体本身对光照强度和颜色的变化是不变的。就是光照和颜色再变化，啥物体就是啥物体。</li><li>错误率降低了。</li></ul> 
<h4><a id="52_Dropout_162"></a>5.2 Dropout</h4> 
<ul><li>0.5的概率随机的丢弃神经元。</li><li>在两个全连接层后使用。</li><li>使用后缓解了过拟合。</li></ul> 
<blockquote> 
 <p>Dropout在现在用的也是蛮多的，等价于一个L2正则项，效果差不多。<br> AlexNet用了三个全连接，4096全连接是他的一大瓶颈，是设计的一个缺陷，导致了模型特别大，放不进GPU里，现在的CNNs设计不会设计那么大的连接，而GPU的发展，导致Dropout防止过拟合也没有那么重要了。但是Dropout在全连接上还是非常有用的，在RNN，Attension上使用的较多。</p> 
</blockquote> 
<h2><a id="6__171"></a>6 训练细节</h2> 
<ul><li>使用SGD（SGD的噪音对模型泛化还是有好处的）。</li><li>batch_size为128。</li><li>冲量momentum为0.9。momentum当你的优化表面非常的不平滑的时候，可以保持一个冲量，从过去那个方向，沿着一个比较平缓的方向往前走。</li><li>权重衰减weight decay为0.0005。</li><li>权重衰减的实现方式：不是加在模型上，而是加在优化算法上。</li></ul> 
<p><img src="https://images2.imgbox.com/cd/e2/tqEeKj01_o.png" alt="在这里插入图片描述"></p> 
<ul><li>均值为0，方差0.01的高斯随机变量来初始化权重。0.01不大不小，更复杂的网络用0.02差不多。</li><li>2、4、5卷积层以及全连接隐藏层中的神经元偏置初始化为常数1。比较奇怪，数据好的时候偏置一般初始化为0，现在全部初始化为0效果也不差，并且也不需要调参。</li><li>学习率手动调整的，当验证错误率不随当前的学习率提高时，将学习率÷10。</li></ul> 
<blockquote> 
 <p>学习率刚开始设计的大，后面要变小。当验证错误不增加的时候，手动将学习率×0.1，降低10倍。盯着你的训练，发现不动了，就手动调一下。现在不这样做了。<br> 比如ResNet训练120个epoch，每30轮下降0.1。或者前面训练长一点60轮或100轮，后面再下降学习率。现在也不这样了。<br> 现在通常的做法是：选择cos函数，一个比较平缓的下降。学习率不能选的太大，一下子会爆炸；也不能太小，太小训练不动。主流的做法是冲0开始，慢慢的上去，再cos慢慢的下来。warm up学习率预热，参见pytorch的学习率优化。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/ff/ac/i4nkP4Ck_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="7__191"></a>7 结果</h2> 
<p><img src="https://images2.imgbox.com/61/d2/iIHqsPgU_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="71_194"></a>7.1定性评估</h4> 
<ul><li>结果：GPU1上的内核在很大程度上是不分颜色的，而GPU2上的内核在很大程度上是特定颜色的。<font color="red">（其实没有关系，本来就是一个随机性的东西，现在也几乎是在一个GPU上进行训练的）</font>。</li></ul> 
<p><img src="https://images2.imgbox.com/18/a9/lv5PvKwS_o.png" alt="在这里插入图片描述"></p> 
<ul><li>对后面的研究有一定的启发性<font color="red">（可解释性）</font>，比如底部的神经元学到了是一些局部的信息，比如纹理，方向；偏上的神经元学习到的比较全局，例如这是一个头，一个手，一个动物这种的，更多的信息在神经元里面。看的是我们到底是想学一个东西的形状，还是一个东西的纹理。</li></ul> 
<h2><a id="8__202"></a>8 讨论</h2> 
<p>（一般论文写的都是结论。）</p> 
<ul><li>删除一个卷积层，导致性能损失2%，因此深度非常重要。<font color="red">不严谨，如果去掉一层，再调参，也可以达到原来的效果，深度和宽度同样重要</font>。</li><li>监督学习研究的较多，无监督学习unsupervised兴起，可以从没有标签的数据集里面进行学习，例如GAN。</li></ul> 
<h2><a id="9__208"></a>9 收场白</h2> 
<h2><a id="AlexNet_210"></a>第二部分：AlexNet代码实现</h2> 
<h4><a id="1_211"></a>1、数据预处理</h4> 
<p>首先对整个训练集的各个通道的像素值计算各个通道的主成分，然后将主成分添加随机数来叠加到图片上。<br> 高斯扰动：mean：0，std：0.1<br> <img src="https://images2.imgbox.com/67/46/7pmnsHBw_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

writer<span class="token operator">=</span>SummaryWriter<span class="token punctuation">(</span><span class="token string">"../logs_gaosiraodong"</span><span class="token punctuation">)</span>
img<span class="token operator">=</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../a_base/images/wang.jpg"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'PIL读取图片的格式:{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''ToTensor()'''</span>
trans_totensor<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
img_tensor<span class="token operator">=</span>trans_totensor<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"ToTensor"</span><span class="token punctuation">,</span>img_tensor<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''Normalize(torch.nn.Module)'''</span>
<span class="token comment">#输入两个参数，是平均值和方差，图片是三维的。(input-mean)/std</span>
<span class="token comment">#output[channel] = (input[channel] - mean[channel]) / std[channel]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'三通道的值:{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>img_tensor<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
trans_norm<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token comment">#每个信道的平均值序列,每个信道的标准差序列</span>
img_norm<span class="token operator">=</span>trans_norm<span class="token punctuation">(</span>img_tensor<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'归一化后三通道的值:{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>img_norm<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"Normalize"</span><span class="token punctuation">,</span>img_norm<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>


writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>控制台：<br> <img src="https://images2.imgbox.com/c9/4a/eMhIPLTA_o.png" alt="在这里插入图片描述"><br> 结果：<br> <font color="red">这个结果应该是有问题的，论文里只是对光照进行了增强，这个结果直接面目全非了，猜测是我没有提取原图的主成分，有会的大佬麻烦评论区指点一下！</font><br> 要注意的是：这种方法慎用，可能会导致模型不收敛。<br> <img src="https://images2.imgbox.com/70/54/Z2dFXZjE_o.png" alt="在这里插入图片描述"></p> 
<p>随机剪裁：也使用pytorch进行实现。<br> <img src="https://images2.imgbox.com/cd/59/0Dwd9aF9_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="2_252"></a>2、模型结构</h4> 
<p>直接用的预训练好的网络。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torchvision

alexnet<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>alexnet<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>progress<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>alexnet<span class="token punctuation">)</span>
</code></pre> 
<p>结果：</p> 
<pre><code class="prism language-python">AlexNet<span class="token punctuation">(</span>
  <span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
  <span class="token punctuation">(</span>avgpool<span class="token punctuation">)</span><span class="token punctuation">:</span> AdaptiveAvgPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>classifier<span class="token punctuation">)</span><span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">9216</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>测试：</p> 
<pre><code class="prism language-python">inp_tensor<span class="token operator">=</span>torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">227</span><span class="token punctuation">,</span><span class="token number">227</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"输入图片的形状:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>inp_tensor<span class="token punctuation">)</span><span class="token punctuation">)</span>

output<span class="token operator">=</span>alexnet<span class="token punctuation">(</span>inp_tensor<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试网络的输出结果:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试网络输出的形状:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/91/dd/U6ihNB31_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/771c9c584b877d50359918ab126f9042/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">wx.miniProgram.navigaTo不起作用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2b0ec8b2709ead84b02618a7ba463ea0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">啃周志华《机器学习》西瓜书难吗？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>