<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>高可用分布式部署Spark、完整详细部署教程 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="高可用分布式部署Spark、完整详细部署教程" />
<meta property="og:description" content="前言 Spark 是 UC Berkeley AMP Lab 开源的通用分布式并行计算框架。
Spark基于map reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。
spark是基于内存计算框架，计算速度非常之快，但是它仅仅只是涉及到计算，并没有涉及到数据的存储，后期需要使用spark对接外部的数据源，比如hdfs。
Spark的四大特性 Simple（易用性）
Spark 提供了丰富的高级运算操作，支持丰富的算子，并支持 Java、Python、Scala、R、SQL 等语言的 API，使用户可以快速构建不同的应用。
开发人员只需调用 Spark 封装好的 API 来实现即可，无需关注 Spark 的底层架构。
Fast(速度快)
Spark 将处理的每个任务都构造成一个DAG（Directed Acyclic Graph, 有向无环图）来执行，实现原理是基于RDD（Resilient Distributed Dataset, 弹性分布式数据集）在内存中对数据进行迭代计算，以实现批量和流式数据的高性能快速计算处理。
Spark比MR速度快的原因
基于内存
mapreduce任务后期再计算的时候，每一个job的输出结果会落地到磁盘，后续有其他的job需要依赖于前面job的输出结果，这个时候就需要进行大量的磁盘io操作。性能就比较低。
spark任务后期再计算的时候，job的输出结果可以保存在内存中，后续有其他的job需要依赖于前面job的输出结果，这个时候就直接从内存中获取得到，避免了磁盘io操作，性能比较高
对于spark程序和mapreduce程序都会产生shuffle阶段，在shuffle阶段中它们产生的数据都会落地到磁盘。
进程与线程
mapreduce任务以进程的方式运行在yarn集群中，比如程序中有100个MapTask，一个task就需要一个进程，这些task要运行就需要开启100个进程。
spark任务以线程的方式运行在进程中，比如程序中有100个MapTask，后期一个task就对应一个线程，这里就不再是进程，这些task需要运行，这里可以极端一点：只需要开启1个进程，在这个进程中启动100个线程就可以了。
进程中可以启动很多个线程，而开启一个进程与开启一个线程需要的时间和调度代价是不一样。 开启一个进程需要的时间远远大于开启一个线程。## Scalable（可融合性）
Unified（通用性）
大数据处理的传统方案需要维护多个平台，比如，离线任务是放在 Hadoop MapRedue 上运行，实时流计算任务是放在 Storm 上运行。
而Spark 提供了一站式的统一解决方案，可用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）等。这些不同类型的处理都可以在同一个应用中无缝组合使用。
Scalable(兼容性)
Spark 可以非常方便地与其他的开源产品进行融合。比如：Spark 可以使用 Hadoop 的 YARN 和 Apache Mesos 作为它的资源管理和调度器；可以处理所有 Hadoop 支持的数据，包括 HDFS、HBase 和 Cassandra 等。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/7ead09d3aa1983cb5d2a1cd835cd85f3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-30T22:31:22+08:00" />
<meta property="article:modified_time" content="2023-12-30T22:31:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">高可用分布式部署Spark、完整详细部署教程</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>前言</h3> 
<p>Spark 是 UC Berkeley AMP Lab 开源的通用分布式并行计算框架。<br> Spark基于map reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。<br> spark是基于内存计算框架，计算速度非常之快，但是它仅仅只是涉及到计算，并没有涉及到数据的存储，后期需要使用spark对接外部的数据源，比如hdfs。</p> 
<h3>Spark的四大特性</h3> 
<p><br> Simple（易用性）<br> Spark 提供了丰富的高级运算操作，支持丰富的算子，并支持 Java、Python、Scala、R、SQL 等语言的 API，使用户可以快速构建不同的应用。</p> 
<p>开发人员只需调用 Spark 封装好的 API 来实现即可，无需关注 Spark 的底层架构。</p> 
<p>Fast(速度快)<br> Spark 将处理的每个任务都构造成一个DAG（Directed Acyclic Graph, 有向无环图）来执行，实现原理是基于RDD（Resilient Distributed Dataset, 弹性分布式数据集）在内存中对数据进行迭代计算，以实现批量和流式数据的高性能快速计算处理。</p> 
<p>Spark比MR速度快的原因<br> 基于内存<br> mapreduce任务后期再计算的时候，每一个job的输出结果会落地到磁盘，后续有其他的job需要依赖于前面job的输出结果，这个时候就需要进行大量的磁盘io操作。性能就比较低。<br> spark任务后期再计算的时候，job的输出结果可以保存在内存中，后续有其他的job需要依赖于前面job的输出结果，这个时候就直接从内存中获取得到，避免了磁盘io操作，性能比较高<br> 对于spark程序和mapreduce程序都会产生shuffle阶段，在shuffle阶段中它们产生的数据都会落地到磁盘。<br> 进程与线程<br> mapreduce任务以进程的方式运行在yarn集群中，比如程序中有100个MapTask，一个task就需要一个进程，这些task要运行就需要开启100个进程。<br> spark任务以线程的方式运行在进程中，比如程序中有100个MapTask，后期一个task就对应一个线程，这里就不再是进程，这些task需要运行，这里可以极端一点：只需要开启1个进程，在这个进程中启动100个线程就可以了。<br> 进程中可以启动很多个线程，而开启一个进程与开启一个线程需要的时间和调度代价是不一样。 开启一个进程需要的时间远远大于开启一个线程。## Scalable（可融合性）<br> Unified（通用性）<br> 大数据处理的传统方案需要维护多个平台，比如，离线任务是放在 Hadoop MapRedue 上运行，实时流计算任务是放在 Storm 上运行。</p> 
<p>而Spark 提供了一站式的统一解决方案，可用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）等。这些不同类型的处理都可以在同一个应用中无缝组合使用。</p> 
<p>Scalable(兼容性)<br> Spark 可以非常方便地与其他的开源产品进行融合。比如：Spark 可以使用 Hadoop 的 YARN 和 Apache Mesos 作为它的资源管理和调度器；可以处理所有 Hadoop 支持的数据，包括 HDFS、HBase 和 Cassandra 等。</p> 
<h2><br> 本博的重点： spark的分布式部署</h2> 
<h3>第一步 下载<a href="https://so.csdn.net/so/search?q=spark&amp;spm=1001.2101.3001.7020" title="spark">spark</a>和 scala</h3> 
<p>scala的下载地址：官网下载scala:https://www.scala-lang.org/download/2.13.1.html </p> 
<p>spark的下载地址： <a href="https://dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz" rel="nofollow" title="https://dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz">https://dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz</a></p> 
<p></p> 
<pre><code>cd /opt/module
官网下载scala:https://www.scala-lang.org/download/2.13.1.html

tar -xvf scala-2.13.1.tgz -C /opt/module</code></pre> 
<pre><code>#主节点的服务器 进入系统准备安装的路径
cd /opt/module/spark
wget https://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz --no-check-certificate

tar -xvf spark-3.3.1-bin-hadoop3.tgz -C /opt/module/spark/spark-3.5.0


</code></pre> 
<h3>第二步 配置SPARK_HOME环境变量</h3> 
<pre><code>vi /etc/profile

#添加以下配置内容，配置jdk环境变量
export JAVA_HOME=/kkb/install/jdk1.8.0_202
export PATH=$PATH:$JAVA_HOME/bin
export HADOOP_HOME=/kkb/install/hadoop-2.6.0-cdh5.14.2
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export SPARK_HOME=/opt/module/spark/spark-3.5.0
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export SCALA_HOME=/opt/module/scala/scala-2.12.8
export PATH=$PATH:$SCALA_HOME/bin</code></pre> 
<p># 加载使其生效</p> 
<pre><code>source /etc/profile</code></pre> 
<h3>第三步 修改spark的配置文件</h3> 
<blockquote> 
 <p># 进入spark conf目录<br> cd /home/spark-3.3.1-bin-hadoop3/conf<br> # 拷贝模板文件<br> cp spark-defaults.conf.template spark-defaults.conf<br> cp spark-env.sh.template spark-env.sh<br>  </p> 
</blockquote> 
<p>1、修改 spark-defaults.conf</p> 
<pre><code>##增加如下内容
spark.master                     spark://node01:7077
spark.serializer                 org.apache.spark.serializer.KryoSerializer
spark.driver.memory              512m
spark.executor.memory            512m</code></pre> 
<p> 2、修改spark-env.sh</p> 
<pre><code>#增加如下内容
export SPARK_DIST_CLASSPATH=$(/kkb/install/hadoop-2.6.0-cdh5.14.2/bin/hadoop classpath)
export HADOOP_CONF_DIR=/kkb/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop
export JAVA_HOME=/kkb/install/jdk1.8.0_202
export HADOOP_HOME=/kkb/install/hadoop-2.6.0-cdh5.14.2
export YARN_CONF_DIR=/kkb/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop
export SPARK_MASTER_HOST=node01
export SPARK_MASTER_PORT=7077</code></pre> 
<p>3、修改slaves文件</p> 
<pre><code>vi slaves

# 修改为如下内容

node01

node02

node03
</code></pre> 
<h3>第四步 将spark目录分发到其他节点</h3> 
<pre><code>cd /home
scp -r ./spark-3.5.0/ hadoop@node02:/opt/module/spark/
scp -r ./spark-3.5.0/ hadoop@node03:/opt/module/spark</code></pre> 
<h3>第五步 启动Spark集群</h3> 
<pre><code> cd /opt/module/spark/spark-3.5.0/sbin
 ./ start-all.sh</code></pre> 
<h3>第六步 . 在web界面查看Spark UI</h3> 
<p>在浏览器里面输入主节点的ip:8080</p> 
<p><img alt="" height="1154" src="https://images2.imgbox.com/8c/13/8t9OBsaq_o.png" width="1200"></p> 
<h3>第七步 spark的运行作业测试案例</h3> 
<pre><code>##提交作业
spark-submit --class org.apache.spark.examples.SparkPi $SPARK_HOME/examples/jars/spark-examples_2.12-3.5.0.jar 10 </code></pre> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/d6/cf/xq5fb9yH_o.png" width="1200"></p> 
<h3>第八步. Yarn模式</h3> 
<p><br> 上面默认是用standalone模式启动的服务，如果想要把资源调度交给yarn来做，则需要配置为yarn模式：</p> 
<p>需要启动的服务：hdfs服务、yarn服务<br> 需要关闭 Standalone 对应的服务(即集群中的Master、Worker进程)。<br> 在Yarn模式中，Spark应用程序有两种运行模式：</p> 
<p>yarn-client：Driver程序运行在客户端，适用于交互、调试，希望立2. 即看到app的输出<br> yarn-cluster：Driver程序运行在由RM启动的 AppMaster中，适用于生产环境</p> 
<p>二者的主要区别：<br> Driver在哪里！</p> 
<p>8.1 启动hdfs、yarn服务<br> 此处略过</p> 
<p>8.2 修改Hadoop中的 yarn-site.xml 配置<br> 在$HADOOP_HOME/etc/hadoop/yarn-site.xml中增加如下配置，然后分发到集群其他节点，重启yarn 服务。</p> 
<pre><code># 打开yarn-site.xml文件
vi /home/hadoop-3.3.2/etc/hadoop/yarn-site.xml
&lt;property&gt;
        &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;</code></pre> 
<p><br> 说明：yarn.nodemanager.pmem-check-enabled ： 是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true。<br> yarn.nodemanager.vmem-check-enabled ：是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true。<br> 8.3 向hdfs上传spark纯净版jar包</p> 
<pre><code>cd /home/software
wget https://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-3.3.1/spark-3.3.1-bin-without-hadoop.tgz --no-check-certificate

tar -zxvf spark-3.3.1-bin-without-hadoop.tgz</code></pre> 
<p><br> 上传spark纯净版jar包到hdfs</p> 
<pre><code>hdfs dfs -mkdir /spark-jars
hdfs dfs -put /home/software/spark-3.3.1-bin-without-hadoop/jars/* /spark-jars</code></pre> 
<p><br><br> 说明：</p> 
<p>Spark任务资源分配由Yarn来调度，该任务有可能被分配到集群的任何一个节点。所以需要将spark的依赖上传到hdfs集群路径，这样集群中任何一个节点都能获取到，依此达到Spark集群的HA。<br> Spark纯净版jar包，不包含hadoop和hive相关依赖，避免和后续安装的Hive出现兼容性问题。<br> 8.4 Spark on Yarn测试<br> 记得，先把Master与worker进程停掉，否则会走standalone模式。</p> 
<p># 停掉standalone模式的服务<br> stop-all.sh<br> 8.4.1 client运行模式<br> 这种模式可以看见：程序计算的结果（即可以看见计算返回的结果）！<br>  </p> 
<pre><code># client
spark-submit --master yarn \
--deploy-mode client \
--class org.apache.spark.examples.SparkPi \
$SPARK_HOME/examples/jars/spark-examples_2.12-3.5.0.jar 20</code></pre> 
<p> <img alt="" height="1166" src="https://images2.imgbox.com/fa/a1/IM3eVMOi_o.png" width="1200"></p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/58/cf/1OEVAdrc_o.png" width="1200"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b3f12354a8905c3c5b1a9c89776236ba/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">[1255]使用Uiautomotorviewer无法获取手机页面元素</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c18b0119e734e55c5134fff31ef705f5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">精致旅游公司Treker网页设计 html模板</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>