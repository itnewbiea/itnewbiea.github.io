<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>spark外置external shuffle service使用介绍 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="spark外置external shuffle service使用介绍" />
<meta property="og:description" content="shuffle是什么 shuffle是Hadoop大数据计算中，一个必不可少的环节，通过shuffle可以将不同节点上的同类数据给移动到一起，这在分组，排序，聚合的场景中非常常见，简单图示如下：
MapReduce数据处理模型假设数据以分布式方式存储在多台机器上，并以一些记录的形式组织起来。数据处理分 3 个阶段进行：
shuffle的三个阶段 Map阶段 使用用户自定义的映射函数，来对数据进行处理，这个阶段的主要目标是预处理和过滤数据，map函数会逐条处理数据集中的每一条数据，然后输出一组（K，V）集合，这里可以有三种情况：
不产生任何数据，也就是说数据被全部过滤掉或者数据源为空生成一个 （K，V）对，如果count，max，min，avg，sum等聚合函数生成多个 （K，V）对，如查询，去重，处理转换后的数据 Shuffle阶段 这个阶段所有的（K，V）对，也就是 map 阶段产生的所有键值对都按键排序并分布在集群中的机器上
Reduce阶段 对每个节点上的数据按照 K % (reduce number) 进行横跨节点的分发， reduce 函数计算每组具有相同键的键值对的最终结果。这样 K 相同的数据都会被 shuffle 到同一个节点，形成节点内局部有序的状态。如果想要全局有序，还需要在加一个 reduce 阶段，从而完成最终的排序
Spark中的shuffle 默认情况下，MR任务shuffle都是由当前任务内部完成的，也就是启动了一个spark job，这个job在内部就可完成整个shuffle流程，也就是实时对接的模式，类似快递小哥送快递给你，到你家楼下打电话给你，不见你面他就一直等着你，直到你来了之后，他把快递亲自交到你的手中，他才可以去干下一件快递的排送，这种模式就是默认shuffle的工作原理。
但缺点比较明显，就是资源利用率低，因为等你的途中，快递小哥什么都不能干，所以才有了快递代收点这种产物，在spark里面，可以专门部署一个内置或外置的独立的shuffle服务来处理shuffle数据，这样可以有几个优点：
1，提高资源利用率，
2，增加动态资源调度的弹性，避免开启了动态资源调度时，因为shuffle数据的占用，导致executor无法回收的问题，或者因为executor被回收了，造成shuffle数据被销毁，从而触发该子任务的重算流程
3，减少executor内部之间网络带宽和本地带宽的占用
外部独立的shuffle服务的存储可以不占用YARN内部的本地磁盘，使用独立的SSD磁盘或者SSD的云存储再配上100G的网络带宽来加速shuffle处理性能。
shuffle数据的存储 此外提交spark任务默认shuffle的存储目录为/tmp目录，如果worker节点上这个默认的存储目录的大小比较小，可以在
spark-defaults.conf中配置默认目录：
spark.local.dir /path/local/dir1,/path/local/dir1 或者在应用提交时增加参数：
spark-submit --conf &#34;spark.local.dir=/path/to/local/dir&#34; ... shuffle数据的回收 shuffle 数据的回收与应用的生命周期有关，当应用结束时一般会自动清理，当前某些情况下shuffle数据可能并不会被清理掉，这个时候我们需要编写脚本或程序来周期性的清理，spark中shuffle的清理的配置参数如下：
参数
默认值
解释
版本支持
spark.cleaner.periodicGC.interval
30min
控制触发垃圾收集的频率。
仅当弱引用被垃圾收集时，此上下文清理器才会触发清理。在具有大型驱动程序 JVM 的长时间运行的应用程序中，驱动程序几乎没有内存压力，这种情况可能偶尔会发生或根本不会发生。根本不清理可能会导致执行器在一段时间后耗尽磁盘空间
1.6.0
spark.cleaner.referenceTracking
true
启用或禁用上下文清理
1.0.0
spark.cleaner.referenceTracking.blocking
true
控制清理线程是否应阻塞清理任务（shuffle 除外，这是由 Spark." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/fca8b9599e25cf293970de8d08ad56a3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-27T20:05:15+08:00" />
<meta property="article:modified_time" content="2023-06-27T20:05:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">spark外置external shuffle service使用介绍</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 id="XHeOV">shuffle是什么</h3> 
<p id="ua9497aa1">shuffle是Hadoop大数据计算中，一个必不可少的环节，通过shuffle可以将不同节点上的同类数据给移动到一起，这在分组，排序，聚合的场景中非常常见，简单图示如下：</p> 
<div class="img-center"> 
 <img alt="" src="https://images2.imgbox.com/f4/20/8MRoReCD_o.png"> 
</div> 
<p id="u60a795e9"></p> 
<p id="ue6cc2c19"></p> 
<p id="ub9399be4">MapReduce数据处理模型假设数据以分布式方式存储在多台机器上，并以一些记录的形式组织起来。数据处理分 3 个阶段进行：</p> 
<h3 id="Ee9XZ">shuffle的三个阶段</h3> 
<h5 id="p2FAS">Map阶段</h5> 
<p id="u42d32249">使用用户自定义的映射函数，来对数据进行处理，这个阶段的主要目标是预处理和过滤数据，map函数会逐条处理数据集中的每一条数据，然后输出一组（K，V）集合，这里可以有三种情况：</p> 
<ol><li id="u5a8c7bca">不产生任何数据，也就是说数据被全部过滤掉或者数据源为空</li><li id="u9286d330">生成一个 （K，V）对，如果count，max，min，avg，sum等聚合函数</li><li id="uf0ea8f3b">生成多个 （K，V）对，如查询，去重，处理转换后的数据</li></ol> 
<h5 id="Wlspw">Shuffle阶段</h5> 
<p id="ue85bd73c">这个阶段所有的（K，V）对，也就是 map 阶段产生的所有键值对都按键排序并分布在集群中的机器上</p> 
<h5 id="tokHO">Reduce阶段</h5> 
<p id="ubdabc57a">对每个节点上的数据按照 K % (reduce number) 进行横跨节点的分发， reduce 函数计算每组具有相同键的键值对的最终结果。这样 K 相同的数据都会被 shuffle 到同一个节点，形成节点内局部有序的状态。如果想要全局有序，还需要在加一个 reduce 阶段，从而完成最终的排序</p> 
<h3 id="p2Niz">Spark中的shuffle</h3> 
<p id="u46180db5">默认情况下，MR任务shuffle都是由当前任务内部完成的，也就是启动了一个spark job，这个job在内部就可完成整个shuffle流程，也就是实时对接的模式，类似快递小哥送快递给你，到你家楼下打电话给你，不见你面他就一直等着你，直到你来了之后，他把快递亲自交到你的手中，他才可以去干下一件快递的排送，这种模式就是默认shuffle的工作原理。</p> 
<p id="u7908f066"></p> 
<p id="ued9b8dee">但缺点比较明显，就是资源利用率低，因为等你的途中，快递小哥什么都不能干，所以才有了快递代收点这种产物，在spark里面，可以专门部署一个内置或外置的独立的shuffle服务来处理shuffle数据，这样可以有几个优点：</p> 
<p id="ufd4a6aac">1，提高资源利用率，</p> 
<p id="u57873309">2，增加动态资源调度的弹性，避免开启了动态资源调度时，因为shuffle数据的占用，导致executor无法回收的问题，或者因为executor被回收了，造成shuffle数据被销毁，从而触发该子任务的重算流程</p> 
<p id="u00e1c61f">3，减少executor内部之间网络带宽和本地带宽的占用</p> 
<p id="u57a2d06c"></p> 
<p id="uf28811e0">外部独立的shuffle服务的存储可以不占用YARN内部的本地磁盘，使用独立的SSD磁盘或者SSD的云存储再配上100G的网络带宽来加速shuffle处理性能。</p> 
<h4 id="VauaU">shuffle数据的存储</h4> 
<p id="u45e93a52">此外提交spark任务默认shuffle的存储目录为/tmp目录，如果worker节点上这个默认的存储目录的大小比较小，可以在</p> 
<p id="u67c6f8e5"><strong>spark-defaults.conf中配置默认目录：</strong></p> 
<pre><code class="language-bash">spark.local.dir /path/local/dir1,/path/local/dir1</code></pre> 
<p id="ud69f6dfc">或者在应用提交时增加参数：</p> 
<pre><code class="language-bash">spark-submit --conf "spark.local.dir=/path/to/local/dir" ...</code></pre> 
<p id="uc6bc2773"></p> 
<h4 id="MxyEh">shuffle数据的回收</h4> 
<p id="uf8004f4d">shuffle 数据的回收与应用的生命周期有关，当应用结束时一般会自动清理，当前某些情况下shuffle数据可能并不会被清理掉，这个时候我们需要编写脚本或程序来周期性的清理，spark中shuffle的清理的配置参数如下：</p> 
<table id="KcO8D"><tbody><tr><td> <p id="uff409c20">参数</p> </td><td> <p id="u071f2dad">默认值</p> </td><td> <p id="uc3aa4736">解释</p> </td><td> <p id="u49cd721e">版本支持</p> </td></tr><tr><td> <p id="ue3bbb030">spark.cleaner.periodicGC.interval</p> </td><td> <p id="u1e104288">30min</p> </td><td> <p id="u92148335">控制触发垃圾收集的频率。</p> <p id="u558d7645">仅当弱引用被垃圾收集时，此上下文清理器才会触发清理。在具有大型驱动程序 JVM 的长时间运行的应用程序中，驱动程序几乎没有内存压力，这种情况可能偶尔会发生或根本不会发生。根本不清理可能会导致执行器在一段时间后耗尽磁盘空间</p> </td><td> <p id="uf9cd03da">1.6.0</p> </td></tr><tr><td> <p id="ub539cee0">spark.cleaner.referenceTracking</p> </td><td> <p id="udafc4d30">true</p> </td><td> <p id="u4ce5e215">启用或禁用上下文清理</p> </td><td> <p id="uea150aa2">1.0.0</p> </td></tr><tr><td> <p id="ue35ea84c">spark.cleaner.referenceTracking.blocking</p> </td><td> <p id="u482659f2">true</p> </td><td> <p id="u4b55d4d8">控制清理线程是否应阻塞清理任务（shuffle 除外，这是由 Spark.cleaner.referenceTracking.blocking.shuffle Spark 属性控制的）</p> </td><td> <p id="u8c0f2ab8">1.0.0</p> </td></tr><tr><td> <p id="u1fa87d75">spark.cleaner.referenceTracking.blocking.shuffle</p> </td><td> <p id="u9a1983ec">false</p> </td><td> <p id="u62ddd472">控制清理线程是否应阻塞随机清理任务</p> </td><td> <p id="u27d3c938">1.1.1</p> </td></tr><tr><td> <p id="ua207d5be">spark.cleaner.referenceTracking.cleanCheckpoints</p> </td><td> <p id="u4696e282">false</p> </td><td> <p id="uee13df06">控制在引用超出范围时是否清理检查点文件</p> </td><td></td></tr></tbody></table> 
<h3 id="LzdYP">动态资源调度</h3> 
<p id="ub6f961e2">通过动态资源调度，可以提升集群资源利用率，但动态资源调度的executor在被回收后，会造成shuffle数据的丢失，当我们启动了外置独立的shuffle服务就可以解决问题。</p> 
<p id="u2f48ad66">配置动态资源调度的两种方式：</p> 
<p id="u21f8c9b7">第一种：使用默认的shuffle service，但需要注意executor的回收策略</p> 
<pre><code class="language-bash">spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.shuffleTracking.enabled=true</code></pre> 
<p id="u06baec26">第二种：使用外置的shuffle service</p> 
<pre><code class="language-bash">spark.dynamicAllocation.enabled=true
spark.shuffle.service.enabled=true</code></pre> 
<p id="u1853f85b">注意：以上的 shuffleTracking 或外部 shuffle 服务的目的是允许删除 executor 而不删除它们生成的 shuffle 文件</p> 
<p id="u4b1b81be"></p> 
<p id="u7f47c7ec">启用 shuffleTracking 很简单，但设置外部 shuffle 服务的方法，不同的资源调度器配置都不一样，如standalone，YARN，Mesos等</p> 
<ol><li id="u3b017227">standalone模式：设置 spark.shuffle.service.enabled = true 即可</li><li id="u64465c61">Mesos coarse-grained 模式：</li></ol> 
<ul><li> 
  <ul><li id="u368f6e2c">启动 $SPARK_HOME/sbin/start-mesos-shuffle-service.sh</li><li id="ub08c62f6">设置 spark.shuffle.service.enabled = true</li></ul></li></ul> 
<p id="u288e2157">3. yarn 模式：</p> 
<ul><li> 
  <ul><li id="ua7ac1251">确保spark-&lt;version&gt;-yarn-shuffle.jar在nodemanager节点的classpath中，可以将这个jar放在hadoop的common目录下</li><li id="u6b9e47c1">确保这个jar在集群所有 nodemanager 节点的 claapath路径中</li><li id="uf2041963">在yarn-site.xml中，追加 spark_shuffle选项到 yarn.nodemanager.aux-services配置项的value中，然后将yarn.nodemanager.aux-services.spark_shuffle.class 设置为org.apache.spark.network.yarn.YarnShuffleService</li><li id="u34b5523c">增加 nodemanager 的内存，默认1GB不够用</li><li id="u560fc867">重启所有的nodemanager节点</li></ul></li></ul> 
<p id="ua4dc32bc"></p> 
<p id="u2f5aa0cc">动态资源调度的配置项参考：</p> 
<p id="ueafd1980"><a href="https://spark.apache.org/docs/3.0.1/configuration.html#dynamic-allocation" rel="nofollow" title="Configuration - Spark 3.0.1 Documentation">Configuration - Spark 3.0.1 Documentation</a></p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4b6ae3da277cc65a6c2eeee44db8c787/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">intent.setAction功能及类别</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ee61f7dde1f01338b7dd71645aa671ef/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python操作mysql数据库</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>