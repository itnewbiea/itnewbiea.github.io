<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>迁移学习的几种迁移方式 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="迁移学习的几种迁移方式" />
<meta property="og:description" content=" 迁移学习是当前深度学习领域的一系列通用的解决方案，而不是一个具体的算法模型。Pre-training &#43; fine-tuning（预训练&#43;调参） 的迁移学习方式是现在深度学习中一个非常流行的迁移学习方式，尤其是以图像领域为代表，很多时候会选择预训练的 ImageNet对模型进行初始化。
在迁移学习中，有几个概念，domain（域）和task（任务） 、source（源） 和target（目标）需要理清楚。
- domain：一般指的是特征空间和概率分布 - task:包含标记空间和目标预测函数
- source和target：前者是用于训练模型的域/任务，后者是要用前者的模型对自己的数据进行预测/分类/聚类等机器学习任务的域/任务。
迁移学习的种类根据迁移的内容可以归纳为以下几种：
-Instance-based TL（样本迁移）：source domain数据不可以整个直接被用到target domain里，但是在source domain中还是找到一些可以重新被用到target domain中的数据。对它们调整权重，使它能与target domain中的数据 匹配之后可以进行迁移。
- Feature-representation-transfer（特征迁移）：找到一些好的有代表性的特征，通过特征变换把source domain和target domain的特征变换到同样的空间，使得这个空间中source domain和target domain的数据具有相同的分 布。
- Parameter-transfer（参数/模型迁移）：假设source tasks和target tasks之间共享一些参数，或者共享模型hyperparameters（超参数）的先验分布。这样把原来的模型迁移到新的domain时，也可以达到不错的精度。Pre-training &#43; fine-tuning 的迁移学习方式就可以理解为是一种Parameter-transfer，这种方法也是最常用的迁移学习的应用。
在Pre-training &#43; fine-tuning模式下的迁移学习过程中，常用的训练trick和调参方法总结有如下几点：
- 把预训练模型当做特征提取器： TensorFlow或者Pytorch都有ImageNet上预训练好的模型，将最后一层全连接层（原始的是1000个类别或者更多）改成你自己的分类任务的种类进行输出，或者把最后一层直接去掉换成自己的分类器， 剩下的全部网络结构当做一个特征提取器。
-fine-tuning： 通常来说，直接把预训练模型来用效果不一定足够好，因此需要进行fine-tuning（微调）。fine-tuning需要冻结网络的前几层参数，只更新网络结构的后面几层和最后的全连接层，这样效果会更好。
-Learning rate： 在迁移学习的微调过程中一般不建议使用过大的学习率，通常来说1e-5是比较合适的选择。
迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。
新的数据集较小，并且和pre-trained model所使用的训练数据集相似度较高： 由于数据集较小，在进行finetune存在overfit的风险，又由于数据集和原始数据集相似度较高，因此二者不论是local
feature还是global feature都比较相 近，所以此时最佳的方法是把CNN网络当做特征提取器然后训练一个分类器进行分类新的数据集较大，并且和pre-trained model所使用的训练数据集相似度较高： 很明显，此时我们不用担心overfit（过拟合），因此对全部网络结构进行finetune是较好的。新的数据集较小，并且和pre-trained model所使用的训练数据集差异很大： 由于数据集较小，不适合进行finetune，由于数据集差异大，应该在单独训练网络结构中较高的层，前面几层local的就不用训练了，直接固定权值。在实际
中，这种问题下较好的解决方案一般是从网络的某层开始取出特征，然后训练SVM分类器。新的数据集较大，并且和pre-trained model所使用的训练数据集差异很大： 本来由于数据集较大，可以从头开始训练的，但是在实际中更偏向于训练整个pre-trained model的网络。 " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/674b863b926f92b76993a55c0ec60307/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-05-28T22:20:49+08:00" />
<meta property="article:modified_time" content="2020-05-28T22:20:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">迁移学习的几种迁移方式</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>迁移学习是当前深度学习领域的一系列通用的解决方案，而不是一个具体的算法模型。Pre-training + fine-tuning（预训练+调参） 的迁移学习方式是现在深度学习中一个非常流行的迁移学习方式，尤其是以图像领域为代表，很多时候会选择预训练的 ImageNet对模型进行初始化。<br> 在迁移学习中，有几个概念，domain（域）和task（任务） 、source（源） 和target（目标）需要理清楚。<br> <strong>- domain</strong>：一般指的是特征空间和概率分布 - task:包含标记空间和目标预测函数<br> <strong>- source和target</strong>：前者是用于训练模型的域/任务，后者是要用前者的模型对自己的数据进行预测/分类/聚类等机器学习任务的域/任务。<br> 迁移学习的种类根据迁移的内容可以归纳为以下几种：<br> <strong>-Instance-based</strong> TL（样本迁移）：source domain数据不可以整个直接被用到target domain里，但是在source domain中还是找到一些可以重新被用到target domain中的数据。对它们调整权重，使它能与target domain中的数据 匹配之后可以进行迁移。<br> <strong>- Feature-representation-transfer</strong>（特征迁移）：找到一些好的有代表性的特征，通过特征变换把source domain和target domain的特征变换到同样的空间，使得这个空间中source domain和target domain的数据具有相同的分 布。<br> <strong>- Parameter-transfer</strong>（参数/模型迁移）：假设source tasks和target tasks之间共享一些参数，或者共享模型hyperparameters（超参数）的先验分布。这样把原来的模型迁移到新的domain时，也可以达到不错的精度。Pre-training + fine-tuning 的迁移学习方式就可以理解为是一种Parameter-transfer，这种方法也是最常用的迁移学习的应用。<br> 在Pre-training + fine-tuning模式下的迁移学习过程中，常用的训练trick和调参方法总结有如下几点：<br> <strong>- 把预训练模型当做特征提取器</strong>： TensorFlow或者Pytorch都有ImageNet上预训练好的模型，将最后一层全连接层（原始的是1000个类别或者更多）改成你自己的分类任务的种类进行输出，或者把最后一层直接去掉换成自己的分类器， 剩下的全部网络结构当做一个特征提取器。<br> <strong>-fine-tuning</strong>： 通常来说，直接把预训练模型来用效果不一定足够好，因此需要进行fine-tuning（微调）。fine-tuning需要冻结网络的前几层参数，只更新网络结构的后面几层和最后的全连接层，这样效果会更好。<br> <strong>-Learning rate</strong>： 在迁移学习的微调过程中一般不建议使用过大的学习率，通常来说1e-5是比较合适的选择。<br> <strong>迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。</strong></p> 
<blockquote> 
 <ul><li>新的数据集较小，并且和pre-trained model所使用的训练数据集相似度较高： 由于数据集较小，在进行finetune存在overfit的风险，又由于数据集和原始数据集相似度较高，因此二者不论是local<br> feature还是global feature都比较相 近，所以此时最佳的方法是把CNN网络当做特征提取器然后训练一个分类器进行分类</li><li>新的数据集较大，并且和pre-trained model所使用的训练数据集相似度较高： 很明显，此时我们不用担心overfit（过拟合），因此对全部网络结构进行finetune是较好的。</li><li>新的数据集较小，并且和pre-trained model所使用的训练数据集差异很大： 由于数据集较小，不适合进行finetune，由于数据集差异大，应该在单独训练网络结构中较高的层，前面几层local的就不用训练了，直接固定权值。在实际<br> 中，这种问题下较好的解决方案一般是从网络的某层开始取出特征，然后训练SVM分类器。</li><li>新的数据集较大，并且和pre-trained model所使用的训练数据集差异很大： 本来由于数据集较大，可以从头开始训练的，但是在实际中更偏向于训练整个pre-trained model的网络。</li></ul> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b6882b5e2c0379b44ac0cd190f10481a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">项目编程总结 2020-04月份~2020-05月份</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9df8ec04c0b12fb4eda9352a789f562a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ROS-读取pcd点云数据进行滤波并在Rviz中显示</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>