<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>GPU 高性能推理加速框架Forward开源啦 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="GPU 高性能推理加速框架Forward开源啦" />
<meta property="og:description" content="项目简介
Forward 是一款腾讯平台和内容事业群（PCG）研发的 GPU 高性能推理加速框架。它直接加载主流框架模型（Tensorflow / PyTorch / Keras）转换成 TensorRT 推理加速引擎，帮助用户节省中间繁杂的模型转换或网络构建步骤。相对于直接使用 TensorRT，Forward 更易用以及更容易扩展支持更多模型和算子。目前，Forward 除了覆盖支持主流的 CV，NLP 及推荐领域的深度学习模型外，还支持一些诸如 BERT，FaceSwap，StyleTransfer 这类高级模型。
行业应用 以近期的百万级 BERT 语言模型推理加速项目为例，原本需要成百上千的 CPU 资源来承载的线上推理服务，使用 Forward 推理加速技术后，能够实现原始已训练模型的无缝接入，并保持与之前线上相当的性能的情况下，能节省 40% 以上的成本，实现大幅的成本效能优化。同样地，其他业务团队（例如 QQ，腾讯看点，腾讯新闻，微视）等团队的业务模型也获得了大幅的吞吐量性能的提升。因此，我们有理由相信 Forward 有广大的需求和落地场景，尤其是在日后 GPU 资源日渐丰富的情况下，更是前景可期。
适用人群 深度学习业务模型运营人员：很多业务模型开发维护团队期望提升自己线上业务的性能，但受限于业界目前工具以及人力资源，迟迟无法提升自己的业务性能。本项目则可助力他们直接提升现有业务模型的性能。
深度学习算法开发人员：包括图像，语言，推荐等各 AI 领域的算法开发人员，经常需要开发或改良新的业务模型。受限于业内现有方案，新模型上线往往耗时耗力甚至不受支持，此时本项目的易用性和扩展性将助力提速其新模型的上线。
功能介绍 模型性能优化高：基于 TensorRT API 开发网络层级的支持，保证对于通用网络层级的推理性能优化处于最优级别。
模型支持范围广：除了通用的 CV，NLP，及推荐类模型，还支持一些诸如 BERT，FaceSwap，StyleTransfer 这类高级模型。
接口简单易用：直接导入已训练好的 Tensorflow(.pb) / PyTorch(.pth) / Keras(.h5) 导出的模型文件，隐式转换为高性能的推理 Engine 进行推理加速。
支持自研扩展：可根据业务模型自研定制扩展网络支持层级。
支持 C&#43;&#43; 和 Python 接口调用。
性能介绍 主流模型：由于最终是直接使用 TensorRT 推理引擎，各主流模型的性能可以参考 TensorRT 官方的 Benchmark。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/6d390b5ddf4486176ef1d0f92c0dfd13/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-03-16T17:21:39+08:00" />
<meta property="article:modified_time" content="2021-03-16T17:21:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GPU 高性能推理加速框架Forward开源啦</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p><strong>项目简介<br></strong></p> 
 <h3></h3> 
 <p style="text-align: left">Forward 是一款腾讯平台和内容事业群（PCG）研发的 GPU 高性能推理加速框架。它直接加载主流框架模型（Tensorflow / PyTorch / Keras）转换成 TensorRT 推理加速引擎，帮助用户节省中间繁杂的模型转换或网络构建步骤。相对于直接使用 TensorRT，Forward 更易用以及更容易扩展支持更多模型和算子。目前，Forward 除了覆盖支持主流的 CV，NLP 及推荐领域的深度学习模型外，还支持一些诸如 BERT，FaceSwap，StyleTransfer 这类高级模型。</p> 
 <h3><br></h3> 
 <h3><strong>行业应用</strong></h3> 
 <p style="text-align: left">以近期的百万级 BERT 语言模型推理加速项目为例，原本需要成百上千的 CPU 资源来承载的线上推理服务，使用 Forward 推理加速技术后，能够实现原始已训练模型的无缝接入，并保持与之前线上相当的性能的情况下，能节省 40% 以上的成本，实现大幅的成本效能优化。同样地，其他业务团队（例如 QQ，腾讯看点，腾讯新闻，微视）等团队的业务模型也获得了大幅的吞吐量性能的提升。因此，我们有理由相信 Forward 有广大的需求和落地场景，尤其是在日后 GPU 资源日渐丰富的情况下，更是前景可期。</p> 
 <h3><br></h3> 
 <h3><strong>适用人群</strong></h3> 
 <ul><li><p style="text-align: left">深度学习业务模型运营人员：很多业务模型开发维护团队期望提升自己线上业务的性能，但受限于业界目前工具以及人力资源，迟迟无法提升自己的业务性能。本项目则可助力他们直接提升现有业务模型的性能。</p></li><li><p style="text-align: left">深度学习算法开发人员：包括图像，语言，推荐等各 AI 领域的算法开发人员，经常需要开发或改良新的业务模型。受限于业内现有方案，新模型上线往往耗时耗力甚至不受支持，此时本项目的易用性和扩展性将助力提速其新模型的上线。</p></li></ul> 
 <h3><br></h3> 
 <h3><strong>功能介绍</strong></h3> 
 <ul><li><p style="text-align: left">模型性能优化高：基于 TensorRT API 开发网络层级的支持，保证对于通用网络层级的推理性能优化处于最优级别。</p></li><li><p style="text-align: left">模型支持范围广：除了通用的 CV，NLP，及推荐类模型，还支持一些诸如 BERT，FaceSwap，StyleTransfer 这类高级模型。</p></li><li><p style="text-align: left">接口简单易用：直接导入已训练好的 Tensorflow(.pb) / PyTorch(.pth) / Keras(.h5) 导出的模型文件，隐式转换为高性能的推理 Engine 进行推理加速。</p></li><li><p style="text-align: left">支持自研扩展：可根据业务模型自研定制扩展网络支持层级。</p></li><li><p style="text-align: left">支持 C++ 和 Python 接口调用。</p></li></ul> 
 <h3><br></h3> 
 <h3><strong>性能介绍</strong></h3> 
 <ul><li><p style="text-align: left">主流模型：由于最终是直接使用 TensorRT 推理引擎，各主流模型的性能可以参考 TensorRT 官方的 Benchmark。</p></li><li><p style="text-align: left">业务模型：针对业务模型中一些 TensorRT 及 ONNX 等未支持的网络层级进行了自研开发支持。GAN 模型提升 5.4 倍，BERT 模型提升 5 倍以上。</p></li></ul> 
 <h3><br></h3> 
 <h3><strong>开源愿景</strong></h3> 
 <h4>补全市场，助力领域发展</h4> 
 <p style="text-align: left">深度学习模型推理加速，是广大算法开发及落地人员所热切关注的领域。如果模型推理能得到提速，则意味着线上服务的降本提效。然而业界现有推理加速方案的开发成本高，支持范围小，易用性低，使得业务团队难以将模型推理加速提上日程。我们可以了解到目前业界这一块正处于起步发展阶段，NVIDIA 和Torch 等团队也想做这样的工具（如 TF-TRT，torch2trt 等）并处于较初级的阶段，有一定局限性，而我们这个项目算是比较成熟的项目，所以期望能开源本项目来补充业界这一块的短暂空白，助力开源社区在这个领域的快速发展。</p> 
 <h4>开源共建，助力项目发展</h4> 
 <p style="text-align: left">根据行业应用可知，此项目在业界应有大量的需求，开源此项目则可以满足那些开发用户的需求。且从立项开始，Forward 就秉承开源社区的先进技术和理念，遵循各方面（包括代码质量，工程架构，版本管理等）开源标准来规范项目。因此，为了项目更好的发展，我们期待开源社区的开发人员帮我们一起共建该项目，我们也会随时跟进开源社区需求，提出并解决各种 Issue ，从而使得该项目能逐渐发展壮大。</p> 
 <h3><br></h3> 
 <h3><strong>项目规划</strong></h3> 
 <ul><li><p style="text-align: left">进一步简化接入步骤，提升使用接入体验。</p></li><li><p style="text-align: left">扩展支持更多模型及算子。</p></li><li><p style="text-align: left">进一步优化各算子，提升相关模型性能。</p></li></ul> 
 <p style="text-align: center"><strong>https://github.com/Tencent/Forward </strong><br></p> 
 <p style="text-align: center">（点击文末阅读原文直接访问）</p> 
 <p style="text-align: center">请给项目 一个 Star !</p> 
 <p style="text-align: center">欢迎提出你的 issue 和 PR！<br></p> 
 <p style="text-align: center"> 国内镜像地址：</p> 
 <p style="text-align: center">https://git.code.tencent.com/Tencent_Open_Source/Forward</p> 
 <p style="text-align: center">（登录后才能访问公开项目）<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/48/7a/bNJG9C3B_o.png"></p> 
 <p style="text-align: center">腾讯工蜂源码系统为开源开发者提供完整、最新的腾讯开源项目国内镜像</p> 
 <p><img src="https://images2.imgbox.com/b8/62/Ube9PDnV_o.png"></p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c007114c50f08fc25c559fbcde8f5514/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">解决git上传远端报错error: failed to push some refs to</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/571780144dec88cff97cea05bf8f6927/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">polyval matlab 怎么用,matlab 中polyval的用法 最好能举个例子</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>