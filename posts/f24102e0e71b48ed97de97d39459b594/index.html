<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>李宏毅机器学习第二十一周周报GAN理论 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="李宏毅机器学习第二十一周周报GAN理论" />
<meta property="og:description" content="文章目录 week21 Theory behind GAN摘要Abstract一、李宏毅机器学习——Theory behind GAN1. Generation2. 最大似然估计3. Generator3. Discriminator 二、文献阅读1. 题目2. abstract3. 网络架构3.1 Sequence Generative Adversarial Nets3.2 SeqGAN via Policy Gradient3.3 The Generative Model for Sequences3.4 The Discriminative Model for Sequences(CNN) 4. 文献解读4.1 Introduction4.2 创新点4.3 实验过程4.3.1 训练设置4.3.2 实验结果4.3.3 相关实验结果 4.4 结论 三、实验内容1. Pytorch实现CycleGAN1.1 任务概况1.2实验代码1.2.1 models1.2.2 datasets1.2.3 utils1.2.4 train1.2.5 test 2. SeqGAN2.1 生成器2.2 分辨器2.3 rollout2.4 target_lstm 小结参考文献 week21 Theory behind GAN 摘要 本文主要讨论了GAN的理论知识。本文介绍了在GAN模型之前用于处理生成式任务的最大似然估计。在此基础上，本文分别阐述了生成器与分辨器的原理以及训练目标最大化与JS散度的关系。其次本文展示了题为SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient的论文主要内容。这篇论文提出了SeqGAN，该模型补充了该网络在序列化数据处理领域的空白。该文在中国诗、奥巴马演讲、音乐等数据集上进行实验，从数据角度证明了该网络的优越性。最后，本文基于pytorch实现了CycleGAN并用于解决分类facades数据集的图像转换问题。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/f24102e0e71b48ed97de97d39459b594/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-16T17:11:00+08:00" />
<meta property="article:modified_time" content="2023-12-16T17:11:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">李宏毅机器学习第二十一周周报GAN理论</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#week21_Theory_behind_GAN_3" rel="nofollow">week21 Theory behind GAN</a></li><li><a href="#_6" rel="nofollow">摘要</a></li><li><a href="#Abstract_10" rel="nofollow">Abstract</a></li><li><a href="#Theory_behind_GAN_14" rel="nofollow">一、李宏毅机器学习——Theory behind GAN</a></li><li><ul><li><a href="#1_Generation_16" rel="nofollow">1. Generation</a></li><li><ul><li><a href="#2__22" rel="nofollow">2. 最大似然估计</a></li><li><a href="#3_Generator_41" rel="nofollow">3. Generator</a></li><li><a href="#3_Discriminator_55" rel="nofollow">3. Discriminator</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_85" rel="nofollow">二、文献阅读</a></li><li><ul><li><a href="#1__87" rel="nofollow">1. 题目</a></li><li><a href="#2_abstract_97" rel="nofollow">2. abstract</a></li><li><a href="#3__103" rel="nofollow">3. 网络架构</a></li><li><ul><li><a href="#31_Sequence_Generative_Adversarial_Nets_105" rel="nofollow">3.1 Sequence Generative Adversarial Nets</a></li><li><a href="#32_SeqGAN_via_Policy_Gradient_119" rel="nofollow">3.2 SeqGAN via Policy Gradient</a></li><li><a href="#33_The_Generative_Model_for_Sequences_180" rel="nofollow">3.3 The Generative Model for Sequences</a></li><li><a href="#34_The_Discriminative_Model_for_SequencesCNN_193" rel="nofollow">3.4 The Discriminative Model for Sequences(CNN)</a></li></ul> 
   </li><li><a href="#4__219" rel="nofollow">4. 文献解读</a></li><li><ul><li><a href="#41_Introduction_221" rel="nofollow">4.1 Introduction</a></li><li><a href="#42__227" rel="nofollow">4.2 创新点</a></li><li><a href="#43__232" rel="nofollow">4.3 实验过程</a></li><li><ul><li><a href="#431__234" rel="nofollow">4.3.1 训练设置</a></li><li><a href="#432__247" rel="nofollow">4.3.2 实验结果</a></li><li><a href="#433__263" rel="nofollow">4.3.3 相关实验结果</a></li></ul> 
    </li><li><a href="#44__277" rel="nofollow">4.4 结论</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_281" rel="nofollow">三、实验内容</a></li><li><ul><li><a href="#1_PytorchCycleGAN_283" rel="nofollow">1. Pytorch实现CycleGAN</a></li><li><ul><li><a href="#11__285" rel="nofollow">1.1 任务概况</a></li><li><a href="#12_297" rel="nofollow">1.2实验代码</a></li><li><ul><li><a href="#121_models_299" rel="nofollow">1.2.1 models</a></li><li><a href="#122_datasets_446" rel="nofollow">1.2.2 datasets</a></li><li><a href="#123_utils_500" rel="nofollow">1.2.3 utils</a></li><li><a href="#124_train_554" rel="nofollow">1.2.4 train</a></li><li><a href="#125_test_871" rel="nofollow">1.2.5 test</a></li></ul> 
   </li></ul> 
   </li><li><a href="#2_SeqGAN_967" rel="nofollow">2. SeqGAN</a></li><li><ul><li><a href="#21__971" rel="nofollow">2.1 生成器</a></li><li><a href="#22__1181" rel="nofollow">2.2 分辨器</a></li><li><a href="#23_rollout_1316" rel="nofollow">2.3 rollout</a></li><li><a href="#24_target_lstm_1451" rel="nofollow">2.4 target_lstm</a></li></ul> 
   </li><li><a href="#_1639" rel="nofollow">小结</a></li><li><a href="#_1644" rel="nofollow">参考文献</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="week21_Theory_behind_GAN_3"></a>week21 Theory behind GAN</h2> 
<h2><a id="_6"></a>摘要</h2> 
<p>本文主要讨论了GAN的理论知识。本文介绍了在GAN模型之前用于处理生成式任务的最大似然估计。在此基础上，本文分别阐述了生成器与分辨器的原理以及训练目标最大化与JS散度的关系。其次本文展示了题为SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient的论文主要内容。这篇论文提出了SeqGAN，该模型补充了该网络在序列化数据处理领域的空白。该文在中国诗、奥巴马演讲、音乐等数据集上进行实验，从数据角度证明了该网络的优越性。最后，本文基于pytorch实现了CycleGAN并用于解决分类facades数据集的图像转换问题。</p> 
<h2><a id="Abstract_10"></a>Abstract</h2> 
<p>This article mainly discusses the theoretical knowledge of GAN. This article describes the maximum likelihood estimation that was used to process generative tasks before the GAN model. On this basis, this article expounds the principles of generator and discriminator, and the relationship between training target maximization and JS divergence. Secondly, this paper presents the main content of the paper entitled SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient. This paper proposes SeqGAN, a model that complements the network’s gaps in the field of serialized data processing. This paper carries out experiments on datasets such as Chinese poetry, Obama speeches, music, etc., which proves the superiority of the network from the perspective of data. Finally, this article implements CycleGAN based on pytorch and is used to solve the image transformation problem of classified facades datasets.</p> 
<h2><a id="Theory_behind_GAN_14"></a>一、李宏毅机器学习——Theory behind GAN</h2> 
<h3><a id="1_Generation_16"></a>1. Generation</h3> 
<p>假定如下的分布<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
         
         
           d 
          
         
           a 
          
         
           t 
          
         
           a 
          
         
        
       
         ( 
        
       
         x 
        
       
         ) 
        
       
      
        P_{data}(x) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span>为理想分布，在实线内生成器可以生成理想输出，反之不理想。同时，分布生成的输出落在实线内概率较大，反之较小。而GAN模型的目标是找到这一确定的分布</p> 
<p><img src="https://images2.imgbox.com/1f/80/RaOGsNps_o.png" alt="image-20231207201324951"></p> 
<h4><a id="2__22"></a>2. 最大似然估计</h4> 
<p>在GAN模型之前，处理该类任务使用的最大似然估计</p> 
<p>对于一个可从中采样的数据分布<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
         
         
           d 
          
         
           a 
          
         
           t 
          
         
           a 
          
         
        
       
         ( 
        
       
         x 
        
       
         ) 
        
       
      
        P_{data}(x) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span>，使用由参数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         θ 
        
       
      
        \theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span></span></span></span></span>控制的分布<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
        
          G 
         
        
       
         ( 
        
       
         x 
        
       
         ; 
        
       
         θ 
        
       
         ) 
        
       
      
        P_G(x;\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span>进行拟合。</p> 
<ul><li>目标是确定一个合适的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          θ 
         
        
       
         \theta 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span></span></span></span></span>使得拟合分布接近真实分布</li><li>若拟合分布是一个高斯混合模型，则<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          θ 
         
        
       
         \theta 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span></span></span></span></span>是高斯分布的均值和方差</li></ul> 
<p>若<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         { 
        
        
        
          x 
         
        
          1 
         
        
       
         , 
        
        
        
          x 
         
        
          2 
         
        
       
         , 
        
       
         … 
        
       
         , 
        
        
        
          x 
         
        
          m 
         
        
       
         } 
        
       
      
        \{x^1,x^2,\dots,x^m\} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0641em; vertical-align: -0.25em;"></span><span class="mopen">{<!-- --></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6644em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
         
         
           d 
          
         
           a 
          
         
           t 
          
         
           a 
          
         
        
       
         ( 
        
       
         x 
        
       
         ) 
        
       
      
        P_{data}(x) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span>中采样获得的样本，则通过这些真实分布的样本可以近似得到多个拟合分布<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
        
          G 
         
        
       
         ( 
        
        
        
          x 
         
        
          i 
         
        
       
         , 
        
       
         θ 
        
       
         ) 
        
       
      
        P_G(x^i,\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0747em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span>。然后计算各生成样本对应拟合分布的似然性<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          L 
         
        
          = 
         
         
         
           ∏ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           m 
          
         
         
         
           P 
          
         
           G 
          
         
        
          ( 
         
         
         
           x 
          
         
           i 
          
         
        
          ; 
         
        
          θ 
         
        
          ) 
         
        
       
         L=\prod_{i=1}^m P_G(x^i;\theta) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.9291em; vertical-align: -1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.6514em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∏</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.2777em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8747em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span></span><br> 确定<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          θ 
         
        
          ∗ 
         
        
       
      
        \theta^* 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span>使得<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         a 
        
       
         r 
        
       
         g 
        
        
        
          max 
         
        
          θ 
         
        
       
         ( 
        
       
         L 
        
       
         ) 
        
       
      
        arg\text{max}_{\theta}(L) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mord"><span class="mord text"><span class="mord">max</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mclose">)</span></span></span></span></span></p> 
<p>相应的由该式可以推导使得似然估计最大化即使得KL散度最小化（KL散度越小，两个分布相似性越大）</p> 
<p><img src="https://images2.imgbox.com/9d/dd/FEXbkaZL_o.jpg" alt=""></p> 
<h4><a id="3_Generator_41"></a>3. Generator</h4> 
<p>但是当函数不是以高斯函数的形式给出，则无法计算其最大似然估计</p> 
<p>由于生成图像所需的真实分布是高维空间的低维映射，所以当使用最大似然估计进行拟合时效果不好。</p> 
<p>若生成器G是一个神经网络，该网络定义了概率分布（拟合分布）<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
        
          G 
         
        
       
      
        P_G 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></p> 
<p>假定由一个正态分布给出z作为生成器G的输入，G根据拟合分布输出<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         x 
        
       
         = 
        
       
         G 
        
       
         ( 
        
       
         z 
        
       
         ) 
        
       
      
        x=G(z) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="mclose">)</span></span></span></span></span>，目标同样是使得拟合分布与真实分布越近越好。从而有<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           G 
          
         
           ∗ 
          
         
        
          = 
         
        
          a 
         
        
          r 
         
        
          g 
         
         
          
          
            min 
           
          
            ⁡ 
           
          
         
           g 
          
         
        
          D 
         
        
          i 
         
        
          v 
         
        
          ( 
         
         
         
           P 
          
         
           G 
          
         
        
          , 
         
         
         
           P 
          
          
          
            d 
           
          
            a 
           
          
            t 
           
          
            a 
           
          
         
        
          ) 
         
        
       
         G^*=arg\min_gDiv(P_G,P_{data}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7387em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7387em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.5861em; vertical-align: -0.8361em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -2.4em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.8361em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><br> 即使得两个分布之间的散度最小化。但由于不知道两个分布的形式而仅可从中采样，因此该散度无法计算。</p> 
<h4><a id="3_Discriminator_55"></a>3. Discriminator</h4> 
<p>将两个分布的采样输入分辨器D，该分辨器产生sigmoid输出，即越接近真实输出分数越大，反之越小。其目标函数为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          V 
         
        
          ( 
         
        
          G 
         
        
          , 
         
        
          D 
         
        
          ) 
         
        
          = 
         
         
         
           E 
          
          
          
            x 
           
          
            ∼ 
           
           
           
             P 
            
            
            
              d 
             
            
              a 
             
            
              t 
             
            
              a 
             
            
           
          
         
        
          [ 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
          D 
         
        
          ( 
         
        
          x 
         
        
          ) 
         
        
          ] 
         
        
          + 
         
         
         
           E 
          
          
          
            x 
           
          
            ∼ 
           
           
           
             P 
            
           
             G 
            
           
          
         
        
          [ 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
          ( 
         
        
          1 
         
        
          − 
         
        
          D 
         
        
          ( 
         
        
          x 
         
        
          ) 
         
        
          ) 
         
        
          ] 
         
        
       
         V(G,D)=E_{x\sim P_{data}}[logD(x)]+E_{x\sim P_G}[log(1-D(x))] 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0059em; vertical-align: -0.2559em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0576em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: -0.1389em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2559em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)]</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0003em; vertical-align: -0.2503em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0576em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3567em; margin-left: -0.1389em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1433em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2503em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))]</span></span></span></span></span></span><br> 在训练过程中G固定，优化D</p> 
<p>训练的目标是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          D 
         
        
          ∗ 
         
        
       
         = 
        
       
         a 
        
       
         r 
        
       
         g 
        
        
         
         
           max 
          
         
           ⁡ 
          
         
        
          D 
         
        
       
         V 
        
       
         ( 
        
       
         D 
        
       
         , 
        
       
         G 
        
       
         ) 
        
       
      
        D^*=arg\max_DV(D,G) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">G</span><span class="mclose">)</span></span></span></span></span></p> 
<p>在该任务情况下，其与二分类器类似，且目标值的最大化与JS散度相关</p> 
<p><img src="https://images2.imgbox.com/aa/05/r6xifeOf_o.png" alt="image-20231207211958262"></p> 
<p>当散度较小时，D难以分辨出数据属于哪个分布，相反当散度较大时，D可以很容易的进行分辨。</p> 
<p>以下证明该训练目标的最大化与JS散度相关</p> 
<p><img src="https://images2.imgbox.com/75/5e/2wdMfPp1_o.jpg" alt=""></p> 
<p>相应的，当训练生成器时，有<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
        
          ∗ 
         
        
       
         = 
        
       
         a 
        
       
         r 
        
       
         g 
        
        
         
         
           min 
          
         
           ⁡ 
          
         
        
          G 
         
        
        
         
         
           max 
          
         
           ⁡ 
          
         
        
          D 
         
        
       
         V 
        
       
         ( 
        
       
         G 
        
       
         , 
        
       
         D 
        
       
         ) 
        
       
      
        G^*=arg\min_G\max_DV(G,D) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6887em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mclose">)</span></span></span></span></span></p> 
<p>如下图，假设仅有三种生成器，各生成器与D的图像如下</p> 
<p>V(G,D)是拟合分布与真实分布的散度，在下图中为蓝色曲线。而红色点为相对于相应生成器，对应的D取最高值，即此时D最能识别出由该生成器生成的数据与真实数据的区别。</p> 
<p>而根据上述目标，显然期望该值越小越好，从而<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
        
          3 
         
        
       
      
        G_3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是这种情况下最优的生成器，因为其可以使得D在各种情况下取得的V值相较于其他生成器处于较低水平。</p> 
<p><img src="https://images2.imgbox.com/bc/25/GsQRV21Z_o.png" alt="image-20231207221424803"></p> 
<h2><a id="_85"></a>二、文献阅读</h2> 
<h3><a id="1__87"></a>1. 题目</h3> 
<p>题目：SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient</p> 
<p>作者：<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+L" rel="nofollow">Lantao Yu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+W" rel="nofollow">Weinan Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+J" rel="nofollow">Jun Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+Y" rel="nofollow">Yong Yu</a></p> 
<p>链接：https://arxiv.org/abs/1609.05473</p> 
<p>期刊：AAAI2017</p> 
<h3><a id="2_abstract_97"></a>2. abstract</h3> 
<p>该文提出了一个序列生成框架，称为SeqGAN。SeqGAN以强化学习中的随机策略为基础思路重新构建了生成器，通过执行梯度策略绕过生成器微分问题。激励函数源自GAN判别器对完整序列的判断，并使用蒙特卡洛搜索回传中间状态——动作步骤。</p> 
<p>This paper proposes a sequence generation framework called SeqGAN. This framework reconstructes the generator based on the stochastic strategy in reinforcement learning, and by passed the generator differentiation problem by executing the gradient strategy. The judgment of the GAN discriminator on the complete sequence controls the reward function. And this framework uses Monte Carlo search to return the intermediate state-action step.</p> 
<h3><a id="3__103"></a>3. 网络架构</h3> 
<h4><a id="31_Sequence_Generative_Adversarial_Nets_105"></a>3.1 Sequence Generative Adversarial Nets</h4> 
<p>文本序列生成模型可以表示为，</p> 
<ol><li>给定真实世界的训练数据集，训练一个生成器<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           G 
          
         
           θ 
          
         
        
       
         G_\theta 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，通过$ G_\theta<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          来产生序列 
         
        
       
         来产生序列 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord cjk_fallback">来产生序列</span></span></span></span></span>Y_{1:T}=(y_1,\dots,y_t,\dots,y_T)\in\mathbb Y<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ，这里 
         
        
       
         ，这里 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord cjk_fallback">，这里</span></span></span></span></span>\mathbb Y<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          表示备选单词的词典。在时间步 
         
        
          t 
         
        
          ，状态 
         
        
          s 
         
        
          是当前已经生成的单词序列 
         
        
       
         表示备选单词的词典。在时间步t ，状态s是当前已经生成的单词序列 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord cjk_fallback">表示备选单词的词典。在时间步</span><span class="mord mathnormal">t</span><span class="mord cjk_fallback">，状态</span><span class="mord mathnormal">s</span><span class="mord cjk_fallback">是当前已经生成的单词序列</span></span></span></span></span>(y_1,\dots,y_t,\dots,y_T)<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ，动作 
         
        
          a 
         
        
          是下一个将要选择的单词 
         
        
       
         ，动作a是下一个将要选择的单词 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord cjk_fallback">，动作</span><span class="mord mathnormal">a</span><span class="mord cjk_fallback">是下一个将要选择的单词</span></span></span></span></span>y_t$ 。故策略模型<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           G 
          
         
           θ 
          
         
        
          ( 
         
         
         
           y 
          
         
           t 
          
         
        
          ∣ 
         
         
         
           Y 
          
          
          
            1 
           
          
            : 
           
          
            t 
           
          
            − 
           
          
            1 
           
          
         
        
          ) 
         
        
       
         G_\theta(y_t|Y_{1:t-1}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>是随机的，但在选择一个动作之后，状态转移是确定的 
  <ul><li>例如当当前状态是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
          
            s 
           
          
            = 
           
           
           
             Y 
            
            
            
              1 
             
            
              : 
             
            
              t 
             
            
              − 
             
            
              1 
             
            
           
          
         
           s=Y_{1:t-1} 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8917em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             δ 
            
            
            
              s 
             
            
              , 
             
             
             
               s 
              
             
               ′ 
              
             
            
           
             a 
            
           
          
            = 
           
          
            1 
           
          
         
           \delta_{s,s'}^a=1 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1055em; vertical-align: -0.4111em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6644em;"><span class="" style="top: -2.425em; margin-left: -0.0379em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6828em;"><span class="" style="top: -2.786em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4111em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>的下一步是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             s 
            
           
             ′ 
            
           
          
            = 
           
           
           
             Y 
            
            
            
              1 
             
            
              : 
             
            
              t 
             
            
           
          
         
           s'=Y_{1:t} 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7519em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，而动作<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
          
            a 
           
          
            = 
           
           
           
             y 
            
           
             t 
            
           
          
         
           a=y_t 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的下一状态是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             s 
            
            
            
              ′ 
             
            
              ′ 
             
            
           
          
            , 
           
           
           
             δ 
            
            
            
              s 
             
            
              , 
             
             
             
               s 
              
              
              
                ′ 
               
              
                ′ 
               
              
             
            
           
             a 
            
           
          
            = 
           
          
            0 
           
          
         
           s'',\delta_{s,s''}^a=0 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.163em; vertical-align: -0.4111em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6644em;"><span class="" style="top: -2.425em; margin-left: -0.0379em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6828em;"><span class="" style="top: -2.786em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4111em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0</span></span></span></span></span></li></ul> </li><li>如下图所示，训练一个<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ϕ 
         
        
       
         \phi 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">ϕ</span></span></span></span></span>参数化判别模型<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           D 
          
         
           ϕ 
          
         
        
       
         D_\phi 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，为改进<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           G 
          
         
           ϕ 
          
         
        
       
         G_\phi 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>提供指导。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           D 
          
         
           ϕ 
          
         
        
          ( 
         
         
         
           Y 
          
          
          
            1 
           
          
            : 
           
          
            T 
           
          
         
        
          ) 
         
        
       
         D_\phi(Y_{1:T}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>是表示序列<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           Y 
          
          
          
            1 
           
          
            : 
           
          
            T 
           
          
         
        
       
         Y_{1:T} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是否来自真实序列数据的概率。如下图所示，通过从实际序列数据中提供正面实例和从生成模型<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           G 
          
         
           θ 
          
         
        
       
         G_\theta 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>生成的合成序列中提供负面示例来训练判别模型<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           D 
          
         
           θ 
          
         
        
       
         D_\theta 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。同时，根据判别模型<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           D 
          
         
           ϕ 
          
         
        
       
         D_\phi 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>得到的期望最终reward，采用策略梯度和MC搜索对生成模型进行更新。通过欺骗判别模型<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           D 
          
         
           ϕ 
          
         
        
       
         D_\phi 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的可能性来估计reward</li></ol> 
<p><img src="https://images2.imgbox.com/35/83/H71gSYjH_o.png" alt="image-20231208182350507"></p> 
<p>上图左侧：D是G对实际数据和生成的数据进行训练。</p> 
<p>上图右侧：G通过策略梯度进行训练，最终的奖励信号由D提供，并通过蒙特卡罗搜索传回中间动作值。</p> 
<h4><a id="32_SeqGAN_via_Policy_Gradient_119"></a>3.2 SeqGAN via Policy Gradient</h4> 
<p>当没有中间状态时，生成器模型<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
        
          θ 
         
        
       
         ( 
        
        
        
          y 
         
        
          t 
         
        
       
         ∣ 
        
        
        
          Y 
         
         
         
           1 
          
         
           : 
          
         
           t 
          
         
           − 
          
         
           1 
          
         
        
       
         ) 
        
       
      
        G_\theta(y_t|Y_{1:t-1}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>的目的是从起始状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          s 
         
        
          0 
         
        
       
      
        s_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>生成一个序列，以使其预测的最终预期结果最大化：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
           
             J 
            
           
             ( 
            
           
             θ 
            
           
             ) 
            
           
             = 
            
           
             E 
            
           
             [ 
            
            
            
              R 
             
            
              T 
             
            
           
             ∣ 
            
            
            
              s 
             
            
              0 
             
            
           
             , 
            
           
             θ 
            
           
             ] 
            
           
             = 
            
            
            
              ∑ 
             
             
              
              
                y 
               
              
                1 
               
              
             
               ∈ 
              
             
               Y 
              
             
            
            
            
              G 
             
            
              θ 
             
            
           
             ( 
            
            
            
              y 
             
            
              1 
             
            
           
             ∣ 
            
            
            
              s 
             
            
              0 
             
            
           
             ) 
            
           
             ⋅ 
            
            
            
              Q 
             
             
             
               D 
              
             
               ϕ 
              
             
             
             
               G 
              
             
               θ 
              
             
            
           
             ( 
            
            
            
              s 
             
            
              0 
             
            
           
             , 
            
            
            
              y 
             
            
              1 
             
            
           
             ) 
            
           
          
          
          
          
            (1) 
           
          
         
        
       
         J(\theta)=\mathbb E[R_T|s_0,\theta]=\sum_{y_1\in \mathcal Y}G_\theta(y_1|s_0)\cdot Q_{D_\phi}^{G_\theta}(s_0,y_1) \tag{1} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathbb">E</span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0077em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0077em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">]</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.4804em; vertical-align: -1.4304em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.05em;"><span class="" style="top: -1.8557em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3173em;"><span class="" style="top: -2.357em; margin-left: -0.0359em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mathcal mtight" style="margin-right: 0.0822em;">Y</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.4304em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.4256em; vertical-align: -0.4966em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.929em;"><span class="" style="top: -2.4065em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: -0.0278em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2901em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.1507em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4966em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 2.4804em; vertical-align: -1.4304em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          R 
         
        
          T 
         
        
       
      
        R_T 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0077em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0077em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是对完整序列的激励。</p> 
<p>奖励来自于鉴别器<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          D 
         
        
          ϕ 
         
        
       
      
        D_\phi 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          Q 
         
         
         
           G 
          
         
           θ 
          
         
         
         
           D 
          
         
           θ 
          
         
        
       
         ( 
        
       
         s 
        
       
         , 
        
       
         a 
        
       
         ) 
        
       
      
        Q_{G_\theta}^{D_\theta}(s,a) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3284em; vertical-align: -0.3994em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.929em;"><span class="" style="top: -2.4065em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.1507em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: -0.0278em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3994em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span></span>是一个序列的动作——值函数，即从状态s开始，采取动作a，然后遵循策略<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
        
          θ 
         
        
       
      
        G_\theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的期望累计报酬。序列目标函数的合理性在于，从给定初始状态开始，生成器的目标是生成一个使得鉴别器认为是真的序列。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              Q 
             
             
             
               G 
              
             
               θ 
              
             
             
             
               D 
              
             
               θ 
              
             
            
           
             ( 
            
           
             a 
            
           
             = 
            
            
            
              y 
             
            
              T 
             
            
           
             , 
            
           
             s 
            
           
             = 
            
            
            
              Y 
             
             
             
               1 
              
             
               : 
              
             
               T 
              
             
               − 
              
             
               1 
              
             
            
           
             ) 
            
           
             = 
            
            
            
              D 
             
            
              ϕ 
             
            
           
             ( 
            
            
            
              Y 
             
             
             
               1 
              
             
               : 
              
             
               T 
              
             
            
           
             ) 
            
           
          
          
          
          
            (2) 
           
          
         
        
       
         Q_{G_\theta}^{D_\theta}(a=y_T,s=Y_{1:T-1})=D_{\phi}(Y_{1:T}) \tag{2} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3284em; vertical-align: -0.3994em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.929em;"><span class="" style="top: -2.4065em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.1507em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: -0.0278em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3994em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 1.3284em; vertical-align: -0.3994em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 对于一个完整的序列相应的提供完整的激励。由于需要兼顾长期序列的稳定性，在每一步考虑之前token的适合性的同时，考虑将来的状态。进一步的，为了评估中间状态的操作值，应用MTCsearch和推理策略<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
        
          β 
         
        
       
      
        G_\beta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0528em;">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>来抽样未知的最后<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          T 
         
        
          t 
         
        
       
      
        T_t 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>各token。将N次的蒙特卡罗搜索表示为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
           
             { 
            
            
            
              Y 
             
             
             
               1 
              
             
               : 
              
             
               T 
              
             
            
              1 
             
            
           
             , 
            
           
             … 
            
           
             , 
            
            
            
              Y 
             
             
             
               1 
              
             
               : 
              
             
               T 
              
             
            
              N 
             
            
           
             } 
            
           
             = 
            
            
            
              MC 
             
             
             
               G 
              
             
               β 
              
             
            
           
             ( 
            
            
            
              Y 
             
             
             
               1 
              
             
               : 
              
             
               t 
              
             
            
           
             ; 
            
           
             N 
            
           
             ) 
            
           
          
          
          
          
            (3) 
           
          
         
        
       
         \{Y_{1:T}^1,\dots,Y_{1:T}^N\}=\text{MC}^{G_\beta}(Y_{1:t};N) \tag{3} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1413em; vertical-align: -0.25em;"></span><span class="mopen">{<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -2.453em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8913em;"><span class="" style="top: -2.453em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.1646em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord text"><span class="mord">MC</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.9146em;"><span class="" style="top: -3.1362em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0528em;">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2901em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 1.1646em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">3</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 综上，有下述公式<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              Q 
             
             
             
               G 
              
             
               θ 
              
             
             
             
               D 
              
             
               θ 
              
             
            
           
             ( 
            
           
             a 
            
           
             = 
            
            
            
              y 
             
            
              T 
             
            
           
             , 
            
           
             s 
            
           
             = 
            
            
            
              Y 
             
             
             
               1 
              
             
               : 
              
             
               T 
              
             
               − 
              
             
               1 
              
             
            
           
             ) 
            
           
             = 
            
            
            
            
              { 
             
             
              
               
                
                 
                  
                  
                    1 
                   
                  
                    N 
                   
                  
                  
                  
                    ∑ 
                   
                   
                   
                     n 
                    
                   
                     = 
                    
                   
                     1 
                    
                   
                  
                    N 
                   
                  
                  
                  
                    D 
                   
                  
                    ϕ 
                   
                  
                 
                   ( 
                  
                  
                  
                    Y 
                   
                   
                   
                     1 
                    
                   
                     : 
                    
                   
                     T 
                    
                   
                  
                    N 
                   
                  
                 
                   ) 
                  
                 
                   , 
                  
                  
                  
                    Y 
                   
                   
                   
                     1 
                    
                   
                     : 
                    
                   
                     T 
                    
                   
                  
                 
                   ∈ 
                  
                  
                  
                    MC 
                   
                   
                   
                     G 
                    
                   
                     β 
                    
                   
                  
                 
                   ( 
                  
                  
                  
                    Y 
                   
                   
                   
                     1 
                    
                   
                     : 
                    
                   
                     t 
                    
                   
                  
                 
                   ; 
                  
                 
                   N 
                  
                 
                   ) 
                  
                  
                 
                   for  
                  
                 
                   t 
                  
                 
                   &lt; 
                  
                 
                   Y 
                  
                 
                   , 
                  
                 
                
               
              
              
               
                
                 
                  
                  
                    D 
                   
                  
                    ϕ 
                   
                  
                 
                   ( 
                  
                  
                  
                    Y 
                   
                   
                   
                     1 
                    
                   
                     : 
                    
                   
                     t 
                    
                   
                  
                 
                   ) 
                  
                  
                 
                   for  
                  
                 
                   t 
                  
                 
                   = 
                  
                 
                   T 
                  
                 
                
               
              
             
            
           
          
          
          
          
            (4) 
           
          
         
        
       
         Q_{G_\theta}^{D_\theta}(a=y_T,s=Y_{1:T-1})=\\ \begin{cases} \frac1N\sum_{n=1}^ND_\phi(Y_{1:T}^N),Y_{1:T}\in \text{MC}^{G_\beta}(Y_{1:t};N)\quad \text{for}\ t&lt;Y,\\ D_\phi(Y_{1:t})\quad \text{for}\ t=T \end{cases} \tag{4} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3284em; vertical-align: -0.3994em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.929em;"><span class="" style="top: -2.4065em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.1507em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: -0.0278em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3994em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 3em; vertical-align: -1.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size4">{<!-- --></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.69em;"><span class="" style="top: -3.69em;"><span class="pstrut" style="height: 3.008em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8451em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9812em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2997em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8413em;"><span class="" style="top: -2.4247em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2753em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mord"><span class="mord text"><span class="mord">MC</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.9146em;"><span class="" style="top: -3.1362em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0528em;">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2901em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mclose">)</span><span class="mspace" style="margin-right: 1em;"></span><span class="mord text"><span class="mord">for</span></span><span class="mspace"> </span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="mpunct">,</span></span></span><span class="" style="top: -2.25em;"><span class="pstrut" style="height: 3.008em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 1em;"></span><span class="mord text"><span class="mord">for</span></span><span class="mspace"> </span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.19em;"><span class=""></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="tag"><span class="strut" style="height: 3em; vertical-align: -1.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">4</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 其中当无中间状态时，该函数从状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          s 
         
        
          ′ 
         
        
       
         = 
        
        
        
          Y 
         
         
         
           1 
          
         
           : 
          
         
           t 
          
         
        
       
      
        s'=Y_{1:t} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7519em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>开始进行推理。</p> 
<p>注：若当前序列已经完整，则生成器使用循环神经网络，此时直接将该序列作为分辨器的输入。若当前序列未完整，则使用蒙特卡洛搜索。即使用已经生成的序列，从当前位置的下一个开始采样，得到完整序列，即roll-out policy。该策略通过神经网络实现，该圣经网络即生成器。之后，在将该生成器的输出作为分辨器的输入。</p> 
<p>使用判别器<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          D 
         
        
          ϕ 
         
        
       
      
        D_\phi 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>作为激励函数的优点是其可以动态更新，以迭代的改进生成模型。一旦有了一组更真实的生成序列，将重新训练鉴别器模型<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
             
             
               min 
              
             
               ⁡ 
              
             
            
              ϕ 
             
            
            
            
              E 
             
             
             
               Y 
              
             
               ∼ 
              
              
              
                p 
               
               
               
                 d 
                
               
                 a 
                
               
                 t 
                
               
                 a 
                
               
              
             
            
           
             [ 
            
           
             log 
            
           
             ⁡ 
            
            
            
              D 
             
            
              ϕ 
             
            
           
             ( 
            
           
             Y 
            
           
             ) 
            
           
             ] 
            
           
             − 
            
            
            
              E 
             
             
             
               Y 
              
             
               ∼ 
              
              
              
                G 
               
              
                θ 
               
              
             
            
           
             [ 
            
           
             log 
            
           
             ⁡ 
            
           
             ( 
            
           
             1 
            
           
             − 
            
            
            
              D 
             
            
              ϕ 
             
            
           
             ( 
            
           
             Y 
            
           
             ) 
            
           
             ) 
            
           
             ] 
            
           
          
          
          
          
            (5) 
           
          
         
        
       
         \min_\phi\mathbb E_{Y\sim p_{data}}[\log D_\phi(Y)]-\mathbb E_{Y\sim G_\theta}[\log(1-D_\phi(Y))] \tag{5} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.6382em; vertical-align: -0.8882em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -2.3479em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.8882em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">Y</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="mclose">)]</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0059em; vertical-align: -0.2559em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">Y</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2559em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="mclose">))]</span></span><span class="tag"><span class="strut" style="height: 1.6382em; vertical-align: -0.8882em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">5</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 每次更新判断器模型时，准备更新生成器。所提出的基于策略的优化参数优化策略来最直接最大化长期结果。目标函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         J 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
      
        J(\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span>的梯度生成器的参数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         θ 
        
       
      
        \theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span></span></span></span></span>可以推导为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              ∇ 
             
            
              θ 
             
            
           
             J 
            
           
             ( 
            
           
             θ 
            
           
             ) 
            
           
             = 
            
            
            
              ∑ 
             
             
             
               t 
              
             
               = 
              
             
               1 
              
             
            
              T 
             
            
            
            
              E 
             
             
             
               Y 
              
              
              
                1 
               
              
                : 
               
              
                t 
               
              
                − 
               
              
                1 
               
              
                ∼ 
               
               
               
                 G 
                
               
                 θ 
                
               
              
             
            
           
             [ 
            
            
            
              ∑ 
             
             
              
              
                y 
               
              
                t 
               
              
             
               ∈ 
              
             
               Y 
              
             
            
            
            
              ∇ 
             
            
              θ 
             
            
            
            
              G 
             
            
              θ 
             
            
           
             ( 
            
            
            
              y 
             
            
              t 
             
            
           
             ∣ 
            
            
            
              Y 
             
             
             
               1 
              
             
               : 
              
             
               t 
              
             
               − 
              
             
               1 
              
             
            
           
             ) 
            
           
             ⋅ 
            
            
            
              Q 
             
             
             
               D 
              
             
               ϕ 
              
             
             
             
               G 
              
             
               θ 
              
             
            
           
             ( 
            
            
            
              Y 
             
             
             
               1 
              
             
               : 
              
             
               t 
              
             
               − 
              
             
               1 
              
             
               , 
              
              
              
                y 
               
              
                t 
               
              
             
            
           
             ) 
            
           
             ] 
            
           
          
          
          
          
            (6) 
           
          
         
        
       
         \nabla_\theta J(\theta)=\sum_{t=1}^T\mathbb E_{Y_{1:t-1\sim G_\theta}}[\sum_{y_t\in \mathcal Y}\nabla_\theta G_\theta(y_t|Y_{1:t-1})\cdot Q_{D_\phi}^{G_\theta}(Y_{1:t-1,y_t})] \tag{6} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 3.2588em; vertical-align: -1.4304em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8283em;"><span class="" style="top: -1.8829em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.2671em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3567em; margin-left: -0.2222em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3448em; margin-left: 0em; margin-right: 0.1em;"><span class="pstrut" style="height: 2.6944em;"></span><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3496em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.393em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4251em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.05em;"><span class="" style="top: -1.8557em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2963em;"><span class="" style="top: -2.357em; margin-left: -0.0359em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mathcal mtight" style="margin-right: 0.0822em;">Y</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.4304em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.4256em; vertical-align: -0.4966em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.929em;"><span class="" style="top: -2.4065em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: -0.0278em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2901em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.1507em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4966em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2963em;"><span class="" style="top: -2.357em; margin-left: -0.0359em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)]</span></span><span class="tag"><span class="strut" style="height: 3.2588em; vertical-align: -1.4304em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">6</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 推导过程如下</p> 
<p><img src="https://images2.imgbox.com/ed/75/7GqYeaLL_o.jpg" alt="微信图片_20231208211231"></p> 
<p>上述形式是基于确定性状态转换和无中间状态产生的。下式为上式的无偏差估计</p> 
<p><img src="https://images2.imgbox.com/fc/c8/SEZmwPHP_o.png" alt="image-20231208211613749"></p> 
<p>其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          Y 
         
         
         
           1 
          
         
           : 
          
         
           t 
          
         
           − 
          
         
           1 
          
         
        
       
      
        Y_{1:t-1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8917em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.2222em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>从<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
        
          θ 
         
        
       
      
        G_\theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>采样的中间状态。期望<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         E 
        
       
         [ 
        
       
         ⋅ 
        
       
         ] 
        
       
      
        \mathbb E[\cdot] 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathbb">E</span><span class="mopen">[</span><span class="mord">⋅</span><span class="mclose">]</span></span></span></span></span>可以通过采样方法来近似，故将生成器的参数更新为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
           
             θ 
            
           
             ← 
            
           
             θ 
            
           
             + 
            
            
            
              α 
             
            
              h 
             
            
            
            
              ∇ 
             
            
              θ 
             
            
           
             J 
            
           
             ( 
            
           
             θ 
            
           
             ) 
            
           
          
          
          
          
            (8) 
           
          
         
        
       
         \theta\leftarrow \theta+\alpha_h\nabla_\theta J(\theta) \tag{8} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7778em; vertical-align: -0.0833em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">8</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          α 
         
        
          h 
         
        
       
         ∈ 
        
        
        
          R 
         
        
          + 
         
        
       
      
        \alpha_h\in \mathbb R^+ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6891em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span>表示第h步对应的学习率。此外，其还可以采样Adam或者RMSprop等算法</p> 
<p>下图中的算法1展示了所提出的SeqGAN的完整细节。在训练开始时，使用最大似然估计来与训练<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
        
          θ 
         
        
       
      
        G_\theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的训练集S。论文作者发现来自与训练鉴别器的监督信号提供了丰富信息，有助于有效的调整生成器。</p> 
<p><img src="https://images2.imgbox.com/f3/3a/ofzuPwAB_o.jpg" alt=""></p> 
<h4><a id="33_The_Generative_Model_for_Sequences_180"></a>3.3 The Generative Model for Sequences</h4> 
<p>使用递归神经网络作为生成器模型（LSTM）。RNN映射序列输入嵌入表示<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          1 
         
        
       
         , 
        
       
         … 
        
       
         , 
        
        
        
          x 
         
        
          T 
         
        
       
      
        x_1,\dots,x_T 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。通过递归的使用更新函数g，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          1 
         
        
       
         , 
        
       
         … 
        
       
         , 
        
        
        
          x 
         
        
          T 
         
        
       
      
        x_1,\dots,x_T 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>转换成一系列隐藏状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          t 
         
        
       
      
        h_t 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span><br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              h 
             
            
              t 
             
            
           
             = 
            
           
             g 
            
           
             ( 
            
            
            
              h 
             
             
             
               t 
              
             
               − 
              
             
               1 
              
             
            
           
             , 
            
            
            
              x 
             
            
              t 
             
            
           
             ) 
            
           
          
          
          
          
            (9) 
           
          
         
        
       
         h_t=g(h_{t-1},x_t) \tag{9} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">9</span></span><span class="mord">)</span></span></span></span></span></span></span><br> softmax输出层z将隐藏状态映射至输出token分布(0-1)中：（bias：c，weight：V）<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
           
             p 
            
           
             ( 
            
            
            
              y 
             
            
              t 
             
            
           
             ∣ 
            
            
            
              x 
             
            
              1 
             
            
           
             , 
            
           
             … 
            
           
             , 
            
            
            
              x 
             
            
              t 
             
            
           
             ) 
            
           
             = 
            
           
             z 
            
           
             ( 
            
            
            
              h 
             
            
              t 
             
            
           
             ) 
            
           
             = 
            
           
             softmax 
            
           
             ( 
            
           
             c 
            
           
             + 
            
           
             V 
            
            
            
              h 
             
            
              t 
             
            
           
             ) 
            
           
          
          
          
          
            (10) 
           
          
         
        
       
         p(y_t|x_1,\dots, x_t)=z(h_t)=\text{softmax}(c+Vh_t) \tag{10} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">10</span></span><span class="mord">)</span></span></span></span></span></span></span></p> 
<h4><a id="34_The_Discriminative_Model_for_SequencesCNN_193"></a>3.4 The Discriminative Model for Sequences(CNN)</h4> 
<p>输入序列<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              E 
             
             
             
               1 
              
             
               : 
              
             
               T 
              
             
            
           
             = 
            
            
            
              x 
             
            
              1 
             
            
           
             ⊕ 
            
            
            
              x 
             
            
              2 
             
            
           
             ⊕ 
            
           
             ⋯ 
            
           
             ⊕ 
            
            
            
              x 
             
            
              T 
             
            
           
          
          
          
          
            (11) 
           
          
         
        
       
         \mathcal E_{1:T}=x_1\oplus x_2\oplus\dots\oplus x_T \tag{11} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.0894em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0894em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.7333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6667em; vertical-align: -0.0833em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">11</span></span><span class="mord">)</span></span></span></span></span></span></span><br> x是k维的，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ⊕ 
        
       
      
        \oplus 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6667em; vertical-align: -0.0833em;"></span><span class="mord">⊕</span></span></span></span></span>表示链接<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           E 
          
          
          
            1 
           
          
            : 
           
          
            T 
           
          
         
        
          ∈ 
         
         
         
           R 
          
          
          
            T 
           
          
            × 
           
          
            k 
           
          
         
        
       
         \mathcal E_{1:T}\in \mathbb R_{T\times k} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.0894em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0894em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8972em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span><br> 一个核<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         w 
        
       
         ∈ 
        
        
        
          R 
         
         
         
           l 
          
         
           × 
          
         
           k 
          
         
        
       
      
        w\in \mathbb R^{l\times k} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5782em; vertical-align: -0.0391em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span></span></span></span></span></span></span></span></span></span></p> 
<p>特征提取：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              c 
             
            
              i 
             
            
           
             = 
            
           
             ρ 
            
           
             ( 
            
           
             w 
            
           
             ⊗ 
            
            
            
              E 
             
             
             
               i 
              
             
               : 
              
             
               i 
              
             
               + 
              
             
               l 
              
             
               − 
              
             
               1 
              
             
            
           
             + 
            
           
             b 
            
           
             ) 
            
           
          
          
          
          
            (12) 
           
          
         
        
       
         c_i=\rho(w\otimes \mathcal E_{i:i+l-1}+b) \tag{12} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">ρ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8917em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.0894em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0894em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">12</span></span><span class="mord">)</span></span></span></span></span></span></span><br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ρ 
        
       
      
        \rho 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">ρ</span></span></span></span></span>为非线性函数，b即bias</p> 
<p>采用最大池化<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           c 
          
         
           ~ 
          
         
        
          = 
         
        
          max 
         
        
          ⁡ 
         
         
          
          
            c 
           
          
            1 
           
          
         
           , 
          
         
           … 
          
         
           , 
          
          
          
            c 
           
           
           
             T 
            
           
             − 
            
           
             l 
            
           
             + 
            
           
             1 
            
           
          
         
        
       
         \tilde c=\max{c_1,\dots,c_{T-l+1}} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6679em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">c</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6389em; vertical-align: -0.2083em;"></span><span class="mop">max</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span><br> 使用一个具有sigmoid激活的全连接层来输出输入序列是真实的概率。优化目标是最小化地面真实性标签与式（5）中所述预测概率之间的交叉熵</p> 
<h3><a id="4__219"></a>4. 文献解读</h3> 
<h4><a id="41_Introduction_221"></a>4.1 Introduction</h4> 
<p>生成模仿真实数据的序列合成数据是无监督学习中的一个重要问题。对于GAN而言，首先该模型旨在生成数值、连续数据，但在直接生成离散标记序列方面存在困难。这是由于GAN生成器从随机采样开始，然后进行模型参数控制的确定性变换。其次GAN只能用于在生成整个序列时给出其损失；对于部分生成的序列，平衡整个序列的损失和未来的情况并非易事。</p> 
<p>SeqGAN将序列生成问题看成序列决策过程，将目前已经生成的token看为状态（state），将下一个将要生成token看为动作（action），使用判别器来对整个序列做出评估指导生成器学习。为了解决梯度很难传递给生成器的问题，将生成器看为随机策略。在策略梯度中，使用MCT搜索来近似状态-动作对的值。</p> 
<h4><a id="42__227"></a>4.2 创新点</h4> 
<ol><li>解决了使用GAN生成序列的过程中所遇到的两个问题（见introduce），即在策略梯度中采样MCT搜索</li><li>提出了用于生成序列的新框架seqGAN</li></ol> 
<h4><a id="43__232"></a>4.3 实验过程</h4> 
<h5><a id="431__234"></a>4.3.1 训练设置</h5> 
<p>为了设置合成数据实验，我们首先初始化遵循正态分布 N(0, 1) 的 LSTM 网络参数，作为描述真实数据分布 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
         
         
           o 
          
         
           r 
          
         
           a 
          
         
           c 
          
         
           l 
          
         
           e 
          
         
        
       
         ( 
        
        
        
          x 
         
        
          t 
         
        
       
         ∣ 
        
        
        
          x 
         
        
          1 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          x 
         
         
         
           t 
          
         
           − 
          
         
           1 
          
         
        
       
         ) 
        
       
      
        G_{oracle}(x_t|x_1, ..., x_{t−1}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">or</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 的预测器。然后用它生成 10,000 个长度为 20 的序列作为生成模型的训练集 S。</p> 
<p>在SeqGAN算法中，判别器的训练集由生成的标签为0的实例和来自S的标签为1的实例组成。对于不同的任务，应该为卷积层设计特定的结构，在合成数据实验中，内核大小从 1 到 T，每个内核大小的数量在 100 到 2003 之间。使用 Dropout和 L2 正则化来避免过度拟合</p> 
<p>将四种生成模型与 SeqGAN 进行了比较。</p> 
<ol><li>随机token生成。</li><li>经过 MLE 训练的 LSTM<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           G 
          
         
           θ 
          
         
        
       
         G_\theta 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</li><li>计划抽样（Bengio et al. 2015）<sup>[2]</sup>。</li><li>BLEU 策略梯度（PG-BLEU）。在计划采样中，训练过程逐渐从完全引导的方案（将真实的先前标记输入 LSTM）转变为较少引导的方案（主要将其生成的标记输入 LSTM）。学习率 ω 用于控制用生成的token替换真实token的概率。为了获得良好且稳定的性能，我们在每个训练周期将 ω 减少 0.002。在 PG-BLEU 算法中，使用 BLEU（一种测量生成序列和参考（训练数据）之间相似性的指标）对蒙特卡罗搜索的最终样本进行评分。</li></ol> 
<h5><a id="432__247"></a>4.3.2 实验结果</h5> 
<p>下表中以<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         N 
        
       
         L 
        
        
        
          L 
         
         
         
           o 
          
         
           r 
          
         
           a 
          
         
           c 
          
         
           l 
          
         
           e 
          
         
        
       
      
        NLL_{oracle} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mord mathnormal">L</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">or</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为指标比较策略生成序列的性能，该文模型有显著改进</p> 
<p><img src="https://images2.imgbox.com/0e/63/0ljXrR8z_o.png" alt="image-20231208225958359"></p> 
<p>下图为SeqGAN学习曲线，最大似然估计和调度采样方法都收敛到相对较高的 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         N 
        
       
         L 
        
        
        
          L 
         
         
         
           o 
          
         
           r 
          
         
           a 
          
         
           c 
          
         
           l 
          
         
           e 
          
         
        
       
      
        NLL_{oracle} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mord mathnormal">L</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">or</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>分数，而 SeqGAN 可以显着提高与基线相同结构的生成器的极限。</p> 
<p><img src="https://images2.imgbox.com/d1/5a/zHCTLr4o_o.png" alt="image-20231208230121323"></p> 
<p>此外，SeqGAN 优于 PG-BLEU，这意味着 GAN 中的判别信号比预定义分数（例如 BLEU）更普遍、更有效，可以指导生成策略捕获序列数据的底层分布。</p> 
<p>下图显示了调整参数g-steps、d-steps、k对该算法的影响</p> 
<p><img src="https://images2.imgbox.com/73/ab/vwlgLeEb_o.png" alt="image-20231208230341120"></p> 
<h5><a id="433__263"></a>4.3.3 相关实验结果</h5> 
<p>使用 BLEU 分数作为评估指标来衡量生成文本与人工创建文本之间的相似程度</p> 
<p>具体来说，对于诗歌评估，将 n-gram 设置为 2 (BLEU-2)，因为中国古典诗歌中的大多数单词（依赖）由一个或两个字符组成 (Yi, Li, and Sun 2016)，出于类似的原因，使用 BLEU-3 和 BLEU-4 来评估奥巴马语音生成性能。</p> 
<p>除了 BLEU 之外，还选择诗歌生成作为人类判断的案例</p> 
<p>然后由70人来评判这60首诗中的每一首是人类还是机器创作的。一旦被认为是真实的，则获得+1分，否则为0分。最后，计算每个算法的平均分。</p> 
<p>本模型相较于MLE有明显提升</p> 
<p><img src="https://images2.imgbox.com/54/01/xcfBlPOW_o.png" alt="image-20231208230449517"></p> 
<h4><a id="44__277"></a>4.4 结论</h4> 
<p>该文提出了一种序列生成方法 SeqGAN，可以有效地训练生成对抗网络，通过策略梯度生成结构化序列。在合成数据实验中，使用了预测器评估机制来明确说明 SeqGAN 相对于基础模型的优越性。对于诗歌、语音和音乐生成这三个现实场景，SeqGAN 在生成创意序列方面表现出了出色的性能。此外，还进行了一组实验来研究训练 SeqGAN 的鲁棒性和稳定性。</p> 
<h2><a id="_281"></a>三、实验内容</h2> 
<h3><a id="1_PytorchCycleGAN_283"></a>1. Pytorch实现CycleGAN</h3> 
<h4><a id="11__285"></a>1.1 任务概况</h4> 
<p>任务要求：使用pytorch实现CycleGAN并使用facades数据集训练模型生成图像</p> 
<p>本次仅训练了10个epoch，以下第二张图为原图，第三张为实际转换后的结果，而第一张是网络生成的结果</p> 
<p><img src="https://images2.imgbox.com/79/e9/pJvKa9Rw_o.jpg" alt="g_A2B_epoch_4_1_A"></p> 
<p><img src="https://images2.imgbox.com/f6/ea/ebCrGS0u_o.jpg" alt="1_A"></p> 
<p><img src="https://images2.imgbox.com/df/bf/lA01wNn6_o.jpg" alt="1_B"></p> 
<h4><a id="12_297"></a>1.2实验代码</h4> 
<h5><a id="121_models_299"></a>1.2.1 models</h5> 
<p>主要就是设置一个初始化参数的函数，在开始训练时调用。<br> 构建了生成器和判别器网络。<br> 生成器中的残差块除了减弱梯度消失外，还可以理解为这是一种自适应深度，也就是网络可以自己调节层数的深浅，至少可以退化为输入，不会变得更糟糕。可以使网络变得更深，更加的平滑，使深度神经网络的训练成为了可能。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch

<span class="token comment">## 定义参数初始化函数</span>
<span class="token keyword">def</span> <span class="token function">weights_init_normal</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>                                    
    classname <span class="token operator">=</span> m<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__                        <span class="token comment">## m作为一个形参，原则上可以传递很多的内容, 为了实现多实参传递，每一个moudle要给出自己的name. 所以这句话就是返回m的名字. </span>
    <span class="token keyword">if</span> classname<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">"Conv"</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>                        <span class="token comment">## find():实现查找classname中是否含有Conv字符，没有返回-1；有返回0.</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>     <span class="token comment">## m.weight.data表示需要初始化的权重。nn.init.normal_():表示随机初始化采用正态分布，均值为0，标准差为0.02.</span>
        <span class="token keyword">if</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token string">"bias"</span><span class="token punctuation">)</span> <span class="token keyword">and</span> m<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>       <span class="token comment">## hasattr():用于判断m是否包含对应的属性bias, 以及bias属性是否不为空.</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span>       <span class="token comment">## nn.init.constant_():表示将偏差定义为常量0.</span>
    <span class="token keyword">elif</span> classname<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">"BatchNorm2d"</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>               <span class="token comment">## find():实现查找classname中是否含有BatchNorm2d字符，没有返回-1；有返回0.</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>     <span class="token comment">## m.weight.data表示需要初始化的权重. nn.init.normal_():表示随机初始化采用正态分布，均值为0，标准差为0.02.</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span>           <span class="token comment">## nn.init.constant_():表示将偏差定义为常量0.</span>


<span class="token comment">##############################</span>
<span class="token comment">##  残差块儿ResidualBlock</span>
<span class="token comment">##############################</span>
<span class="token keyword">class</span> <span class="token class-name">ResidualBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ResidualBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>block <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                     <span class="token comment">## block = [pad + conv + norm + relu + pad + conv + norm]</span>
            nn<span class="token punctuation">.</span>ReflectionPad2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                      <span class="token comment">## ReflectionPad2d():利用输入边界的反射来填充输入张量</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     <span class="token comment">## 卷积</span>
            nn<span class="token punctuation">.</span>InstanceNorm2d<span class="token punctuation">(</span>in_features<span class="token punctuation">)</span><span class="token punctuation">,</span>             <span class="token comment">## InstanceNorm2d():在图像像素上对HW做归一化，用在风格化迁移</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                      <span class="token comment">## 非线性激活</span>
            nn<span class="token punctuation">.</span>ReflectionPad2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                      <span class="token comment">## ReflectionPad2d():利用输入边界的反射来填充输入张量</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     <span class="token comment">## 卷积</span>
            nn<span class="token punctuation">.</span>InstanceNorm2d<span class="token punctuation">(</span>in_features<span class="token punctuation">)</span><span class="token punctuation">,</span>             <span class="token comment">## InstanceNorm2d():在图像像素上对HW做归一化，用在风格化迁移</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>                               <span class="token comment">## 输入为 一张图像</span>
        <span class="token keyword">return</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>block<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                        <span class="token comment">## 输出为 图像加上网络的残差输出</span>



<span class="token comment">##############################</span>
<span class="token comment">##  生成器网络GeneratorResNet</span>
<span class="token comment">##############################</span>
<span class="token keyword">class</span> <span class="token class-name">GeneratorResNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">,</span> num_residual_blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment">## (input_shape = (3, 256, 256), num_residual_blocks = 9)</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GeneratorResNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        channels <span class="token operator">=</span> input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                           <span class="token comment">## 输入通道数channels = 3</span>

        <span class="token comment">## 初始化网络结构</span>
        out_features <span class="token operator">=</span> <span class="token number">64</span>                                   <span class="token comment">## 输出特征数out_features = 64 </span>
        model <span class="token operator">=</span> <span class="token punctuation">[</span>                                           <span class="token comment">## model = [Pad + Conv + Norm + ReLU]</span>
            nn<span class="token punctuation">.</span>ReflectionPad2d<span class="token punctuation">(</span>channels<span class="token punctuation">)</span><span class="token punctuation">,</span>                   <span class="token comment">## ReflectionPad2d(3):利用输入边界的反射来填充输入张量</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>channels<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token comment">## Conv2d(3, 64, 7)</span>
            nn<span class="token punctuation">.</span>InstanceNorm2d<span class="token punctuation">(</span>out_features<span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token comment">## InstanceNorm2d(64):在图像像素上对HW做归一化，用在风格化迁移</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                          <span class="token comment">## 非线性激活</span>
        <span class="token punctuation">]</span>
        in_features <span class="token operator">=</span> out_features                          <span class="token comment">## in_features = 64</span>

        <span class="token comment">## 下采样，循环2次</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            out_features <span class="token operator">*=</span> <span class="token number">2</span>                                                   <span class="token comment">## out_features = 128 -&gt; 256</span>
            model <span class="token operator">+=</span> <span class="token punctuation">[</span>                                                          <span class="token comment">## (Conv + Norm + ReLU) * 2</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>InstanceNorm2d<span class="token punctuation">(</span>out_features<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">]</span>
            in_features <span class="token operator">=</span> out_features                                          <span class="token comment">## in_features = 256</span>

        <span class="token comment"># 残差块儿，循环9次</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_residual_blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>
            model <span class="token operator">+=</span> <span class="token punctuation">[</span>ResidualBlock<span class="token punctuation">(</span>out_features<span class="token punctuation">)</span><span class="token punctuation">]</span>                              <span class="token comment">## model += [pad + conv + norm + relu + pad + conv + norm]</span>

        <span class="token comment"># 上采样两次</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            out_features <span class="token operator">//=</span> <span class="token number">2</span>                                                  <span class="token comment">## out_features = 128 -&gt; 64</span>
            model <span class="token operator">+=</span> <span class="token punctuation">[</span>                                                          <span class="token comment">## model += [Upsample + conv + norm + relu]</span>
                nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>InstanceNorm2d<span class="token punctuation">(</span>out_features<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">]</span>
            in_features <span class="token operator">=</span> out_features                                          <span class="token comment">## out_features = 64</span>

        <span class="token comment">## 网络输出层                                                            ## model += [pad + conv + tanh]</span>
        model <span class="token operator">+=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>ReflectionPad2d<span class="token punctuation">(</span>channels<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_features<span class="token punctuation">,</span> channels<span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token comment">## 将(3)的数据每一个都映射到[-1, 1]之间</span>

        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>model<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>           <span class="token comment">## 输入(1, 3, 256, 256)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment">## 输出(1, 3, 256, 256)</span>



<span class="token comment">##############################</span>
<span class="token comment">#        Discriminator</span>
<span class="token comment">##############################</span>
<span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>                                        
        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        channels<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width <span class="token operator">=</span> input_shape                                       <span class="token comment">## input_shape:(3， 256， 256)</span>

        <span class="token comment"># Calculate output shape of image discriminator (PatchGAN)</span>
        self<span class="token punctuation">.</span>output_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> height <span class="token operator">//</span> <span class="token number">2</span> <span class="token operator">**</span> <span class="token number">4</span><span class="token punctuation">,</span> width <span class="token operator">//</span> <span class="token number">2</span> <span class="token operator">**</span> <span class="token number">4</span><span class="token punctuation">)</span>                  <span class="token comment">## output_shape = (1, 16, 16)</span>

        <span class="token keyword">def</span> <span class="token function">discriminator_block</span><span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>           <span class="token comment">## 鉴别器块儿</span>
            <span class="token triple-quoted-string string">"""Returns downsampling layers of each discriminator block"""</span>
            layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>   <span class="token comment">## layer += [conv + norm + relu]    </span>
            <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>                                                           <span class="token comment">## 每次卷积尺寸会缩小一半，共卷积了4次</span>
                layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>InstanceNorm2d<span class="token punctuation">(</span>out_filters<span class="token punctuation">)</span><span class="token punctuation">)</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> layers

        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                                                 
            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span>channels<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token comment">## layer += [conv(3, 64) + relu]</span>
            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                              <span class="token comment">## layer += [conv(64, 128) + norm + relu]</span>
            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                             <span class="token comment">## layer += [conv(128, 256) + norm + relu]</span>
            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                             <span class="token comment">## layer += [conv(256, 512) + norm + relu]</span>
            nn<span class="token punctuation">.</span>ZeroPad2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 <span class="token comment">## layer += [pad]</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>                             <span class="token comment">## layer += [conv(512, 1)]</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>             <span class="token comment">## 输入(1, 3, 256, 256)    </span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>          <span class="token comment">## 输出(1, 1, 16, 16)</span>



<span class="token comment"># ## test</span>
<span class="token comment"># img_shape = (3, 256, 256)</span>
<span class="token comment"># n_residual_blocks = 9</span>
<span class="token comment"># G_AB = GeneratorResNet(img_shape, n_residual_blocks)</span>
<span class="token comment"># D_A = Discriminator(img_shape)</span>
<span class="token comment"># img = torch.rand((1, 3, 256, 256))</span>
<span class="token comment"># fake = G_AB(img)</span>
<span class="token comment"># print(fake.shape)</span>

<span class="token comment"># fake_D = D_A(img)</span>
<span class="token comment"># print(fake_D.shape)</span>

</code></pre> 
<h5><a id="122_datasets_446"></a>1.2.2 datasets</h5> 
<p>其中的root代表着存放的文件夹，命名格式如：./datasets/facades<br> 调用train_data_loader()函数即可，得到的是字典格式的数据，可以通过data[‘A’]，和data[‘B’]操作将不同类型的图片取出来。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> glob
<span class="token keyword">import</span> random
<span class="token keyword">import</span> os
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms

<span class="token comment">## 如果输入的数据集是灰度图像，将图片转化为rgb图像(本次采用的facades不需要这个)</span>
<span class="token keyword">def</span> <span class="token function">to_rgb</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">:</span>
    rgb_image <span class="token operator">=</span> Image<span class="token punctuation">.</span>new<span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">,</span> image<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
    rgb_image<span class="token punctuation">.</span>paste<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
    <span class="token keyword">return</span> rgb_image


<span class="token comment">## 构建数据集</span>
<span class="token keyword">class</span> <span class="token class-name">ImageDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">,</span> transforms_<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> unaligned<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token comment">## (root = "./datasets/facades", unaligned=True:非对其数据)</span>
        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>transforms_<span class="token punctuation">)</span>                                <span class="token comment">## transform变为tensor数据</span>
        self<span class="token punctuation">.</span>unaligned <span class="token operator">=</span> unaligned

        self<span class="token punctuation">.</span>files_A <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span> <span class="token string">"%sA"</span> <span class="token operator">%</span> mode<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"/*.*"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment">## "./datasets/facades/trainA/*.*"</span>
        self<span class="token punctuation">.</span>files_B <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span> <span class="token string">"%sB"</span> <span class="token operator">%</span> mode<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"/*.*"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment">## "./datasets/facades/trainB/*.*"</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image_A <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>files_A<span class="token punctuation">[</span>index <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>files_A<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                   <span class="token comment">## 在A中取一张照片</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>unaligned<span class="token punctuation">:</span>                                                              <span class="token comment">## 如果采用非配对数据，在B中随机取一张</span>
            image_B <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>files_B<span class="token punctuation">[</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>files_B<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            image_B <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>files_B<span class="token punctuation">[</span>index <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>files_B<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token comment"># 如果是灰度图，把灰度图转换为RGB图</span>
        <span class="token keyword">if</span> image_A<span class="token punctuation">.</span>mode <span class="token operator">!=</span> <span class="token string">"RGB"</span><span class="token punctuation">:</span>
            image_A <span class="token operator">=</span> to_rgb<span class="token punctuation">(</span>image_A<span class="token punctuation">)</span>
        <span class="token keyword">if</span> image_B<span class="token punctuation">.</span>mode <span class="token operator">!=</span> <span class="token string">"RGB"</span><span class="token punctuation">:</span>
            image_B <span class="token operator">=</span> to_rgb<span class="token punctuation">(</span>image_B<span class="token punctuation">)</span>
        
        <span class="token comment"># 把RGB图像转换为tensor图, 方便计算，返回字典数据</span>
        item_A <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>image_A<span class="token punctuation">)</span>
        item_B <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>image_B<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span><span class="token string">"A"</span><span class="token punctuation">:</span> item_A<span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">:</span> item_B<span class="token punctuation">}</span>

    <span class="token comment">## 获取A,B数据的长度</span>
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>files_A<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>files_B<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<h5><a id="123_utils_500"></a>1.2.3 utils</h5> 
<p>这个模块设计了一个缓冲区，和学习率更新的函数<br> 在更新discriminators的时候，用的是之前生成的图片，而不是最新的图片，所以设立图片缓冲区，可以存放50张之前生成的图片。<br> 学习率初始为0.0003，总的epoch为50，在0-30的时候，学习率为0.0003，在30-50的时候，学习率逐渐线性减小为0，所以需要进行学习率的更新。<br> 需要的变量有：总的训练epoch，当前的epoch，和开始进行衰减的epoch，即可实现lr的线性变化。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> random
<span class="token keyword">import</span> time
<span class="token keyword">import</span> datetime
<span class="token keyword">import</span> sys
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>utils <span class="token keyword">import</span> save_image

<span class="token comment">## 先前生成的样本的缓冲区</span>
<span class="token keyword">class</span> <span class="token class-name">ReplayBuffer</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> max_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> max_size <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"Empty buffer or trying to create a black hole. Be careful."</span>
        self<span class="token punctuation">.</span>max_size <span class="token operator">=</span> max_size
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">push_and_pop</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>                       <span class="token comment">## 放入一张图像，再从buffer里取一张出来</span>
        to_return <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                                  <span class="token comment">## 确保数据的随机性，判断真假图片的鉴别器识别率</span>
        <span class="token keyword">for</span> element <span class="token keyword">in</span> data<span class="token punctuation">.</span>data<span class="token punctuation">:</span>
            element <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>element<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>max_size<span class="token punctuation">:</span>          <span class="token comment">## 最多放入50张，没满就一直添加</span>
                self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>element<span class="token punctuation">)</span>
                to_return<span class="token punctuation">.</span>append<span class="token punctuation">(</span>element<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0.5</span><span class="token punctuation">:</span>          <span class="token comment">## 满了就1/2的概率从buffer里取，或者就用当前的输入图片</span>
                    i <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>
                    to_return<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> element
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    to_return<span class="token punctuation">.</span>append<span class="token punctuation">(</span>element<span class="token punctuation">)</span>
        <span class="token keyword">return</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>to_return<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment">## 设置学习率为初始学习率乘以给定lr_lambda函数的值</span>
<span class="token keyword">class</span> <span class="token class-name">LambdaLR</span><span class="token punctuation">:</span>                                
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_epochs<span class="token punctuation">,</span> offset<span class="token punctuation">,</span> decay_start_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>                                                <span class="token comment">## (n_epochs = 50, offset = epoch, decay_start_epoch = 30)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>n_epochs <span class="token operator">-</span> decay_start_epoch<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"Decay must start before the training session ends!"</span>     <span class="token comment">## 断言，要让n_epochs &gt; decay_start_epoch 才可以</span>
        self<span class="token punctuation">.</span>n_epochs <span class="token operator">=</span> n_epochs
        self<span class="token punctuation">.</span>offset <span class="token operator">=</span> offset
        self<span class="token punctuation">.</span>decay_start_epoch <span class="token operator">=</span> decay_start_epoch

    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>                                              <span class="token comment">## return    1-max(0, epoch - 30) / (50 - 30)</span>
        <span class="token keyword">return</span> <span class="token number">1.0</span> <span class="token operator">-</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> epoch <span class="token operator">+</span> self<span class="token punctuation">.</span>offset <span class="token operator">-</span> self<span class="token punctuation">.</span>decay_start_epoch<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_epochs <span class="token operator">-</span> self<span class="token punctuation">.</span>decay_start_epoch<span class="token punctuation">)</span>

</code></pre> 
<h5><a id="124_train_554"></a>1.2.4 train</h5> 
<p>这个是训练的函数，开始训练。<br> 先配置下超参数，优化器，数据集，损失函数，然后开始训练<br> 训练过程中打印日志，每100次保存测试集测试结果图片<br> 训练完成后保存模型</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> argparse
<span class="token keyword">import</span> os
<span class="token keyword">from</span> tkinter <span class="token keyword">import</span> Image
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> math
<span class="token keyword">import</span> itertools
<span class="token keyword">import</span> datetime
<span class="token keyword">import</span> time
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>utils <span class="token keyword">import</span> save_image<span class="token punctuation">,</span> make_grid
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> models <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> dataset <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> utils <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image

<span class="token comment">## 超参数配置</span>
parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--epoch"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"epoch to start training from"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--n_epochs"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of epochs of training"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--dataset_name"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">"facades"</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"name of the dataset"</span><span class="token punctuation">)</span><span class="token comment">## ../input/facades-dataset</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--batch_size"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"size of the batches"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--lr"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.0003</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"adam: learning rate"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--b1"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"adam: decay of first order momentum of gradient"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--b2"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.999</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"adam: decay of first order momentum of gradient"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--decay_epoch"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"epoch from which to start lr decay"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--n_cpu"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of cpu threads to use during batch generation"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--img_height"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"size of image height"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--img_width"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"size of image width"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--channels"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of image channels"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--sample_interval"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"interval between saving generator outputs"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--checkpoint_interval"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"interval between saving model checkpoints"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--n_residual_blocks"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of residual blocks in generator"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--lambda_cyc"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"cycle loss weight"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--lambda_id"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"identity loss weight"</span><span class="token punctuation">)</span>
opt <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># opt = parser.parse_args(args=[])                 ## 在colab中运行时，换为此行</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>opt<span class="token punctuation">)</span>

<span class="token comment">## 创建文件夹</span>
os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">"images/%s"</span> <span class="token operator">%</span> opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">"save/%s"</span> <span class="token operator">%</span> opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">## input_shape:(3, 256, 256)</span>
input_shape <span class="token operator">=</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>img_height<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>img_width<span class="token punctuation">)</span>         

<span class="token comment">## 创建生成器，判别器对象</span>
G_AB <span class="token operator">=</span> GeneratorResNet<span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>n_residual_blocks<span class="token punctuation">)</span>
G_BA <span class="token operator">=</span> GeneratorResNet<span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>n_residual_blocks<span class="token punctuation">)</span>
D_A <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>
D_B <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

<span class="token comment">## 损失函数</span>
<span class="token comment">## MES 二分类的交叉熵</span>
<span class="token comment">## L1loss 相比于L2 Loss保边缘</span>
criterion_GAN <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
criterion_cycle <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>
criterion_identity <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">## 如果有显卡，都在cuda模式中运行</span>
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    G_AB <span class="token operator">=</span> G_AB<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    G_BA <span class="token operator">=</span> G_BA<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    D_A <span class="token operator">=</span> D_A<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    D_B <span class="token operator">=</span> D_B<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    criterion_GAN<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    criterion_cycle<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    criterion_identity<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">## 如果epoch == 0，初始化模型参数; 如果epoch == n, 载入训练到第n轮的预训练模型</span>
<span class="token keyword">if</span> opt<span class="token punctuation">.</span>epoch <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
    <span class="token comment"># 载入训练到第n轮的预训练模型</span>
    G_AB<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"saved/%s/G_AB_%d.pth"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    G_BA<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"saved/%s/G_BA_%d.pth"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    D_A<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"saved/%s/D_A_%d.pth"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    D_B<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"saved/%s/D_B_%d.pth"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token comment"># 初始化模型参数</span>
    G_AB<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init_normal<span class="token punctuation">)</span>
    G_BA<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init_normal<span class="token punctuation">)</span>
    D_A<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init_normal<span class="token punctuation">)</span>
    D_B<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init_normal<span class="token punctuation">)</span>


<span class="token comment">## 定义优化函数,优化函数的学习率为0.0003</span>
optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>
    itertools<span class="token punctuation">.</span>chain<span class="token punctuation">(</span>G_AB<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> G_BA<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
optimizer_D_A <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>D_A<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>
optimizer_D_B <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>D_B<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">## 学习率更行进程</span>
lr_scheduler_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>
    optimizer_G<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span>LambdaLR<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>decay_epoch<span class="token punctuation">)</span><span class="token punctuation">.</span>step
<span class="token punctuation">)</span>
lr_scheduler_D_A <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>
    optimizer_D_A<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span>LambdaLR<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>decay_epoch<span class="token punctuation">)</span><span class="token punctuation">.</span>step
<span class="token punctuation">)</span>
lr_scheduler_D_B <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>
    optimizer_D_B<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span>LambdaLR<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>decay_epoch<span class="token punctuation">)</span><span class="token punctuation">.</span>step
<span class="token punctuation">)</span>

<span class="token comment">## 先前生成的样本的缓冲区</span>
fake_A_buffer <span class="token operator">=</span> ReplayBuffer<span class="token punctuation">(</span><span class="token punctuation">)</span>
fake_B_buffer <span class="token operator">=</span> ReplayBuffer<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment">## 图像 transformations</span>
transforms_ <span class="token operator">=</span> <span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>img_height <span class="token operator">*</span> <span class="token number">1.12</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token comment">## 图片放大1.12倍</span>
    transforms<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>img_height<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>img_width<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         <span class="token comment">## 随机裁剪成原来的大小</span>
    transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                              <span class="token comment">## 随机水平翻转</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                          <span class="token comment">## 变为Tensor数据</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         <span class="token comment">## 正则化</span>
<span class="token punctuation">]</span>

<span class="token comment">## Training data loader </span>
dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>        <span class="token comment">## 改成自己存放文件的目录</span>
    ImageDataset<span class="token punctuation">(</span><span class="token string">"datasets/facades"</span><span class="token punctuation">,</span> transforms_<span class="token operator">=</span>transforms_<span class="token punctuation">,</span> unaligned<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment">## "./datasets/facades" , unaligned:设置非对其数据</span>
    batch_size<span class="token operator">=</span>opt<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>                                                                  <span class="token comment">## batch_size = 1</span>
    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    num_workers<span class="token operator">=</span>opt<span class="token punctuation">.</span>n_cpu<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token comment">## Test data loader</span>
val_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>
    ImageDataset<span class="token punctuation">(</span><span class="token string">"datasets/facades"</span><span class="token punctuation">,</span> transforms_<span class="token operator">=</span>transforms_<span class="token punctuation">,</span> unaligned<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">## "./datasets/facades"</span>
    batch_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    num_workers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>


<span class="token comment">## 每间隔100次打印图片</span>
<span class="token keyword">def</span> <span class="token function">sample_images</span><span class="token punctuation">(</span>batches_done<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token comment">## （100/200/300/400...）</span>
    <span class="token triple-quoted-string string">"""保存测试集中生成的样本"""</span>
    imgs <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>val_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment">## 取一张图像 </span>
    G_AB<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    G_BA<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    real_A <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">[</span><span class="token string">"A"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">## 取一张真A</span>
    fake_B <span class="token operator">=</span> G_AB<span class="token punctuation">(</span>real_A<span class="token punctuation">)</span>                  <span class="token comment">## 用真A生成假B</span>
    real_B <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">[</span><span class="token string">"B"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">## 去一张真B</span>
    fake_A <span class="token operator">=</span> G_BA<span class="token punctuation">(</span>real_B<span class="token punctuation">)</span>                  <span class="token comment">## 用真B生成假A</span>
    <span class="token comment"># Arange images along x-axis</span>
    <span class="token comment">## make_grid():用于把几个图像按照网格排列的方式绘制出来</span>
    real_A <span class="token operator">=</span> make_grid<span class="token punctuation">(</span>real_A<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    real_B <span class="token operator">=</span> make_grid<span class="token punctuation">(</span>real_B<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    fake_A <span class="token operator">=</span> make_grid<span class="token punctuation">(</span>fake_A<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    fake_B <span class="token operator">=</span> make_grid<span class="token punctuation">(</span>fake_B<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># Arange images along y-axis</span>
    <span class="token comment">## 把以上图像都拼接起来，保存为一张大图片</span>
    image_grid <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>real_A<span class="token punctuation">,</span> fake_B<span class="token punctuation">,</span> real_B<span class="token punctuation">,</span> fake_A<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    save_image<span class="token punctuation">(</span>image_grid<span class="token punctuation">,</span> <span class="token string">"images/%s/%s.png"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> batches_done<span class="token punctuation">)</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>



<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># ----------</span>
    <span class="token comment">#  Training</span>
    <span class="token comment"># ----------</span>
    prev_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>                             <span class="token comment">## 开始时间</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment">## for epoch in (0, 50)</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token comment">## batch is a dict, batch['A']:(1, 3, 256, 256), batch['B']:(1, 3, 256, 256)</span>
    <span class="token comment">#       print('here is %d' % i)</span>
            <span class="token comment">## 读取数据集中的真图片</span>
            <span class="token comment">## 将tensor变成Variable放入计算图中，tensor变成variable之后才能进行反向传播求梯度</span>
            real_A <span class="token operator">=</span> Variable<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">"A"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">## 真图像A</span>
            real_B <span class="token operator">=</span> Variable<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">"B"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">## 真图像B</span>

            <span class="token comment">## 全真，全假的标签</span>
            valid <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>real_A<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>D_A<span class="token punctuation">.</span>output_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment">## 定义真实的图片label为1 ones((1, 1, 16, 16))</span>
            fake <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>real_A<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>D_A<span class="token punctuation">.</span>output_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment">## 定义假的图片的label为0 zeros((1, 1, 16, 16))</span>
            
            
            <span class="token comment">## -----------------</span>
            <span class="token comment">##  Train Generator</span>
            <span class="token comment">## 原理：目的是希望生成的假的图片被判别器判断为真的图片，</span>
            <span class="token comment">## 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，</span>
            <span class="token comment">## 反向传播更新的参数是生成网络里面的参数，</span>
            <span class="token comment">## 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的, 这样就达到了对抗的目的</span>
            <span class="token comment">## -----------------</span>
            G_AB<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
            G_BA<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment">## Identity loss                                              ## A风格的图像 放在 B -&gt; A 生成器中，生成的图像也要是 A风格</span>
            loss_id_A <span class="token operator">=</span> criterion_identity<span class="token punctuation">(</span>G_BA<span class="token punctuation">(</span>real_A<span class="token punctuation">)</span><span class="token punctuation">,</span> real_A<span class="token punctuation">)</span>          <span class="token comment">## loss_id_A就是把图像A1放入 B2A 的生成器中，那当然生成图像A2的风格也得是A风格, 要让A1,A2的差距很小 </span>
            loss_id_B <span class="token operator">=</span> criterion_identity<span class="token punctuation">(</span>G_AB<span class="token punctuation">(</span>real_B<span class="token punctuation">)</span><span class="token punctuation">,</span> real_B<span class="token punctuation">)</span>

            loss_identity <span class="token operator">=</span> <span class="token punctuation">(</span>loss_id_A <span class="token operator">+</span> loss_id_B<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>                   <span class="token comment">## Identity loss </span>

            <span class="token comment">## GAN loss</span>
            fake_B <span class="token operator">=</span> G_AB<span class="token punctuation">(</span>real_A<span class="token punctuation">)</span>                                         <span class="token comment">## 用真图像A生成的假图像B</span>
            loss_GAN_AB <span class="token operator">=</span> criterion_GAN<span class="token punctuation">(</span>D_B<span class="token punctuation">(</span>fake_B<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>               <span class="token comment">## 用B鉴别器鉴别假图像B，训练生成器的目的就是要让鉴别器以为假的是真的，假的太接近真的让鉴别器分辨不出来</span>
            fake_A <span class="token operator">=</span> G_BA<span class="token punctuation">(</span>real_B<span class="token punctuation">)</span>                                         <span class="token comment">## 用真图像B生成的假图像A</span>
            loss_GAN_BA <span class="token operator">=</span> criterion_GAN<span class="token punctuation">(</span>D_A<span class="token punctuation">(</span>fake_A<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>               <span class="token comment">## 用A鉴别器鉴别假图像A，训练生成器的目的就是要让鉴别器以为假的是真的,假的太接近真的让鉴别器分辨不出来</span>

            loss_GAN <span class="token operator">=</span> <span class="token punctuation">(</span>loss_GAN_AB <span class="token operator">+</span> loss_GAN_BA<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>                    <span class="token comment">## GAN loss</span>

            <span class="token comment"># Cycle loss 循环一致性损失                                                 </span>
            recov_A <span class="token operator">=</span> G_BA<span class="token punctuation">(</span>fake_B<span class="token punctuation">)</span>                                        <span class="token comment">## 之前中realA 通过 A -&gt; B 生成的假图像B，再经过 B -&gt; A ，使得fakeB 得到的循环图像recovA， </span>
            loss_cycle_A <span class="token operator">=</span> criterion_cycle<span class="token punctuation">(</span>recov_A<span class="token punctuation">,</span> real_A<span class="token punctuation">)</span>               <span class="token comment">## realA和recovA的差距应该很小，以保证A,B间不仅风格有所变化，而且图片对应的的细节也可以保留</span>
            recov_B <span class="token operator">=</span> G_AB<span class="token punctuation">(</span>fake_A<span class="token punctuation">)</span>
            loss_cycle_B <span class="token operator">=</span> criterion_cycle<span class="token punctuation">(</span>recov_B<span class="token punctuation">,</span> real_B<span class="token punctuation">)</span>

            loss_cycle <span class="token operator">=</span> <span class="token punctuation">(</span>loss_cycle_A <span class="token operator">+</span> loss_cycle_B<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>

            <span class="token comment"># Total loss                                                  ## 就是上面所有的损失都加起来</span>
            loss_G <span class="token operator">=</span> loss_GAN <span class="token operator">+</span> opt<span class="token punctuation">.</span>lambda_cyc <span class="token operator">*</span> loss_cycle <span class="token operator">+</span> opt<span class="token punctuation">.</span>lambda_id <span class="token operator">*</span> loss_identity
            optimizer_G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>                                       <span class="token comment">## 在反向传播之前，先将梯度归0</span>
            loss_G<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>                                             <span class="token comment">## 将误差反向传播</span>
            optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                                            <span class="token comment">## 更新参数</span>
            
            
            <span class="token comment">## -----------------------</span>
            <span class="token comment">## Train Discriminator A</span>
            <span class="token comment">## 分为两部分：1、真的图像判别为真；2、假的图像判别为假</span>
            <span class="token comment">## -----------------------</span>
            <span class="token comment">## 真的图像判别为真</span>
            loss_real <span class="token operator">=</span> criterion_GAN<span class="token punctuation">(</span>D_A<span class="token punctuation">(</span>real_A<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>
            <span class="token comment">## 假的图像判别为假(从之前的buffer缓存中随机取一张)</span>
            fake_A_ <span class="token operator">=</span> fake_A_buffer<span class="token punctuation">.</span>push_and_pop<span class="token punctuation">(</span>fake_A<span class="token punctuation">)</span>
            loss_fake <span class="token operator">=</span> criterion_GAN<span class="token punctuation">(</span>D_A<span class="token punctuation">(</span>fake_A_<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fake<span class="token punctuation">)</span>
            <span class="token comment"># Total loss</span>
            loss_D_A <span class="token operator">=</span> <span class="token punctuation">(</span>loss_real <span class="token operator">+</span> loss_fake<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
            optimizer_D_A<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>                                     <span class="token comment">## 在反向传播之前，先将梯度归0</span>
            loss_D_A<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>                                           <span class="token comment">## 将误差反向传播</span>
            optimizer_D_A<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                                          <span class="token comment">## 更新参数</span>

            <span class="token comment">## -----------------------</span>
            <span class="token comment">## Train Discriminator B</span>
            <span class="token comment">## 分为两部分：1、真的图像判别为真；2、假的图像判别为假</span>
            <span class="token comment">## -----------------------</span>
            <span class="token comment"># 真的图像判别为真</span>
            loss_real <span class="token operator">=</span> criterion_GAN<span class="token punctuation">(</span>D_B<span class="token punctuation">(</span>real_B<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>                
            <span class="token comment">## 假的图像判别为假(从之前的buffer缓存中随机取一张)</span>
            fake_B_ <span class="token operator">=</span> fake_B_buffer<span class="token punctuation">.</span>push_and_pop<span class="token punctuation">(</span>fake_B<span class="token punctuation">)</span>
            loss_fake <span class="token operator">=</span> criterion_GAN<span class="token punctuation">(</span>D_B<span class="token punctuation">(</span>fake_B_<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fake<span class="token punctuation">)</span>
            <span class="token comment"># Total loss</span>
            loss_D_B <span class="token operator">=</span> <span class="token punctuation">(</span>loss_real <span class="token operator">+</span> loss_fake<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
            optimizer_D_B<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>                                     <span class="token comment">## 在反向传播之前，先将梯度归0</span>
            loss_D_B<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>                                           <span class="token comment">## 将误差反向传播</span>
            optimizer_D_B<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                                          <span class="token comment">## 更新参数</span>

            loss_D <span class="token operator">=</span> <span class="token punctuation">(</span>loss_D_A <span class="token operator">+</span> loss_D_B<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
            
            
            <span class="token comment">## ----------------------</span>
            <span class="token comment">##  打印日志Log Progress</span>
            <span class="token comment">## ----------------------</span>

            <span class="token comment">## 确定剩下的大约时间  假设当前 epoch = 5， i = 100</span>
            batches_done <span class="token operator">=</span> epoch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span> <span class="token operator">+</span> i                                        <span class="token comment">## 已经训练了多长时间 5 * 400 + 100 次</span>
            batches_left <span class="token operator">=</span> opt<span class="token punctuation">.</span>n_epochs <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span> <span class="token operator">-</span> batches_done                      <span class="token comment">## 还剩下 50 * 400 - 2100 次</span>
            time_left <span class="token operator">=</span> datetime<span class="token punctuation">.</span>timedelta<span class="token punctuation">(</span>seconds<span class="token operator">=</span>batches_left <span class="token operator">*</span> <span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> prev_time<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">## 还需要的时间 time_left = 剩下的次数 * 每次的时间</span>
            prev_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># Print log</span>
            sys<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>write<span class="token punctuation">(</span>
                <span class="token string">"\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s"</span>
                <span class="token operator">%</span> <span class="token punctuation">(</span>
                    epoch<span class="token punctuation">,</span>
                    opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">,</span>
                    i<span class="token punctuation">,</span>
                    <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    loss_D<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    loss_G<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    loss_GAN<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    loss_cycle<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    loss_identity<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    time_left<span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
            <span class="token punctuation">)</span>

            <span class="token comment"># 每训练100张就保存一组测试集中的图片</span>
            <span class="token keyword">if</span> batches_done <span class="token operator">%</span> opt<span class="token punctuation">.</span>sample_interval <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                sample_images<span class="token punctuation">(</span>batches_done<span class="token punctuation">)</span>

        <span class="token comment"># 更新学习率</span>
        lr_scheduler_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        lr_scheduler_D_A<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        lr_scheduler_D_B<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        
    <span class="token comment">## 训练结束后，保存模型</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>G_AB<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"save/%s/G_AB_%d.pth"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>G_BA<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"save/%s/G_BA_%d.pth"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>D_A<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"save/%s/D_A_%d.pth"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>D_B<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"save/%s/D_B_%d.pth"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"save my model finished !!"</span><span class="token punctuation">)</span>
    <span class="token comment">#    ## 每间隔几个epoch保存一次模型</span>
    <span class="token comment">#     if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:</span>
    <span class="token comment">#         # Save model checkpoints</span>
    <span class="token comment">#         torch.save(G_AB.state_dict(), "saved_models/%s/G_AB_%d.pth" % (opt.dataset_name, epoch))</span>
    <span class="token comment">#         torch.save(G_BA.state_dict(), "saved_models/%s/G_BA_%d.pth" % (opt.dataset_name, epoch))</span>
    <span class="token comment">#         torch.save(D_A.state_dict(), "saved_models/%s/D_A_%d.pth" % (opt.dataset_name, epoch))</span>
    <span class="token comment">#         torch.save(D_B.state_dict(), "saved_models/%s/D_B_%d.pth" % (opt.dataset_name, epoch))</span>



<span class="token comment">## 函数的起始</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    train<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<h5><a id="125_test_871"></a>1.2.5 test</h5> 
<p>测试过程，实际上就是用之前训练好的生成器模型参数，放入到一个新的生成器中，把图片放进去看对应生成图片的效果，测试不需要鉴别器。把生成后的图片放入到output/A，output/B文件夹中去</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> argparse
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> os
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>utils <span class="token keyword">import</span> save_image
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> models <span class="token keyword">import</span> GeneratorResNet
<span class="token keyword">from</span> dataset <span class="token keyword">import</span> ImageDataset

<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">## 超参数设置</span>
    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--batchSize'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'size of the batches'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--dataroot'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'D:/XCH/GAN_ZOO/datasets/facades'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'root directory of the dataset'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--channels'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of channels of input data'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--n_residual_blocks'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of channels of output data'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--size'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'size of the data (squared assumed)'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--cuda'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">bool</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'use GPU computation'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--n_cpu'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of cpu threads to use during batch generation'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--generator_A2B'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'D:/XCH/GAN_ZOO/save/facades/G_AB_4.pth'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'A2B generator checkpoint file'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--generator_B2A'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'D:/XCH/GAN_ZOO/save/facades/G_BA_4.pth'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'B2A generator checkpoint file'</span><span class="token punctuation">)</span>
    opt <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>opt<span class="token punctuation">)</span>

    <span class="token comment">#################################</span>
    <span class="token comment">##          test准备工作        ##</span>
    <span class="token comment">#################################</span>

    <span class="token comment">## input_shape:(3, 256, 256)</span>
    input_shape <span class="token operator">=</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>size<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>size<span class="token punctuation">)</span> 
    <span class="token comment">## 创建生成器，判别器对象</span>
    netG_A2B <span class="token operator">=</span> GeneratorResNet<span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>n_residual_blocks<span class="token punctuation">)</span>
    netG_B2A <span class="token operator">=</span> GeneratorResNet<span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>n_residual_blocks<span class="token punctuation">)</span>

    <span class="token comment">## 使用cuda</span>
    <span class="token keyword">if</span> opt<span class="token punctuation">.</span>cuda<span class="token punctuation">:</span>
        netG_A2B<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        netG_B2A<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">## 载入训练模型参数</span>
    netG_A2B<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>generator_A2B<span class="token punctuation">)</span><span class="token punctuation">)</span>
    netG_B2A<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>generator_B2A<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">## 设置为测试模式</span>
    netG_A2B<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    netG_B2A<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">## 创建一个tensor数组</span>
    Tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>FloatTensor <span class="token keyword">if</span> opt<span class="token punctuation">.</span>cuda <span class="token keyword">else</span> torch<span class="token punctuation">.</span>Tensor
    input_A <span class="token operator">=</span> Tensor<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>batchSize<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>size<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
    input_B <span class="token operator">=</span> Tensor<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>batchSize<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>size<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>size<span class="token punctuation">)</span>


    <span class="token triple-quoted-string string">'''构建测试数据集'''</span>
    transforms_ <span class="token operator">=</span> <span class="token punctuation">[</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">]</span>
    dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>ImageDataset<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>dataroot<span class="token punctuation">,</span> transforms_<span class="token operator">=</span>transforms_<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                            batch_size<span class="token operator">=</span>opt<span class="token punctuation">.</span>batchSize<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span>opt<span class="token punctuation">.</span>n_cpu<span class="token punctuation">)</span>



    <span class="token comment">#################################</span>
    <span class="token comment">##           test开始          ##</span>
    <span class="token comment">#################################</span>

    <span class="token triple-quoted-string string">'''如果文件路径不存在, 则创建一个 (存放测试输出的图片)'''</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string">'output/A'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'output/A'</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string">'output/B'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'output/B'</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">## 输入数据 real</span>
        real_A <span class="token operator">=</span> Variable<span class="token punctuation">(</span>input_A<span class="token punctuation">.</span>copy_<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        real_B <span class="token operator">=</span> Variable<span class="token punctuation">(</span>input_B<span class="token punctuation">.</span>copy_<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment">## 通过生成器生成的 fake</span>
        fake_B <span class="token operator">=</span> <span class="token number">0.5</span><span class="token operator">*</span><span class="token punctuation">(</span>netG_A2B<span class="token punctuation">(</span>real_A<span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token operator">+</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
        fake_A <span class="token operator">=</span> <span class="token number">0.5</span><span class="token operator">*</span><span class="token punctuation">(</span>netG_B2A<span class="token punctuation">(</span>real_B<span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token operator">+</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
        <span class="token comment">## 保存图片</span>
        save_image<span class="token punctuation">(</span>fake_A<span class="token punctuation">,</span> <span class="token string">'output/A/%04d.png'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        save_image<span class="token punctuation">(</span>fake_B<span class="token punctuation">,</span> <span class="token string">'output/B/%04d.png'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'processing (%04d)-th image...'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试完成"</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    test<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<h3><a id="2_SeqGAN_967"></a>2. SeqGAN</h3> 
<p>基于tensorflow</p> 
<h4><a id="21__971"></a>2.1 生成器</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_emb<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span>
                 sequence_length<span class="token punctuation">,</span> start_token<span class="token punctuation">,</span>
                 learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> reward_gamma<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>num_emb <span class="token operator">=</span> num_emb
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size
        self<span class="token punctuation">.</span>emb_dim <span class="token operator">=</span> emb_dim
        self<span class="token punctuation">.</span>hidden_dim <span class="token operator">=</span> hidden_dim
        self<span class="token punctuation">.</span>sequence_length <span class="token operator">=</span> sequence_length
        self<span class="token punctuation">.</span>start_token <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span>start_token<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">,</span> trainable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>reward_gamma <span class="token operator">=</span> reward_gamma
        self<span class="token punctuation">.</span>g_params <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>d_params <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>temperature <span class="token operator">=</span> <span class="token number">1.0</span>
        self<span class="token punctuation">.</span>grad_clip <span class="token operator">=</span> <span class="token number">5.0</span>

        self<span class="token punctuation">.</span>expected_reward <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'generator'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>g_embeddings <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>num_emb<span class="token punctuation">,</span> self<span class="token punctuation">.</span>emb_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>g_params<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>g_recurrent_unit <span class="token operator">=</span> self<span class="token punctuation">.</span>create_recurrent_unit<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_params<span class="token punctuation">)</span>  <span class="token comment"># maps h_tm1 to h_t for generator</span>
            self<span class="token punctuation">.</span>g_output_unit <span class="token operator">=</span> self<span class="token punctuation">.</span>create_output_unit<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_params<span class="token punctuation">)</span>  <span class="token comment"># maps h_t to o_t (output token logits)</span>

        <span class="token comment"># placeholder definition</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># sequence of tokens generated by generator</span>
        self<span class="token punctuation">.</span>rewards <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># get from rollout policy and discriminator</span>

        <span class="token comment"># processed for batch</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"/cpu:0"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>processed_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">,</span> self<span class="token punctuation">.</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># seq_length x batch_size x emb_dim</span>

        <span class="token comment"># Initial states</span>
        self<span class="token punctuation">.</span>h0 <span class="token operator">=</span> tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>h0 <span class="token operator">=</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>h0<span class="token punctuation">,</span> self<span class="token punctuation">.</span>h0<span class="token punctuation">]</span><span class="token punctuation">)</span>

        gen_o <span class="token operator">=</span> tensor_array_ops<span class="token punctuation">.</span>TensorArray<span class="token punctuation">(</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
                                             dynamic_size<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> infer_shape<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        gen_x <span class="token operator">=</span> tensor_array_ops<span class="token punctuation">.</span>TensorArray<span class="token punctuation">(</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
                                             dynamic_size<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> infer_shape<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">_g_recurrence</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> x_t<span class="token punctuation">,</span> h_tm1<span class="token punctuation">,</span> gen_o<span class="token punctuation">,</span> gen_x<span class="token punctuation">)</span><span class="token punctuation">:</span>
            h_t <span class="token operator">=</span> self<span class="token punctuation">.</span>g_recurrent_unit<span class="token punctuation">(</span>x_t<span class="token punctuation">,</span> h_tm1<span class="token punctuation">)</span>  <span class="token comment"># hidden_memory_tuple</span>
            o_t <span class="token operator">=</span> self<span class="token punctuation">.</span>g_output_unit<span class="token punctuation">(</span>h_t<span class="token punctuation">)</span>  <span class="token comment"># batch x vocab , logits not prob</span>
            log_prob <span class="token operator">=</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>o_t<span class="token punctuation">)</span><span class="token punctuation">)</span>
            next_token <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>log_prob<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
            x_tp1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">,</span> next_token<span class="token punctuation">)</span>  <span class="token comment"># batch x emb_dim</span>
            gen_o <span class="token operator">=</span> gen_o<span class="token punctuation">.</span>write<span class="token punctuation">(</span>i<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>next_token<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                             tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>o_t<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># [batch_size] , prob</span>
            gen_x <span class="token operator">=</span> gen_x<span class="token punctuation">.</span>write<span class="token punctuation">(</span>i<span class="token punctuation">,</span> next_token<span class="token punctuation">)</span>  <span class="token comment"># indices, batch_size</span>
            <span class="token keyword">return</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> x_tp1<span class="token punctuation">,</span> h_t<span class="token punctuation">,</span> gen_o<span class="token punctuation">,</span> gen_x

        _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> self<span class="token punctuation">.</span>gen_o<span class="token punctuation">,</span> self<span class="token punctuation">.</span>gen_x <span class="token operator">=</span> control_flow_ops<span class="token punctuation">.</span>while_loop<span class="token punctuation">(</span>
            cond<span class="token operator">=</span><span class="token keyword">lambda</span> i<span class="token punctuation">,</span> _1<span class="token punctuation">,</span> _2<span class="token punctuation">,</span> _3<span class="token punctuation">,</span> _4<span class="token punctuation">:</span> i <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
            body<span class="token operator">=</span>_g_recurrence<span class="token punctuation">,</span>
            loop_vars<span class="token operator">=</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">,</span>
                       tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">,</span> self<span class="token punctuation">.</span>start_token<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>h0<span class="token punctuation">,</span> gen_o<span class="token punctuation">,</span> gen_x<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>gen_x <span class="token operator">=</span> self<span class="token punctuation">.</span>gen_x<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># seq_length x batch_size</span>
        self<span class="token punctuation">.</span>gen_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gen_x<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># batch_size x seq_length</span>

        <span class="token comment"># supervised pretraining for generator</span>
        g_predictions <span class="token operator">=</span> tensor_array_ops<span class="token punctuation">.</span>TensorArray<span class="token punctuation">(</span>
            dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
            dynamic_size<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> infer_shape<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        ta_emb_x <span class="token operator">=</span> tensor_array_ops<span class="token punctuation">.</span>TensorArray<span class="token punctuation">(</span>
            dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">)</span>
        ta_emb_x <span class="token operator">=</span> ta_emb_x<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_x<span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">_pretrain_recurrence</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> x_t<span class="token punctuation">,</span> h_tm1<span class="token punctuation">,</span> g_predictions<span class="token punctuation">)</span><span class="token punctuation">:</span>
            h_t <span class="token operator">=</span> self<span class="token punctuation">.</span>g_recurrent_unit<span class="token punctuation">(</span>x_t<span class="token punctuation">,</span> h_tm1<span class="token punctuation">)</span>
            o_t <span class="token operator">=</span> self<span class="token punctuation">.</span>g_output_unit<span class="token punctuation">(</span>h_t<span class="token punctuation">)</span>
            g_predictions <span class="token operator">=</span> g_predictions<span class="token punctuation">.</span>write<span class="token punctuation">(</span>i<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>o_t<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># batch x vocab_size</span>
            x_tp1 <span class="token operator">=</span> ta_emb_x<span class="token punctuation">.</span>read<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
            <span class="token keyword">return</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> x_tp1<span class="token punctuation">,</span> h_t<span class="token punctuation">,</span> g_predictions

        _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> self<span class="token punctuation">.</span>g_predictions <span class="token operator">=</span> control_flow_ops<span class="token punctuation">.</span>while_loop<span class="token punctuation">(</span>
            cond<span class="token operator">=</span><span class="token keyword">lambda</span> i<span class="token punctuation">,</span> _1<span class="token punctuation">,</span> _2<span class="token punctuation">,</span> _3<span class="token punctuation">:</span> i <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
            body<span class="token operator">=</span>_pretrain_recurrence<span class="token punctuation">,</span>
            loop_vars<span class="token operator">=</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">,</span>
                       tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">,</span> self<span class="token punctuation">.</span>start_token<span class="token punctuation">)</span><span class="token punctuation">,</span>
                       self<span class="token punctuation">.</span>h0<span class="token punctuation">,</span> g_predictions<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>g_predictions <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_predictions<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># batch_size x seq_length x vocab_size</span>

        <span class="token comment"># pretraining loss</span>
        self<span class="token punctuation">.</span>pretrain_loss <span class="token operator">=</span> <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>
            tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>to_int32<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>clip_by_value<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_predictions<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1e-20</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
        <span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>sequence_length <span class="token operator">*</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>

        <span class="token comment"># training updates</span>
        pretrain_opt <span class="token operator">=</span> self<span class="token punctuation">.</span>g_optimizer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>pretrain_grad<span class="token punctuation">,</span> _ <span class="token operator">=</span> tf<span class="token punctuation">.</span>clip_by_global_norm<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>gradients<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pretrain_loss<span class="token punctuation">,</span> self<span class="token punctuation">.</span>g_params<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>grad_clip<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pretrain_updates <span class="token operator">=</span> pretrain_opt<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>pretrain_grad<span class="token punctuation">,</span> self<span class="token punctuation">.</span>g_params<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment">#######################################################################################################</span>
        <span class="token comment">#  Unsupervised Training</span>
        <span class="token comment">#######################################################################################################</span>
        self<span class="token punctuation">.</span>g_loss <span class="token operator">=</span> <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>
            tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>to_int32<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>clip_by_value<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_predictions<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1e-20</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>rewards<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        g_opt <span class="token operator">=</span> self<span class="token punctuation">.</span>g_optimizer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>g_grad<span class="token punctuation">,</span> _ <span class="token operator">=</span> tf<span class="token punctuation">.</span>clip_by_global_norm<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>gradients<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_loss<span class="token punctuation">,</span> self<span class="token punctuation">.</span>g_params<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>grad_clip<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>g_updates <span class="token operator">=</span> g_opt<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_grad<span class="token punctuation">,</span> self<span class="token punctuation">.</span>g_params<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sess<span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gen_x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs

    <span class="token keyword">def</span> <span class="token function">pretrain_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sess<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>pretrain_updates<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pretrain_loss<span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>x<span class="token punctuation">:</span> x<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs

    <span class="token keyword">def</span> <span class="token function">init_matrix</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span>shape<span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">init_vector</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">create_recurrent_unit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Weights and Bias for input and hidden tensor</span>
        self<span class="token punctuation">.</span>Wi <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>emb_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>Ui <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bi <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>Wf <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>emb_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>Uf <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bf <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>Wog <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>emb_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>Uog <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bog <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>Wc <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>emb_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>Uc <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bc <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        params<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>
            self<span class="token punctuation">.</span>Wi<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Ui<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bi<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>Wf<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uf<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bf<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>Wog<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uog<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bog<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>Wc<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uc<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bc<span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">unit</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> hidden_memory_tm1<span class="token punctuation">)</span><span class="token punctuation">:</span>
            previous_hidden_state<span class="token punctuation">,</span> c_prev <span class="token operator">=</span> tf<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>hidden_memory_tm1<span class="token punctuation">)</span>

            <span class="token comment"># Input Gate</span>
            i <span class="token operator">=</span> tf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wi<span class="token punctuation">)</span> <span class="token operator">+</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>previous_hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Ui<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bi
            <span class="token punctuation">)</span>

            <span class="token comment"># Forget Gate</span>
            f <span class="token operator">=</span> tf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wf<span class="token punctuation">)</span> <span class="token operator">+</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>previous_hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uf<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bf
            <span class="token punctuation">)</span>

            <span class="token comment"># Output Gate</span>
            o <span class="token operator">=</span> tf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wog<span class="token punctuation">)</span> <span class="token operator">+</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>previous_hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uog<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bog
            <span class="token punctuation">)</span>

            <span class="token comment"># New Memory Cell</span>
            c_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wc<span class="token punctuation">)</span> <span class="token operator">+</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>previous_hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uc<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bc
            <span class="token punctuation">)</span>

            <span class="token comment"># Final Memory cell</span>
            c <span class="token operator">=</span> f <span class="token operator">*</span> c_prev <span class="token operator">+</span> i <span class="token operator">*</span> c_

            <span class="token comment"># Current Hidden state</span>
            current_hidden_state <span class="token operator">=</span> o <span class="token operator">*</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>c<span class="token punctuation">)</span>

            <span class="token keyword">return</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>current_hidden_state<span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> unit

    <span class="token keyword">def</span> <span class="token function">create_output_unit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>Wo <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bo <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>init_matrix<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>num_emb<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        params<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>Wo<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bo<span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">unit</span><span class="token punctuation">(</span>hidden_memory_tuple<span class="token punctuation">)</span><span class="token punctuation">:</span>
            hidden_state<span class="token punctuation">,</span> c_prev <span class="token operator">=</span> tf<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>hidden_memory_tuple<span class="token punctuation">)</span>
            <span class="token comment"># hidden_state : batch x hidden_dim</span>
            logits <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wo<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bo
            <span class="token comment"># output = tf.nn.softmax(logits)</span>
            <span class="token keyword">return</span> logits

        <span class="token keyword">return</span> unit

    <span class="token keyword">def</span> <span class="token function">g_optimizer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="22__1181"></a>2.2 分辨器</h4> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">linear</span><span class="token punctuation">(</span>input_<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> scope<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Linear map: output[k] = sum_i(Matrix[k, i] * input_[i] ) + Bias[k]
    Args:
    input_: a tensor or a list of 2D, batch x n, Tensors.
    output_size: int, second dimension of W[i].
    scope: VariableScope for the created subgraph; defaults to "Linear".
  Returns:
    A 2D Tensor with shape [batch x output_size] equal to
    sum_i(input_[i] * W[i]), where W[i]s are newly created matrices.
  Raises:
    ValueError: if some of the arguments has unspecified or wrong shape.
  '''</span>

    shape <span class="token operator">=</span> input_<span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>as_list<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Linear is expecting 2D arguments: %s"</span> <span class="token operator">%</span> <span class="token builtin">str</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Linear expects shape[1] of arguments: %s"</span> <span class="token operator">%</span> <span class="token builtin">str</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    input_size <span class="token operator">=</span> shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

    <span class="token comment"># Now the computation.</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span>scope <span class="token keyword">or</span> <span class="token string">"SimpleLinear"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        matrix <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">"Matrix"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>output_size<span class="token punctuation">,</span> input_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>input_<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        bias_term <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">"Bias"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>output_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>input_<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>

    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>matrix<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> bias_term

<span class="token keyword">def</span> <span class="token function">highway</span><span class="token punctuation">(</span>input_<span class="token punctuation">,</span> size<span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token operator">-</span><span class="token number">2.0</span><span class="token punctuation">,</span> f<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">,</span> scope<span class="token operator">=</span><span class="token string">'Highway'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Highway Network (cf. http://arxiv.org/abs/1505.00387).
    t = sigmoid(Wy + b)
    z = t * g(Wy + b) + (1 - t) * y
    where g is nonlinearity, t is transform gate, and (1 - t) is carry gate.
    """</span>

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span>scope<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            g <span class="token operator">=</span> f<span class="token punctuation">(</span>linear<span class="token punctuation">(</span>input_<span class="token punctuation">,</span> size<span class="token punctuation">,</span> scope<span class="token operator">=</span><span class="token string">'highway_lin_%d'</span> <span class="token operator">%</span> idx<span class="token punctuation">)</span><span class="token punctuation">)</span>

            t <span class="token operator">=</span> tf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>linear<span class="token punctuation">(</span>input_<span class="token punctuation">,</span> size<span class="token punctuation">,</span> scope<span class="token operator">=</span><span class="token string">'highway_gate_%d'</span> <span class="token operator">%</span> idx<span class="token punctuation">)</span> <span class="token operator">+</span> bias<span class="token punctuation">)</span>

            output <span class="token operator">=</span> t <span class="token operator">*</span> g <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1.</span> <span class="token operator">-</span> t<span class="token punctuation">)</span> <span class="token operator">*</span> input_
            input_ <span class="token operator">=</span> output

    <span class="token keyword">return</span> output

<span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A CNN for text classification.
    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
            self<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span>
            embedding_size<span class="token punctuation">,</span> filter_sizes<span class="token punctuation">,</span> num_filters<span class="token punctuation">,</span> l2_reg_lambda<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Placeholders for input, output and dropout</span>
        self<span class="token punctuation">.</span>input_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> sequence_length<span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"input_x"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"input_y"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout_keep_prob <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"dropout_keep_prob"</span><span class="token punctuation">)</span>

        <span class="token comment"># Keeping track of l2 regularization loss (optional)</span>
        l2_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span>
        
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'discriminator'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

            <span class="token comment"># Embedding layer</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'/cpu:0'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"embedding"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>W <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>random_uniform<span class="token punctuation">(</span><span class="token punctuation">[</span>vocab_size<span class="token punctuation">,</span> embedding_size<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    name<span class="token operator">=</span><span class="token string">"W"</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>embedded_chars <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>input_x<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>embedded_chars_expanded <span class="token operator">=</span> tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedded_chars<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

            <span class="token comment"># Create a convolution + maxpool layer for each filter size</span>
            pooled_outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> filter_size<span class="token punctuation">,</span> num_filter <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>filter_sizes<span class="token punctuation">,</span> num_filters<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"conv-maxpool-%s"</span> <span class="token operator">%</span> filter_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token comment"># Convolution Layer</span>
                    filter_shape <span class="token operator">=</span> <span class="token punctuation">[</span>filter_size<span class="token punctuation">,</span> embedding_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> num_filter<span class="token punctuation">]</span>
                    W <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span>filter_shape<span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"W"</span><span class="token punctuation">)</span>
                    b <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>num_filter<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"b"</span><span class="token punctuation">)</span>
                    conv <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>
                        self<span class="token punctuation">.</span>embedded_chars_expanded<span class="token punctuation">,</span>
                        W<span class="token punctuation">,</span>
                        strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        padding<span class="token operator">=</span><span class="token string">"VALID"</span><span class="token punctuation">,</span>
                        name<span class="token operator">=</span><span class="token string">"conv"</span><span class="token punctuation">)</span>
                    <span class="token comment"># Apply nonlinearity</span>
                    h <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>conv<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span>
                    <span class="token comment"># Maxpooling over the outputs</span>
                    pooled <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>
                        h<span class="token punctuation">,</span>
                        ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> sequence_length <span class="token operator">-</span> filter_size <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        padding<span class="token operator">=</span><span class="token string">'VALID'</span><span class="token punctuation">,</span>
                        name<span class="token operator">=</span><span class="token string">"pool"</span><span class="token punctuation">)</span>
                    pooled_outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pooled<span class="token punctuation">)</span>
            
            <span class="token comment"># Combine all the pooled features</span>
            num_filters_total <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>num_filters<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>h_pool <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>pooled_outputs<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>h_pool_flat <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h_pool<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_filters_total<span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment"># Add highway</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"highway"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>h_highway <span class="token operator">=</span> highway<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h_pool_flat<span class="token punctuation">,</span> self<span class="token punctuation">.</span>h_pool_flat<span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

            <span class="token comment"># Add dropout</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"dropout"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>h_drop <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h_highway<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout_keep_prob<span class="token punctuation">)</span>

            <span class="token comment"># Final (unnormalized) scores and predictions</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                W <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>num_filters_total<span class="token punctuation">,</span> num_classes<span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"W"</span><span class="token punctuation">)</span>
                b <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>num_classes<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"b"</span><span class="token punctuation">)</span>
                l2_loss <span class="token operator">+=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_loss<span class="token punctuation">(</span>W<span class="token punctuation">)</span>
                l2_loss <span class="token operator">+=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_loss<span class="token punctuation">(</span>b<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>scores <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>xw_plus_b<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h_drop<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"scores"</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>ypred_for_auc <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>self<span class="token punctuation">.</span>scores<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>predictions <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>self<span class="token punctuation">.</span>scores<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"predictions"</span><span class="token punctuation">)</span>

            <span class="token comment"># CalculateMean cross-entropy loss</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"loss"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                losses <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax_cross_entropy_with_logits<span class="token punctuation">(</span>logits<span class="token operator">=</span>self<span class="token punctuation">.</span>scores<span class="token punctuation">,</span> labels<span class="token operator">=</span>self<span class="token punctuation">.</span>input_y<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>losses<span class="token punctuation">)</span> <span class="token operator">+</span> l2_reg_lambda <span class="token operator">*</span> l2_loss

        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">[</span>param <span class="token keyword">for</span> param <span class="token keyword">in</span> tf<span class="token punctuation">.</span>trainable_variables<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token string">'discriminator'</span> <span class="token keyword">in</span> param<span class="token punctuation">.</span>name<span class="token punctuation">]</span>
        d_optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span><span class="token number">1e-4</span><span class="token punctuation">)</span>
        grads_and_vars <span class="token operator">=</span> d_optimizer<span class="token punctuation">.</span>compute_gradients<span class="token punctuation">(</span>self<span class="token punctuation">.</span>loss<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">,</span> aggregation_method<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>train_op <span class="token operator">=</span> d_optimizer<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span>grads_and_vars<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="23_rollout_1316"></a>2.3 rollout</h4> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">linear</span><span class="token punctuation">(</span>input_<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> scope<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Linear map: output[k] = sum_i(Matrix[k, i] * input_[i] ) + Bias[k]
    Args:
    input_: a tensor or a list of 2D, batch x n, Tensors.
    output_size: int, second dimension of W[i].
    scope: VariableScope for the created subgraph; defaults to "Linear".
  Returns:
    A 2D Tensor with shape [batch x output_size] equal to
    sum_i(input_[i] * W[i]), where W[i]s are newly created matrices.
  Raises:
    ValueError: if some of the arguments has unspecified or wrong shape.
  '''</span>

    shape <span class="token operator">=</span> input_<span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>as_list<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Linear is expecting 2D arguments: %s"</span> <span class="token operator">%</span> <span class="token builtin">str</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Linear expects shape[1] of arguments: %s"</span> <span class="token operator">%</span> <span class="token builtin">str</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    input_size <span class="token operator">=</span> shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

    <span class="token comment"># Now the computation.</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span>scope <span class="token keyword">or</span> <span class="token string">"SimpleLinear"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        matrix <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">"Matrix"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>output_size<span class="token punctuation">,</span> input_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>input_<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        bias_term <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">"Bias"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>output_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>input_<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>

    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>matrix<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> bias_term

<span class="token keyword">def</span> <span class="token function">highway</span><span class="token punctuation">(</span>input_<span class="token punctuation">,</span> size<span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token operator">-</span><span class="token number">2.0</span><span class="token punctuation">,</span> f<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">,</span> scope<span class="token operator">=</span><span class="token string">'Highway'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Highway Network (cf. http://arxiv.org/abs/1505.00387).
    t = sigmoid(Wy + b)
    z = t * g(Wy + b) + (1 - t) * y
    where g is nonlinearity, t is transform gate, and (1 - t) is carry gate.
    """</span>

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span>scope<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            g <span class="token operator">=</span> f<span class="token punctuation">(</span>linear<span class="token punctuation">(</span>input_<span class="token punctuation">,</span> size<span class="token punctuation">,</span> scope<span class="token operator">=</span><span class="token string">'highway_lin_%d'</span> <span class="token operator">%</span> idx<span class="token punctuation">)</span><span class="token punctuation">)</span>

            t <span class="token operator">=</span> tf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>linear<span class="token punctuation">(</span>input_<span class="token punctuation">,</span> size<span class="token punctuation">,</span> scope<span class="token operator">=</span><span class="token string">'highway_gate_%d'</span> <span class="token operator">%</span> idx<span class="token punctuation">)</span> <span class="token operator">+</span> bias<span class="token punctuation">)</span>

            output <span class="token operator">=</span> t <span class="token operator">*</span> g <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1.</span> <span class="token operator">-</span> t<span class="token punctuation">)</span> <span class="token operator">*</span> input_
            input_ <span class="token operator">=</span> output

    <span class="token keyword">return</span> output

<span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A CNN for text classification.
    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
            self<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span>
            embedding_size<span class="token punctuation">,</span> filter_sizes<span class="token punctuation">,</span> num_filters<span class="token punctuation">,</span> l2_reg_lambda<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Placeholders for input, output and dropout</span>
        self<span class="token punctuation">.</span>input_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> sequence_length<span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"input_x"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"input_y"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout_keep_prob <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"dropout_keep_prob"</span><span class="token punctuation">)</span>

        <span class="token comment"># Keeping track of l2 regularization loss (optional)</span>
        l2_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span>
        
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'discriminator'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

            <span class="token comment"># Embedding layer</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'/cpu:0'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"embedding"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>W <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>random_uniform<span class="token punctuation">(</span><span class="token punctuation">[</span>vocab_size<span class="token punctuation">,</span> embedding_size<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    name<span class="token operator">=</span><span class="token string">"W"</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>embedded_chars <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>input_x<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>embedded_chars_expanded <span class="token operator">=</span> tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedded_chars<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

            <span class="token comment"># Create a convolution + maxpool layer for each filter size</span>
            pooled_outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> filter_size<span class="token punctuation">,</span> num_filter <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>filter_sizes<span class="token punctuation">,</span> num_filters<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"conv-maxpool-%s"</span> <span class="token operator">%</span> filter_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token comment"># Convolution Layer</span>
                    filter_shape <span class="token operator">=</span> <span class="token punctuation">[</span>filter_size<span class="token punctuation">,</span> embedding_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> num_filter<span class="token punctuation">]</span>
                    W <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span>filter_shape<span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"W"</span><span class="token punctuation">)</span>
                    b <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>num_filter<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"b"</span><span class="token punctuation">)</span>
                    conv <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>
                        self<span class="token punctuation">.</span>embedded_chars_expanded<span class="token punctuation">,</span>
                        W<span class="token punctuation">,</span>
                        strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        padding<span class="token operator">=</span><span class="token string">"VALID"</span><span class="token punctuation">,</span>
                        name<span class="token operator">=</span><span class="token string">"conv"</span><span class="token punctuation">)</span>
                    <span class="token comment"># Apply nonlinearity</span>
                    h <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>conv<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span>
                    <span class="token comment"># Maxpooling over the outputs</span>
                    pooled <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>
                        h<span class="token punctuation">,</span>
                        ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> sequence_length <span class="token operator">-</span> filter_size <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        padding<span class="token operator">=</span><span class="token string">'VALID'</span><span class="token punctuation">,</span>
                        name<span class="token operator">=</span><span class="token string">"pool"</span><span class="token punctuation">)</span>
                    pooled_outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pooled<span class="token punctuation">)</span>
            
            <span class="token comment"># Combine all the pooled features</span>
            num_filters_total <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>num_filters<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>h_pool <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>pooled_outputs<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>h_pool_flat <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h_pool<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_filters_total<span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment"># Add highway</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"highway"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>h_highway <span class="token operator">=</span> highway<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h_pool_flat<span class="token punctuation">,</span> self<span class="token punctuation">.</span>h_pool_flat<span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

            <span class="token comment"># Add dropout</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"dropout"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>h_drop <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h_highway<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout_keep_prob<span class="token punctuation">)</span>

            <span class="token comment"># Final (unnormalized) scores and predictions</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                W <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>num_filters_total<span class="token punctuation">,</span> num_classes<span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"W"</span><span class="token punctuation">)</span>
                b <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>num_classes<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"b"</span><span class="token punctuation">)</span>
                l2_loss <span class="token operator">+=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_loss<span class="token punctuation">(</span>W<span class="token punctuation">)</span>
                l2_loss <span class="token operator">+=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_loss<span class="token punctuation">(</span>b<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>scores <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>xw_plus_b<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h_drop<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"scores"</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>ypred_for_auc <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>self<span class="token punctuation">.</span>scores<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>predictions <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>self<span class="token punctuation">.</span>scores<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"predictions"</span><span class="token punctuation">)</span>

            <span class="token comment"># CalculateMean cross-entropy loss</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">"loss"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                losses <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax_cross_entropy_with_logits<span class="token punctuation">(</span>logits<span class="token operator">=</span>self<span class="token punctuation">.</span>scores<span class="token punctuation">,</span> labels<span class="token operator">=</span>self<span class="token punctuation">.</span>input_y<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>losses<span class="token punctuation">)</span> <span class="token operator">+</span> l2_reg_lambda <span class="token operator">*</span> l2_loss

        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">[</span>param <span class="token keyword">for</span> param <span class="token keyword">in</span> tf<span class="token punctuation">.</span>trainable_variables<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token string">'discriminator'</span> <span class="token keyword">in</span> param<span class="token punctuation">.</span>name<span class="token punctuation">]</span>
        d_optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span><span class="token number">1e-4</span><span class="token punctuation">)</span>
        grads_and_vars <span class="token operator">=</span> d_optimizer<span class="token punctuation">.</span>compute_gradients<span class="token punctuation">(</span>self<span class="token punctuation">.</span>loss<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">,</span> aggregation_method<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>train_op <span class="token operator">=</span> d_optimizer<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span>grads_and_vars<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="24_target_lstm_1451"></a>2.4 target_lstm</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">TARGET_LSTM</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_emb<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> start_token<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>num_emb <span class="token operator">=</span> num_emb
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size
        self<span class="token punctuation">.</span>emb_dim <span class="token operator">=</span> emb_dim
        self<span class="token punctuation">.</span>hidden_dim <span class="token operator">=</span> hidden_dim
        self<span class="token punctuation">.</span>sequence_length <span class="token operator">=</span> sequence_length
        self<span class="token punctuation">.</span>start_token <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span>start_token<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>g_params <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>temperature <span class="token operator">=</span> <span class="token number">1.0</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> params

        tf<span class="token punctuation">.</span>set_random_seed<span class="token punctuation">(</span><span class="token number">66</span><span class="token punctuation">)</span>

        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'generator'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>g_embeddings <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>g_params<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>g_recurrent_unit <span class="token operator">=</span> self<span class="token punctuation">.</span>create_recurrent_unit<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_params<span class="token punctuation">)</span>  <span class="token comment"># maps h_tm1 to h_t for generator</span>
            self<span class="token punctuation">.</span>g_output_unit <span class="token operator">=</span> self<span class="token punctuation">.</span>create_output_unit<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_params<span class="token punctuation">)</span>  <span class="token comment"># maps h_t to o_t (output token logits)</span>

        <span class="token comment"># placeholder definition</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># sequence of tokens generated by generator</span>

        <span class="token comment"># processed for batch</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"/cpu:0"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>processed_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">,</span> self<span class="token punctuation">.</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># seq_length x batch_size x emb_dim</span>

        <span class="token comment"># initial states</span>
        self<span class="token punctuation">.</span>h0 <span class="token operator">=</span> tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>h0 <span class="token operator">=</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>h0<span class="token punctuation">,</span> self<span class="token punctuation">.</span>h0<span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token comment"># generator on initial randomness</span>
        gen_o <span class="token operator">=</span> tensor_array_ops<span class="token punctuation">.</span>TensorArray<span class="token punctuation">(</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
                                             dynamic_size<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> infer_shape<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        gen_x <span class="token operator">=</span> tensor_array_ops<span class="token punctuation">.</span>TensorArray<span class="token punctuation">(</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
                                             dynamic_size<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> infer_shape<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">_g_recurrence</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> x_t<span class="token punctuation">,</span> h_tm1<span class="token punctuation">,</span> gen_o<span class="token punctuation">,</span> gen_x<span class="token punctuation">)</span><span class="token punctuation">:</span>
            h_t <span class="token operator">=</span> self<span class="token punctuation">.</span>g_recurrent_unit<span class="token punctuation">(</span>x_t<span class="token punctuation">,</span> h_tm1<span class="token punctuation">)</span>  <span class="token comment"># hidden_memory_tuple</span>
            o_t <span class="token operator">=</span> self<span class="token punctuation">.</span>g_output_unit<span class="token punctuation">(</span>h_t<span class="token punctuation">)</span>  <span class="token comment"># batch x vocab , logits not prob</span>
            log_prob <span class="token operator">=</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>o_t<span class="token punctuation">)</span><span class="token punctuation">)</span>
            next_token <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>log_prob<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
            x_tp1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">,</span> next_token<span class="token punctuation">)</span>  <span class="token comment"># batch x emb_dim</span>
            gen_o <span class="token operator">=</span> gen_o<span class="token punctuation">.</span>write<span class="token punctuation">(</span>i<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>next_token<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                             tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>o_t<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># [batch_size] , prob</span>
            gen_x <span class="token operator">=</span> gen_x<span class="token punctuation">.</span>write<span class="token punctuation">(</span>i<span class="token punctuation">,</span> next_token<span class="token punctuation">)</span>  <span class="token comment"># indices, batch_size</span>
            <span class="token keyword">return</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> x_tp1<span class="token punctuation">,</span> h_t<span class="token punctuation">,</span> gen_o<span class="token punctuation">,</span> gen_x

        _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> self<span class="token punctuation">.</span>gen_o<span class="token punctuation">,</span> self<span class="token punctuation">.</span>gen_x <span class="token operator">=</span> control_flow_ops<span class="token punctuation">.</span>while_loop<span class="token punctuation">(</span>
            cond<span class="token operator">=</span><span class="token keyword">lambda</span> i<span class="token punctuation">,</span> _1<span class="token punctuation">,</span> _2<span class="token punctuation">,</span> _3<span class="token punctuation">,</span> _4<span class="token punctuation">:</span> i <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
            body<span class="token operator">=</span>_g_recurrence<span class="token punctuation">,</span>
            loop_vars<span class="token operator">=</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">,</span>
                       tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">,</span> self<span class="token punctuation">.</span>start_token<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>h0<span class="token punctuation">,</span> gen_o<span class="token punctuation">,</span> gen_x<span class="token punctuation">)</span>
            <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>gen_x <span class="token operator">=</span> self<span class="token punctuation">.</span>gen_x<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># seq_length x batch_size</span>
        self<span class="token punctuation">.</span>gen_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gen_x<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># batch_size x seq_length</span>

        <span class="token comment"># supervised pretraining for generator</span>
        g_predictions <span class="token operator">=</span> tensor_array_ops<span class="token punctuation">.</span>TensorArray<span class="token punctuation">(</span>
            dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
            dynamic_size<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> infer_shape<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        ta_emb_x <span class="token operator">=</span> tensor_array_ops<span class="token punctuation">.</span>TensorArray<span class="token punctuation">(</span>
            dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">)</span>
        ta_emb_x <span class="token operator">=</span> ta_emb_x<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>self<span class="token punctuation">.</span>processed_x<span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">_pretrain_recurrence</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> x_t<span class="token punctuation">,</span> h_tm1<span class="token punctuation">,</span> g_predictions<span class="token punctuation">)</span><span class="token punctuation">:</span>
            h_t <span class="token operator">=</span> self<span class="token punctuation">.</span>g_recurrent_unit<span class="token punctuation">(</span>x_t<span class="token punctuation">,</span> h_tm1<span class="token punctuation">)</span>
            o_t <span class="token operator">=</span> self<span class="token punctuation">.</span>g_output_unit<span class="token punctuation">(</span>h_t<span class="token punctuation">)</span>
            g_predictions <span class="token operator">=</span> g_predictions<span class="token punctuation">.</span>write<span class="token punctuation">(</span>i<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>o_t<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># batch x vocab_size</span>
            x_tp1 <span class="token operator">=</span> ta_emb_x<span class="token punctuation">.</span>read<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
            <span class="token keyword">return</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> x_tp1<span class="token punctuation">,</span> h_t<span class="token punctuation">,</span> g_predictions

        _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> self<span class="token punctuation">.</span>g_predictions <span class="token operator">=</span> control_flow_ops<span class="token punctuation">.</span>while_loop<span class="token punctuation">(</span>
            cond<span class="token operator">=</span><span class="token keyword">lambda</span> i<span class="token punctuation">,</span> _1<span class="token punctuation">,</span> _2<span class="token punctuation">,</span> _3<span class="token punctuation">:</span> i <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
            body<span class="token operator">=</span>_pretrain_recurrence<span class="token punctuation">,</span>
            loop_vars<span class="token operator">=</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">,</span>
                       tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_embeddings<span class="token punctuation">,</span> self<span class="token punctuation">.</span>start_token<span class="token punctuation">)</span><span class="token punctuation">,</span>
                       self<span class="token punctuation">.</span>h0<span class="token punctuation">,</span> g_predictions<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>g_predictions <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>g_predictions<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># batch_size x seq_length x vocab_size</span>

        <span class="token comment"># pretraining loss</span>
        self<span class="token punctuation">.</span>pretrain_loss <span class="token operator">=</span> <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>
            tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>to_int32<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_predictions<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>sequence_length <span class="token operator">*</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>out_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>
            tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>
                <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>to_int32<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>
                        tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>g_predictions<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_emb<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">]</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span>
        <span class="token punctuation">)</span>  <span class="token comment"># batch_size</span>

    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> session<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># h0 = np.random.normal(size=self.hidden_dim)</span>
        outputs <span class="token operator">=</span> session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gen_x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs

    <span class="token keyword">def</span> <span class="token function">init_matrix</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span>shape<span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">create_recurrent_unit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Weights and Bias for input and hidden tensor</span>
        self<span class="token punctuation">.</span>Wi <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>Ui <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bi <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>Wf <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>Uf <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bf <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>Wog <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>Uog <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bog <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>Wc <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>Uc <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bc <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        params<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>
            self<span class="token punctuation">.</span>Wi<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Ui<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bi<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>Wf<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uf<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bf<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>Wog<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uog<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bog<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>Wc<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uc<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bc<span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">unit</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> hidden_memory_tm1<span class="token punctuation">)</span><span class="token punctuation">:</span>
            previous_hidden_state<span class="token punctuation">,</span> c_prev <span class="token operator">=</span> tf<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>hidden_memory_tm1<span class="token punctuation">)</span>

            <span class="token comment"># Input Gate</span>
            i <span class="token operator">=</span> tf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wi<span class="token punctuation">)</span> <span class="token operator">+</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>previous_hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Ui<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bi
            <span class="token punctuation">)</span>

            <span class="token comment"># Forget Gate</span>
            f <span class="token operator">=</span> tf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wf<span class="token punctuation">)</span> <span class="token operator">+</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>previous_hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uf<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bf
            <span class="token punctuation">)</span>

            <span class="token comment"># Output Gate</span>
            o <span class="token operator">=</span> tf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wog<span class="token punctuation">)</span> <span class="token operator">+</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>previous_hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uog<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bog
            <span class="token punctuation">)</span>

            <span class="token comment"># New Memory Cell</span>
            c_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wc<span class="token punctuation">)</span> <span class="token operator">+</span>
                tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>previous_hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Uc<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bc
            <span class="token punctuation">)</span>

            <span class="token comment"># Final Memory cell</span>
            c <span class="token operator">=</span> f <span class="token operator">*</span> c_prev <span class="token operator">+</span> i <span class="token operator">*</span> c_

            <span class="token comment"># Current Hidden state</span>
            current_hidden_state <span class="token operator">=</span> o <span class="token operator">*</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>c<span class="token punctuation">)</span>

            <span class="token keyword">return</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>current_hidden_state<span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> unit

    <span class="token keyword">def</span> <span class="token function">create_output_unit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>Wo <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bo <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        params<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>Wo<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bo<span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">unit</span><span class="token punctuation">(</span>hidden_memory_tuple<span class="token punctuation">)</span><span class="token punctuation">:</span>
            hidden_state<span class="token punctuation">,</span> c_prev <span class="token operator">=</span> tf<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>hidden_memory_tuple<span class="token punctuation">)</span>
            <span class="token comment"># hidden_state : batch x hidden_dim</span>
            logits <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Wo<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bo
            <span class="token comment"># output = tf.nn.softmax(logits)</span>
            <span class="token keyword">return</span> logits

        <span class="token keyword">return</span> unit
</code></pre> 
<h3><a id="_1639"></a>小结</h3> 
<p>本周主要完成了GAN网络理论的学习，首先推到了最大似然估计即最小KL散度，然后简要介绍了生成器与分辨器，并由生成器的训练目标推导了其与JS散度的相关性。此外，从图像角度，进一步直观的了解了最大化的目标与JS散度的相关性<br> 本周阅读的论文提出了一种用于序列化处理的GAN模型——SeqGAN，其将MCT用于GAN以将状态转移模型化从而实现了该模型。<br> 最后本周实现了上周提到的CyclGAN，但仅运行了较少的epoch，因此效果不佳。<br> 下周会学习GAN理论或者BERT</p> 
<h3><a id="_1644"></a>参考文献</h3> 
<p>[1] Yu, Lantao, et al. “Seqgan: Sequence Generative Adversarial Nets with Policy Gradient.” <em>arXiv.Org</em>, 25 Aug. 2017, arxiv.org/abs/1609.05473.</p> 
<p>[2] Bengio, S.; Vinyals, O.; Jaitly, N.; and Shazeer,N. 2015. Scheduled sampling for sequence prediction with recurrent neural networks. In NIPS, 1171–1179.</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e9a27f2aacd91f6bb2f0d3b03a4207f9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">图文—神经网络组成（卷积层、池化层、全链接层、激活函数）与发展史（LeNet、AlexNet、VGG、ResNet、GAN）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/557095551db5fca6878dfff6ca4e0622/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">connect: Network is unreachable问题解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>