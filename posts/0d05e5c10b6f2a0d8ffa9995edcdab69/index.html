<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习（四） -- 模型评估（3） - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习（四） -- 模型评估（3）" />
<meta property="og:description" content="系列文章目录 机器学习（一） -- 概述
机器学习（二） -- 数据预处理（1-3）
机器学习（三） -- 特征工程（1-2）
机器学习（四） -- 模型评估（1-4）
未完待续……
目录
机器学习（四） -- 模型评估（1）
机器学习（四） -- 模型评估（2）
---
系列文章目录
前言
四、 回归模型评估指标
1、均方误差（Mean Squared Error，MSE）
2、***均方根误差（Root Mean Squared Error，RMSE）
3、***均方对数误差（Mean Squared Log Error，MSLE）
4、平均绝对误差（Mean Absolute Error，MAE）
5、***平均绝对百分比误差（Mean Absolute Percentage Error，MAPE）
6、决定系数（R2，R-square）
7、***校正决定系数（Adjusted R-square）
前言 tips：这里只是总结，不是教程哈。
“***”开头的是给好奇心重的宝宝看的，其实不太重要可以跳过。
此处以下所有内容均为暂定，因为我还没找到一个好的，让小白（我自己）也能容易理解（更系统、嗯应该是宏观）的讲解顺序与方式。
第一文主要简述了一下机器学习大致有哪些东西（当然远远不止这些），对大体框架有了一定了解。接着我们根据机器学习的流程一步步来学习吧，掐掉其他不太用得上我们的步骤，精练起来就4步（数据预处理，特征工程，训练模型，模型评估），其中训练模型则是我们的重头戏，基本上所有算法也都是这一步，so，这个最后写，先把其他三个讲了，然后，在结合这三步来进行算法的学习，兴许会好点（个人拙见）。
衡量模型泛化能力的评价标准就是性能度量（模型评估指标、模型评价标准），而针对不同的任务有不同的评价指标。按照数据集的目标值不同，可以把模型评估分为分类模型评估、回归模型评估和聚类模型评估。
四、 回归模型评估指标 均方误差（MSE）、均方根误差（RMSE）、均方对数误差（MSLE）、
平均绝对误差（MAE）​​​​​​、平均绝对百分比误差（MAPE）、
决定系数（R2，R-square）、校正决定系数（Adjusted R-square）
1、均方误差（Mean Squared Error，MSE） 回归任务最常用的性能度量就是均方误差。是预测数据和原始数据对应点误差的平方和的均值。越小越好。
公式：
​
均方误差存在一个明显的缺陷，
假设，现在有三个样本，它们的预测值与真实值的差分别为 3、4、5，通过均方误差的计算公式，我们可以分别计算出这三个样本的误差为 9、16 和 25；第三个样本的误差等于前两个样本的误差和，也就是说样本的预测值离真实值越远，误差也越大，且增长幅度越来越大。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/0d05e5c10b6f2a0d8ffa9995edcdab69/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-06T22:41:01+08:00" />
<meta property="article:modified_time" content="2024-01-06T22:41:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习（四） -- 模型评估（3）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95">系列文章目录</h2> 
<p><a href="https://blog.csdn.net/zqx1473/article/details/135242730" title="机器学习（一） -- 概述">机器学习（一） -- 概述</a></p> 
<p><a href="https://blog.csdn.net/zqx1473/article/details/135280575" title="机器学习（二） -- 数据预处理（1-3）">机器学习（二） -- 数据预处理（1-3）</a></p> 
<p><a href="https://blog.csdn.net/zqx1473/article/details/135307321" title="机器学习（三） -- 特征工程（1-2）">机器学习（三） -- 特征工程（1-2）</a></p> 
<p><a href="https://blog.csdn.net/zqx1473/article/details/135347196" title="机器学习（四） -- 模型评估（1-4）">机器学习（四） -- 模型评估（1-4）</a></p> 
<p></p> 
<p>未完待续……</p> 
<hr> 
<p id="main-toc"><strong>目录</strong></p> 
<p><a href="https://blog.csdn.net/zqx1473/article/details/135347196" title="机器学习（四） -- 模型评估（1）">机器学习（四） -- 模型评估（1）</a></p> 
<p><a href="https://blog.csdn.net/zqx1473/article/details/135371241" title="机器学习（四） -- 模型评估（2）">机器学习（四） -- 模型评估（2）</a></p> 
<p><strong>---</strong></p> 
<p id="%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95-toc" style="margin-left:0px;"><a href="#%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95" rel="nofollow">系列文章目录</a></p> 
<p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E5%89%8D%E8%A8%80" rel="nofollow">前言</a></p> 
<p id="%E5%9B%9B%E3%80%81%C2%A0%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%C2%A0%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87" rel="nofollow">四、 回归模型评估指标</a></p> 
<p id="1%E3%80%81%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Squared%20Error%EF%BC%8CMSE%EF%BC%89-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Squared%20Error%EF%BC%8CMSE%EF%BC%89" rel="nofollow">1、均方误差（Mean Squared Error，MSE）</a></p> 
<p id="2%E3%80%81***%E5%9D%87%E6%96%B9%E6%A0%B9%E8%AF%AF%E5%B7%AE%EF%BC%88Root%C2%A0Mean%20Squared%20Error%EF%BC%8CRMSE%EF%BC%89-toc" style="margin-left:40px;"><a href="#2%E3%80%81***%E5%9D%87%E6%96%B9%E6%A0%B9%E8%AF%AF%E5%B7%AE%EF%BC%88Root%C2%A0Mean%20Squared%20Error%EF%BC%8CRMSE%EF%BC%89" rel="nofollow">2、***均方根误差（Root Mean Squared Error，RMSE）</a></p> 
<p id="3%E3%80%81***%E5%9D%87%E6%96%B9%E5%AF%B9%E6%95%B0%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Squared%20Log%20Error%EF%BC%8CMSLE%EF%BC%89-toc" style="margin-left:40px;"><a href="#3%E3%80%81***%E5%9D%87%E6%96%B9%E5%AF%B9%E6%95%B0%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Squared%20Log%20Error%EF%BC%8CMSLE%EF%BC%89" rel="nofollow">3、***均方对数误差（Mean Squared Log Error，MSLE）</a></p> 
<p id="4%E3%80%81%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Absolute%20Error%EF%BC%8CMAE%EF%BC%89-toc" style="margin-left:40px;"><a href="#4%E3%80%81%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Absolute%20Error%EF%BC%8CMAE%EF%BC%89" rel="nofollow">4、平均绝对误差（Mean Absolute Error，MAE）</a></p> 
<p id="5%E3%80%81***%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E7%99%BE%E5%88%86%E6%AF%94%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Absolute%20Percentage%20Error%EF%BC%8CMAPE%EF%BC%89-toc" style="margin-left:40px;"><a href="#5%E3%80%81***%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E7%99%BE%E5%88%86%E6%AF%94%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Absolute%20Percentage%20Error%EF%BC%8CMAPE%EF%BC%89" rel="nofollow">5、***平均绝对百分比误差（Mean Absolute Percentage Error，MAPE）</a></p> 
<p id="6%E3%80%81%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0%EF%BC%88R2%EF%BC%8CR-square%EF%BC%89-toc" style="margin-left:40px;"><a href="#6%E3%80%81%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0%EF%BC%88R2%EF%BC%8CR-square%EF%BC%89" rel="nofollow">6、决定系数（R2，R-square）</a></p> 
<p id="7%E3%80%81***%E6%A0%A1%E6%AD%A3%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0%EF%BC%88Adjusted%20R-square%EF%BC%89-toc" style="margin-left:40px;"><a href="#7%E3%80%81***%E6%A0%A1%E6%AD%A3%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0%EF%BC%88Adjusted%20R-square%EF%BC%89" rel="nofollow">7、***校正决定系数（Adjusted R-square）</a></p> 
<p></p> 
<hr> 
<h2 id="%E5%89%8D%E8%A8%80"><a id="_12"></a>前言</h2> 
<p><code>tips：这里只是<strong>总结</strong>，不是教程哈。</code></p> 
<p><code>“***”开头的是给好奇心重的宝宝看的，其实不太重要可以跳过。</code></p> 
<p><code>此处以下所有内容均为暂定，因为我还没找到一个好的，让小白（我自己）也能容易理解（更系统、嗯应该是宏观）的讲解顺序与方式。</code></p> 
<p><code>第一文主要简述了一下机器学习大致有哪些东西（当然远远不止这些），对大体框架有了一定了解。接着我们根据机器学习的流程一步步来学习吧，掐掉其他不太用得上我们的步骤，精练起来就4步（数据预处理，特征工程，训练模型，模型评估），其中训练模型则是我们的重头戏，基本上所有算法也都是这一步，so，这个最后写，先把其他三个讲了，然后，在结合这三步来进行算法的学习，兴许会好点（个人拙见）。</code></p> 
<hr> 
<p id="%E4%B8%80%E3%80%81%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E7%AE%80%E4%BB%8B">衡量模型泛化能力的评价标准就是<strong>性能度量（模型评估指标、模型评价标准）</strong>，而针对不同的任务有不同的评价指标。按照数据集的目标值不同，可以把模型评估分为分类模型评估、回归模型评估和聚类模型评估。</p> 
<h2 id="%E5%9B%9B%E3%80%81%C2%A0%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87">四、 回归模型评估指标</h2> 
<p>均方误差（MSE）、均方根误差（RMSE）、均方对数误差（MSLE）、<br> 平均绝对误差（MAE）​​​​​​、平均绝对百分比误差（MAPE）、<br> 决定系数（R2，R-square）、校正决定系数（Adjusted R-square）</p> 
<h3 id="1%E3%80%81%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Squared%20Error%EF%BC%8CMSE%EF%BC%89">1、均方误差（Mean Squared Error，MSE）</h3> 
<p>回归任务最常用的性能度量就是均方误差。是预测数据和原始数据对应点误差的平方和的均值。越小越好。</p> 
<p><strong>公式</strong>：</p> 
<p><img alt="" height="94" src="https://images2.imgbox.com/1b/94/nPFGajMW_o.png" width="338"><span title="点击并拖拽以改变尺寸">​</span></p> 
<p>均方误差存在一个明显的缺陷，<br> 假设，现在有三个样本，它们的预测值与真实值的差分别为 3、4、5，通过均方误差的计算公式，我们可以分别计算出这三个样本的误差为 9、16 和 25；第三个样本的误差等于前两个样本的误差和，也就是说<strong>样本的预测值离真实值越远，误差也越大，且增长幅度越来越大。</strong></p> 
<p>模型为了降低误差，势必会想办法优先让偏差最大的样本尽可能靠近真实值。换言之，<strong>偏差越大的样本对模型的影响也越大</strong>，如果这个样本是噪声，那么这对模型的精度产生重大负面影响。简单地说，均方误差对噪声不鲁棒。【<em>鲁棒性（robustness）是指系统或者算法在不同的情况下，仍能够保持稳定和可靠的能力。</em>】</p> 
<p>就像我们再【数据预处理（2）的2.1.3、3σ法则】中遇到的情况一样噪声数据影响过大。</p> 
<p><strong>API</strong>：</p> 
<div> 
 <pre><code class="language-python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error</code></pre> 
</div> 
<p>我们用波士顿房价数据集为例，模型选择决策树算法，来测试。</p> 
<div> 
 <pre><code class="language-python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_boston
<span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeRegressor
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split


<span class="hljs-comment"># 引入数据集</span>
boston = load_boston()

<span class="hljs-comment"># 划分数据集</span>
x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">134</span>)

<span class="hljs-comment">#模型训练</span>
model = DecisionTreeRegressor()
model.fit(x_train, y_train)</code></pre> 
</div> 
<p><img alt="" height="422" src="https://images2.imgbox.com/42/6d/tddKxTrc_o.png" width="1128"><span title="点击并拖拽以改变尺寸">​</span></p> 
<div> 
 <pre><code class="language-python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error

<span class="hljs-comment"># 均方误差</span>
mean_squared_error(y_test, model.predict(x_test))</code></pre> 
</div> 
<p> <img alt="" height="159" src="https://images2.imgbox.com/ba/e6/00Lvzft1_o.png" width="576"><span title="点击并拖拽以改变尺寸">​</span></p> 
<h3 id="2%E3%80%81***%E5%9D%87%E6%96%B9%E6%A0%B9%E8%AF%AF%E5%B7%AE%EF%BC%88Root%C2%A0Mean%20Squared%20Error%EF%BC%8CRMSE%EF%BC%89">2、***均方根误差（Root Mean Squared Error，RMSE）</h3> 
<p>均方误差开根号。</p> 
<p>和MSE一样，对异常点（outliers）较敏感，如果回归器对某个点的回归值很不理性，那么它的误差则较大，从而会对RMSE的值有较大影响，即平均值是<strong>非鲁棒</strong>的。</p> 
<p><strong>公式</strong>：</p> 
<p><img alt="" height="127" src="https://images2.imgbox.com/68/86/eBoquMfp_o.png" width="402"><span title="点击并拖拽以改变尺寸">​</span></p> 
<p><strong>代码</strong>：</p> 
<p>代码也很简单，上面那个开个平方就好了。 </p> 
<div> 
 <pre><code class="language-python hljs"><span class="hljs-comment"># 均方根误差</span>
np.sqrt(mean_squared_error(y_test, model.predict(x_test)))</code></pre> 
</div> 
<p><img alt="" height="101" src="https://images2.imgbox.com/f1/40/8RdoSmUo_o.png" width="630"><span title="点击并拖拽以改变尺寸">​</span></p> 
<h3 id="3%E3%80%81***%E5%9D%87%E6%96%B9%E5%AF%B9%E6%95%B0%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Squared%20Log%20Error%EF%BC%8CMSLE%EF%BC%89">3、***均方对数误差（Mean Squared Log Error，MSLE）</h3> 
<p><strong>公式</strong>：</p> 
<p><img alt="" height="111" src="https://images2.imgbox.com/b3/db/3kKalwke_o.png" width="596"><span title="点击并拖拽以改变尺寸">​</span></p> 
<p><strong>代码</strong>：</p> 
<div> 
 <pre><code class="language-python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_log_error

<span class="hljs-comment"># 均方对数误差</span>
mean_squared_log_error(y_test, model.predict(x_test))</code></pre> 
</div> 
<p><img alt="" height="149" src="https://images2.imgbox.com/be/8c/2he1Jt47_o.png" width="579"><span title="点击并拖拽以改变尺寸">​</span></p> 
<h3 id="4%E3%80%81%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Absolute%20Error%EF%BC%8CMAE%EF%BC%89">4、平均绝对误差（Mean Absolute Error，MAE）</h3> 
<p><strong>公式</strong>：</p> 
<p><img alt="" height="108" src="https://images2.imgbox.com/63/65/2hg7mqNT_o.png" width="328"><span title="点击并拖拽以改变尺寸">​</span></p> 
<p><strong>代码</strong>：</p> 
<div> 
 <pre><code class="language-python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_absolute_error

<span class="hljs-comment"># 平均绝对误差</span>
mean_absolute_error(y_test, model.predict(x_test))</code></pre> 
</div> 
<p><img alt="" height="133" src="https://images2.imgbox.com/74/3d/BuQ1yx78_o.png" width="550"><span title="点击并拖拽以改变尺寸">​</span></p> 
<h3 id="5%E3%80%81***%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E7%99%BE%E5%88%86%E6%AF%94%E8%AF%AF%E5%B7%AE%EF%BC%88Mean%20Absolute%20Percentage%20Error%EF%BC%8CMAPE%EF%BC%89">5、***平均绝对百分比误差（Mean Absolute Percentage Error，MAPE）</h3> 
<p><strong>公式</strong>：</p> 
<p><img alt="" height="98" src="https://images2.imgbox.com/49/5f/XioJd68k_o.png" width="407"><span title="点击并拖拽以改变尺寸">​</span></p> 
<p><strong>代码</strong>：</p> 
<div> 
 <pre><code class="language-python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_absolute_percentage_error

<span class="hljs-comment"># 平均绝对百分比误差</span>
mean_absolute_percentage_error(y_test, model.predict(x_test))</code></pre> 
</div> 
<p><img alt="" height="146" src="https://images2.imgbox.com/74/9e/HbFzjHNs_o.png" width="637"><span title="点击并拖拽以改变尺寸">​</span></p> 
<h3 id="6%E3%80%81%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0%EF%BC%88R2%EF%BC%8CR-square%EF%BC%89">6、决定系数（R2，R-square）</h3> 
<p>反映因变量的全部变异能通过回归关系被自变量解释的比例。拟合优度越大，自变量对因变量的解释程度越高，自变量引起的变动占总变动的百分比越高，观察点在回归直线附近越密集。<br> 决定系数R2越高，越接近于1，模型的拟合效果就越好。</p> 
<p><strong>公式</strong>：S^2是方差</p> 
<p><img alt="" height="202" src="https://images2.imgbox.com/5c/ed/R6Kezpwz_o.png" width="464"><span title="点击并拖拽以改变尺寸">​</span></p> 
<p><strong>代码</strong>：</p> 
<div> 
 <pre><code class="language-python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> r2_score

<span class="hljs-comment"># 决定系数</span>
r2_score(y_test, model.predict(x_test))</code></pre> 
</div> 
<p><img alt="" height="141" src="https://images2.imgbox.com/ed/47/ubTMreay_o.png" width="444"><span title="点击并拖拽以改变尺寸">​</span></p> 
<h3 id="7%E3%80%81***%E6%A0%A1%E6%AD%A3%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0%EF%BC%88Adjusted%20R-square%EF%BC%89">7、***校正决定系数（Adjusted R-square）</h3> 
<p><strong>公式</strong>：</p> 
<p><img alt="" height="90" src="https://images2.imgbox.com/d4/f2/gh2DNVxp_o.png" width="897"><span title="点击并拖拽以改变尺寸">​</span></p> 
<p><strong>代码</strong>：</p> 
<div> 
 <pre><code class="language-python hljs">r2=r2_score(y_test, model.predict(x_test))

n, p = x_test.shape
adjusted_r2 = <span class="hljs-number">1</span> - ((<span class="hljs-number">1</span> - r2) * (n - <span class="hljs-number">1</span>)) / (n - p - <span class="hljs-number">1</span>)
adjusted_r2</code></pre> 
</div> 
<p><img alt="" height="134" src="https://images2.imgbox.com/8c/fe/sg0nd9Nu_o.png" width="566"><span title="点击并拖拽以改变尺寸">​</span></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a4f6ac82d5ff91d98d3cdae399726ac2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">机器学习（三） -- 特征工程（2）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6561b4834ddab3ec5d017e7c0240bb01/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">高级算法设计与分析（八） -- 总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>