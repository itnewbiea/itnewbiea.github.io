<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Ubuntu18.04/16.04&#43; Tensorflow1.8 &#43;anaconda安装总结 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Ubuntu18.04/16.04&#43; Tensorflow1.8 &#43;anaconda安装总结" />
<meta property="og:description" content="Ubuntu18.04/16.04&#43; Tensorflow1.8 &#43;anaconda安装总结 主要参考网址：
1.https://blog.csdn.net/Aiolia86/article/details/80342240
2.https://blog.csdn.net/weixin_40920290/article/details/80462734#3cudnn70
Ubuntu18.04发行已经有一段时间了，正好最近Tensorflow也发布了1.8版本，于是决定两个一起装上，以下是安装总结，时间证明该教程适用于ubuntu16.04与18.04,。
大致可以分为5个步骤
确认当前软件和硬件环境、版本
更新显卡驱动，软件版本准备
CUDA 9.0 ToolKit安装
cuDNN7.1.3 for CUDA9.0安装
TensorFlow GPU 安装
Test it!
1.确认硬件软件环境、版本 系统版本，Ubuntu18.04 自然没什么好说的， 终端输入指令查看ubuntu信息
sudolsb_release-a 得到以下输出结果：
No LSB modules are available.
Distributor ID: Ubuntu
Description: Ubuntu 18.04.5 LTS
Release: 18.04
Codename: xenial﻿
GCC和G&#43;&#43; 版本，18.04的ubuntu默认的是7.0，同时也有附带安装6.0，不过我们这次安装需要更低版本的GCC以及G&#43;&#43;
下面两行命令查看gcc和g&#43;&#43;版本号：
gcc --version
g&#43;&#43; --version
我选择采用的是4.8版本gcc和g&#43;&#43;，后面给出降级方法。
英伟达显卡驱动版本， 使用nvidia-smi 可以得到相关信息，我使用的是GTX960显卡，驱动使用384.130版本。
Python 版本， python2 –version 和 python3 –version， 应该对应2.7&#43; 和 3.6&#43;版本了都，默认较新版本，可以忽略。
2.更新显卡驱动，软件版本准备 主要是更新显卡驱动，以及降级默认GCC/G&#43;&#43;版本.
如果是已经装过NVIDIA显卡驱动，通过以下指令升级
sudo add-apt-repository ppa:graphics-drivers/ppa" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/0f46ed6758b8a5a1a5f7dd944c41dea8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-01-13T13:04:56+08:00" />
<meta property="article:modified_time" content="2019-01-13T13:04:56+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Ubuntu18.04/16.04&#43; Tensorflow1.8 &#43;anaconda安装总结</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2><strong>Ubuntu18.04/16.04+ Tensorflow1.8 +anaconda</strong><strong>安装总结</strong></h2> 
<p><strong>主要参考网址：</strong></p> 
<p>1.<a href="https://blog.csdn.net/Aiolia86/article/details/80342240">https://blog.csdn.net/Aiolia86/article/details/80342240</a></p> 
<p>2.<u>https://blog.csdn.net/weixin_40920290/article/details/80462734#3cudnn70</u></p> 
<p>Ubuntu18.04发行已经有一段时间了，正好最近Tensorflow也发布了1.8版本，于是决定两个一起装上，以下是安装总结，时间证明该教程适用于ubuntu16.04与18.04,。</p> 
<p>大致可以分为5个步骤</p> 
<p>确认当前软件和硬件环境、版本</p> 
<p>更新显卡驱动，软件版本准备</p> 
<p>CUDA 9.0 ToolKit安装</p> 
<p>cuDNN7.1.3 for CUDA9.0安装</p> 
<p>TensorFlow GPU 安装</p> 
<p>Test it!</p> 
<hr> 
<h3><a name="t1"></a><a name="1%E7%A1%AE%E8%AE%A4%E7%A1%AC%E4%BB%B6%E8%BD%AF%E4%BB%B6%E7%8E%AF%E5%A2%83%E7%89%88%E6%9C%AC"></a><strong>1.</strong><strong>确认硬件软件环境、版本</strong></h3> 
<p>系统版本，Ubuntu18.04 自然没什么好说的， 终端输入指令查看ubuntu信息</p> 
<pre id="leanote_ace_1547349708028_0">sudolsb_release-a</pre> 
<p>得到以下输出结果：</p> 
<p>No LSB modules are available.<br> Distributor ID: Ubuntu<br> Description: Ubuntu 18.04.5 LTS<br> Release: 18.04<br> Codename: xenial﻿</p> 
<p>GCC和G++ 版本，18.04的ubuntu默认的是7.0，同时也有附带安装6.0，不过我们这次安装需要更低版本的GCC以及G++</p> 
<p>下面两行命令查看gcc和g++版本号：</p> 
<p>gcc --version</p> 
<p>g++ --version</p> 
<p>我选择采用的是4.8版本gcc和g++，后面给出降级方法。</p> 
<p>英伟达显卡驱动版本， 使用<code>nvidia-smi</code> 可以得到相关信息，我使用的是GTX960显卡，驱动使用384.130版本。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/81/57/GLQl2onh_o.png"></p> 
<p>Python 版本， python2 –version 和 python3 –version， 应该对应2.7+ 和 3.6+版本了都，默认较新版本，可以忽略。</p> 
<p><img alt="" class="has" height="90" src="https://images2.imgbox.com/5f/02/WNXKo7R1_o.png" width="651"></p> 
<hr> 
<h3><a name="t2"></a><a name="2%E6%9B%B4%E6%96%B0%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8%E8%BD%AF%E4%BB%B6%E7%89%88%E6%9C%AC%E5%87%86%E5%A4%87"></a><strong>2.</strong><strong>更新显卡驱动，软件版本准备</strong></h3> 
<p>主要是更新显卡驱动，以及降级默认GCC/G++版本.</p> 
<p>如果是已经装过NVIDIA显卡驱动，通过以下指令升级</p> 
<p>sudo add-apt-repository ppa:graphics-drivers/ppa</p> 
<p>sudo apt update</p> 
<p>sudo apt install nvidia-390</p> 
<p>如果有NVIDIA显卡，但是没有安装过显卡相应驱动，CUDA Toolkit中会有集成的384版本驱动，需要关闭图形界面到指令行界面安装，相关方法请上网查找。</p> 
<p>GCC降级,先安装 4.8版本</p> 
<p>sudo apt-get install gcc-4.8</p> 
<p>sudo apt-get install g++-4.8</p> 
<p>装完后进入到/usr/bin目录下在终端输入</p> 
<p>ls -l gcc*</p> 
<p>会显示以下结果</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/4e/b2/UZMBCHO2_o.png"></p> 
<p>发现gcc链接到gcc-7.0, 需要将它改为链接到gcc-4.8，方法如下:</p> 
<p>sudo mv gcc gcc.bak#备份</p> 
<p>sudo ln -s gcc-4.8 gcc#重新链接</p> 
<p><img alt="" class="has" height="52" src="https://images2.imgbox.com/c1/41/js4s1zdq_o.png" width="447"></p> 
<p>同理，对g++也做同样的修改：</p> 
<p>ls -l g++*</p> 
<p><img alt="" class="has" height="84" src="https://images2.imgbox.com/b3/7c/u8IBI3wm_o.png" width="570"></p> 
<p>需要将g++链接改为g++-4.8:</p> 
<p>sudo mv g++ g++.bak</p> 
<p>sudo ln -s g++-4.8 g++</p> 
<p><img alt="" class="has" height="41" src="https://images2.imgbox.com/c3/08/ZJvaCMce_o.png" width="465"></p> 
<p>再查看gcc和g++版本号：</p> 
<pre id="leanote_ace_1547350553440_0">gcc -v
g++ -v </pre> 
<p>均显示gcc version 4.8 ，说明gcc 48.8安装成功。</p> 
<h3><a name="t3"></a><a name="3cuda-toolkit-%E5%AE%89%E8%A3%85"></a><strong>3.CUDA ToolKit </strong><strong>安装</strong></h3> 
<p>下载以下三个安装包：</p> 
<p>（1）CUDA 到<a href="https://developer.nvidia.com/cuda-90-download-archive" rel="nofollow">CUDA9.0</a> 下载页面下载runfile(最近NVIDIA官网被停)安装，Tensorflow官网给的暂时还是9.0版本,新版本可以尝试一下.稳妥起见，这里选择9.0。</p> 
<p>下载9.0安装包 </p> 
<p>（2）在终端输入以下命令：</p> 
<p>wget https://developer.nvidia.com/compute/cuda/9.0/Prod/patches/1/cuda_9.0.176.1_linux-run</p> 
<p>（3）在终端输入以下命令:</p> 
<p>wget https://developer.nvidia.com/compute/cuda/9.0/Prod/patches/2/cuda_9.0.176.2_linux-run</p> 
<p>～/应该有 以下三个文件</p> 
<p><img alt="" class="has" height="69" src="https://images2.imgbox.com/e5/6f/Ve2eOQ63_o.png" width="476"></p> 
<p>在确认GCC版本在4.8后， 直接输入以下指令</p> 
<p>sh cuda_9.0.176_384.81_linux.run --override</p> 
<p>执行，如果有安装了显卡驱动的，注意在提问是否安装显卡驱动时选择no,其他 选择默认路径或者yes即可。 如果没有安装显卡驱动，需要退出图形界面，到命令行终端安装，这里不再赘述。(可以参考另一片笔记：ubuntu16.04安装显卡驱动)。</p> 
<p>cuda安装完显示如下：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/83/2f/00rT5yQv_o.png"></p> 
<p>安装完成后，可能会得到提示，CUDA 安装不完整，这是因为显卡驱动没有安装，这里忽略掉。</p> 
<p>接下来安装另外两个：</p> 
<p>在这里之前要获取root权限</p> 
<p>sudo su</p> 
<p>sh cuda_9.0.176.1_linux-run</p> 
<p>sh cuda_9.0.176.2_linux-run</p> 
<p>sudo gedit  ~/.barshrc</p> 
<p>添加以下两行：</p> 
<p>export PATH=/usr/local/cuda-9.0/bin${PATH:+:$PATH}} <br> export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}</p> 
<p>保存后终端输入：source ~/.barshrc﻿</p> 
<h2><br><strong>4.cuDNN7.1.3</strong><strong>安装</strong></h2> 
<p>cuDNN 到 <a href="https://developer.nvidia.com/rdp/cudnn-download" rel="nofollow">cuDNN</a> 官网页面下载即可，这里注意要选择对应CUDA9.0的软件包， 下载完毕后，切到默认的Downloads文件夹，可以看到 cudnn-9.0-linux-x64-v7.1.tgz 压缩包 <br> 先解压，后复制到CUDA安装文件夹里面.</p> 
<p>sudo cp cuda/include/cudnn.h /usr/local/cuda/include</p> 
<p>sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64</p> 
<p>sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</p> 
<p>在这里进入/usr/local 查看是否有cuda和cuda-9.0文件</p> 
<p><img alt="" class="has" height="53" src="https://images2.imgbox.com/6c/9b/Ng4nCluA_o.png" width="621"></p> 
<p>完成后，可以到～/NVIDIA_CUDA-9.0_Samples/文件夹下测试CUDA功能完整性。这里参照CUDA Getting Start测试即可。一般都会在结果输出Test pass 字段。</p> 
<p>测试过程（以下两种方法任选其一即可）：</p> 
<p>测试方法1：</p> 
<p>cd~/NVIDIA_CUDA-9.0_Samples/5_Simulations/nbody</p> 
<p>make</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/8f/d0/aD9iZ1ZR_o.png"></p> 
<p>再运行：</p> 
<p>./nbody</p> 
<p>即在CUDA上运行nbody示例，make部分报错</p> 
<p>WARNING - libGLU.so not found, refer to CUDA Getting Started Guide for how to find and install them. &lt;&lt;&lt;<br> WARNING - glu.h not found, refer to CUDA Getting Started Guide for how to find and install them.&lt;&lt;&lt;</p> 
<p>解决方法：(如果显示错误就一个一个的安装)</p> 
<p>sudo apt-get install freeglut3-dev<br> sudo apt-get install build-essential<br> sudo apt-get install libx11-dev<br> sudo apt-get install libxmu-dev<br> sudo apt-get install libxi-dev<br> sudo apt-get install libgl1-mesa-glx<br> sudo apt-get install libglu1-mesa<br> sudo apt-get install libglu1-mesa-dev<br> sudo apt-get install libglfw3-dev<br> sudo apt-get install libgles2-mesa-dev﻿</p> 
<p>然后进入/home/lilywei/NVIDIA_CUDA-9.0_Samples/5_Simulations文件夹，双击目录下的nobody出现以下画面即安装成功</p> 
<p><img alt="" class="has" height="510" src="https://images2.imgbox.com/cb/dc/xYGKKNXK_o.png" width="720"></p> 
<p> 测试方法2：</p> 
<p>进入/home/lilywei/NVIDIA_CUDA-9.0_Samples/1_Utilities/deviceQuery</p> 
<p>运行make，结果如下：</p> 
<p><img alt="" class="has" height="235" src="https://images2.imgbox.com/94/18/DPJEtFe4_o.png" width="731"></p> 
<p>会发现文件夹中出现了一个</p> 
<p><img alt="" class="has" height="103" src="https://images2.imgbox.com/bd/51/KczwwdYe_o.png" width="92"></p> 
<p>再继续运行如下：</p> 
<p>./deviceQuery</p> 
<p>最后出现这样的结果表示cuda安装成功</p> 
<p><img alt="" class="has" height="63" src="https://images2.imgbox.com/50/fc/RYgMBSIA_o.png" width="727"></p> 
<p><strong>5.anaconda安装</strong></p> 
<p><strong>从中科大的镜像</strong><strong>https://mirrors.ustc.edu.cn/anaconda/archive/ </strong><strong>上下载</strong><strong>anaconda3</strong><strong>并放在主目录下安装（注意不要安装python3.7版本的anaconda</strong><strong>，目前还不支持）</strong></p> 
<p>输入命令：<code>bash An***.sh</code>,具体看你哪个版本，根据提示操作即可.遇到选项都选yes，要安装c++库也同意.<a href="https://blog.csdn.net/u012318074/article/details/77074665">参考安装网站</a>，这里有两个要注意的.</p> 
<p>1.不要用<code>sudo</code>命令，会造成anaconda文件夹其他应用无法修改</p> 
<p>2.一定要添加环境变量还有提示的库安装，如果自己重新添加的话会很麻烦.</p> 
<p><img alt="" class="has" height="287" src="https://images2.imgbox.com/97/7e/xQtmWx0P_o.png" width="700"></p> 
<p>安装完之后，输入python查看是否安装成功</p> 
<p><img alt="" class="has" height="87" src="https://images2.imgbox.com/ef/4f/SLYxFo7l_o.png" width="702"></p> 
<p>这里默认的python不是anaconda（如果是则不需要设置），否则需要设置以下：</p> 
<p>在终端输入以下命令，打开profile文件。</p> 
<pre id="leanote_ace_1547350762324_0">sudo gedit /etc/profile</pre> 
<p>在文件末尾添加一行：</p> 
<p>export PATH=/home/lilywei/anaconda3/bin:$PATH</p> 
<p>其中，将“/home/lilywei/anaconda3/bin”替换为你实际的安装路径。保存。 再重新在终端输入</p> 
<p>source  ~/.bashrc</p> 
<h2><a name="51tensorflow18%E5%AE%89%E8%A3%85"></a><strong>5.1TensorFlow1.8</strong><strong>安装</strong></h2> 
<p>TensorFlow1.8的话需要自己安装，conda不会自动安装CUDA8.0、cudnn6.0这些配置(未来可能会支持自动安装CUDA9..0、cudnn7.0)，拭目以待.</p> 
<p>打开桌面终端，输入</p> 
<p>source activate base</p> 
<p>base是默认的Anaconda环境，也可以自己新建一个环境再激活它.</p> 
<p>搜索各个tensorflow版本.</p> 
<pre id="leanote_ace_1547351031291_0"> </pre> 
<p>anaconda search -t conda tensorflow</p> 
<p><img alt="" class="has" height="395" src="https://images2.imgbox.com/53/ab/q2v8ERlT_o.png" width="730"></p> 
<p>搜这里xxbandy123/tensorflow代表CPU版本，TensorFLow版本1.6，支持linux-64，py2.7之类的信息，这里我们不用管，因为有个TensorFlow源仓库始终保持最新版本，并且兼容win64和linux64.</p> 
<p>3.输入命令</p> 
<pre id="leanote_ace_1547351056210_0">anaconda show aaronzs/tensorflow-gpu</pre> 
<p>然后照着提示，比如我的提示是<code>conda install --channel https://conda.anaconda.org/aaronzs tensorflow-gpu</code>安装.</p> 
<p>中间的都点yes。安装完成后现实如下：</p> 
<p><img alt="" class="has" height="436" src="https://images2.imgbox.com/13/5d/UpgxNleE_o.png" width="723"></p> 
<h2><a name="%E6%B5%8B%E8%AF%95"></a></h2> 
<h2> </h2> 
<h2><strong>5.2测试</strong></h2> 
<p>如果安装好了TensorFlow，可以测试一下，这里我给一个测试文件.复制保存成1<code>.py</code>之后，在该文件目录打开终端，输入<code>python 1.py</code>直接运行，如果没有报错的话，就说明TensorFlow安装成功了.会输抽出准确率、保存训练日志、完成时间等,GT660在GPU训练情况下在40秒左右，可以拿来参考.</p> 
<h3><a name="t15"></a><a name="%E6%B5%8B%E8%AF%95%E6%96%87%E4%BB%B6"></a><strong>测试文件</strong></h3> 
<pre class="has"><code>importargparse

importsys

importtensorflowastf

fromtensorflow.examples.tutorials.mnistimportinput_data

importtime

#1.2(1).(2)A.B

#一步一步来，否则最后很难找错误

NUM_CLASSES=10

IMAGE_SIZE=28

IMAGE_PIXELS=IMAGE_SIZE*IMAGE_SIZE

#1.添加全局变量

FLAGS=None

#这个初始化只是方便一下，抓住主线

defweight_variable(shape):

'''权重初始化，返回默认为形状为shape标准差为0.1的截断正态分布矩阵.

:paramshape:权重矩阵的形状.

:return:初始化后的权重矩阵

'''

initial_Weight=tf.Variable(tf.truncated_normal(shape,stddev=0.1))

returninitial_Weight

defbias_variable(shape):

'''偏置初始化，默认初始化为全为1，形状为shape的偏置矩阵

:paramshape:偏置矩阵的shape

:return:初始化后的偏置矩阵

'''

initial_bias=tf.Variable(tf.constant(0.1,shape=shape))

returninitial_bias

#A.summary.scalar一下

#B.merge_all成summaries节点

#C.sess.run(节点)成str

#D.将stradd进事件，并且附上步数

#E.记录训练汇总信息

#A1.对一个张量进行全面的汇总（均值，标准差，最大最小值，直方图）写一个函数

defvariable_summaries(var):

withtf.name_scope('summaries'):

mean=tf.reduce_mean(var)

tf.summary.scalar('mean',mean)

withtf.name_scope('stddev'):

#标准差计算公式

stddev=tf.sqrt(tf.reduce_mean(tf.square(var-mean)))

tf.summary.scalar('stddev',stddev)

tf.summary.scalar('max',tf.reduce_max(var))

tf.summary.scalar('min',tf.reduce_min(var))

tf.summary.histogram('histogram',var)

#神经元个数一般讲该神经层输出的数目.

defnn_layer(input_tensor,input_dim,output_dim,layer_name,act=tf.nn.relu):

'''它在内部做了一个矩阵乘法，偏置加法，然后利用relu进行非线性输出映射.添加了每一层的name_scope

和汇总节点

:paraminput_tensor:输入Tensor,即X

:paraminput_dim:输入的维度

:paramoutput_dim:神经元的数目

:paramlayer_name:神经层的名字

:paramact:激活函数,默认tf.nn.relu

:return:该神经层节点

'''

withtf.name_scope(layer_name):

withtf.name_scope('Weights'):

weights=weight_variable([input_dim,output_dim])

#A2.scalar一下

variable_summaries(weights)

withtf.name_scope('biases'):

biases=bias_variable([output_dim])

#A2.scalar一下

variable_summaries(biases)

withtf.name_scope('Wx_plus_b'):

peractivate=tf.matmul(input_tensor,weights)+biases

tf.summary.histogram('pre_activations',peractivate)

activations=act(peractivate)

tf.summary.histogram('activations',activations)

#最后换行return还是怎样ruturn是看逻辑的，不一定需要在with里面return

returnactivations

#3.构造计算图，之后启动训练过程《《主函数》》

deftrain():

#(1)占位符

#(7).声明一个交互式会话

#(6).导入数据，喂数据.也写在计算图中，因为是往占位符中喂数据，所以要在占位符之后

mnist=input_data.read_data_sets(FLAGS.data_dir,one_hot=True,fake_data=FLAGS.fake_data)

sess=tf.InteractiveSession()

withtf.name_scope('input'):

x=tf.placeholder(tf.float32,[None,IMAGE_PIXELS],name='X_input')

y_true=tf.placeholder(tf.float32,[None,NUM_CLASSES],name='Y_input')

#&lt;&lt;图片

withtf.name_scope('input_reshape'):

image_shape_input=tf.reshape(x,[-1,28,28,1])#batch_size

tf.summary.image('input',image_shape_input,10)#放10个图像

#(2)Inference00.mnist_with_summaries.py

hidden1=nn_layer(x,IMAGE_PIXELS,FLAGS.hidden1,'layer1')

withtf.name_scope('dropout'):

#要放入计算图中看的，要用TF函数.想要不断手动调整的，更改的用placeholder.数据也用placeholder传入

#如果用常量，就不方便更改dropout，不方便汇总看后面代码

#训练和测试的时候，这个keep率不同。因此需要占位符

keep_prob=tf.placeholder(tf.float32)

tf.summary.scalar('dropout_keep_probability',keep_prob)

#A1tf.summary.scalar('dropout_keep_probability',keep_prob)

dropped=tf.nn.dropout(hidden1,keep_prob)

logits=nn_layer(dropped,FLAGS.hidden1,NUM_CLASSES,'layer2',act=tf.identity)#tf.identity什么都不做

#(3)Loss定义损失节点，先让图跑起来，再决定要查看什么数据

withtf.name_scope('cross_entropy'):

diff=tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=logits)

withtf.name_scope('total'):

cross_entropy=tf.reduce_mean(diff)

#A1

tf.summary.scalar('cross_entropy',cross_entropy)

#(4)定义训练节点

withtf.name_scope('train'):

optimizer=tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)

train_step=optimizer.minimize(cross_entropy)

#(5)定义评估节点

withtf.name_scope('accuracy'):

#当前批次样本的预测正确性

withtf.name_scope('correct_prediction'):

correct_prediction=tf.equal(tf.argmax(logits,1),tf.argmax(y_true,1))#返回的是布尔类型

withtf.name_scope('accuracy'):

accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))

deffeed_dict(train):

'''

喂数据

:paramtrain:TrueorFalse

:return:训练集/测试集合

'''

iftrainorFLAGS.fake_data:#这里只是作为提示，加上FLAGS.fake_data

#True/false

xs,ys=mnist.train.next_batch(100,fake_data=FLAGS.fake_data)

k=FLAGS.dropout#k=0.9

else:#否则是测试集

xs,ys=mnist.test.images,mnist.test.labels

k=1.0

return{x:xs,y_true:ys,keep_prob:k}#喂数据要字典形式传入

#B1.merge_all成summaries节点

merged=tf.summary.merge_all()

#B2.写入测试日志节点(计算图中的程序不一定顺序运行，需要调用，所以这里不需要条件判断，会各自存在计算图中)

train_writer=tf.summary.FileWriter(FLAGS.log_dir+'/train',sess.graph)

#B2.写入测试日志节点(因为前后先后调用，前面sess.graph已经打开，所以这里不需要sess.graph）

test_writer=tf.summary.FileWriter(FLAGS.log_dir+'/test')

#(8).初始化所有变量

tf.global_variables_initializer().run()

#写入计算图（喂测试0

#wirter=tf.summary.FileWriter(logdir=FLAGS.log_dir,graph=tf.get_default_graph())(这里为了演示前面的过程，保证计算图正确)

#wirter.close()

#4.开启训练模式

#首先每次训练，将训练信息记录进summary,隔10步记录一次测试信息.

#在余下的9步里面，隔100步跟踪一次各个权重.添加进训练信息.

#剩下的99步，

time_start=time.time()

forstepinrange(FLAGS.max_steps):

#(1）利用feed_dict()函数喂数据

#C1.sess.run(节点)成str

#D.将stradd进训练事件，分别写入，并且附上步数.step

#是add进去的.因为训练是每一步都进行的，喂的数据是训练数据,同样要打开merged文件.

ifstep%10==0:

summary,acc=sess.run([merged,accuracy],feed_dict(False))

test_writer.add_summary(summary,global_step=step)

print('第%s，准确率=%s'%(step,acc))

#E.1记录训练汇总信息

else:

ifstep%100==99:#每隔100步跟踪一次数据

#A.run_optins-tf.RunOptions

#B.run_metadat-tf.RunMetadata()

#C.sess.runoptions/run

#D.add_run_metadata

run_options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)

run_metadata=tf.RunMetadata()

summary,_=sess.run([merged,train_step],

feed_dict=feed_dict(True),

options=run_options,

run_metadata=run_metadata)

train_writer.add_run_metadata(run_metadata,'step%03d'%step)

train_writer.add_summary(summary,step)

else:

summary,_=sess.run([merged,train_step],feed_dict=feed_dict(True))

train_writer.add_summary(summary,step)

#最后要关闭FileWriter.Python关闭文件的位置很重要.

time_end=time.time()

print('totallycost',time_end-time_start)

train_writer.close()

test_writer.close()

#2.运行主函数main，创建日志文件（log_dir)，启动训练过程

defmain(_):

iftf.gfile.Exists(FLAGS.log_dir):

#tf.gfile:tensorflow的文件管理模块

tf.gfile.DeleteRecursively(FLAGS.log_dir)

tf.gfile.MakeDirs(FLAGS.log_dir)

train()

#1这里是开始读程序的地方

if__name__=='__main__':

#1.1实例化一个全局解析器

parser=argparse.ArgumentParser()

#1.2往全局解析器里面添加东西

#是否用假数据

parser.add_argument('--fake_data',nargs='?',const=True,type=bool,

default=False,

help='Iftrue,usesfakedataforunittesting.')

parser.add_argument('--max_steps',type=int,default=1000,

help='Numberofstepstoruntrainer.')

parser.add_argument('--learning_rate',type=float,default=0.001,

help='Initiallearningrate')

parser.add_argument('--hidden1',type=int,default=500,

help='第一个隐藏层的神经元个数')

#dropout为防止过拟合

parser.add_argument('--dropout',type=float,default=0.9,

help='Keepprobabilityfortrainingdropout.')

parser.add_argument('--data_dir',type=str,

default='MNIST_data/',

help='Directoryforstoringinputdata')

parser.add_argument('--log_dir',type=str,

default='logs/mnist_with_summaries',

help='Summarieslogdirectory')

#1.3将这些参数解析到全局变量FLAGS中

FLAGS,unparsed=parser.parse_known_args()

#1.4运行某个程序，以某个全局解析器的参数

tf.app.run(main=main,argv=[sys.argv[0]]+unparsed)</code></pre> 
<h3>这里出现错误如下：</h3> 
<p><img alt="" class="has" height="413" src="https://images2.imgbox.com/32/d8/xXRouHTU_o.png" width="720"></p> 
<h3>解决办法：</h3> 
<p>这里到home里面双击打开.bashrc文件（看不见ctrl+h查看隐藏文件），添加下面这几个命令。然后在终端运行<strong>source ~/.bashrc</strong></p> 
<p>export CUDA_HOME=/usr/local/cuda-9.0<br> export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:$LD_LIBRARY_PATHs<br> export PATH=/usr/local/cuda-9.0/bin:$PATH<br> export LD_LIBRARY_PATH="/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/lib64"</p> 
<h3>解决完错误后再次运行</h3> 
<p><img alt="" class="has" height="417" src="https://images2.imgbox.com/40/41/CNBOLg70_o.png" width="740"></p> 
<p>最后结果显示：<br><img alt="" class="has" height="264" src="https://images2.imgbox.com/c0/33/b9ACPuaB_o.png" width="331"></p> 
<h3><strong>成功！</strong></h3> 
<h3><a name="t16"></a><a name="%E9%94%99%E8%AF%AF%E8%B0%83%E8%AF%95"></a><strong>注意：错误调试</strong></h3> 
<p>缺少libcublas.so文件，检查一下<code>.bashrc</code>文件是否添加上文所说的几行，并且是否在终端运行<code>source ~/.bashrc</code>.</p> 
<p>python不是Anaconda版本，这个也是检查.bashrc，是否添加这一句，注意lilywei是我的用户名，请修改成自己的。</p> 
<p>export PATH="/home/lilywei/anaconda3/bin:$PATH"</p> 
<p>有些.bashr路径需要检查一下，是否是你自己的文件路径，不同电脑位置可能会有不同.</p> 
<p>检查到底哪一步出错，CUDA9.0、cudnn(最容易出错的地方)还是什么，自己百度一下。</p> 
<p>如果解决不了，就安装TensorFlow-gpu-1.3版本，或者安装Windows下的TensorFlow。</p> 
<p>如果还是不行，其实cpu版本也蛮快的。</p> 
<h2><a name="6%E5%AE%89%E8%A3%85pycharm"></a><strong>6.</strong><strong>安装</strong><strong>pycharm</strong></h2> 
<h3><a name="t18"></a><a name="pycharm%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E"></a><strong>pycharm</strong><strong>版本说明</strong></h3> 
<p>如果前面都安装好的话，就可以装pycharm了.这里我用的是2018专业版，如果有校园邮箱,也就是edu.cn结尾的邮箱的同学可以免费申请pycharm，可以自己百度一下，免费用一年，第二年再激活一下还可以再用，并且可以在好几台电脑上使用.据说毕业了就不能用了，但问题不大.如果不是校内学生或者老师的话，建议购买(ttmgl)专业版，也可以使用社区版或者网上搜破解版.(pycharm还是挺良心的对科研人员，因此我个人不推荐).</p> 
<h3><a name="t19"></a><a name="%E5%AE%89%E8%A3%85-2"></a><strong>安装</strong></h3> 
<p>我们去官网下载下来，<code>pycharm-professional-2018.1.4.tar.gz</code>，双击打开，解压到要安装的目录,到该目录bin下，打开终端输入<code>sh pycharm.sh</code>就可以打开了，与平时一样正常使用.(不要在ubuntu software里面安装，因为后面我们要编辑pycharm启动文件，否则pycharm里面不能运行tensorflow) </p> 
<p><img alt="" class="has" height="519" src="https://images2.imgbox.com/05/18/OiAcZn1F_o.png" width="890"></p> 
<p>这里安装的时候出现一个问题</p> 
<p><img alt="" class="has" height="224" src="https://images2.imgbox.com/20/a1/c9wAPYfU_o.png" width="734"></p> 
<p>解决方法，在终端中输入：</p> 
<p>sudo apt-get install libcanberra-gtk-module<br> 再次重新安装成功。</p> 
<p>然而我们发现，在终端里面测试文件可以被正常运行，pycharm里面又不能运行了，解决办法如下：</p> 
<p>在pycharm的file&gt;setting&gt;project interpreter中设置路径，注意在这里设置conda环境，然后保存。</p> 
<p><img alt="" class="has" height="185" src="https://images2.imgbox.com/5e/13/k6P5AsNe_o.png" width="897"></p> 
<p>然后在pycharm中运行1.py。得出下图运行结果。</p> 
<p><img alt="" class="has" height="260" src="https://images2.imgbox.com/31/fa/nlKiYryZ_o.png" width="420"></p> 
<p>至此安装成功！尽情的使用tensorflow吧！</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/38c0800cd33adeddea5d6c20b3a9b8e2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">嵌入式Linux开发常用C语言标准库函数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c9cfb4fd55fd76e12865bc764961d366/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">linux上运行php目录不可写问题（无权限）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>