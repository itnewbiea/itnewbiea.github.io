<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>不使用任何框架实现CNN网络 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="不使用任何框架实现CNN网络" />
<meta property="og:description" content="文章目录 一、 问题描述二、 设计简要描述三、程序清单四、结果分析五、调试报告六、实验小结 一、 问题描述 基于Numpy和函数im2col与col2im来实现一个简单的卷积神经网络，将其用于手写体识别。
二、 设计简要描述 机器学习的三个基本步骤——
程序设计思路——(此图放大可看清)
三、程序清单 1．卷积层实现
import numpy as np from main import im2col, col2im class Convolution: def __init__(self, W, b, stride=1, pad=0): self.W = W self.b = b self.stride = stride self.pad = pad # 中间数据（backward时使用） self.x = None self.col = None self.col_W = None # 权重和偏置参数的梯度 self.dW = None self.db = None def forward(self, x): FN, C, FH, FW = self." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/b18f21097226be4ddb0204bbcd013b0f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-03-07T10:50:21+08:00" />
<meta property="article:modified_time" content="2021-03-07T10:50:21+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">不使用任何框架实现CNN网络</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#%09_1" rel="nofollow">一、 问题描述</a></li><li><a href="#__4" rel="nofollow">二、 设计简要描述</a></li><li><a href="#_9" rel="nofollow">三、程序清单</a></li><li><a href="#_375" rel="nofollow">四、结果分析</a></li><li><a href="#_381" rel="nofollow">五、调试报告</a></li><li><a href="#_411" rel="nofollow">六、实验小结</a></li></ul> 
</div> 
<p></p> 
<h2><a id="%09_1"></a>一、 问题描述</h2> 
<p>基于Numpy和函数im2col与col2im来实现一个简单的卷积神经网络，将其用于手写体识别。</p> 
<h2><a id="__4"></a>二、 设计简要描述</h2> 
<p>机器学习的三个基本步骤——<br> <img src="https://images2.imgbox.com/2b/b1/cMk5uCs3_o.png" alt="在这里插入图片描述"><br> 程序设计思路——(此图放大可看清)<br> <img src="https://images2.imgbox.com/87/43/YlJF578g_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_9"></a>三、程序清单</h2> 
<p>1．卷积层实现</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> main <span class="token keyword">import</span> im2col<span class="token punctuation">,</span> col2im


<span class="token keyword">class</span> <span class="token class-name">Convolution</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> W
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> b
        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride
        self<span class="token punctuation">.</span>pad <span class="token operator">=</span> pad

        <span class="token comment"># 中间数据（backward时使用）</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>col <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>col_W <span class="token operator">=</span> <span class="token boolean">None</span>

        <span class="token comment"># 权重和偏置参数的梯度</span>
        self<span class="token punctuation">.</span>dW <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        FN<span class="token punctuation">,</span> C<span class="token punctuation">,</span> FH<span class="token punctuation">,</span> FW <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>shape  <span class="token comment"># 卷积核的形状</span>
        N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape  <span class="token comment"># 输入数据形状</span>
        out_h <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>H <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>pad <span class="token operator">-</span> FH<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>  <span class="token comment"># 输出数据的高</span>
        out_w <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>W <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>pad <span class="token operator">-</span> FW<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>  <span class="token comment"># 输出数据的宽</span>

        col <span class="token operator">=</span> im2col<span class="token punctuation">(</span>x<span class="token punctuation">,</span> FH<span class="token punctuation">,</span> FW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>  <span class="token comment"># 展开的数据</span>
        col_W <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>FN<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T  <span class="token comment"># 卷积核展开为二维数组</span>
        out <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>col<span class="token punctuation">,</span> col_W<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b  <span class="token comment"># 计算展开后的矩阵乘积</span>

        <span class="token comment"># 输出大小转换为合适的形状</span>
        <span class="token comment"># transpose会更改多维数组的轴的顺序，将输出数据形状由(N,H,W,C)转变为(N,C,H,W)</span>
        <span class="token comment"># 索引(0,1,2,3)对应着(N,H,W,C)</span>
        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> out_h<span class="token punctuation">,</span> out_w<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

        <span class="token comment"># 更新backward过程需要用到的中间数据</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x
        self<span class="token punctuation">.</span>col <span class="token operator">=</span> col
        self<span class="token punctuation">.</span>col_W <span class="token operator">=</span> col_W

        <span class="token keyword">return</span> out
</code></pre> 
<p>2．池化层实现</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> main <span class="token keyword">import</span> im2col<span class="token punctuation">,</span> col2im


<span class="token keyword">class</span> <span class="token class-name">Pooling</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pool_h<span class="token punctuation">,</span> pool_w<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>pool_h <span class="token operator">=</span> pool_h
        self<span class="token punctuation">.</span>pool_w <span class="token operator">=</span> pool_w
        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride
        self<span class="token punctuation">.</span>pad <span class="token operator">=</span> pad

        <span class="token comment"># 存储backward需用到的中间数据</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>arg_max <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        out_h <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H <span class="token operator">-</span> self<span class="token punctuation">.</span>pool_h<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>  <span class="token comment"># 输出数据的高</span>
        out_w <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>W <span class="token operator">-</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>  <span class="token comment"># 输出数据的宽</span>

        <span class="token comment"># 展开输入数据</span>
        col <span class="token operator">=</span> im2col<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_h<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>
        col <span class="token operator">=</span> col<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_h <span class="token operator">*</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">)</span>

        arg_max <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>col<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 求出各行的最大值</span>
        out <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>col<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 通过reshape方法将数据转换为合适的形状</span>
        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> out_h<span class="token punctuation">,</span> out_w<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

        <span class="token comment"># 保存backward过程中需要用到的中间数据</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x
        self<span class="token punctuation">.</span>arg_max <span class="token operator">=</span> arg_max

        <span class="token keyword">return</span> out

    <span class="token comment"># 反向传播</span>
    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dout <span class="token operator">=</span> dout<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

        pool_size <span class="token operator">=</span> self<span class="token punctuation">.</span>pool_h <span class="token operator">*</span> self<span class="token punctuation">.</span>pool_w
        dmax <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>dout<span class="token punctuation">.</span>size<span class="token punctuation">,</span> pool_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        dmax<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>self<span class="token punctuation">.</span>arg_max<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>arg_max<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dout<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
        dmax <span class="token operator">=</span> dmax<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>dout<span class="token punctuation">.</span>shape <span class="token operator">+</span> <span class="token punctuation">(</span>pool_size<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        dcol <span class="token operator">=</span> dmax<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>dmax<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> dmax<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> dmax<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        dx <span class="token operator">=</span> col2im<span class="token punctuation">(</span>dcol<span class="token punctuation">,</span> self<span class="token punctuation">.</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_h<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>

        <span class="token keyword">return</span> dx
</code></pre> 
<p>3．网络搭建</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> Convolution <span class="token keyword">import</span> Convolution
<span class="token keyword">from</span> Pooling <span class="token keyword">import</span> Pooling
<span class="token keyword">from</span> SoftmaxWithLoss <span class="token keyword">import</span> SoftmaxWithLoss
<span class="token keyword">from</span> Relu <span class="token keyword">import</span> Relu
<span class="token keyword">from</span> Affine <span class="token keyword">import</span> Affine


<span class="token keyword">class</span> <span class="token class-name">SimpleConvNet</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""简单的ConvNet
    conv - relu - pool - linear - relu - linear - softmax
    Parameters
    ----------
    input_size : 输入大小（MNIST的情况下为784）
    conv_param : 保存卷积层的超参数（字典）
    hidden_size_list : 隐藏层的神经元数量的列表（e.g. [100, 100, 100]）
    output_size : 输出大小（MNIST的情况下为10）
    activation : 'relu' or 'sigmoid'
    weight_init_std : 指定权重的标准差（e.g. 0.01）
        指定'relu'或'he'的情况下设定“He的初始值”
        指定'sigmoid'或'xavier'的情况下设定“Xavier的初始值”
    """</span>

    <span class="token comment"># input_dim是输入数据的通道，高，长</span>
    <span class="token comment"># conv_param是卷积层的超参数</span>
    <span class="token comment"># hidden_size是倒数第二个全连接层神经元数量</span>
    <span class="token comment"># output_size是最后一个全连接层神经元数量</span>
    <span class="token comment"># weight_init_std是权重的标准差</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 conv_param<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'filter_num'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'filter_size'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'pad'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'stride'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                 hidden_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> weight_init_std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
这里将由初始化参数传入的卷积层的超参数从字典中取了出来（以方便后面使用），然后，计算卷积层和池化层的输出大小。
        """</span>
        filter_num <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'filter_num'</span><span class="token punctuation">]</span>  <span class="token comment"># conv_param―卷积层的超参数（字典）。</span>
        filter_size <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'filter_size'</span><span class="token punctuation">]</span>  <span class="token comment"># 卷积核的大小</span>
        filter_pad <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'pad'</span><span class="token punctuation">]</span>  <span class="token comment"># 步幅</span>
        filter_stride <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span>  <span class="token comment"># 填充</span>
        input_size <span class="token operator">=</span> input_dim<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        conv_output_size <span class="token operator">=</span> <span class="token punctuation">(</span>input_size <span class="token operator">-</span> filter_size <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> filter_pad<span class="token punctuation">)</span> <span class="token operator">/</span> filter_stride <span class="token operator">+</span> <span class="token number">1</span>
        pool_output_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>filter_num <span class="token operator">*</span> <span class="token punctuation">(</span>conv_output_size <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>conv_output_size <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 初始化权重</span>
        <span class="token triple-quoted-string string">"""学习所需的参数是第1层的卷积层和剩余两个全连接层的权重和偏置。将这些参数保存在实例变量的params字典中。
        将第1层的卷积层的权重设为关键字W1，偏置设为关键字b1。同样，分别用关键字W2、b2和关键字W3、b3来保存第2个和第3个全连接层的权重和偏置。
        """</span>
        <span class="token comment"># 卷积层的参数初始化</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> \
                            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>filter_num<span class="token punctuation">,</span> input_dim<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> filter_size<span class="token punctuation">,</span> filter_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>filter_num<span class="token punctuation">)</span>
        <span class="token comment"># 两个Linear层的参数的初始化</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> \
                            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>pool_output_size<span class="token punctuation">,</span>
                                            hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> \
                            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_size<span class="token punctuation">)</span>

        <span class="token comment"># 生成层</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 向有序字典（OrderedDict）的layers中添加层</span>
        <span class="token comment"># 依次命名为'Conv1'、'Relu1'、'Pool1'、'Linear1'、'Relu2'、'Affine2'</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Convolution<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                           self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                           conv_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                           conv_param<span class="token punctuation">[</span><span class="token string">'pad'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Relu1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Pool1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Pooling<span class="token punctuation">(</span>pool_h<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> pool_w<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Affine<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Relu2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Affine<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>lastLayer <span class="token operator">=</span> SoftmaxWithLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token triple-quoted-string string">"""
参数x是输入数据，t是教师标签。
用于推理的predict方法从头开始依次调用已添加的层，并将结果传递给下一层。
在求损失函数的loss方法中，除了使用 forward方法进行的前向传播处理之外，还会继续进行forward处理，直到到达最后的SoftmaxWithLoss层。
        """</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""求损失函数
        参数x是输入数据、t是数据标签
        """</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>lastLayer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> t<span class="token punctuation">.</span>ndim <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span> t <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>t<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        acc <span class="token operator">=</span> <span class="token number">0.0</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            tx <span class="token operator">=</span> x<span class="token punctuation">[</span>i <span class="token operator">*</span> batch_size<span class="token punctuation">:</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> batch_size<span class="token punctuation">]</span>
            tt <span class="token operator">=</span> t<span class="token punctuation">[</span>i <span class="token operator">*</span> batch_size<span class="token punctuation">:</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> batch_size<span class="token punctuation">]</span>
            y <span class="token operator">=</span> self<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>tx<span class="token punctuation">)</span>
            y <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y <span class="token operator">==</span> tt<span class="token punctuation">)</span>

        <span class="token keyword">return</span> acc <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token triple-quoted-string string">"""
        参数的梯度通过误差反向传播法（反向传播）求出，通过把正向传播和反向传播组装在一起来完
成。因为已经在各层正确实现了正向传播和反向传播的功能，所以这里只需要以合适的顺序调用
即可。最后，把各个权重参数的梯度保存到grads字典中。
        """</span>

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 运用误差反向传播法求取梯度</span>
        <span class="token comment"># forward</span>
        self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

        <span class="token comment"># backward</span>
        dout <span class="token operator">=</span> <span class="token number">1</span>
        dout <span class="token operator">=</span> self<span class="token punctuation">.</span>lastLayer<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>dout<span class="token punctuation">)</span>
        layers <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        layers<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>
            dout <span class="token operator">=</span> layer<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>dout<span class="token punctuation">)</span>

        <span class="token comment"># 将学习过程中计算出的权重参数梯度保存到grads字典中</span>
        grads <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>db
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>db
        grads<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>db

        <span class="token keyword">return</span> grads
</code></pre> 
<p>4．训练模型与结果展示</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> mnist <span class="token keyword">import</span> load_mnist
<span class="token keyword">from</span> optimizer <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> SimpleConvNet <span class="token keyword">import</span> SimpleConvNet

<span class="token comment"># 读入数据</span>
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">)</span> <span class="token operator">=</span> load_mnist<span class="token punctuation">(</span>flatten<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># 处理花费时间较长的情况下减少数据</span>
x_train<span class="token punctuation">,</span> t_train <span class="token operator">=</span> x_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> t_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5000</span><span class="token punctuation">]</span>
x_test<span class="token punctuation">,</span> t_test <span class="token operator">=</span> x_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> t_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1000</span><span class="token punctuation">]</span>


<span class="token keyword">class</span> <span class="token class-name">Trainer</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""进行神经网络的训练的类
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> network<span class="token punctuation">,</span> x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">,</span>
                 epochs<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> mini_batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">'Adam'</span><span class="token punctuation">,</span> optimizer_param<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                 evaluate_sample_num_per_epoch<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>network <span class="token operator">=</span> network
        self<span class="token punctuation">.</span>verbose <span class="token operator">=</span> verbose
        self<span class="token punctuation">.</span>x_train <span class="token operator">=</span> x_train
        self<span class="token punctuation">.</span>t_train <span class="token operator">=</span> t_train
        self<span class="token punctuation">.</span>x_test <span class="token operator">=</span> x_test
        self<span class="token punctuation">.</span>t_test <span class="token operator">=</span> t_test
        self<span class="token punctuation">.</span>epochs <span class="token operator">=</span> epochs
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> mini_batch_size
        self<span class="token punctuation">.</span>evaluate_sample_num_per_epoch <span class="token operator">=</span> evaluate_sample_num_per_epoch

        <span class="token comment"># 选择优化方式</span>
        optimizer_class_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'sgd'</span><span class="token punctuation">:</span> SGD<span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> Momentum<span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> Nesterov<span class="token punctuation">,</span>
                                <span class="token string">'adagrad'</span><span class="token punctuation">:</span> AdaGrad<span class="token punctuation">,</span> <span class="token string">'rmsprpo'</span><span class="token punctuation">:</span> RMSprop<span class="token punctuation">,</span> <span class="token string">'adam'</span><span class="token punctuation">:</span> Adam<span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> optimizer_class_dict<span class="token punctuation">[</span>optimizer<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token operator">**</span>optimizer_param<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>train_size <span class="token operator">=</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>iter_per_epoch <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>train_size <span class="token operator">/</span> mini_batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>max_iter <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>epochs <span class="token operator">*</span> self<span class="token punctuation">.</span>iter_per_epoch<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>current_iter <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>current_epoch <span class="token operator">=</span> <span class="token number">0</span>

        self<span class="token punctuation">.</span>train_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>train_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>test_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">train_step</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>self<span class="token punctuation">.</span>train_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        x_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>x_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
        t_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>t_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>

        <span class="token comment"># 调用网络的backward函数获取梯度</span>
        grads <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>

        <span class="token comment"># 使用优化器更新参数</span>
        self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>update<span class="token punctuation">(</span>self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>params<span class="token punctuation">,</span> grads<span class="token punctuation">)</span>

        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>train_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train loss:"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>current_iter <span class="token operator">%</span> self<span class="token punctuation">.</span>iter_per_epoch <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>current_epoch <span class="token operator">+=</span> <span class="token number">1</span>

            x_train_sample<span class="token punctuation">,</span> t_train_sample <span class="token operator">=</span> self<span class="token punctuation">.</span>x_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_train
            x_test_sample<span class="token punctuation">,</span> t_test_sample <span class="token operator">=</span> self<span class="token punctuation">.</span>x_test<span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_test
            <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>evaluate_sample_num_per_epoch <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                t <span class="token operator">=</span> self<span class="token punctuation">.</span>evaluate_sample_num_per_epoch
                x_train_sample<span class="token punctuation">,</span> t_train_sample <span class="token operator">=</span> self<span class="token punctuation">.</span>x_train<span class="token punctuation">[</span><span class="token punctuation">:</span>t<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_train<span class="token punctuation">[</span><span class="token punctuation">:</span>t<span class="token punctuation">]</span>
                x_test_sample<span class="token punctuation">,</span> t_test_sample <span class="token operator">=</span> self<span class="token punctuation">.</span>x_test<span class="token punctuation">[</span><span class="token punctuation">:</span>t<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_test<span class="token punctuation">[</span><span class="token punctuation">:</span>t<span class="token punctuation">]</span>

            <span class="token comment"># 计算训练精度train_acc和测试精度test_acc</span>
            train_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_train_sample<span class="token punctuation">,</span> t_train_sample<span class="token punctuation">)</span>
            test_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_test_sample<span class="token punctuation">,</span> t_test_sample<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>train_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>test_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span>

            <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span> <span class="token keyword">print</span><span class="token punctuation">(</span>
                <span class="token string">"=== epoch:"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>current_epoch<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">", train acc:"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span> <span class="token operator">+</span>
                <span class="token string">", test acc:"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" ==="</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>current_iter <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 训练循环</span>
            self<span class="token punctuation">.</span>train_step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        test_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x_test<span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_test<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=============== Final Test Accuracy ==============="</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"test acc:"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>


max_epochs <span class="token operator">=</span> <span class="token number">20</span>

<span class="token comment"># 将之前定义的SimpleConvNet网络实例化</span>
network <span class="token operator">=</span> SimpleConvNet<span class="token punctuation">(</span>input_dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                        conv_param<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'filter_num'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'filter_size'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'pad'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'stride'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                        hidden_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> weight_init_std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>network<span class="token punctuation">,</span> x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">,</span>
                  epochs<span class="token operator">=</span>max_epochs<span class="token punctuation">,</span> mini_batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">'Adam'</span><span class="token punctuation">,</span> optimizer_param<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.001</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                  evaluate_sample_num_per_epoch<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>
trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 绘制图形</span>
markers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">:</span> <span class="token string">'s'</span><span class="token punctuation">}</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>max_epochs<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> trainer<span class="token punctuation">.</span>train_acc_list<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> markevery<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> trainer<span class="token punctuation">.</span>test_acc_list<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'s'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">,</span> markevery<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"epochs"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_375"></a>四、结果分析</h2> 
<p><img src="https://images2.imgbox.com/2d/9c/wysBa90d_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6e/9b/nyPjVhEC_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/75/ca/shIfSHlx_o.png" alt="在这里插入图片描述"><br> 实验结果符合预期</p> 
<h2><a id="_381"></a>五、调试报告</h2> 
<p>1.控制台报错<br> Traceback (most recent call last):<br> File “E:/project/pythonProject/08_CNN/Trainer.py”, line 101, in <br> trainer = Trainer(network, x_train, t_train, x_test, t_test,<br> File “E:/project/pythonProject/08_CNN/Trainer.py”, line 35, in <strong>init</strong><br> self.optimizer = optimizer_class_dict<a href="**lr" rel="nofollow">optimizer.lower()</a><br> TypeError: type object argument after ** must be a mapping, not float<br> 解决：应该将训练类在初始化参数时的lr = 0.001改为optimizer_param={‘lr’:0.01}</p> 
<ol start="2"><li>控制台报错<br> Traceback (most recent call last):<br> File “E:/project/pythonProject/08_CNN/Trainer.py”, line 104, in <br> trainer.train()<br> File “E:/project/pythonProject/08_CNN/Trainer.py”, line 85, in train<br> self.train_step()<br> File “E:/project/pythonProject/08_CNN/Trainer.py”, line 53, in train_step<br> grads = self.network.backward(x_batch, t_batch)<br> File “E:\project\pythonProject\08_CNN\SimpleConvNet.py”, line 124, in backward<br> self.loss(x, t)<br> File “E:\project\pythonProject\08_CNN\SimpleConvNet.py”, line 99, in loss<br> return self.lastLayer.forward(y, t)<br> AttributeError: ‘SimpleConvNet’ object has no attribute ‘lastLayer’</li></ol> 
<p>原因：定义网络时参数用的是<br> <img src="https://images2.imgbox.com/4a/82/DorDK9un_o.png" alt="在这里插入图片描述"><br> 解决：改为lastLayer即可</p> 
<h2><a id="_411"></a>六、实验小结</h2> 
<p>本次实验使用numpy和两个展开函数实现了CNN的卷积和池化层，进一步理解了CNN的内部结构，并结合之前的实验搭建了一个简单的卷积神经网络进行手写体识别，采用反向传播和Adam来优化，在较短的时间内得到了较好的实验精度，可见CNN的优势所在。最大的收获是对卷积层和池化层原理的透彻理解。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/be7c6e7edc2fe8fdc052e0f4c627832a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【自然语言处理入门笔记】—— 二元语法与中文分词</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bd4442992d5f1ca67170516f2dc19347/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">CVPR 2021 | 即插即用！ CA：新注意力机制，助力分类/检测/分割涨点！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>