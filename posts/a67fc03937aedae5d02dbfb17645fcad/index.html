<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>目标检测：RCNN、Fast RCNN、 Faster RCNN 基本思想和网络结构介绍 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="目标检测：RCNN、Fast RCNN、 Faster RCNN 基本思想和网络结构介绍" />
<meta property="og:description" content="目录 一、目标检测的基本介绍1.1 什么是目标检测？1.2 目标检测算法的分类 二、RCNN2.1 RCNN简介2.2 RCNN算法流程2.3 RCNN流程图2.4 RCNN框架2.5 RCNN的缺点 三、Fast RCNN3.1 Fast RCNN简介3.2 Fast RCNN算法流程3.3 Fast RCNN流程图3.3.1 总体流程3.3.2 softmax 分类器3.3.3 边界框回归器（bbox regressor ） 3.3 Fast RCNN 中 loss 的计算3.4 Fast RCNN框架3.5 Fast RCNN的缺点 四、Faster RCNN4.1 Faster RCNN简介4.2 Faster RCNN算法流程4.2 RPN网络4.2.1 RPN网络结构4.2.2 anchor的定义4.2.3 RPN生成proposal的过程 4.3 Faster RCNN框架 五、三者的比较：RCNN、Fast RCNN、 Faster RCN六、参考资料 一、目标检测的基本介绍 1.1 什么是目标检测？ 所谓目标检测就是在一张图像中找到我们关注的目标，并确定它的类别和位置，这是计算机视觉领域最核心的问题之一。由于各类目标不同的外观，颜色，大小以及在成像时光照，遮挡等具有挑战性的问题，目标检测一直处于不断的优化和研究中。
1.2 目标检测算法的分类 传统的目标检测算法有：SIFT（尺度不变特征变换）、HOG（方向梯度直方图）、DPM（一种基于组件的图像检测算法）等。
基于深度学习的目标检测算法可以分为两类：二阶算法（Two Stage）和一阶算法（One Stage）
二阶算法：先生成区域候选框，再通过卷积神经网络进行分类和回归修正。常见算法有 RCNN、SPPNet、Fast RCNN，Faster RCNN 和 RFCN 等。二阶算法检测结果更精确。一阶算法：不生成候选框，直接在网络中提取特征来预测物体的分类和位置。常见算法有 SSD、YOLO系列 和 RetinaNet 等。一阶算法检测速度与更快。 二、RCNN 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/a67fc03937aedae5d02dbfb17645fcad/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-13T17:26:29+08:00" />
<meta property="article:modified_time" content="2023-07-13T17:26:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">目标检测：RCNN、Fast RCNN、 Faster RCNN 基本思想和网络结构介绍</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><ul><li><a href="#_1" rel="nofollow">一、目标检测的基本介绍</a></li><li><ul><li><a href="#11__2" rel="nofollow">1.1 什么是目标检测？</a></li><li><a href="#12__5" rel="nofollow">1.2 目标检测算法的分类</a></li></ul> 
   </li><li><a href="#RCNN_14" rel="nofollow">二、RCNN</a></li><li><ul><li><a href="#21__RCNN_15" rel="nofollow">2.1 RCNN简介</a></li><li><a href="#22__RCNN_25" rel="nofollow">2.2 RCNN算法流程</a></li><li><a href="#23__RCNN_95" rel="nofollow">2.3 RCNN流程图</a></li><li><a href="#24_RCNN_102" rel="nofollow">2.4 RCNN框架</a></li><li><a href="#25_RCNN_108" rel="nofollow">2.5 RCNN的缺点</a></li></ul> 
   </li><li><a href="#Fast_RCNN_117" rel="nofollow">三、Fast RCNN</a></li><li><ul><li><a href="#31__Fast_RCNN_118" rel="nofollow">3.1 Fast RCNN简介</a></li><li><a href="#32__Fast_RCNN_126" rel="nofollow">3.2 Fast RCNN算法流程</a></li><li><a href="#33__Fast_RCNN_150" rel="nofollow">3.3 Fast RCNN流程图</a></li><li><ul><li><a href="#331__151" rel="nofollow">3.3.1 总体流程</a></li><li><a href="#332_softmax__165" rel="nofollow">3.3.2 softmax 分类器</a></li><li><a href="#333_bbox_regressor__169" rel="nofollow">3.3.3 边界框回归器（bbox regressor ）</a></li></ul> 
    </li><li><a href="#33__Fast_RCNN__loss__183" rel="nofollow">3.3 Fast RCNN 中 loss 的计算</a></li><li><a href="#34_Fast_RCNN_187" rel="nofollow">3.4 Fast RCNN框架</a></li><li><a href="#35_Fast_RCNN_207" rel="nofollow">3.5 Fast RCNN的缺点</a></li></ul> 
   </li><li><a href="#Faster_RCNN_212" rel="nofollow">四、Faster RCNN</a></li><li><ul><li><a href="#41__Faster_RCNN_213" rel="nofollow">4.1 Faster RCNN简介</a></li><li><a href="#42__Faster_RCNN_216" rel="nofollow">4.2 Faster RCNN算法流程</a></li><li><a href="#42__RPN_237" rel="nofollow">4.2 RPN网络</a></li><li><ul><li><a href="#421_RPN_239" rel="nofollow">4.2.1 RPN网络结构</a></li><li><a href="#422_anchor_246" rel="nofollow">4.2.2 anchor的定义</a></li><li><a href="#423_RPNproposal_264" rel="nofollow">4.2.3 RPN生成proposal的过程</a></li></ul> 
    </li><li><a href="#43_Faster_RCNN_271" rel="nofollow">4.3 Faster RCNN框架</a></li></ul> 
   </li><li><a href="#RCNNFast_RCNN_Faster_RCN_280" rel="nofollow">五、三者的比较：RCNN、Fast RCNN、 Faster RCN</a></li><li><a href="#_293" rel="nofollow">六、参考资料</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_1"></a>一、目标检测的基本介绍</h3> 
<h4><a id="11__2"></a>1.1 什么是目标检测？</h4> 
<p>所谓目标检测就是在一张图像中找到我们关注的目标，并确定它的类别和位置，这是计算机视觉领域最核心的问题之一。由于各类目标不同的外观，颜色，大小以及在成像时光照，遮挡等具有挑战性的问题，目标检测一直处于不断的优化和研究中。</p> 
<h4><a id="12__5"></a>1.2 目标检测算法的分类</h4> 
<p>传统的目标检测算法有：SIFT（尺度不变特征变换）、HOG（方向梯度直方图）、DPM（一种基于组件的图像检测算法）等。</p> 
<p>基于深度学习的目标检测算法可以分为两类：二阶算法（Two Stage）和一阶算法（One Stage）</p> 
<ul><li>二阶算法：先生成区域候选框，再通过卷积神经网络进行分类和回归修正。常见算法有 RCNN、SPPNet、Fast RCNN，Faster RCNN 和 RFCN 等。二阶算法检测结果更精确。</li><li>一阶算法：不生成候选框，直接在网络中提取特征来预测物体的分类和位置。常见算法有 SSD、YOLO系列 和 RetinaNet 等。一阶算法检测速度与更快。</li></ul> 
<h3><a id="RCNN_14"></a>二、RCNN</h3> 
<h4><a id="21__RCNN_15"></a>2.1 RCNN简介</h4> 
<p>RCNN（Region with CNN feature）算法出现于2014年，是将深度学习应用到目标检测领域的开山之作，凭借卷积神经网络出色的特征提取能力，大幅度提升了目标检测的效果。</p> 
<p>RCNN在PASCAL VOC2012数据集上将检测率从35.1%提升至53.7%，使得CNN在目标检测领域成为常态，也使得大家开始探索CNN在其他计算机视觉领域的巨大潜力。</p> 
<p>论文：《 Rich feature hierarchies for accurate object detection and semantic segmentation 》<br> 作者：Ross Girshick<br> 源码（作者提供）：https://github.com/rbgirshick/rcnn</p> 
<h4><a id="22__RCNN_25"></a>2.2 RCNN算法流程</h4> 
<p>RCNN继承了传统目标检测的思想，将目标检测当做分类问题进行处理，先提取一系列目标的候选区域，然后对候选区域进行类。</p> 
<p>其具体算法流程包含以下4步：</p> 
<p><strong>（1）生成候选区域：</strong></p> 
<p>采用一定区域候选算法（如 Selective Search）将图像分割成小区域，然后合并包含同一物体可能性高的区域作为候选区域输出，这里也需要采用一些合并策略。不同候选区域会有重合部分，如下图所示（黑色框是候选区域）：</p> 
<img src="https://images2.imgbox.com/63/22/qL60XcQL_o.png" width="45%"> 
<p>        </p> 
<p>要生成1000-2000个候选区域（以2000个为例），之后将每个区域进行归一化，即缩放到固定的大小（227*227）</p> 
<p><strong>（2）对每个候选区域用CNN进行特征提取：</strong></p> 
<p>这里要事先选择一个预训练神经网络（如AlexNet、VGG），并重新训练全连接层，即 fintune 技术的应用。</p> 
<p>将候选区域输入训练好的AlexNet CNN网络，得到固定维度的特征输出（4096维），得到2000×4096的特征矩阵。<br>         </p> 
<img src="https://images2.imgbox.com/da/c4/fmCrhImu_o.png" width="65%"> 
<p>        <br> <strong>（3）用每一类的SVM分类器对CNN的输出特征进行分类：</strong></p> 
<p>此处以PASCAL VOC数据集为例，该数据集中有20个类别，因此设置20个SVM分类器。</p> 
<p>将 2000×4096 的特征与20个SVM组成的权值矩阵 4096×20 相乘，获得 2000×20 维的矩阵，表示2000个候选区域分别属于20个分类的概率，因此矩阵的每一行之和为1</p> 
<img src="https://images2.imgbox.com/8f/3e/h7pOwr6u_o.png" width="55%"> 
<p>        <br> 分别对上述2000×20维矩阵中每一列（即每一类）进行非极大值抑制剔除重叠建议框，得到该列即该类中概率最大的一些候选框。</p> 
<p><strong>非极大值抑制剔除重叠建议框的具体实现方法是：</strong></p> 
<p>第一步：定义 IoU 指数(Intersection over Union)，即 (A∩B) / (AUB) ，即AB的重合区域面积与AB总面积的比。直观上来讲 IoU 就是表示AB重合的比率， IoU越大说明AB的重合部分占比越大，即A和B越相似。</p> 
<img src="https://images2.imgbox.com/16/14/QWs5Zlo7_o.png" width="30%"> 
<p>        <br> 第二步：找到每一类中2000个候选区域中概率最高的区域，计算其他区域与该区域的IoU值，删除所有IoU值大于阈值的候选区域。这样可以只保留少数重合率较低的候选区域，去掉重复区域。</p> 
<p>比如下面的例子，A是向日葵类对应的所有候选框中概率最大的区域，B是另一个区域，计算AB的IoU，其结果大于阈值，那么就认为AB属于同一类（即都是向日葵），所以应该保留A，删除B，这就是非极大值抑制。</p> 
<img src="https://images2.imgbox.com/64/ec/S35RApQX_o.png" width="85%"> 
<p>        <br>         </p> 
<p>使用 SVM 进行二分类的一个问题是样本不均衡：背景图片很多，前景图片很少；导致 SVM 的训练需要解决样本不均衡的问题。</p> 
<p><strong>（4）使用回归器精修候选区域的位置：</strong></p> 
<p>通过 Selective Search算法得到的候选区域位置不一定准确，因此用20个回归器对上述20个类别中剩余的建议框进行回归操作，最终得到每个类别的修正后的目标区域。具体实现如下：</p> 
<p>如图，黄色框表示候选区域 Region Proposal,绿色窗口表示实际区域Ground Truth（人工标注的），红色窗口表示 Region Proposal 进行回归后的预测区域，可以用最小二乘法解决线性回归问题。</p> 
<p>通过回归器可以得到候选区域的四个参数，分别为：候选区域的x和y的偏移量，高度和宽度的缩放因子。可以通过这四个参数对候选区域的位置进行精修调整，就得到了红色的预测区域。</p> 
<img src="https://images2.imgbox.com/81/fa/nFE5IZv2_o.png" width="35%"> 
<p>        </p> 
<h4><a id="23__RCNN_95"></a>2.3 RCNN流程图</h4> 
<img src="https://images2.imgbox.com/96/cf/RHsjsgZM_o.png" width="120%"> 
<p>        </p> 
<h4><a id="24_RCNN_102"></a>2.4 RCNN框架</h4> 
<p>RCNN由四个部分组成：SS算法、CNN、SVM、bbox regression。</p> 
<img src="https://images2.imgbox.com/22/4b/LxMUNdOX_o.png" width="65%"> 
<p>        </p> 
<h4><a id="25_RCNN_108"></a>2.5 RCNN的缺点</h4> 
<p>（1）训练和测试速度慢，需要多步训练，非常繁琐。</p> 
<p>（2）由于涉及分类中的全连接网络，因此输入CNN的候选区域尺寸是固定的，造成了精度的降低。</p> 
<p>（3）候选区域需要提前提取并保存，占用的空间很大。对于非常深的网络，如VGG16，从VOCO7训练集上的5000张图片上提取的特征需要数百GB的存储空间，这个问题是致命的。</p> 
<p>RCNN 成为了当时目标检测领域的SOAT算法，尽管现在已经不怎么用了，但其思想仍然值得我们借鉴和学习。</p> 
<h3><a id="Fast_RCNN_117"></a>三、Fast RCNN</h3> 
<h4><a id="31__Fast_RCNN_118"></a>3.1 Fast RCNN简介</h4> 
<p>在RCNN之后，SPPNet解决了重复卷积计算和固定输出尺寸两个问题，SPPNet的主要贡献是在整张图像上计算全局特征图，然后对于特定的建议候选框，只需要在全局特征图上取出对应坐标的特征图就可以了。但SPPNe仍然存在一些弊端，如仍然需要将特征保存在磁盘中，速度还是很慢。</p> 
<p>Fast RCNN算法是2015年Ross Girshick（还是这位大佬）提出的，在RCNN和SPPNet的基础上进行了改进。根据名字就知道，Fast RCNN更快更强。其训练步骤实现了端到端，基于CGG16网络，其训练速度比RCNN快了9倍，测试速度快了213倍，在PASCAL VOC2012数据集达到了68.4%的准确率。</p> 
<p>论文：《Fast R-CNN》<br> 源码（作者提供）：https://github.com/rbgirshick/fast-rcnn</p> 
<h4><a id="32__Fast_RCNN_126"></a>3.2 Fast RCNN算法流程</h4> 
<p>（1）一张图像生成1K~2K个候选区域(使用Selective Search算法，简称SS算法)，我们将某个候选区域称为ROI区域。</p> 
<p>（2）将图像输入网络得到相应的特征图，将SS算法生成的候选框投影到特征图上获得相应的特征矩阵。</p> 
<p>R-CNN vs Fast-RCNN：</p> 
<p>R-CNN依次将2000个候选框区域输入卷积神经网络得到特征，存在大量冗余，提取时间很长。<br> Fast-RCNN将整张图像送入网络，一次性计算整张图像特征，这样就可以根据特征图的坐标获得想要的候选区域的特征图，不需要重复计算。</p> 
<p>（3）将每个特征矩阵通过 ROI pooling 层缩放到7×7大小的特征图。</p> 
<p>前面讲到RCNN需要将候选区域归一化到固定大小（227×227），而 Fast RCNN并不需要这样的操作，Fast RCNN 通过pooling层将每个候选区域的特征图都变为7×7，如下图所示：</p> 
<img src="https://images2.imgbox.com/5c/21/eSD8v4Tg_o.png" width="90%"> 
<p>        </p> 
<p>（4）将特征图展平（reshape）为向量，通过一系列全连接层和 softmax得到预测结果。</p> 
<h4><a id="33__Fast_RCNN_150"></a>3.3 Fast RCNN流程图</h4> 
<h5><a id="331__151"></a>3.3.1 总体流程</h5> 
<p>        </p> 
<img src="https://images2.imgbox.com/97/4b/q1xQiyO9_o.png" width="120%"> 
<p>        </p> 
<p>如图，将一张图像输入到 Deep ConvNet 中得到图像的特征图，根据ROI区域与整体图像的坐标映射关系 （RoI Projection）进行特征映射（Conv feature map），能够得到每一个候选区域（ROI区域）的特征矩阵。</p> 
<p>将每一个特征矩阵通过RoI pooling layer，池化到固定尺寸（7*7），然后展平为向量（vector）。再经过两个全连接层（fully connected layers,FC），得到ROI特征向量（ROI feature vector）。</p> 
<p>之后 ROI feature vector 并联两个FC，其中一个用于目标概率预测（softmax），另一个用于边界框参数的回归（bbox regressor，bbox 表示 bounding box）。</p> 
<h5><a id="332_softmax__165"></a>3.3.2 softmax 分类器</h5> 
<p>softmax 分类器输出N+1个类别的概率，如下图所示。PASCAL VOC2012数据集中有20个分类，因此会输出21个类别的概率，其中第一个为背景概率，其余20个为每个分类的概率。所以softmax的FC中有N+1个节点。</p> 
<p><img src="https://images2.imgbox.com/a0/9a/tvCt42hc_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="333_bbox_regressor__169"></a>3.3.3 边界框回归器（bbox regressor ）</h5> 
<p>一幅图片中会画出N+1个分类的候选框，每个候选框都有x、y、w、d四个参数，所以 bbox regressor 的FC中有 4(N+1) 个节点。</p> 
<p><img src="https://images2.imgbox.com/98/12/4ufsbEgc_o.png" alt="在这里插入图片描述"><br> 边界框参数回归的计算方法：</p> 
<img src="https://images2.imgbox.com/fd/15/dY6jmvML_o.png" width="85%"> 
<p>        </p> 
<h4><a id="33__Fast_RCNN__loss__183"></a>3.3 Fast RCNN 中 loss 的计算</h4> 
<p>因为在Fast RCNN 中需要预测N+1个类别的概率以及边界框的回归参数，所以定义了两个损失函数：分类损失和边界框回归损失。</p> 
<p><img src="https://images2.imgbox.com/9c/0d/tKk9Pwkk_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="34_Fast_RCNN_187"></a>3.4 Fast RCNN框架</h4> 
<p>首先回顾一下RCNN的框架：</p> 
<img src="https://images2.imgbox.com/71/c9/HStYboXS_o.png" width="65%"> 
<p>        </p> 
<p>RCNN由四部分组成，因此需要多步训练，非常繁琐。</p> 
<p>Fast RCNN将CNN特征提取，SVM边界框分类，bbox regression边界框回归三部分结合到了一起，都融合到同一个CNN中。那么Fast RCNN就只有两部分了：先通过SS算法获取候选框，再通过CNN完成特征提取、分类和边界框回归。</p> 
<img src="https://images2.imgbox.com/b2/d2/BT90Gllb_o.png" width="65%"> 
<p>        </p> 
<p>那么自然而然的，在接下来的 Faster RCNN 算法中，就要考虑如何将 Region proposal 也融入到CNN中，将整个算法合并为一个网络，这样就可以实现端到端的目标检测。</p> 
<h4><a id="35_Fast_RCNN_207"></a>3.5 Fast RCNN的缺点</h4> 
<p>1、尽管用到了GPU，但Region proposal还是在CPU上实现的。在CPU中，用SS算法提取一张图片的候选框区域大约需要2s，而完成整个CNN则只需要0.32s，因此Fast RCNN 计算速度的瓶颈是Region proposal。</p> 
<p>2、无法满足实时应用，没有真正实现端到端训练测试；</p> 
<h3><a id="Faster_RCNN_212"></a>四、Faster RCNN</h3> 
<h4><a id="41__Faster_RCNN_213"></a>4.1 Faster RCNN简介</h4> 
<p>Faster RCNN 是作者 Ross Girshick 继 RCNN 和 Fast RCNN后的又一力作。同样使用 VGG16作为网络的backbone，推理速度在GPU上达到5fps(包括候选区域的生成)，准确率也有进一步的提升。在2015年的ILSVRC以及cOco竞赛中获得多个项目的第一名。</p> 
<h4><a id="42__Faster_RCNN_216"></a>4.2 Faster RCNN算法流程</h4> 
<blockquote> 
 <p>Faster RCNN = RPN + Fast RCNN</p> 
</blockquote> 
<p>RPN 是指 Region Proposal Network，建议区域生成网络。 Faster RCNN 中用 RPN 来代替了 Fast RCNN 中的SS算法。</p> 
<p><strong>算法流程：</strong></p> 
<p>（1）将图像输入CNN网络得到相应的特征图。</p> 
<p>（2）使用RPN网络生成候选框，将RPN生成的候选框投影到特征图上获得ROI区域的特征矩阵。</p> 
<p>（3）将每个ROI区域的特征矩阵通过 ROI pooling 层缩放到7×7大小的特征图，接着将特征图展平为vector，之后通过一系列全连接层得到预测结果。</p> 
<p><strong>Faster RCNN 网络的基本结构如下：</strong></p> 
<img src="https://images2.imgbox.com/e5/41/VlxT8pj8_o.png" width="65%"> 
<p>        </p> 
<h4><a id="42__RPN_237"></a>4.2 RPN网络</h4> 
<h5><a id="421_RPN_239"></a>4.2.1 RPN网络结构</h5> 
<img src="https://images2.imgbox.com/83/68/k4XpIXZr_o.png" width="80%"> 
<p>        <br> 图中的 conv feature map 是图像输入网络得到相应的特征图，通过sliding window处理之后产生一个256d的一维向量。该向量通过两个全连接层，分别输出分类概率scores和边界框回归参数coordinates，其中k是指 k个 anchor boxes，2k个scores是每个 anchor box 分别为前景和背景的概率（注意这里只区分前景和背景，所有的类别都归为前景），4k个coordinates是因为每个anchor box 有四个参数。</p> 
<h5><a id="422_anchor_246"></a>4.2.2 anchor的定义</h5> 
<p>那么什么是 anchor呢？</p> 
<p>首先要明确，anchor不是候选框（Proposal），后面会提到二者的区别。</p> 
<p>我们在特征图中找一个点，就可以在原图中找到对应的一个像素点，以该像素点为中心，画出9个不同大小和长宽比的框，称为anchor 。如下图所示，这些anchor里面可能包含目标，也可能没有目标。因为我们在一张图中想找的的目标的大小和长宽比并不是固定的，所以这里用9个不同大小和长宽比的anchor来进行预测。</p> 
<p><img src="https://images2.imgbox.com/bc/db/tp6MOUJz_o.png" alt="在这里插入图片描述"><br> 那么为什么是9个anchor呢？</p> 
<p>论文中给出了每个anchor的面积和长宽比：</p> 
<p><img src="https://images2.imgbox.com/de/37/yg9MA4CQ_o.png" alt="在这里插入图片描述"></p> 
<p>所以特征图中的每个位置在原图中都会生成 3×3=9 个anchor，如下图所示，蓝色的三个anchor是面积为128×128的，红色是面积为256×256的，绿色是512×512的。</p> 
<p><img src="https://images2.imgbox.com/ec/2b/m2Nq7I8i_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="423_RPNproposal_264"></a>4.2.3 RPN生成proposal的过程</h5> 
<p>对于一张 1000x600x3 的图像（三通道），用3x3的卷积核进行特征提取得到60x40的特征图，则共有 60x40x9 （约2w个）个anchor。忽略超过图片边界的 anchor 后，剩下约 6000 个anchor。</p> 
<p>对于这6000 个 anchor，通过RPN生成的边界框回归参数将每个 anchor 调整为proposal（前面提到了每个anchor经过RPN都输出2个概率和4个边界框回归参数），这里就能看到anchor和proposal的区别。这个过程就是 RPN 生成候选框的过程。</p> 
<p>RPN 生成的候选框之间存在大量重叠，基于候选框的cls得分，采用非极大值抑制，IoU设为0.7，这样每张图片只剩下 2000 个候选框。</p> 
<h4><a id="43_Faster_RCNN_271"></a>4.3 Faster RCNN框架</h4> 
<img src="https://images2.imgbox.com/d0/2c/kDtQ909a_o.png" width="65%"> 
<p>        <br> Faster RCNN 在Fast RCNN的基础上更进一步，将候选框生成也融入到CNN网络中，使得 候选框生成、特征提取、候选框分类、候选框边界回归这四大部分都结合在一个CNN网络中，避免了分步训练，实现了真正端到端的目标检测。<br>         </p> 
<h3><a id="RCNNFast_RCNN_Faster_RCN_280"></a>五、三者的比较：RCNN、Fast RCNN、 Faster RCN</h3> 
<p>三者都是二阶算法，网络框架比较：</p> 
<img src="https://images2.imgbox.com/29/09/LC9dl6Pz_o.png" width="120%"> 
<p>        </p> 
<p>可以看到，从RCNN、Fast RCNN 到 Faster RCNN，网络框架越来越简洁，目标检测效果也越来越好。</p> 
<p>三者的优缺点比较：<br>         <br> <img src="https://images2.imgbox.com/30/97/PymoJpFN_o.png" alt="在这里插入图片描述"><br>         </p> 
<h3><a id="_293"></a>六、参考资料</h3> 
<p>视频（B站）：<a href="https://www.bilibili.com/video/BV1af4y1m7iL?p=1" rel="nofollow">Faster RCNN理论合集</a></p> 
<p>博客：<a href="https://blog.csdn.net/qq_17448289/article/details/52871461">Faster R-CNN论文笔记——FR</a></p> 
<p>博客：<a href="https://blog.csdn.net/weixin_45564943/article/details/121877359">Faster RCNN 优缺点说明</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/64377b7063656b087184860e2081ab55/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python 教学 | Pandas 妙不可言的条件数据筛选</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ecf38707673354b15994c33e35a6511e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vs2019&#43;pcl1.11.1库安装与环境配置教程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>