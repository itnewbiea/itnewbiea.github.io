<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>李宏毅机器学习第十九周周报GAN3 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="李宏毅机器学习第十九周周报GAN3" />
<meta property="og:description" content="文章目录 week 19 GAN3摘要Abstract一、李宏毅机器学习——GAN31. Introduce2. Difficulty in GAN training3. Evaluation of Generation4. Conditional Generation 二、文献阅读1. 题目2. abstract3. 文章主要内容3.1 基于GANs的双时间尺度更新规则3.2 Adam确保TTUR收敛3.2.1 使用Adam以降低收敛至局域最小的概率3.2.2 分析是否收敛的过程 4. 文献解读4.1 Introduction4.2 创新点4.3 实验过程4.3.1 性能指标4.3.2 模型选择与评估4.3.3 图像数据上的WGAN-GP4.3.4 语言数据上的WGAN-GP 4.4 结论 三、pytorch实现diffusion模型1. 实验结果2. 实验代码小结参考文献 week 19 GAN3 摘要 本文主要讨论了生成式对抗神经网络。首先，本文介绍了GAN训练困难性以及其在训练过程中可能出现的问题。在此基础下，本文阐述了一种可以更好评估网络的标准——Fréchet Inception Distance（FID）。此外，本文简要介绍了Conditional GAN的各种应用以及大致框架。其次本文展示了题为GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium的论文主要内容。这篇论文提出了双时间尺度更新规则（TTUR），并证明了使用Adam和TTUR训练GAN的收敛性。同时，该文设计了一系列实验用于评估该方法的优越性并在实验中引入了FID作为评估标准。最后，本文基于pytorch实现了Diffusion并用于绘制S型曲线。
Abstract This article focuses on GAN. First of all, this article introduces the difficulty of GAN training and the problems that may arise during its training." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/d846ff5d5c87011d88e420e369bf415c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-02T23:27:01+08:00" />
<meta property="article:modified_time" content="2023-12-02T23:27:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">李宏毅机器学习第十九周周报GAN3</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#week_19_GAN3_3" rel="nofollow">week 19 GAN3</a></li><li><a href="#_6" rel="nofollow">摘要</a></li><li><a href="#Abstract_10" rel="nofollow">Abstract</a></li><li><a href="#GAN3_14" rel="nofollow">一、李宏毅机器学习——GAN3</a></li><li><ul><li><a href="#1_Introduce_16" rel="nofollow">1. Introduce</a></li><li><a href="#2_Difficulty_in_GAN_training_30" rel="nofollow">2. Difficulty in GAN training</a></li><li><a href="#3_Evaluation_of_Generation_48" rel="nofollow">3. Evaluation of Generation</a></li><li><a href="#4_Conditional_Generation_92" rel="nofollow">4. Conditional Generation</a></li></ul> 
  </li><li><a href="#_110" rel="nofollow">二、文献阅读</a></li><li><ul><li><a href="#1__112" rel="nofollow">1. 题目</a></li><li><a href="#2_abstract_120" rel="nofollow">2. abstract</a></li><li><a href="#3__126" rel="nofollow">3. 文章主要内容</a></li><li><ul><li><a href="#31_GANs_128" rel="nofollow">3.1 基于GANs的双时间尺度更新规则</a></li><li><a href="#32_AdamTTUR_141" rel="nofollow">3.2 Adam确保TTUR收敛</a></li><li><a href="#321_Adam_143" rel="nofollow">3.2.1 使用Adam以降低收敛至局域最小的概率</a></li><li><ul><li><a href="#322__153" rel="nofollow">3.2.2 分析是否收敛的过程</a></li></ul> 
   </li></ul> 
   </li><li><a href="#4__186" rel="nofollow">4. 文献解读</a></li><li><ul><li><a href="#41_Introduction_188" rel="nofollow">4.1 Introduction</a></li><li><a href="#42__196" rel="nofollow">4.2 创新点</a></li><li><a href="#43__203" rel="nofollow">4.3 实验过程</a></li><li><ul><li><a href="#431___205" rel="nofollow">4.3.1 性能指标</a></li><li><a href="#432__224" rel="nofollow">4.3.2 模型选择与评估</a></li><li><a href="#433_WGANGP_240" rel="nofollow">4.3.3 图像数据上的WGAN-GP</a></li><li><a href="#434_WGANGP_254" rel="nofollow">4.3.4 语言数据上的WGAN-GP</a></li></ul> 
    </li><li><a href="#44__268" rel="nofollow">4.4 结论</a></li></ul> 
  </li></ul> 
  </li><li><a href="#pytorchdiffusion_272" rel="nofollow">三、pytorch实现diffusion模型</a></li><li><ul><li><a href="#1__278" rel="nofollow">1. 实验结果</a></li><li><a href="#2__288" rel="nofollow">2. 实验代码</a></li><li><a href="#_558" rel="nofollow">小结</a></li><li><a href="#_560" rel="nofollow">参考文献</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="week_19_GAN3_3"></a>week 19 GAN3</h2> 
<h2><a id="_6"></a>摘要</h2> 
<p>本文主要讨论了生成式对抗神经网络。首先，本文介绍了GAN训练困难性以及其在训练过程中可能出现的问题。在此基础下，本文阐述了一种可以更好评估网络的标准——Fréchet Inception Distance（FID）。此外，本文简要介绍了Conditional GAN的各种应用以及大致框架。其次本文展示了题为GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium的论文主要内容。这篇论文提出了双时间尺度更新规则（TTUR），并证明了使用Adam和TTUR训练GAN的收敛性。同时，该文设计了一系列实验用于评估该方法的优越性并在实验中引入了FID作为评估标准。最后，本文基于pytorch实现了Diffusion并用于绘制S型曲线。</p> 
<h2><a id="Abstract_10"></a>Abstract</h2> 
<p>This article focuses on GAN. First of all, this article introduces the difficulty of GAN training and the problems that may arise during its training. On this basis, this article elaborates on a standard that can better evaluate networks—Fréchet Inception Distance(FID). In addition, this article briefly introduces the various applications of Conditional GAN and the general framework. Secondly, this paper presents the main content of the paper entitled GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. This paper proposes a two time-scale update rule (TTUR) and demonstrates the convergence of training GANs using Adam and TTUR. At the same time, this paper designs a series of experiments to evaluate the superiority of the method, and introduces FID as the evaluation criterion in the experiments. Finally, this article implements Diffusion model based on pytorch and plot S-shaped curves wirh it.</p> 
<h2><a id="GAN3_14"></a>一、李宏毅机器学习——GAN3</h2> 
<h3><a id="1_Introduce_16"></a>1. Introduce</h3> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            max 
           
          
            ⁡ 
           
          
          
          
            D 
           
          
            ∈ 
           
          
            1 
           
          
            − 
           
          
            L 
           
          
            i 
           
          
            p 
           
          
            s 
           
          
            c 
           
          
            h 
           
          
            i 
           
          
            t 
           
          
            z 
           
          
         
        
          { 
         
         
         
           E 
          
          
          
            y 
           
          
            ∼ 
           
           
           
             P 
            
            
            
              d 
             
            
              a 
             
            
              t 
             
            
              a 
             
            
           
          
         
        
          [ 
         
        
          D 
         
        
          ( 
         
        
          y 
         
        
          ) 
         
        
          ] 
         
        
          − 
         
         
         
           E 
          
          
          
            y 
           
          
            ∼ 
           
           
           
             P 
            
           
             G 
            
           
          
            [ 
           
          
            D 
           
          
            ( 
           
          
            y 
           
          
            ) 
           
          
            ] 
           
          
         
        
          } 
         
        
       
         \max_{D\in1-Lipschitz}\{E_{y\sim P_{data}}[D(y)]-E_{y\sim P_G[D(y)]}\} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.6382em; vertical-align: -0.8882em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.4306em;"><span class="" style="top: -2.3479em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span><span class="mrel mtight">∈</span><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">sc</span><span class="mord mathnormal mtight">hi</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right: 0.044em;">z</span></span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.8882em;"><span class=""></span></span></span></span></span><span class="mopen">{<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0576em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: -0.1389em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mclose">)]</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1052em; vertical-align: -0.3552em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: -0.0576em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3567em; margin-left: -0.1389em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1433em;"><span class=""></span></span></span></span></span></span><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="mclose mtight">)]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span></span></p> 
<p>上述是上节中WGAN的目标公式，而在此思路下，效果最好的神经网络是<a href="https://arxiv.org/abs/1802.05957" rel="nofollow">SNGAN</a></p> 
<p>尽管有WGAN，但GAN仍然难以训练。由于两者在训练过程中是相互对抗的，当一者收敛时（但效果不佳），另一个也将收敛。</p> 
<p>以下是几种改进训练过程的tips</p> 
<p><img src="https://images2.imgbox.com/91/1e/0OKrSDcw_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2_Difficulty_in_GAN_training_30"></a>2. Difficulty in GAN training</h3> 
<p>在训练GAN语言模型时，通常Discriminator会难以训练。这是因为当改变decoder时，网络内部的token可能发生较大的变化，但generator 的输出结果可能并没有变动。在这种情况下，discriminator并不会变化，此时其无需修改。</p> 
<p><img src="https://images2.imgbox.com/11/ba/4qCEeImi_o.png" alt="image-20231121211719876"></p> 
<p>前文描述了GAN难以训练的原因，但GAN仍然可以通过多种pretrain方法来降低训练难度。<a href="https://arxiv.org/abs/1905.09922" rel="nofollow">Training language GANs from Scratch</a>中给出了多种pretrain方法并将其与文中的baseline比较得出了每个方法对于GAN的提升幅度。</p> 
<p><img src="https://images2.imgbox.com/72/0b/lOYIbo2l_o.png" alt="image-20231121212917193"></p> 
<p>以下还提供了几个有价值的生成式模型，并提供了链接（GAN原文在week17已经讨论，故不在此处给出链接）</p> 
<p><img src="https://images2.imgbox.com/49/95/g7w5dnJ4_o.png" alt="image-20231121212849033"></p> 
<p>当然也可以按照一定规律为图片匹配one-hot vector，从而增强模型的效果，下图给出了大致过程与文章链接</p> 
<p><img src="https://images2.imgbox.com/ef/82/sgmv8tUm_o.png" alt="image-20231121213617549"></p> 
<h3><a id="3_Evaluation_of_Generation_48"></a>3. Evaluation of Generation</h3> 
<p>在没有有效方法以前，通常使用人为评价标准。而在作业6中，使用动漫人脸探测作为评价标准，在一张图片中抓到的人脸越多，则说明该生成器的效果更加。但该探测器仅对作业6生效</p> 
<p>另一种方法是再训练一个影像分类模型，将图像输入模型，模型输出图像属于各个类别的概率分布。当概率分布较为集中时，意味着分类器能够较为清晰的辨别出图像，即生成器能够生成易于辨别的图像。</p> 
<p><img src="https://images2.imgbox.com/b8/cf/O9YkHaE5_o.png" alt="image-20231121215036608"></p> 
<p>但仅使用上述方法是不可行的，可能出现mode collapse的问题。该问题是指模型生成的图像在分布上趋向于围绕单一数据点，或者仅分布在一类数据点周围。</p> 
<p><img src="https://images2.imgbox.com/32/70/AuIYaTVs_o.png" alt="image-20231121215856613"></p> 
<p>还有另一种更难以侦测的问题，mode dropping。在单一iteration内该问题并不明显，但在进行一次迭代后，可能会出现下图中的情况，这意味着模型并不稳定。其分布如下图所示</p> 
<p><img src="https://images2.imgbox.com/70/94/ZB29c8ye_o.png" alt="image-20231121220924330"></p> 
<p>对于mode collapse，可以让生成器生成一个批次的图片，使用分类器处理这些图片，然后将分类器输出<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         P 
        
       
         ( 
        
       
         c 
        
       
         ∣ 
        
        
        
          y 
         
        
          i 
         
        
       
         ) 
        
       
      
        P(c|y^i) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0747em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>的分布取平均<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         P 
        
       
         ( 
        
       
         c 
        
       
         ) 
        
       
      
        P(c) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mclose">)</span></span></span></span></span>。若结果集中在一个类别上，那么意味着该生成器的结果丰富度较低。相反，若其丰富度较高，则均值分布应该是在各个类别上较为平均分布的。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          P 
         
        
          ( 
         
        
          c 
         
        
          ) 
         
        
          = 
         
         
         
           1 
          
         
           N 
          
         
         
         
           ∑ 
          
         
           n 
          
         
        
          P 
         
        
          ( 
         
        
          c 
         
        
          ∣ 
         
         
         
           y 
          
         
           n 
          
         
        
          ) 
         
        
       
         P(c)=\frac1N\sum_{n}P(c|y^n) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.5714em; vertical-align: -1.25em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.05em;"><span class="" style="top: -1.9em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.25em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7144em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><br> 基于上述思路有inception score（IS），该评估标准对质量和丰富度均有要求，当两者均较大时，IS较大。但对于人脸识别任务（HW6），由于其识别的目标均是人脸，尽管人物的各项特征可能有所不同，但是对于IS标准而言其丰富度仍是较低的，因此该任务不适合使用该评价标准。</p> 
<p>下图描述了分布集中，丰富度较低的情况。</p> 
<p><img src="https://images2.imgbox.com/f7/b2/bpkChDU0_o.png" alt="image-20231121221545653"></p> 
<p>Fréchet Inception Distance（FID）</p> 
<p>相对IS，FID使用卷积神经网络在softmax之前的vector，该向量的维数相较于softmax输出的概率分布更高。因此该向量可以更充分反应图像的特征，例如在遇到上文中的mode dropping情况时，该向量会因为迭代后人的面部肤色变化而改变，FID则通过变化推断出生成器分布可能发生了mode dropping。</p> 
<p>而从计算角度来解释，假定下图中红色点代表cnn输出的真实图片的特征向量在特征空间内的分布情况，而蓝色则代表生成图片。FID要做的是计算两个高斯分布之间的Fréchet Distance</p> 
<p>但该评价标准也有缺点，例如特征空间内的分布可能不是高斯分布，又或者不太确定生成图片的数量，太少不能很好的反应分布，而太多会浪费算量。上述原因会导致FID可能无法精确的评估模型，因此在HW6中需要同时考虑在探测器分辨出的人脸数量以及FID。</p> 
<p><img src="https://images2.imgbox.com/d6/de/oT7hZ9Fn_o.png" alt="image-20231122203525200"></p> 
<p>下图使用FID评估各种网络架构，各个架构均使用相同的网络结构，但使用不同的random seed在large-scale dataset上训练。可以看出GAN的loss分布范围较大，而VAE相对稳定，但部分GAN的下限要比VAE低。然而由于该研究使用了相同的网络架构，而各个网络适应的加过不同，可能导致结果出现偏差。</p> 
<p><img src="https://images2.imgbox.com/e9/65/bfttIjMf_o.png" alt="image-20231122204617203"></p> 
<p>除了上文中提到的问题以外，GAN还可能生成真实数据差异不大或者其翻转。这时FID很低，但评估无效，因此GAN还需要更多评价标准。下图的论文系统性的讨论了GAN的评价标准</p> 
<p><img src="https://images2.imgbox.com/ae/bb/KHcpMmIu_o.png" alt="image-20231122205348340"></p> 
<h3><a id="4_Conditional_Generation_92"></a>4. Conditional Generation</h3> 
<p>相较于non-conditional generation，该类网络使用输入特征x以及简单分布z作为网络输入。</p> 
<p>相应的，辨别器也应当作出改变，因为non-conditional的分辨器仅需要考虑生成的图片是否和输入特征x相匹配。该分辨器的输入应当是生成图片y和x，输出是y是否真实以及x和y是否匹配。</p> 
<p><img src="https://images2.imgbox.com/e0/66/Iol1Xw1L_o.png" alt="image-20231122210945536"></p> 
<p>conditional GAN除了上文中的text to image以外，还可以是pix2pix。在这类任务上，使用监督学习可以使得生成图片的结构大致相似，而使用GAN可以生成更加真实的图片。因此可以将二者同时使用</p> 
<p><img src="https://images2.imgbox.com/0e/13/MqUqk03q_o.png" alt="image-20231122212119585"></p> 
<p>此外，还有很多可以使用GAN完成的任务，例如输入声音生成图片，或是根据输入的图片以及声音让图片动起来。</p> 
<h2><a id="_110"></a>二、文献阅读</h2> 
<h3><a id="1__112"></a>1. 题目</h3> 
<p>题目：GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium</p> 
<p>作者：<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heusel,+M" rel="nofollow">Martin Heusel</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramsauer,+H" rel="nofollow">Hubert Ramsauer</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Unterthiner,+T" rel="nofollow">Thomas Unterthiner</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nessler,+B" rel="nofollow">Bernhard Nessler</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hochreiter,+S" rel="nofollow">Sepp Hochreiter</a></p> 
<p>发布：NIPS2017</p> 
<h3><a id="2_abstract_120"></a>2. abstract</h3> 
<p>该文提出了一种两时间尺度更新规则（TTUR），用于在任意GAN损失函数上使用随机梯度下降来训练GAN。该文证明了TTUR在温和假设下收敛于稳态局部Nash均匀。此外，该文引入了Fréchet Inception Distance（FID）作为评估标准，它比 Inception Score 更好地捕获了生成图像与真实图像的相似性。</p> 
<p>This article proposes a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. It also prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. In addition, this article introduces the ‘Fréchet Inception Distance”(FID) as an evaluation criterion, which captures the similarity of generated images to real ones better than the Inception Score.</p> 
<h3><a id="3__126"></a>3. 文章主要内容</h3> 
<h4><a id="31_GANs_128"></a>3.1 基于GANs的双时间尺度更新规则</h4> 
<p>假定有判别器<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         D 
        
       
         ( 
        
       
         . 
        
       
         ; 
        
       
         w 
        
       
         ) 
        
       
      
        D(.;w) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord">.</span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span></span></span></span></span>以及生成器<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         G 
        
       
         ( 
        
       
         . 
        
       
         ; 
        
       
         θ 
        
       
         ) 
        
       
      
        G(.;\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord">.</span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span>，其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         w 
        
       
         , 
        
       
         θ 
        
       
      
        w,\theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span></span></span></span></span>均是参数向量；训练基于随机梯度，判别器损失函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
        
          D 
         
        
       
      
        \mathcal L_D 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的随机梯度为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          g 
         
        
          ~ 
         
        
       
         ( 
        
       
         θ 
        
       
         ; 
        
       
         w 
        
       
         ) 
        
       
      
        \tilde g(\theta;w) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">~</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1944em;"><span class=""></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span></span></span></span></span>，生成器损失函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
        
          G 
         
        
       
      
        \mathcal L_G 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的随机梯度为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          ~ 
         
        
       
         ( 
        
       
         θ 
        
       
         , 
        
       
         w 
        
       
         ) 
        
       
      
        \tilde h(\theta,w) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1813em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.9313em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">h</span></span><span class="" style="top: -3.6134em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span></span></span></span></span>。两个损失函数不一定相关。若真实梯度是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         g 
        
       
         ( 
        
       
         θ 
        
       
         , 
        
       
         w 
        
       
         ) 
        
       
         = 
        
        
        
          ∇ 
         
        
          w 
         
        
        
        
          L 
         
        
          D 
         
        
       
         , 
        
       
         h 
        
       
         ( 
        
       
         θ 
        
       
         , 
        
       
         w 
        
       
         ) 
        
       
         = 
        
        
        
          ∇ 
         
        
          θ 
         
        
        
        
          L 
         
        
          G 
         
        
       
      
        g(\theta,w)=\nabla_w\mathcal L_D,h(\theta,w)=\nabla_\theta\mathcal L_G 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，则定义梯度<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          g 
         
        
          ~ 
         
        
       
         ( 
        
       
         θ 
        
       
         ， 
        
       
         w 
        
       
         ) 
        
       
         = 
        
       
         g 
        
       
         ( 
        
       
         θ 
        
       
         , 
        
       
         w 
        
       
         ) 
        
       
         + 
        
       
         M 
        
       
         ( 
        
       
         w 
        
       
         ) 
        
       
      
        \tilde g(\theta，w)=g(\theta,w)+M(w) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">~</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1944em;"><span class=""></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mord cjk_fallback">，</span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">M</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          ~ 
         
        
       
         ( 
        
       
         θ 
        
       
         , 
        
       
         w 
        
       
         ) 
        
       
         = 
        
       
         h 
        
       
         ( 
        
       
         θ 
        
       
         , 
        
       
         w 
        
       
         ) 
        
       
         + 
        
       
         M 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
      
        \tilde h(\theta,w)=h(\theta,w)+M(\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1813em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.9313em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">h</span></span><span class="" style="top: -3.6134em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">M</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span>，随机变量为M(w)和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         M 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
      
        M(\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">M</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span>。通过双尺度随机近似算法来分析GAN的收敛性。对于TTUR，分别使用学习率b(n)和a(n)进行判别器和生成器的更新：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              w 
             
             
             
               n 
              
             
               + 
              
             
               1 
              
             
            
           
             = 
            
            
            
              w 
             
            
              n 
             
            
           
             + 
            
           
             b 
            
           
             ( 
            
           
             n 
            
           
             ) 
            
           
             ( 
            
           
             g 
            
           
             ( 
            
            
            
              θ 
             
            
              n 
             
            
           
             , 
            
            
            
              w 
             
            
              n 
             
            
           
             ) 
            
           
             + 
            
            
            
              M 
             
            
              n 
             
             
             
               ( 
              
             
               w 
              
             
               ) 
              
             
            
           
             ) 
            
           
             ) 
            
           
             , 
            
            
            
              θ 
             
             
             
               n 
              
             
               + 
              
             
               1 
              
             
            
           
             = 
            
            
            
              θ 
             
            
              n 
             
            
           
             + 
            
           
             a 
            
           
             ( 
            
           
             n 
            
           
             ) 
            
           
             ( 
            
           
             h 
            
           
             ( 
            
            
            
              θ 
             
            
              n 
             
            
           
             , 
            
            
            
              w 
             
            
              n 
             
            
           
             ) 
            
           
             + 
            
            
            
              M 
             
            
              n 
             
             
             
               ( 
              
             
               θ 
              
             
               ) 
              
             
            
           
             ) 
            
           
          
          
          
          
            (1) 
           
          
         
        
       
         w_{n+1}=w_n+b(n)(g(\theta_n,w_n)+M_n^{(w)})),\theta_{n+1}=\theta_n+a(n)(h(\theta_n,w_n)+M_n^{(\theta)}) \tag{1} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6389em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">b</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.188em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -2.453em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose">))</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.188em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -2.453em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">θ</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 1.188em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></span><br> <img src="https://images2.imgbox.com/65/14/MpsABPuX_o.jpg" alt="微信图片_20231123230039"></p> 
<p>上述过程证明了TTUR可收敛，而下图给出了其具体的线性更新规则以及各部分的含义（不包括上文已经给出的部分）。</p> 
<p><img src="https://images2.imgbox.com/7b/d7/NdAAxtjN_o.jpg" alt="微信图片_20231124150912"></p> 
<h4><a id="32_AdamTTUR_141"></a>3.2 Adam确保TTUR收敛</h4> 
<h4><a id="321_Adam_143"></a>3.2.1 使用Adam以降低收敛至局域最小的概率</h4> 
<p>作者计划使用Adam随机拟合以规避mode collapsing（课程部分已经给出，不再赘述）。</p> 
<p>在作者的描述中，Adam被看作具有摩擦力的的重球（HBF），因其对过去梯度进行平均。该均值能在生成器能够抵抗被推入小区域时提供速度。</p> 
<p><img src="https://images2.imgbox.com/5e/14/NKzT6gKc_o.png" alt="image-20231124152028151"></p> 
<p>简单来说，如上图，Adam能够在<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          θ 
         
        
          + 
         
        
       
      
        \theta^+ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span>位置为生成器提供速度，使得其能够脱离局部最极小值，并进一步达到平滑最小值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          θ 
         
        
          ∗ 
         
        
       
      
        \theta^* 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span></p> 
<h5><a id="322__153"></a>3.2.2 分析是否收敛的过程</h5> 
<p>第n步的Adam更新规则，</p> 
<ul><li>学习率为a</li><li>梯度<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ∇ 
         
        
          f 
         
        
          ( 
         
         
         
           θ 
          
          
          
            n 
           
          
            − 
           
          
            1 
           
          
         
        
          ) 
         
        
       
         \nabla f(\theta_{n-1}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></li><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           β 
          
         
           1 
          
         
        
       
         \beta_1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，第一次估计的指数衰减率</li><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           β 
          
         
           2 
          
         
        
       
         \beta_2 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，第二次估计的指数衰减率</li><li><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ϵ 
         
        
       
         \epsilon 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span></span>，防止在计算过程中除以零</li></ul> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              g 
             
            
              n 
             
            
           
             ← 
            
           
             ∇ 
            
           
             f 
            
           
             ( 
            
            
            
              θ 
             
             
             
               n 
              
             
               − 
              
             
               1 
              
             
            
           
             ) 
            
            
            
            
              m 
             
            
              n 
             
            
           
             ← 
            
           
             ( 
            
            
            
              β 
             
            
              1 
             
            
           
             / 
            
           
             ( 
            
           
             1 
            
           
             − 
            
            
            
              β 
             
            
              1 
             
            
              n 
             
            
           
             ) 
            
           
             ) 
            
            
            
              m 
             
             
             
               n 
              
             
               − 
              
             
               1 
              
             
            
           
             + 
            
           
             ( 
            
           
             ( 
            
           
             1 
            
           
             − 
            
            
            
              β 
             
            
              1 
             
            
           
             ) 
            
           
             / 
            
           
             ( 
            
           
             1 
            
           
             − 
            
            
            
              β 
             
            
              1 
             
            
              n 
             
            
           
             ) 
            
           
             ) 
            
            
            
              g 
             
            
              n 
             
            
            
            
            
              v 
             
            
              n 
             
            
           
             ← 
            
           
             ( 
            
            
            
              β 
             
            
              2 
             
            
           
             / 
            
           
             ( 
            
           
             1 
            
           
             − 
            
            
            
              β 
             
            
              2 
             
            
              n 
             
            
           
             ) 
            
           
             ) 
            
            
            
              v 
             
             
             
               n 
              
             
               − 
              
             
               1 
              
             
            
           
             + 
            
           
             ( 
            
           
             ( 
            
           
             1 
            
           
             − 
            
            
            
              β 
             
            
              2 
             
            
           
             ) 
            
           
             / 
            
           
             ( 
            
           
             1 
            
           
             − 
            
            
            
              β 
             
            
              2 
             
            
              n 
             
            
           
             ) 
            
           
             ) 
            
            
            
              g 
             
            
              n 
             
            
           
             ⊙ 
            
            
            
              g 
             
            
              n 
             
            
            
            
            
              θ 
             
            
              n 
             
            
           
             ← 
            
            
            
              θ 
             
             
             
               n 
              
             
               − 
              
             
               1 
              
             
            
           
             − 
            
           
             a 
            
            
            
              m 
             
            
              n 
             
            
           
             / 
            
           
             ( 
            
            
             
             
               v 
              
             
            
              n 
             
            
           
             + 
            
           
             ϵ 
            
           
             ) 
            
           
          
          
          
          
            (2) 
           
          
         
        
       
         g_n\leftarrow \nabla f(\theta_{n-1})\\ m_n\leftarrow (\beta_1/(1-\beta_1^n))m_{n-1}+((1-\beta_1)/(1-\beta_1^n))g_n\\ v_n\leftarrow(\beta_2/(1-\beta_2^n))v_{n-1}+((1-\beta_2)/(1-\beta_2^n))g_n\odot g_n\\ \theta_n\leftarrow \theta_{n-1}-am_n/(\sqrt v_n+\epsilon) \tag{2} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">/</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7144em;"><span class="" style="top: -2.453em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose">))</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">((</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7144em;"><span class="" style="top: -2.453em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose">))</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">/</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7144em;"><span class="" style="top: -2.453em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose">))</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">((</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7144em;"><span class="" style="top: -2.453em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose">))</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0992em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">/</span><span class="mopen">(</span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8492em;"><span class="svg-align" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em; padding-left: 0.833em;">v</span></span><span class="" style="top: -2.8092em;"><span class="pstrut" style="height: 3em;"></span><span class="hide-tail" style="min-width: 0.853em; height: 1.08em;"> 
             <svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"> 
              <path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path> 
             </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1908em;"><span class=""></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.0608em;"><span class="" style="top: -2.4595em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2405em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 1.0992em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></span></p> 
<p>为了使用ODE思想描述Adam，从而使用证明使用TTUR和Adam作为GAN的构建能够使得该网络收敛。首先引入阻尼系数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         a 
        
       
         ( 
        
       
         n 
        
       
         ) 
        
       
         = 
        
        
        
          a 
         
        
          n 
         
         
         
           − 
          
         
           τ 
          
         
        
       
           
        
       
         f 
        
       
         o 
        
       
         r 
        
       
           
        
       
         τ 
        
       
         ∈ 
        
       
         ( 
        
       
         0 
        
       
         , 
        
       
         1 
        
       
         ] 
        
       
      
        a(n)=a_n^{-\tau}\ for\ \tau\in(0,1] 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0183em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right: 0.1132em;">τ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal" style="margin-right: 0.0278em;">or</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span></span>。其次，令指数记忆<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         r 
        
       
         ( 
        
       
         n 
        
       
         ) 
        
       
         = 
        
       
         r 
        
       
      
        r(n)=r 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span></span></span></span></span>，多项式记忆<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         r 
        
       
         ( 
        
       
         n 
        
       
         ) 
        
       
         = 
        
       
         r 
        
       
         / 
        
        
        
          ∑ 
         
         
         
           l 
          
         
           = 
          
         
           1 
          
         
        
          n 
         
        
       
         a 
        
       
         ( 
        
       
         l 
        
       
         ) 
        
       
      
        r(n)=r/\sum_{l=1}^na(l) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.104em; vertical-align: -0.2997em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord">/</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8043em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2997em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mclose">)</span></span></span></span></span></p> 
<p><strong>Theorem2</strong>：若使用Adam作为优化器，且<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          β 
         
        
          1 
         
        
       
         = 
        
       
         1 
        
       
         − 
        
       
         a 
        
       
         ( 
        
       
         n 
        
       
         + 
        
       
         1 
        
       
         ) 
        
       
         r 
        
       
         ( 
        
       
         n 
        
       
         ) 
        
       
         , 
        
        
        
          β 
         
        
          2 
         
        
       
         = 
        
       
         1 
        
       
         − 
        
       
         α 
        
       
         a 
        
       
         ( 
        
       
         n 
        
       
         + 
        
       
         1 
        
       
         ) 
        
       
         r 
        
       
         ( 
        
       
         n 
        
       
         ) 
        
       
      
        \beta_1=1-a(n+1)r(n),\beta_2=1-\alpha a(n+1)r(n) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0528em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span></span>，同时<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ∇ 
        
       
         f 
        
       
      
        \nabla f 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span></span></span></span></span>是下界连续可微目标f的完整梯度，则对于梯度的平稳二阶矩，Adam遵循带有HBF的微分方程<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
             
             
               θ 
              
             
               t 
              
             
            
              ¨ 
             
            
           
             + 
            
           
             a 
            
           
             ( 
            
           
             t 
            
           
             ) 
            
            
             
             
               θ 
              
             
               t 
              
             
            
              ˙ 
             
            
           
             + 
            
           
             ∇ 
            
           
             f 
            
           
             ( 
            
            
            
              θ 
             
            
              t 
             
            
           
             ) 
            
           
             = 
            
           
             0 
            
           
          
          
          
          
            (3) 
           
          
         
        
       
         \ddot {\theta_t}+a(t)\dot {\theta_t}+\nabla f(\theta_t)=\bf 0 \tag{3} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0813em; vertical-align: -0.15em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9313em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="" style="top: -3.2634em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">¨</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1813em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9313em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="" style="top: -3.2634em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1389em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord"><span class="mord mathbf">0</span></span></span><span class="tag"><span class="strut" style="height: 1.1813em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">3</span></span><span class="mord">)</span></span></span></span></span></span></span><br> Adam收敛于L-Lipschitz梯度<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ∇ 
        
       
         f 
        
       
      
        \nabla f 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span></span></span></span></span></p> 
<p>证明过程如下</p> 
<p><img src="https://images2.imgbox.com/59/86/d62EhzTJ_o.jpg" alt="微信图片_20231124172554"></p> 
<h3><a id="4__186"></a>4. 文献解读</h3> 
<h4><a id="41_Introduction_188"></a>4.1 Introduction</h4> 
<p>由于训练GAN是一种博弈，其解决方案是nash均衡，因此梯度下降可能无法使其收敛。因为梯度下降是一种局部优化方法，相应的其只能找到局部纳什均衡。作者将参数空间中某个点周围存在一个局部邻域，其中生成器和判别器都不能单方面减少各自的损失，称之为局部纳什均衡。即当对抗双方中的一个停止提升时，另一方也无法提升。</p> 
<p>作者证明了使用TTUR训练的GAN在训练时会收敛至稳态纳什均衡。作者还将Adam描述为一个具有摩擦力的重球，从而使用二阶微分方程来进行描述。最后使用TTUR和Adam训练GAN，并评估了FID作为评价标准的效果，结果证明其效果由于IS（Inception Score）。</p> 
<p>tips：纳什均衡的定义：在博弈G=﹛S1,…,Sn：u1,…，un﹜中，如果由各个博弈方的各一个策略组成的某个策略组合（s1 *,…，sn *）中，任一博弈方i的策略si *，都是对其余博弈方策略的组合（s1 *,…s *i-1,s *i+1,…，sn *）的最佳对策，也即ui（s1 *,…s *i-1,si *,s *i+1,…，sn *）≥ui（s1 *,…s *i-1,sij *,s *i+1,…，sn *）对任意sij∈Si都成立，则称（s1 *,…，sn *）为G的一个纳什均衡。</p> 
<h4><a id="42__196"></a>4.2 创新点</h4> 
<ol><li>给出了新的双时间尺度的更新规则</li><li>证明了TTUR能够使得GAN收敛于稳态纳什均衡</li><li>使用TTUR和Adam训练GAN至稳态纳什均衡</li><li>使用FID和IS评估，并证明了FID在该任务上的优越性</li></ol> 
<h4><a id="43__203"></a>4.3 实验过程</h4> 
<h5><a id="431___205"></a>4.3.1 性能指标</h5> 
<p>FID公式如下<sup>[4]</sup><br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              d 
             
            
              2 
             
            
           
             ( 
            
           
             ( 
            
           
             m 
            
           
             , 
            
           
             C 
            
           
             ) 
            
           
             , 
            
           
             ( 
            
            
            
              m 
             
            
              w 
             
            
           
             , 
            
            
            
              C 
             
            
              w 
             
            
           
             ) 
            
           
             ) 
            
           
             = 
            
           
             ∣ 
            
           
             ∣ 
            
           
             m 
            
           
             − 
            
            
            
              m 
             
            
              w 
             
            
           
             ∣ 
            
            
            
              ∣ 
             
            
              2 
             
            
              2 
             
            
           
             + 
            
           
             Tr 
            
           
             ( 
            
           
             C 
            
           
             + 
            
            
            
              C 
             
            
              w 
             
            
           
             − 
            
           
             2 
            
           
             ( 
            
           
             C 
            
            
            
              C 
             
            
              w 
             
            
            
            
              ) 
             
             
             
               1 
              
             
               2 
              
             
            
           
             ) 
            
           
          
          
          
          
            (6) 
           
          
         
        
       
         d^2((m,C),(m_w,C_w))=||m-m_w||_2^2+\text{Tr}(C+C_w-2(CC_w)^{\frac12}) \tag{6} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1141em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mopen">((</span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0715em;">C</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0715em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">))</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">∣∣</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1141em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">Tr</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0715em;">C</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0715em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.254em; vertical-align: -0.25em;"></span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0715em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0715em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 1.004em;"><span class="" style="top: -3.413em; margin-right: 0.05em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8443em;"><span class="" style="top: -2.656em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class="" style="top: -3.2255em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line mtight" style="border-bottom-width: 0.049em;"></span></span><span class="" style="top: -3.384em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.344em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height: 1.254em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">6</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 下图评估了FID，左上Gaussian noise，上中Gaussian blur，右上implanted black rectangles</p> 
<p>左下swirled images，下中salt and pepper noise（黑白噪点），右下CelebA dataset, ImageNet images混合</p> 
<p><img src="https://images2.imgbox.com/c1/71/GKhZdVK2_o.png" alt="image-20231124174114349"></p> 
<p>根据上图FID可以很好的捕捉干扰水平，在实验中可以使用FID来评估GAN的性能</p> 
<p>下图对比了使用FID和使用IS评估的效果，图片添加高斯噪声。显然IS没有明显变化，但FID随着噪声强度增大明显增大。该文还提供了其他各种噪声类型的对比情况，不再赘述。</p> 
<p><img src="https://images2.imgbox.com/58/cd/WmQ4ueJ4_o.png" alt="image-20231124174343855"></p> 
<h5><a id="432__224"></a>4.3.2 模型选择与评估</h5> 
<p>将 GAN 的两种时间尺度更新规则（TTUR）与原始 GAN 训练进行比较，看看 TTUR 是否提高了 GAN 的收敛速度和性能。该文选择 Adam 随机优化来降低模式崩溃的风险。 对于每个实验，通过 FID 或 Jensen-Shannon 散度 (JSD) 的减小来表明学习率在合理区间。当最佳模型的 FID 或 JSD不再减小时，将停止训练的时间点固定为更新步骤。</p> 
<p>对于某些模型，FID 在某个时间点出现发散或开始增加。如下图。</p> 
<ul><li>实线周围的区域标识DCGAN在各个数据集上的8次运行内的最大值最小值区间。</li><li>实线为FID均值</li><li>“orig 1e-5”，表示原始GAN，学习率为1e-5。</li><li>"TTUR 1e-5 5e-4"表示TTUR模型，分辨器学习率1e-5，生成器学习率1e-4。</li><li>四张图分别表示在CelebA、CIFAR-10、SVHN、LSUN Bedrooms各个数据集上的运行效果。</li></ul> 
<p>由TTUR训练的模型更加稳定，且方差更小，有一个较好的FID。</p> 
<p><img src="https://images2.imgbox.com/3d/45/FQCeMVmz_o.png" alt="image-20231124175922986"></p> 
<h5><a id="433_WGANGP_240"></a>4.3.3 图像数据上的WGAN-GP</h5> 
<p>使用 WGAN-GP 图像模型通过 CIFAR-10 和 LSUN Bedrooms 数据集测试 TTUR。每次生成器更新时TTUR更新分辨器一次，故将训练进度与时间刻度保持一致。TTUR可为判别器使用更大学习率，因为其可以稳定学习。下图显示了使用原始学习方法和TTUR方法进行学习期间的FID</p> 
<p>规则与上图大致相同，故不再赘述，左侧为CIFAR-10，右侧为LSUN Bedrooms。TTUR也表现出了更稳定更好的效果。</p> 
<p><img src="https://images2.imgbox.com/48/99/sqxZFnFG_o.png" alt="image-20231124183029179"></p> 
<p>下表显示了采用TTUR和单一时间尺度训练的最佳FID，并标识了优化迭代次数和学习率，以进行比较。TTUR的FID相较单一尺度更低。</p> 
<p>tip：下表分为三部分，从上到下，第一部分在图像数据上使用DCGAN（4.3.2），第二部分在图像数据上使用WGAN-GP（4.3.3），第三部分在语言数据上使用WGAN-GP（4.3.4）</p> 
<p><img src="https://images2.imgbox.com/7f/3c/VEjYNmlK_o.png" alt="image-20231124183331577"></p> 
<h5><a id="434_WGANGP_254"></a>4.3.4 语言数据上的WGAN-GP</h5> 
<p>使用十亿字基准（One Billion Word Benchmark）用于评估 WGAN-GP 上的 TTUR。由于 FID 准则仅适用于图像，因此使用JSD来测量性能。每次生成器更新，TTUR 仅更新分辨器一次，因此我们将训练进度与时间刻度保持一致。</p> 
<p>上表中第三部分为最佳时间步长的最佳 JSD，其中 TTUR 优于标准训练两项措施。 TTUR 在 6-gram 统计数据上相对于原始训练的改进表明，TTUR 能够学习生成更微妙的伪词，更类似于真实单词。</p> 
<p>下图显示了 4 和 6 粒度的单词评估的原始训练和 TTUR 训练十次运行的归一化平均 JSD。（左侧4-gram，右侧6-gram）</p> 
<p><img src="https://images2.imgbox.com/6a/70/yNN9MNwT_o.png" alt="image-20231124184827096"></p> 
<h4><a id="44__268"></a>4.4 结论</h4> 
<p>该文引入了双时间尺度更新规则（TTUR），且证明了该规则可收敛至稳态局部纳什均衡。然后证明了用TTUR和Adam训练的GAN收敛至稳态局部纳什均衡。引入了FID，并使用实验以及理论上证明了其比IS更能捕捉生成图像和真实图像的相似性。最后使用DCGAN、WGAN-GP网络在多个不同类别的数据集上使用FID或者JSD证明了文中方法的优越性。</p> 
<h2><a id="pytorchdiffusion_272"></a>三、pytorch实现diffusion模型</h2> 
<p>关于该模型的原理将由另一篇文章<a href="http://t.csdnimg.cn/AByWw" rel="nofollow">介绍</a>，以下为实验记录</p> 
<h3><a id="1__278"></a>1. 实验结果</h3> 
<p>第一个批次时的图像</p> 
<p><img src="https://images2.imgbox.com/41/50/fSHBZnSm_o.png" alt=""></p> 
<p>最后一个批次的图像</p> 
<p><img src="https://images2.imgbox.com/a4/b8/vCIOeWKu_o.png" alt=""></p> 
<h3><a id="2__288"></a>2. 实验代码</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_s_curve
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> io
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token comment"># 生成一万个点，得到s curve</span>
s_curve<span class="token punctuation">,</span>_ <span class="token operator">=</span> make_s_curve<span class="token punctuation">(</span><span class="token number">10</span><span class="token operator">**</span><span class="token number">4</span><span class="token punctuation">,</span>noise<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
s_curve <span class="token operator">=</span> s_curve<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">10.0</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"shape of s:"</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>s_curve<span class="token punctuation">)</span><span class="token punctuation">)</span>

data <span class="token operator">=</span> s_curve<span class="token punctuation">.</span>T

fig<span class="token punctuation">,</span>ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span><span class="token operator">*</span>data<span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span>edgecolor<span class="token operator">=</span><span class="token string">'white'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

ax<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
<span class="token comment">#当成一个数据集</span>
dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>s_curve<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#画出 s curve</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment">#确定超参数的值</span>
num_steps <span class="token operator">=</span> <span class="token number">100</span>  <span class="token comment">#可由beta值估算</span>

<span class="token comment">#制定每一步的beta，beta按照时间从小到大变化</span>
betas <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span>num_steps<span class="token punctuation">)</span>
betas <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>betas<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">0.5e-2</span> <span class="token operator">-</span> <span class="token number">1e-5</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1e-5</span>

<span class="token comment">#计算alpha、alpha_prod、alpha_prod_previous、alpha_bar_sqrt等变量的值</span>
alphas <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">-</span>betas
<span class="token comment"># alpha连乘</span>
alphas_prod <span class="token operator">=</span> torch<span class="token punctuation">.</span>cumprod<span class="token punctuation">(</span>alphas<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment">#从第一项开始，第0项另乘1？？？</span>
alphas_prod_p <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>alphas_prod<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># alphas_prod开根号</span>
alphas_bar_sqrt <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>alphas_prod<span class="token punctuation">)</span>
<span class="token comment">#之后公式中要用的</span>
one_minus_alphas_bar_log <span class="token operator">=</span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> alphas_prod<span class="token punctuation">)</span>
one_minus_alphas_bar_sqrt <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> alphas_prod<span class="token punctuation">)</span>
<span class="token comment"># 大小都一样，常数不需要训练</span>
<span class="token keyword">assert</span> alphas<span class="token punctuation">.</span>shape<span class="token operator">==</span>alphas_prod<span class="token punctuation">.</span>shape<span class="token operator">==</span>alphas_prod_p<span class="token punctuation">.</span>shape<span class="token operator">==</span>\
alphas_bar_sqrt<span class="token punctuation">.</span>shape<span class="token operator">==</span>one_minus_alphas_bar_log<span class="token punctuation">.</span>shape\
<span class="token operator">==</span>one_minus_alphas_bar_sqrt<span class="token punctuation">.</span>shape
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"all the same shape"</span><span class="token punctuation">,</span>betas<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#给定初始，算出任意时刻采样值——正向扩散</span>
<span class="token comment"># 计算任意时刻的x采样值，基于x_0和重参数化</span>
<span class="token keyword">def</span> <span class="token function">q_x</span><span class="token punctuation">(</span>x_0<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""可以基于x[0]得到任意时刻t的x[t]"""</span>
    <span class="token comment">#生成正态分布采样</span>
    noise <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>x_0<span class="token punctuation">)</span>
    <span class="token comment">#得到均值方差</span>
    alphas_t <span class="token operator">=</span> alphas_bar_sqrt<span class="token punctuation">[</span>t<span class="token punctuation">]</span>
    alphas_1_m_t <span class="token operator">=</span> one_minus_alphas_bar_sqrt<span class="token punctuation">[</span>t<span class="token punctuation">]</span>
    <span class="token comment">#根据x0求xt</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>alphas_t <span class="token operator">*</span> x_0 <span class="token operator">+</span> alphas_1_m_t <span class="token operator">*</span> noise<span class="token punctuation">)</span>  <span class="token comment"># 在x[0]的基础上添加噪声</span>

<span class="token comment"># 演示加噪过程，加噪100步情况</span>
num_shows <span class="token operator">=</span> <span class="token number">20</span>
fig<span class="token punctuation">,</span>axs <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>rc<span class="token punctuation">(</span><span class="token string">'text'</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>

<span class="token comment">#共有10000个点，每个点包含两个坐标</span>
<span class="token comment">#生成100步以内每隔5步加噪声后的图像，扩散过程散点图演示——基于x0生成条件分布采样得到xt</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_shows<span class="token punctuation">)</span><span class="token punctuation">:</span>
    j <span class="token operator">=</span> i<span class="token operator">//</span><span class="token number">10</span>
    k <span class="token operator">=</span> i<span class="token operator">%</span><span class="token number">10</span>
    q_i <span class="token operator">=</span> q_x<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token operator">*</span>num_steps<span class="token operator">//</span>num_shows<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 生成t时刻的采样数据</span>
    axs<span class="token punctuation">[</span>j<span class="token punctuation">,</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>q_i<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>q_i<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span>edgecolor<span class="token operator">=</span><span class="token string">'white'</span><span class="token punctuation">)</span>
    axs<span class="token punctuation">[</span>j<span class="token punctuation">,</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span>set_axis_off<span class="token punctuation">(</span><span class="token punctuation">)</span>
    axs<span class="token punctuation">[</span>j<span class="token punctuation">,</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'$q(\mathbf{x}_{'</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token operator">*</span>num_steps<span class="token operator">//</span>num_shows<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">'})$'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment"># 拟合逆扩散过程高斯分布模型——拟合逆扩散时的噪声</span>


<span class="token comment">#自定义神经网络</span>
<span class="token keyword">class</span> <span class="token class-name">MLPDiffusion</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_steps<span class="token punctuation">,</span> num_units<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MLPDiffusion<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>linears <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>
                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> num_units<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_units<span class="token punctuation">,</span> num_units<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_units<span class="token punctuation">,</span> num_units<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_units<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>step_embeddings <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>
                nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>n_steps<span class="token punctuation">,</span> num_units<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>n_steps<span class="token punctuation">,</span> num_units<span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>n_steps<span class="token punctuation">,</span> num_units<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">]</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#         x = x_0</span>
        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> embedding_layer <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>step_embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span>
            t_embedding <span class="token operator">=</span> embedding_layer<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>linears<span class="token punctuation">[</span><span class="token number">2</span> <span class="token operator">*</span> idx<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            x <span class="token operator">+=</span> t_embedding
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>linears<span class="token punctuation">[</span><span class="token number">2</span> <span class="token operator">*</span> idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linears<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x

<span class="token comment">#编写训练误差函数</span>
<span class="token keyword">def</span> <span class="token function">diffusion_loss_fn</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> x_0<span class="token punctuation">,</span> alphas_bar_sqrt<span class="token punctuation">,</span> one_minus_alphas_bar_sqrt<span class="token punctuation">,</span> n_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""对任意时刻t进行采样计算loss"""</span>
    batch_size <span class="token operator">=</span> x_0<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token comment"># 对一个batchsize样本生成随机的时刻t，t变得随机分散一些，一个batch size里面覆盖更多的t</span>
    t <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_steps<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>batch_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    t <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t<span class="token punctuation">,</span> n_steps <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> t<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># t的形状（bz）</span>
    t <span class="token operator">=</span> t<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># t的形状（bz,1）</span>

    <span class="token comment"># x0的系数，根号下(alpha_bar_t)</span>
    a <span class="token operator">=</span> alphas_bar_sqrt<span class="token punctuation">[</span>t<span class="token punctuation">]</span>

    <span class="token comment"># eps的系数,根号下(1-alpha_bar_t)</span>
    aml <span class="token operator">=</span> one_minus_alphas_bar_sqrt<span class="token punctuation">[</span>t<span class="token punctuation">]</span>

    <span class="token comment"># 生成随机噪音eps</span>
    e <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>x_0<span class="token punctuation">)</span>

    <span class="token comment"># 构造模型的输入</span>
    x <span class="token operator">=</span> x_0 <span class="token operator">*</span> a <span class="token operator">+</span> e <span class="token operator">*</span> aml

    <span class="token comment"># 送入模型，得到t时刻的随机噪声预测值</span>
    output <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 与真实噪声一起计算误差，求平均值</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>e <span class="token operator">-</span> output<span class="token punctuation">)</span><span class="token punctuation">.</span>square<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#编写逆扩散采样函数</span>

<span class="token comment">#从xt恢复x0</span>
<span class="token keyword">def</span> <span class="token function">p_sample_loop</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> shape<span class="token punctuation">,</span> n_steps<span class="token punctuation">,</span> betas<span class="token punctuation">,</span> one_minus_alphas_bar_sqrt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""从x[T]恢复x[T-1]、x[T-2]|...x[0]"""</span>
    cur_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>
    x_seq <span class="token operator">=</span> <span class="token punctuation">[</span>cur_x<span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>n_steps<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        cur_x <span class="token operator">=</span> p_sample<span class="token punctuation">(</span>model<span class="token punctuation">,</span> cur_x<span class="token punctuation">,</span> i<span class="token punctuation">,</span> betas<span class="token punctuation">,</span> one_minus_alphas_bar_sqrt<span class="token punctuation">)</span>
        x_seq<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cur_x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x_seq


<span class="token keyword">def</span> <span class="token function">p_sample</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">,</span> betas<span class="token punctuation">,</span> one_minus_alphas_bar_sqrt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""从x[T]采样t时刻的重构值"""</span>
    t <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span>

    coeff <span class="token operator">=</span> betas<span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">/</span> one_minus_alphas_bar_sqrt<span class="token punctuation">[</span>t<span class="token punctuation">]</span>

    eps_theta <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
    <span class="token comment">#得到均值</span>
    mean <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> betas<span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> <span class="token punctuation">(</span>coeff <span class="token operator">*</span> eps_theta<span class="token punctuation">)</span><span class="token punctuation">)</span>

    z <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    sigma_t <span class="token operator">=</span> betas<span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#得到sample的分布</span>
    sample <span class="token operator">=</span> mean <span class="token operator">+</span> sigma_t <span class="token operator">*</span> z

    <span class="token keyword">return</span> <span class="token punctuation">(</span>sample<span class="token punctuation">)</span>

<span class="token comment">#开始训练模型，打印loss以及中间的重构效果</span>
seed <span class="token operator">=</span> <span class="token number">1234</span>


<span class="token keyword">class</span> <span class="token class-name">EMA</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""构建一个参数平滑器"""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mu<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>mu <span class="token operator">=</span> mu
        self<span class="token punctuation">.</span>shadow <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>

    <span class="token keyword">def</span> <span class="token function">register</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> val<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>shadow<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> val<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>shadow
        new_average <span class="token operator">=</span> self<span class="token punctuation">.</span>mu <span class="token operator">*</span> x <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>mu<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>shadow<span class="token punctuation">[</span>name<span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>shadow<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> new_average<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> new_average


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Training model...'</span><span class="token punctuation">)</span>
batch_size <span class="token operator">=</span> <span class="token number">128</span>
<span class="token comment"># dataset放到dataloader中</span>
dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment"># 迭代周期</span>
num_epoch <span class="token operator">=</span> <span class="token number">4000</span>
plt<span class="token punctuation">.</span>rc<span class="token punctuation">(</span><span class="token string">'text'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">)</span>
<span class="token comment">#实例化模型，传入一个数</span>
model <span class="token operator">=</span> MLPDiffusion<span class="token punctuation">(</span>num_steps<span class="token punctuation">)</span>  <span class="token comment"># 输出维度是2，输入是x和step</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span>
<span class="token comment"># epoch遍历</span>
<span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> t <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch:"</span><span class="token punctuation">,</span> t<span class="token punctuation">)</span>
    <span class="token comment"># dataloader遍历</span>
    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> batch_x <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 得到loss</span>
        loss <span class="token operator">=</span> diffusion_loss_fn<span class="token punctuation">(</span>model<span class="token punctuation">,</span> batch_x<span class="token punctuation">,</span> alphas_bar_sqrt<span class="token punctuation">,</span> one_minus_alphas_bar_sqrt<span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment">#梯度clip，保持稳定性</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#每100步打印效果</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>t <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
        <span class="token comment">#根据参数采样一百个步骤的x，每隔十步画出来，迭代了4000个周期，逐渐更接近于原始</span>
        x_seq <span class="token operator">=</span> p_sample_loop<span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> num_steps<span class="token punctuation">,</span> betas<span class="token punctuation">,</span> one_minus_alphas_bar_sqrt<span class="token punctuation">)</span>

        fig<span class="token punctuation">,</span> axs <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            cur_x <span class="token operator">=</span> x_seq<span class="token punctuation">[</span>i <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
            axs<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>cur_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cur_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span> edgecolor<span class="token operator">=</span><span class="token string">'white'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            axs<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_axis_off<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            axs<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'$q(\mathbf{x}_{'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>i <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'})$'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 前向后向过程gif</span>
imgs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>clf<span class="token punctuation">(</span><span class="token punctuation">)</span>
    q_i <span class="token operator">=</span> q_x<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>q_i<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> q_i<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span> edgecolor<span class="token operator">=</span><span class="token string">'white'</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    img_buf <span class="token operator">=</span> io<span class="token punctuation">.</span>BytesIO<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>img_buf<span class="token punctuation">,</span> <span class="token builtin">format</span><span class="token operator">=</span><span class="token string">'png'</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_buf<span class="token punctuation">)</span>
    imgs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
reverse <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>clf<span class="token punctuation">(</span><span class="token punctuation">)</span>
    cur_x <span class="token operator">=</span> x_seq<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>cur_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cur_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span> edgecolor<span class="token operator">=</span><span class="token string">'white'</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>

    img_buf <span class="token operator">=</span> io<span class="token punctuation">.</span>BytesIO<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>img_buf<span class="token punctuation">,</span> <span class="token builtin">format</span><span class="token operator">=</span><span class="token string">'png'</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_buf<span class="token punctuation">)</span>
    reverse<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
imgs <span class="token operator">=</span> imgs <span class="token operator">+</span>reverse
imgs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"diffusion.gif"</span><span class="token punctuation">,</span><span class="token builtin">format</span><span class="token operator">=</span><span class="token string">'GIF'</span><span class="token punctuation">,</span>append_images<span class="token operator">=</span>imgs<span class="token punctuation">,</span>save_all<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>duration<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>loop<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

</code></pre> 
<h3><a id="_558"></a>小结</h3> 
<p>上周学习了WGAN，该模型可以降低GAN模型的训练难度，但总的来说，该模型依旧难以训练。传统的随机梯度下降算法在GAN中仅能通过Discriminator来控制整个网络。然而由于该模型的特殊性，在Discriminator输出不变的情况下，Generator网络中的参数可能有较大的变动。在文中提到的论文中验证了可以使用多种pretrain方法来降低GAN的训练难度。而在HW6中采用了另一种评估标准来降低训练难度，因为该评估标准当模型发生mode collapse、mode dropping等问题时能够提供反应。最后，本文简要介绍了conditional GAN，这也是下周计划的学习内容。</p> 
<h3><a id="_560"></a>参考文献</h3> 
<p>[1] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, &amp; S. Hochreiter, “gans trained by a two time-scale update rule converge to a local nash equilibrium”, 2017. https://doi.org/10.48550/arxiv.1706.08500</p> 
<p>[2] S. Gadat, F. Panloup, and S. Saadane. Stochastic heavy ball. arXiv e-prints, arXiv:1609.04228,<br> 2016.</p> 
<p>[3] H. Attouch, X. Goudou, and P. Redont. The heavy ball with friction method, I. the continu-<br> ous dynamical system: Global exploration of the local minima of a real-valued function by<br> asymptotic analysis of a dissipative dynamical system. Communications in Contemporary<br> Mathematics, 2(1):1–34, 2000.</p> 
<p>[4] D. C. Dowson and B. V. Landau. The Fréchet distance between multivariate normal distributions. Journal ofMultivariate Analysis, 12:450–455, 1982.</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9907a929a45a49dd7c2149654ddf2b27/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Timestamps are unset in a packet for stream X.This is deprecated and will stop working in the future</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dd379369783085e1d21cce1f150a6d85/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python每日一题——20旋转图像</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>