<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ILSVRC-ImageNet历年竞赛冠军 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ILSVRC-ImageNet历年竞赛冠军" />
<meta property="og:description" content="ImageNet 是一个超过15 million的图像数据集，大约有22,000类。
是由李飞飞团队从2007年开始，耗费大量人力，通过各种方式（网络抓取，人工标注，亚马逊众包平台）收集制作而成，它作为论文在CVPR-2009发布。当时人们还很怀疑通过更多数据就能改进算法的看法。
深度学习发展起来有几个关键的因素，一个就是庞大的数据（比如说ImageNet），一个是GPU的出现。（还有更优的深度模型，更好的优化算法，可以说数据和GPU推动了这些的产生，这些产生继续推动深度学习的发展）。
ILSVRC 是一个比赛，全称是ImageNet Large-Scale Visual Recognition Challenge，平常说的ImageNet比赛指的是这个比赛。
使用的数据集是ImageNet数据集的一个子集，一般说的ImageNet（数据集）实际上指的是ImageNet的这个子集，总共有1000类，每类大约有1000张图像。具体地，有大约1.2 million的训练集，5万验证集，15万测试集。
ILSVRC从2010年开始举办，到2017年是最后一届（在算法层面已经刷过拟合了，再比下去意义不是很大了）。ILSVRC-2012的数据集被用在2012-2014年的挑战赛中（VGG论文中提到）。ILSVRC-2010是唯一提供了test set的一年。
ImageNet可能是指整个数据集（15 million），也可能指比赛用的那个子集（1000类，大约每类1000张），也可能指ILSVRC这个比赛。需要根据语境自行判断。
12-15年期间在ImageNet比赛上提出了一些经典网络，比如AlexNet，ZFNet，OverFeat，VGG，Inception，ResNet。
16年之后也有一些经典网络，比如WideResNet，FractalNet，DenseNet，ResNeXt，DPN，SENet。
2012年 AlexNet是2012年ImageNet竞赛冠军获得者Hinton和他的学生Alex Krizhevsky设计的。也是在那年之后，更多的更深的神经网络被提出，比如优秀的vgg,GoogLeNet。AlexNet中包含了几个比较新的技术点，也首次在CNN中成功应用了ReLU、Dropout和LRN等Trick。
2013年 OverFeat：OverFeat是早期经典的one-stage Object Detection的方法，基于AlexNet，实现了识别、定位、检测共用同一个网络框架；获得了2013年ILSVRC定位比赛的冠军。
OverFeat方法的主要创新点是 multiscale 、sliding window、offset pooling，以及基于AlexNet的识别、定位和检测方法的融合。
2014年 GoogLeNet 冠军：从Inception v1到v4。引入稀疏特性和将全连接层转换成稀疏连接。在inception结构中，大量采用了1x1的矩阵，主要是两点作用：1）对数据进行降维；2）引入更多的非线性，提高泛化能力，因为卷积后要经过ReLU激活函数。
VGG（亚军）：VGG模型在多个迁移学习任务中的表现要优于googLeNet。而且，从图像中提取CNN特征，VGG模型是首选算法。它的缺点在于，参数量有140M之多，需要更大的存储空间。
VGG的特点：
小卷积核。作者将卷积核全部替换为3x3（极少用了1x1）；
小池化核。相比AlexNet的3x3的池化核，VGG全部为2x2的池化核；
层数更深特征图更宽。基于前两点外，由于卷积核专注于扩大通道数、池化专注于缩小宽和高，使得模型架构上更深更宽的同时，计算量的增加放缓；
全连接转卷积。网络测试阶段将训练阶段的三个全连接替换为三个卷积，测试重用训练时的参数，使得测试得到的全卷积网络因为没有全连接的限制，因而可以接收任意宽或高为的输入。
2015年 ResNet：
残差网络的特点是容易优化，并且能够通过增加相当的深度来提高准确率。其内部的残差块使用了跳跃连接，缓解了在深度神经网络中增加深度带来的梯度消失问题 。
生成了ResNet-50，ResNet-101，ResNet-152. 随着深度增加，因为解决了退化问题，性能不断提升。作者最后在Cifar-10上尝试了1202层的网络，结果在训练误差上与一个较浅的110层的相近，但是测试误差要比110层大1.5%。作者认为是采用了太深的网络，发生了过拟合
2016年 Trimps-Soushen冠军
ResNeXt（亚军）：
ResNeXt是ResNet[2]和Inception[3]的结合体，不同于Inception v4[4]的是，ResNext不需要人工设计复杂的Inception结构细节，而是每一个分支都采用相同的拓扑结构。ResNeXt的本质是分组卷积（Group Convolution）[5]，通过变量基数（Cardinality）来控制组的数量。组卷机是普通卷积和深度可分离卷积的一个折中方案，即每个分支产生的Feature Map的通道数为 [公式]
2017年 SENet
SENet是ImageNet 2017（ImageNet收官赛）的冠军模型，和ResNet的出现类似，都在很大程度上减小了之前模型的错误率），并且复杂度低，新增参数和计算量小。下面就来具体介绍一些SENet的神奇之处。
SENet的全称是Squeeze-and-Excitation Networks，中文可以翻译为压缩和激励网络。主要由两部分组成：
Squeeze部分。即为压缩部分，原始feature map的维度为HWC，其中H是高度（Height），W是宽度（width），C是通道数（channel）。Squeeze做的事情是把HWC压缩为11C，相当于把HW压缩成一维了，实际中一般是用global average pooling实现的。HW压缩成一维后，相当于这一维参数获得了之前H*W全局的视野，感受区域更广。
Excitation部分。得到Squeeze的11C的表示后，加入一个FC全连接层（Fully Connected），对每个通道的重要性进行预测，得到不同channel的重要性大小后再作用（激励）到之前的feature map的对应channel上，再进行后续操作。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/42e2319b913f17cbc41aa5cefb13a086/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-08-09T12:34:51+08:00" />
<meta property="article:modified_time" content="2020-08-09T12:34:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ILSVRC-ImageNet历年竞赛冠军</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="ImageNet_0"></a>ImageNet</h3> 
<p>是一个超过15 million的图像数据集，大约有22,000类。<br> 是由李飞飞团队从2007年开始，耗费大量人力，通过各种方式（网络抓取，人工标注，亚马逊众包平台）收集制作而成，它作为论文在CVPR-2009发布。当时人们还很怀疑通过更多数据就能改进算法的看法。<br> 深度学习发展起来有几个关键的因素，一个就是庞大的数据（比如说ImageNet），一个是GPU的出现。（还有更优的深度模型，更好的优化算法，可以说数据和GPU推动了这些的产生，这些产生继续推动深度学习的发展）。</p> 
<h3><a id="ILSVRC_6"></a>ILSVRC</h3> 
<p>是一个比赛，全称是ImageNet Large-Scale Visual Recognition Challenge，平常说的ImageNet比赛指的是这个比赛。<br> 使用的数据集是ImageNet数据集的一个子集，一般说的ImageNet（数据集）实际上指的是ImageNet的这个子集，总共有1000类，每类大约有1000张图像。具体地，有大约1.2 million的训练集，5万验证集，15万测试集。</p> 
<p>ILSVRC<strong>从2010年开始举办，到2017年是最后一届</strong>（在算法层面已经刷过拟合了，再比下去意义不是很大了）。ILSVRC-2012的数据集被用在2012-2014年的挑战赛中（VGG论文中提到）。ILSVRC-2010是唯一提供了test set的一年。<br> ImageNet可能是指整个数据集（15 million），也可能指比赛用的那个子集（1000类，大约每类1000张），也可能指ILSVRC这个比赛。需要根据语境自行判断。<br> 12-15年期间在ImageNet比赛上提出了一些经典网络，比如AlexNet，ZFNet，OverFeat，VGG，Inception，ResNet。<br> 16年之后也有一些经典网络，比如WideResNet，FractalNet，DenseNet，ResNeXt，DPN，SENet。</p> 
<h3><a id="2012_16"></a>2012年</h3> 
<p>AlexNet是2012年ImageNet竞赛冠军获得者Hinton和他的学生Alex Krizhevsky设计的。也是在那年之后，更多的更深的神经网络被提出，比如优秀的vgg,GoogLeNet。AlexNet中包含了几个比较新的技术点，也首次在CNN中成功应用了ReLU、Dropout和LRN等Trick。</p> 
<h3><a id="2013_20"></a>2013年</h3> 
<p>OverFeat：OverFeat是早期经典的one-stage Object Detection的方法，基于AlexNet，实现了识别、定位、检测共用同一个网络框架；获得了2013年ILSVRC定位比赛的冠军。</p> 
<p>OverFeat方法的主要创新点是 multiscale 、sliding window、offset pooling，以及基于AlexNet的识别、定位和检测方法的融合。</p> 
<h3><a id="2014_25"></a>2014年</h3> 
<p><strong>GoogLeNet</strong> 冠军：从Inception v1到v4。引入稀疏特性和将全连接层转换成稀疏连接。在inception结构中，大量采用了1x1的矩阵，主要是两点作用：1）对数据进行降维；2）引入更多的非线性，提高泛化能力，因为卷积后要经过ReLU激活函数。</p> 
<p><strong>VGG</strong>（亚军）：VGG模型在多个迁移学习任务中的表现要优于googLeNet。而且，从图像中提取CNN特征，VGG模型是首选算法。它的缺点在于，参数量有140M之多，需要更大的存储空间。</p> 
<p>VGG的特点：<br> 小卷积核。作者将卷积核全部替换为3x3（极少用了1x1）；<br> 小池化核。相比AlexNet的3x3的池化核，VGG全部为2x2的池化核；<br> 层数更深特征图更宽。基于前两点外，由于卷积核专注于扩大通道数、池化专注于缩小宽和高，使得模型架构上更深更宽的同时，计算量的增加放缓；<br> 全连接转卷积。网络测试阶段将训练阶段的三个全连接替换为三个卷积，测试重用训练时的参数，使得测试得到的全卷积网络因为没有全连接的限制，因而可以接收任意宽或高为的输入。</p> 
<h3><a id="2015_36"></a>2015年</h3> 
<p>ResNet：<br> 残差网络的特点是容易优化，并且能够通过增加相当的深度来提高准确率。其内部的残差块使用了跳跃连接，缓解了在深度神经网络中增加深度带来的梯度消失问题 。</p> 
<p>生成了ResNet-50，ResNet-101，ResNet-152. 随着深度增加，因为解决了退化问题，性能不断提升。作者最后在Cifar-10上尝试了1202层的网络，结果在训练误差上与一个较浅的110层的相近，但是测试误差要比110层大1.5%。作者认为是采用了太深的网络，发生了过拟合</p> 
<h3><a id="2016_43"></a>2016年</h3> 
<p>Trimps-Soushen冠军</p> 
<p><strong>ResNeXt</strong>（亚军）：<br> ResNeXt是ResNet[2]和Inception[3]的结合体，不同于Inception v4[4]的是，ResNext不需要人工设计复杂的Inception结构细节，而是每一个分支都采用相同的拓扑结构。ResNeXt的本质是分组卷积（Group Convolution）[5]，通过变量基数（Cardinality）来控制组的数量。组卷机是普通卷积和深度可分离卷积的一个折中方案，即每个分支产生的Feature Map的通道数为 [公式]</p> 
<h3><a id="2017_49"></a>2017年</h3> 
<p><strong>SENet</strong><br> SENet是ImageNet 2017（ImageNet收官赛）的冠军模型，和ResNet的出现类似，都在很大程度上减小了之前模型的错误率），并且复杂度低，新增参数和计算量小。下面就来具体介绍一些SENet的神奇之处。</p> 
<p>SENet的全称是Squeeze-and-Excitation Networks，中文可以翻译为压缩和激励网络。主要由两部分组成：</p> 
<ol><li> <p>Squeeze部分。即为压缩部分，原始feature map的维度为H<em>W</em>C，其中H是高度（Height），W是宽度（width），C是通道数（channel）。Squeeze做的事情是把H<em>W</em>C压缩为1<em>1</em>C，相当于把H<em>W压缩成一维了，实际中一般是用global average pooling实现的。H</em>W压缩成一维后，相当于这一维参数获得了之前H*W全局的视野，感受区域更广。</p> </li><li> <p>Excitation部分。得到Squeeze的1<em>1</em>C的表示后，加入一个FC全连接层（Fully Connected），对每个通道的重要性进行预测，得到不同channel的重要性大小后再作用（激励）到之前的feature map的对应channel上，再进行后续操作。</p> </li></ol> 
<p><img src="https://images2.imgbox.com/e5/d3/PuCwnUUc_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8be91741fc6dec2bbd3ceba1375f2641/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">美团（Leaf）分布式ID生成器，好用的一批！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/41149bbdb66131cfb728223ac9edd033/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">WPF基本介绍</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>