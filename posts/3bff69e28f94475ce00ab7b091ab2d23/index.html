<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FFmpeg - Android 直播推拉流 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FFmpeg - Android 直播推拉流" />
<meta property="og:description" content="1. 搭建自己的流媒体服务器 首先登录自己的云主机，下载解压 nginx 和 rtmp
sudo wget https://github.com/nginx/nginx/archive/release-1.17.1.tar.gz sudo wget https://github.com/arut/nginx-rtmp-module/archive/v1.2.1.tar.gz sudo tar -zxvf release-1.17.1.tar.gz sudo tar -zxvf v1.2.1.tar.gz 然后编译安装nginx和rtmp
./auto/configure --add-module=/lib/nginx/nginx-rtmp-module-1.2.1 make make install 最后配置测试流媒体服务器
cd /usr/local/nginx/sbin/ ./nginx .\ffmpeg.exe -re -i 01.mp4 -vcodec libx264 -acodec aac -f flv rtmp://148.70.96.230/myapp/mystream 2. 集成 RTMP 推流的源码 当我们的流媒体服务器搭建好后，要用 ffmpeg 测试一下，确保流媒体服务器搭建成功后，我们再来集成 RTMP 推流的源码。
git clone git://git.ffmpeg.org/rtmpdump set(CMAKE_C_FLAGS &#34;${CMAKE_C_FLAGS} -DNO_CRYPTO&#34;) /** * 初始化连接流媒体服务器 */ void *initConnectFun(void *context) { DZLivePush *pLivePush = (DZLivePush *) context; // 创建 RTMP pLivePush-&gt;pRtmp = RTMP_Alloc(); // 初始化 RTMP RTMP_Init(pLivePush-&gt;pRtmp); // 设置连接超时 pLivePush-&gt;pRtmp-&gt;Link." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/3bff69e28f94475ce00ab7b091ab2d23/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-25T22:01:43+08:00" />
<meta property="article:modified_time" content="2022-11-25T22:01:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FFmpeg - Android 直播推拉流</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>1. 搭建自己的流媒体服务器</h2> 
<p>首先登录自己的云主机，下载解压 nginx 和 rtmp</p> 
<pre><code>sudo wget https://github.com/nginx/nginx/archive/release-1.17.1.tar.gz
sudo wget https://github.com/arut/nginx-rtmp-module/archive/v1.2.1.tar.gz
sudo tar -zxvf release-1.17.1.tar.gz
sudo tar -zxvf v1.2.1.tar.gz
</code></pre> 
<p>然后编译安装nginx和rtmp</p> 
<pre><code>./auto/configure --add-module=/lib/nginx/nginx-rtmp-module-1.2.1
make
make install
</code></pre> 
<p>最后配置测试流媒体服务器</p> 
<pre><code>cd /usr/local/nginx/sbin/
./nginx
.\ffmpeg.exe -re -i 01.mp4 -vcodec libx264 -acodec aac -f flv rtmp://148.70.96.230/myapp/mystream
</code></pre> 
<h2>2. 集成 RTMP 推流的源码</h2> 
<p>当我们的流媒体服务器搭建好后，要用 ffmpeg 测试一下，确保流媒体服务器搭建成功后，我们再来集成 RTMP 推流的源码。</p> 
<pre><code>git clone git://git.ffmpeg.org/rtmpdump

set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -DNO_CRYPTO")

/**
 * 初始化连接流媒体服务器
 */
void *initConnectFun(void *context) {
    DZLivePush *pLivePush = (DZLivePush *) context;
    // 创建 RTMP
    pLivePush-&gt;pRtmp = RTMP_Alloc();
    // 初始化 RTMP
    RTMP_Init(pLivePush-&gt;pRtmp);
    // 设置连接超时
    pLivePush-&gt;pRtmp-&gt;Link.timeout = 10;
    pLivePush-&gt;pRtmp-&gt;Link.lFlags |= RTMP_LF_LIVE;
    RTMP_SetupURL(pLivePush-&gt;pRtmp, pLivePush-&gt;url);
    RTMP_EnableWrite(pLivePush-&gt;pRtmp);
    // 连接失败回调到 java 层
    if (!RTMP_Connect(pLivePush-&gt;pRtmp, NULL)) {
        LOGE("connect url error");
        pLivePush-&gt;pJniCall-&gt;callConnectError(THREAD_CHILD, RTMP_CONNECT_ERROR_CODE, "connect url error");
        return (void *) RTMP_CONNECT_ERROR_CODE;
    }
    if (!RTMP_ConnectStream(pLivePush-&gt;pRtmp, 0)) {
        LOGE("connect stream url error");
        pLivePush-&gt;pJniCall-&gt;callConnectError(THREAD_CHILD, RTMP_STREAM_CONNECT_ERROR_CODE, "connect stream url error");
        return (void *) RTMP_STREAM_CONNECT_ERROR_CODE;
    }
    // 连接成功也回调到 Java 层，可以开始推流了
    LOGE("connect succeed");
    pLivePush-&gt;pJniCall-&gt;callConnectSuccess(THREAD_CHILD);
    return (void *) 0;
}
</code></pre> 
<h2>3. H.264 协议介绍</h2> 
<p>我们打算采用最常见的 H.264 来编码推流，那么现在我们不得不来了解一下 H.264 的协议了，这些东西虽说看似比较枯燥复杂，但这也是最最重要的部分。首先需要明确 H264 可以分为两层：1.VCL video codinglayer（视频编码层），2.NAL network abstraction layer（网络提取层）。对于 VCL 具体的编解码算法这里暂时先不介绍，只介绍常用的 NAL 层，即网络提取层，这是解码的基础。</p> 
<p><img alt="NAL" src="https://images2.imgbox.com/35/c2/csZzCNNY_o.png"></p> 
<p>SPS：序列参数集<br> PPS：图像参数集<br> I帧：帧内编码帧，可独立解码生成完整的图片。<br> P帧: 前向预测编码帧，需要参考其前面的一个I 或者B 来生成一张完整的图片。<br> B帧: 双向预测内插编码帧，则要参考其前一个I或者P帧及其后面的一个P帧来生成一张完整的图片</p> 
<p>根据上面所说，现在我们就得思考几个问题了：</p> 
<p>SPS 和 PPS 到底存的是什么数据？<br> 我们怎么判断获取每一个 NALU ？<br> 如何判断某一个 NALU 是 I 帧、P 帧、 B 帧还是其他？</p> 
<h3></h3> 
<h2>4. 直播推流视频数据</h2> 
<p>为了确保直播过程中进来的用户也可以正常的观看直播，我们需要在每个关键帧前先把 SPS 和 PPS 推送到流媒体服务器。</p> 
<blockquote> 
 <p style="margin-left:0;"><span style="background-color:#FFFFFF;"><strong><span style="background-color:#eef0f4;"><span style="color:#FF0000;">本文福利， 免费领取C++音视频学习资料包、技术视频，内容包括（音视频开发，面试题，FFmpeg ，webRTC ，rtmp ，hls ，rtsp ，ffplay ，编解码，推拉流，srs）↓↓↓↓↓↓见下面↓↓文章底部点击免费领取↓↓</span></span></strong></span></p> 
</blockquote> 
<pre><code>/**
 * 发送 sps 和 pps 到流媒体服务器
 * @param spsData sps 的数据
 * @param spsLen sps 的数据长度
 * @param ppsData pps 的数据
 * @param ppsLen pps 的数据长度
 */
void DZLivePush::pushSpsPps(jbyte *spsData, jint spsLen, jbyte *ppsData, jint ppsLen) {
    // frame type : 1关键帧，2 非关键帧 (4bit)
    // CodecID : 7表示 AVC (4bit)  , 与 frame type 组合起来刚好是 1 个字节  0x17
    // fixed : 0x00 0x00 0x00 0x00 (4byte)
    // configurationVersion  (1byte)  0x01版本
    // AVCProfileIndication  (1byte)  sps[1] profile
    // profile_compatibility (1byte)  sps[2] compatibility
    // AVCLevelIndication    (1byte)  sps[3] Profile level
    // lengthSizeMinusOne    (1byte)  0xff   包长数据所使用的字节数

    // sps + pps 的数据
    // sps number            (1byte)  0xe1   sps 个数
    // sps data length       (2byte)  sps 长度
    // sps data                       sps 的内容
    // pps number            (1byte)  0x01   pps 个数
    // pps data length       (2byte)  pps 长度
    // pps data                       pps 的内容

    // body 长度 = spsLen + ppsLen + 上面所罗列出来的 16 字节
    int bodySize = spsLen + ppsLen + 16;
    // 初始化创建 RTMPPacket
    RTMPPacket *pPacket = static_cast&lt;RTMPPacket *&gt;(malloc(sizeof(RTMPPacket)));
    RTMPPacket_Alloc(pPacket, bodySize);
    RTMPPacket_Reset(pPacket);

    // 按照上面的协议，开始一个一个给 body 赋值
    char *body = pPacket-&gt;m_body;
    int index = 0;

    // CodecID 与 frame type 组合起来刚好是 1 个字节  0x17
    body[index++] = 0x17;
    // fixed : 0x00 0x00 0x00 0x00 (4byte)
    body[index++] = 0x00;
    body[index++] = 0x00;
    body[index++] = 0x00;
    body[index++] = 0x00;
    //0x01版本
    body[index++] = 0x01;
    // sps[1] profile
    body[index++] = spsData[1];
    // sps[2] compatibility
    body[index++] = spsData[2];
    // sps[3] Profile level
    body[index++] = spsData[3];
    // 0xff   包长数据所使用的字节数
    body[index++] = 0xff;

    // 0xe1   sps 个数
    body[index++] = 0xe1;
    // sps 长度
    body[index++] = (spsLen &gt;&gt; 8) &amp; 0xff;
    body[index++] = spsLen &amp; 0xff;
    // sps 的内容
    memcpy(&amp;body[index], spsData, spsLen);
    index += spsLen;
    // 0x01   pps 个数
    body[index++] = 0x01;
    // pps 长度
    body[index++] = (ppsLen &gt;&gt; 8) &amp; 0xff;
    body[index++] = ppsLen &amp; 0xff;
    // pps 的内容
    memcpy(&amp;body[index], ppsData, ppsLen);

    // 设置 RTMPPacket 的参数
    pPacket-&gt;m_packetType = RTMP_PACKET_TYPE_VIDEO;
    pPacket-&gt;m_nBodySize = bodySize;
    pPacket-&gt;m_nTimeStamp = 0;
    pPacket-&gt;m_hasAbsTimestamp = 0;
    pPacket-&gt;m_nChannel = 0x04;
    pPacket-&gt;m_headerType = RTMP_PACKET_SIZE_MEDIUM;
    pPacket-&gt;m_nInfoField2 = this-&gt;pRtmp-&gt;m_stream_id;
    // 添加到发送队列
    pPacketQueue-&gt;push(pPacket);
}
</code></pre> 
<p>紧接着发送每一帧的数据</p> 
<pre><code>/**
 * 发送每一帧的视频数据到服务器
 * @param videoData
 * @param dataLen
 * @param keyFrame
 */
void DZLivePush::pushVideo(jbyte *videoData, jint dataLen, jboolean keyFrame) {
    // frame type : 1关键帧，2 非关键帧 (4bit)
    // CodecID : 7表示 AVC (4bit)  , 与 frame type 组合起来刚好是 1 个字节  0x17
    // fixed : 0x01 0x00 0x00 0x00 (4byte)  0x01  表示 NALU 单元

    // video data length       (4byte)  video 长度
    // video data

    // body 长度 = dataLen + 上面所罗列出来的 9 字节
    int bodySize = dataLen + 9;
    // 初始化创建 RTMPPacket
    RTMPPacket *pPacket = static_cast&lt;RTMPPacket *&gt;(malloc(sizeof(RTMPPacket)));
    RTMPPacket_Alloc(pPacket, bodySize);
    RTMPPacket_Reset(pPacket);

    // 按照上面的协议，开始一个一个给 body 赋值
    char *body = pPacket-&gt;m_body;
    int index = 0;

    // CodecID 与 frame type 组合起来刚好是 1 个字节  0x17
    if (keyFrame) {
        body[index++] = 0x17;
    } else {
        body[index++] = 0x27;
    }
    // fixed : 0x01 0x00 0x00 0x00 (4byte)  0x01  表示 NALU 单元
    body[index++] = 0x01;
    body[index++] = 0x00;
    body[index++] = 0x00;
    body[index++] = 0x00;

    // (4byte)  video 长度
    body[index++] = (dataLen &gt;&gt; 24) &amp; 0xff;
    body[index++] = (dataLen &gt;&gt; 16) &amp; 0xff;
    body[index++] = (dataLen &gt;&gt; 8) &amp; 0xff;
    body[index++] = dataLen &amp; 0xff;
    // video data
    memcpy(&amp;body[index], videoData, dataLen);

    // 设置 RTMPPacket 的参数
    pPacket-&gt;m_packetType = RTMP_PACKET_TYPE_VIDEO;
    pPacket-&gt;m_nBodySize = bodySize;
    pPacket-&gt;m_nTimeStamp = RTMP_GetTime() - startPushTime;
    pPacket-&gt;m_hasAbsTimestamp = 0;
    pPacket-&gt;m_nChannel = 0x04;
    pPacket-&gt;m_headerType = RTMP_PACKET_SIZE_LARGE;
    pPacket-&gt;m_nInfoField2 = this-&gt;pRtmp-&gt;m_stream_id;
    pPacketQueue-&gt;push(pPacket);
}
</code></pre> 
<h2>5. 直播推流音频数据</h2> 
<p>最后就是把录制的声音数据推到媒体房间，这部分流程跟视频推流类似。</p> 
<blockquote> 
 <p style="text-align:center;"><span style="background-color:#eef0f4;"><span style="color:#4f4f4f;">CSDN</span><span style="color:#4f4f4f;">站内私信我，领取最新最全</span><span style="color:#4f4f4f;">C++</span><span style="color:#4f4f4f;">音视频</span><span style="color:#121212;">学习提升资料，内容包括（</span><span style="color:#121212;">C/C++</span><span style="color:#121212;">，</span><span style="color:#121212;">Linux </span><span style="color:#121212;">服务器开发，</span><span style="color:#121212;">FFmpeg </span><span style="color:#121212;">，</span><span style="color:#121212;">webRTC </span><span style="color:#121212;">，</span><span style="color:#121212;">rtmp </span><span style="color:#121212;">，</span><span style="color:#121212;">hls </span><span style="color:#121212;">，</span><span style="color:#121212;">rtsp </span><span style="color:#121212;">，</span><span style="color:#121212;">ffplay </span><span style="color:#121212;">，</span><span style="color:#121212;">srs</span><span style="color:#121212;">）</span></span></p> 
</blockquote> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/8f/40/wFN1l5Lk_o.png">  </p> 
<pre><code>/**
 * 发送音频数据到服务器
 * @param audioData 
 * @param dataLen 
 */
void DZLivePush::pushAudio(jbyte *audioData, jint dataLen) {
    // 2 字节头信息
    // 前四位表示音频数据格式 AAC  10(A)
    // 五六位表示采样率 0 = 5.5k  1 = 11k  2 = 22k  3(11) = 44k
    // 七位表示采样采样的精度 0 = 8bits  1 = 16bits
    // 八位表示音频类型  0 = mono  1 = stereo
    // 我们这里算出来第一个字节是 0xAF
    // 0x01 代表 aac 原始数据

    // body 长度 = dataLen + 上面所罗列出来的 2 字节
    int bodySize = dataLen + 2;
    // 初始化创建 RTMPPacket
    RTMPPacket *pPacket = static_cast&lt;RTMPPacket *&gt;(malloc(sizeof(RTMPPacket)));
    RTMPPacket_Alloc(pPacket, bodySize);
    RTMPPacket_Reset(pPacket);

    // 按照上面的协议，开始一个一个给 body 赋值
    char *body = pPacket-&gt;m_body;
    int index = 0;
    // 我们这里算出来第一个字节是 0xAF
    body[index++] = 0xAF;
    body[index++] = 0x01;
    // audio data
    memcpy(&amp;body[index], audioData, dataLen);

    // 设置 RTMPPacket 的参数
    pPacket-&gt;m_packetType = RTMP_PACKET_TYPE_AUDIO;
    pPacket-&gt;m_nBodySize = bodySize;
    pPacket-&gt;m_nTimeStamp = RTMP_GetTime() - startPushTime;
    pPacket-&gt;m_hasAbsTimestamp = 0;
    pPacket-&gt;m_nChannel = 0x04;
    pPacket-&gt;m_headerType = RTMP_PACKET_SIZE_LARGE;
    pPacket-&gt;m_nInfoField2 = this-&gt;pRtmp-&gt;m_stream_id;
    pPacketQueue-&gt;push(pPacket);
}
</code></pre> 
<blockquote> 
 <p style="margin-left:0;"><span style="background-color:#FFFFFF;"><strong><span style="background-color:#eef0f4;"><span style="color:#FF0000;">本文福利， 免费领取C++音视频学习资料包、技术视频，内容包括（音视频开发，面试题，FFmpeg ，webRTC ，rtmp ，hls ，rtsp ，ffplay ，编解码，推拉流，srs）↓↓↓↓↓↓见下面↓↓文章底部点击免费领取↓↓</span></span></strong></span></p> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4d749601159eef3291790173c147f5c1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">finetune一个GPT3模型</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c753aacdf7a7f20fe652b8ad248107ab/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">思迅软件收银系统E店通10数据库无缝迁移导入到Eshop</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>