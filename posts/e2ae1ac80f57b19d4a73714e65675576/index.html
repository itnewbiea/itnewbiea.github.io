<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Pytorch(笔记3)--MaxPool2d&amp;AdaptiveAvgPool2d - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Pytorch(笔记3)--MaxPool2d&amp;AdaptiveAvgPool2d" />
<meta property="og:description" content="在上一节中我们详细的阐述了Conv2d的计算原理，今天我们来讲述下Pytorch中其他比较常见的操作！
在lenet5的时候，受限于计算能力和存储能力，通常采用downsample来降维
在pytorch中使用Pooling操作来实现采样，常见的pool操作包含Max_pool，Avg_pool等
Max_pool x = t.rand(1,3,7,7) out = nn.MaxPool2d(kernel_size=2,stride=2) out.forward(x).shape torch.Size([1, 3, 3, 3]) 启动kernel代表的是观察角度，如下图kernel就是2*2，stride和Conv操作中一样代表每次移动的步长。
下图操作，在每次观察区域内取最大值作为采样数据进行降维操作，这样做的优点是可以使显性特征更明显，降维操作并没有更改输出和输出的channel_num Avg_pool 对于Avg_pool来说，参数和Max_pool是完全相同的，主要区别就是在kernel中取的是平均值操作。
AdaptiveAvgPool2d&amp;AdaptiveMaxPool2d 和之前的运算方法不同，torch.nn提供了自适应size的函数样例如下：
可以看出，输出结果的size是按照我们给丁的结果进行运算的，一个参数代表H和W相同，也可以自定义（H，W），底层是对F.adaptive_avg_pool2d的封装，一般在类中的是大写小写的是函数，在Function中。
class AdaptiveAvgPool2d(_AdaptiveAvgPoolNd): r&#34;&#34;&#34;Applies a 2D adaptive average pooling over an input signal composed of several input planes. The output is of size H x W, for any input size. The number of output features is equal to the number of input planes. Args: output_size: the target output size of the image of the form H x W." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/e2ae1ac80f57b19d4a73714e65675576/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-05-18T14:01:39+08:00" />
<meta property="article:modified_time" content="2019-05-18T14:01:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Pytorch(笔记3)--MaxPool2d&amp;AdaptiveAvgPool2d</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>   在上一节中我们详细的阐述了<a href="https://blog.csdn.net/Haiqiang1995/article/details/90300686">Conv2d的计算原理</a>，今天我们来讲述下Pytorch中其他比较常见的操作！</p> 
<p><img alt="" class="has" height="299" src="https://images2.imgbox.com/f3/b3/WnfD9lvI_o.png" width="1000"></p> 
<p>   在lenet5的时候，受限于计算能力和存储能力，通常采用downsample来降维</p> 
<p>        <img alt="" class="has" height="343" src="https://images2.imgbox.com/20/5f/7z1aHdab_o.png" width="500"></p> 
<p>在pytorch中使用Pooling操作来实现采样，常见的pool操作包含Max_pool，Avg_pool等</p> 
<h4>Max_pool</h4> 
<pre class="has"><code class="language-python">x = t.rand(1,3,7,7)
out = nn.MaxPool2d(kernel_size=2,stride=2)
out.forward(x).shape
torch.Size([1, 3, 3, 3])
</code></pre> 
<p>启动kernel代表的是观察角度，如下图kernel就是2*2，stride和Conv操作中一样代表每次移动的步长。</p> 
<p>下图操作，在每次观察区域内取最大值作为采样数据进行降维操作，这样做的优点是可以使显性特征更明显，降维操作并没有更改输出和输出的channel_num </p> 
<p><img alt="" class="has" height="390" src="https://images2.imgbox.com/3c/24/p4gfGz74_o.png" width="500"></p> 
<h4>Avg_pool</h4> 
<p>对于Avg_pool来说，参数和Max_pool是完全相同的，主要区别就是在kernel中取的是平均值操作。</p> 
<p><img alt="" class="has" height="142" src="https://images2.imgbox.com/a8/31/VWBUhsHr_o.png" width="400"></p> 
<h4>AdaptiveAvgPool2d&amp;AdaptiveMaxPool2d</h4> 
<p>和之前的运算方法不同，torch.nn提供了自适应size的函数样例如下：</p> 
<p><img alt="" class="has" height="186" src="https://images2.imgbox.com/df/77/qdI4SWXD_o.png" width="654"></p> 
<p>可以看出，输出结果的size是按照我们给丁的结果进行运算的，一个参数代表H和W相同，也可以自定义（H，W），底层是对F.adaptive_avg_pool2d的封装，一般在类中的是大写小写的是函数，在Function中。</p> 
<pre class="has"><code class="language-python">class AdaptiveAvgPool2d(_AdaptiveAvgPoolNd):
    r"""Applies a 2D adaptive average pooling over an input signal composed of several input planes.

    The output is of size H x W, for any input size.
    The number of output features is equal to the number of input planes.

    Args:
        output_size: the target output size of the image of the form H x W.
                     Can be a tuple (H, W) or a single H for a square image H x H.
                     H and W can be either a ``int``, or ``None`` which means the size will
                     be the same as that of the input.

    Examples:
        &gt;&gt;&gt; # target output size of 5x7
        &gt;&gt;&gt; m = nn.AdaptiveAvgPool2d((5,7))
        &gt;&gt;&gt; input = torch.randn(1, 64, 8, 9)
        &gt;&gt;&gt; output = m(input)
        &gt;&gt;&gt; # target output size of 7x7 (square)
        &gt;&gt;&gt; m = nn.AdaptiveAvgPool2d(7)
        &gt;&gt;&gt; input = torch.randn(1, 64, 10, 9)
        &gt;&gt;&gt; output = m(input)
        &gt;&gt;&gt; # target output size of 10x7
        &gt;&gt;&gt; m = nn.AdaptiveMaxPool2d((None, 7))
        &gt;&gt;&gt; input = torch.randn(1, 64, 10, 9)
        &gt;&gt;&gt; output = m(input)

    """

    @weak_script_method
    def forward(self, input):
        return F.adaptive_avg_pool2d(input, self.output_size)</code></pre> 
<p>我们可以根据下面的内容推导出我们不知道的参数，从而实现AdaptiveAvgPool2d&amp;AdaptiveMaxPool2与前两个函数的转换，<a href="https://github.com/pytorch/pytorch/blob/65b00aa5972e23b2a70aa60dec5125671a3d7153/aten/src/ATen/native/AdaptiveAveragePooling.cpp">C++源码</a></p> 
<pre class="has"><code class="language-python">stride = floor ( (input_size / (output_size) )

kernel_size = input_size − (output_size−1) * stride

padding = 0</code></pre> 
<p>坚持一件事或许很难，但坚持下来一定很酷！^_^</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4fc2f681eb829a3b17232995379164c4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">gojs去水印</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8f5e542e244e5d98ca01331374faea90/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">利用git执行gradle项目（图解）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>