<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>TensorRT - 使用trtexec工具转换模型、运行模型、测试网络性能 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="TensorRT - 使用trtexec工具转换模型、运行模型、测试网络性能" />
<meta property="og:description" content="文章目录 1 转换模型1.1 Caffe模型转换为TensorRT模型1.2 ONNX模型转换为TensorRT模型1.3 UFF模型转换为TensorRT模型 2 运行ONNX模型3 网络性能测试 1 转换模型 1.1 Caffe模型转换为TensorRT模型 将Caffe模型转换为TensorRT模型，启动所有精度以达到最佳性能 trtexec --deploy=mnist.prototex --model=mnist.caffe --saveEngine=mnist.trt --best 将Caffe模型转换为TensorRT模型，启动所有精度以达到最佳性能，并跳过推理性能测试 trtexec --deploy=mnist.prototex --model=mnist.caffe --saveEngine=mnist.trt --best --buildOnly 1.2 ONNX模型转换为TensorRT模型 将ONNX模型转换为静态batchsize的TensorRT模型，启动所有精度以达到最佳性能，工作区大小设置为1024M trtexec --onnx=mnist.onnx --explicitBatch --saveEngine=mnist.trt --workspace=1024 --best 将ONNX模型转换为动态batchsize的TensorRT模型，启动所有精度以达到最佳性能，工作区大小设置为1024M trtexec --onnx=mnist.onnx --minShapes=input:&lt;shape_of_min_batch&gt; --optShapes=input:&lt;shape_of_opt_batch&gt; --maxShapes=input:&lt;shape_of_max_batch&gt; --saveEngine=mnist.trt --best --workspace=1024 --best –minShapes，–optShapes ，–maxShapes必须全部设置，设置的形式为：batchsize x 通道数 x 输入尺寸x x 输入尺寸y
例如：
--minShapes=input:1x3x416x416 --optShapes=input:8x3x416x416 --maxShapes=input:8x3x416x416 1.3 UFF模型转换为TensorRT模型 待补充
2 运行ONNX模型 在具有静态输入形状的全维模式下运行 ONNX 模型 trtexec --onnx=model.onnx 使用给定的输入形状在全维模式下运行 ONNX 模型 trtexec --onnx=model." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/e3e7be82182d3c69fa373e327dfca056/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-09-21T10:40:37+08:00" />
<meta property="article:modified_time" content="2021-09-21T10:40:37+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">TensorRT - 使用trtexec工具转换模型、运行模型、测试网络性能</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1__1" rel="nofollow">1 转换模型</a></li><li><ul><li><a href="#11_CaffeTensorRT_3" rel="nofollow">1.1 Caffe模型转换为TensorRT模型</a></li><li><a href="#12_ONNXTensorRT_18" rel="nofollow">1.2 ONNX模型转换为TensorRT模型</a></li><li><a href="#13_UFFTensorRT_42" rel="nofollow">1.3 UFF模型转换为TensorRT模型</a></li></ul> 
  </li><li><a href="#2_ONNX_45" rel="nofollow">2 运行ONNX模型</a></li><li><a href="#3__65" rel="nofollow">3 网络性能测试</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1__1"></a>1 转换模型</h2> 
<h3><a id="11_CaffeTensorRT_3"></a>1.1 Caffe模型转换为TensorRT模型</h3> 
<ul><li>将Caffe模型转换为TensorRT模型，启动所有精度以达到最佳性能</li></ul> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>deploy<span class="token operator">=</span>mnist<span class="token punctuation">.</span>prototex <span class="token operator">--</span>model<span class="token operator">=</span>mnist<span class="token punctuation">.</span>caffe <span class="token operator">--</span>saveEngine<span class="token operator">=</span>mnist<span class="token punctuation">.</span>trt <span class="token operator">--</span>best
</code></pre> 
<ul><li>将Caffe模型转换为TensorRT模型，启动所有精度以达到最佳性能，并跳过推理性能测试</li></ul> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>deploy<span class="token operator">=</span>mnist<span class="token punctuation">.</span>prototex <span class="token operator">--</span>model<span class="token operator">=</span>mnist<span class="token punctuation">.</span>caffe <span class="token operator">--</span>saveEngine<span class="token operator">=</span>mnist<span class="token punctuation">.</span>trt <span class="token operator">--</span>best <span class="token operator">--</span>buildOnly
</code></pre> 
<h3><a id="12_ONNXTensorRT_18"></a>1.2 ONNX模型转换为TensorRT模型</h3> 
<ul><li>将ONNX模型转换为静态batchsize的TensorRT模型，启动所有精度以达到最佳性能，工作区大小设置为1024M</li></ul> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>onnx<span class="token operator">=</span>mnist<span class="token punctuation">.</span>onnx <span class="token operator">--</span>explicitBatch <span class="token operator">--</span>saveEngine<span class="token operator">=</span>mnist<span class="token punctuation">.</span>trt <span class="token operator">--</span>workspace<span class="token operator">=</span><span class="token number">1024</span> <span class="token operator">--</span>best
</code></pre> 
<ul><li>将ONNX模型转换为动态batchsize的TensorRT模型，启动所有精度以达到最佳性能，工作区大小设置为1024M</li></ul> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>onnx<span class="token operator">=</span>mnist<span class="token punctuation">.</span>onnx <span class="token operator">--</span>minShapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token operator">&lt;</span>shape_of_min_batch<span class="token operator">&gt;</span> <span class="token operator">--</span>optShapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token operator">&lt;</span>shape_of_opt_batch<span class="token operator">&gt;</span> <span class="token operator">--</span>maxShapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token operator">&lt;</span>shape_of_max_batch<span class="token operator">&gt;</span> <span class="token operator">--</span>saveEngine<span class="token operator">=</span>mnist<span class="token punctuation">.</span>trt <span class="token operator">--</span>best <span class="token operator">--</span>workspace<span class="token operator">=</span><span class="token number">1024</span> <span class="token operator">--</span>best
</code></pre> 
<p>–minShapes，–optShapes ，–maxShapes必须全部设置，设置的形式为：batchsize x 通道数 x 输入尺寸x x 输入尺寸y</p> 
<p>例如：</p> 
<pre><code class="prism language-cpp"><span class="token operator">--</span>minShapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token number">1</span>x3x416x416
<span class="token operator">--</span>optShapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token number">8</span>x3x416x416
<span class="token operator">--</span>maxShapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token number">8</span>x3x416x416
</code></pre> 
<h3><a id="13_UFFTensorRT_42"></a>1.3 UFF模型转换为TensorRT模型</h3> 
<p>待补充</p> 
<h2><a id="2_ONNX_45"></a>2 运行ONNX模型</h2> 
<ul><li>在具有静态输入形状的全维模式下运行 ONNX 模型</li></ul> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>onnx<span class="token operator">=</span>model<span class="token punctuation">.</span>onnx
</code></pre> 
<ul><li>使用给定的输入形状在全维模式下运行 ONNX 模型</li></ul> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>onnx<span class="token operator">=</span>model<span class="token punctuation">.</span>onnx <span class="token operator">--</span>shapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token number">32</span>x3x244x244
</code></pre> 
<ul><li>使用一系列可能的输入形状对 ONNX 模型进行基准测试</li></ul> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>onnx<span class="token operator">=</span>model<span class="token punctuation">.</span>onnx <span class="token operator">--</span>minShapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token number">1</span>x3x244x244 <span class="token operator">--</span>optShapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token number">16</span>x3x244x244 <span class="token operator">--</span>maxShapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token number">32</span>x3x244x244 <span class="token operator">--</span>shapes<span class="token operator">=</span>input<span class="token operator">:</span><span class="token number">5</span>x3x244x244
</code></pre> 
<h2><a id="3__65"></a>3 网络性能测试</h2> 
<ul><li>加载转换后的TensorRT模型进行性能测试，指定batch大小</li></ul> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>loadEngine<span class="token operator">=</span>mnist16<span class="token punctuation">.</span>trt <span class="token operator">--</span>batch<span class="token operator">=</span><span class="token number">1</span>
</code></pre> 
<ul><li>收集和打印时序跟踪信息</li></ul> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>deploy<span class="token operator">=</span>data<span class="token operator">/</span>AlexNet<span class="token operator">/</span>AlexNet_N2<span class="token punctuation">.</span>prototxt <span class="token operator">--</span>output<span class="token operator">=</span>prob <span class="token operator">--</span>exportTimes<span class="token operator">=</span>trace<span class="token punctuation">.</span>json
</code></pre> 
<ul><li>使用多流调整吞吐量</li></ul> 
<p>调整吞吐量可能需要运行多个并发执行流。例如，当实现的延迟完全在所需阈值内时，我们可以增加吞吐量，即使以一些延迟为代价。例如，为批量大小 1 和 2 保存引擎并假设两者都在 2ms 内执行，延迟阈值：</p> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>deploy<span class="token operator">=</span>GoogleNet_N2<span class="token punctuation">.</span>prototxt <span class="token operator">--</span>output<span class="token operator">=</span>prob <span class="token operator">--</span>batch<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">--</span>saveEngine<span class="token operator">=</span>g1<span class="token punctuation">.</span>trt <span class="token operator">--</span>int8 <span class="token operator">--</span>buildOnly
trtexec <span class="token operator">--</span>deploy<span class="token operator">=</span>GoogleNet_N2<span class="token punctuation">.</span>prototxt <span class="token operator">--</span>output<span class="token operator">=</span>prob <span class="token operator">--</span>batch<span class="token operator">=</span><span class="token number">2</span> <span class="token operator">--</span>saveEngine<span class="token operator">=</span>g2<span class="token punctuation">.</span>trt <span class="token operator">--</span>int8 <span class="token operator">--</span>buildOnly
</code></pre> 
<p>保存的引擎可以尝试找到低于 2 ms 的组合批次/流，以最大化吞吐量：</p> 
<pre><code class="prism language-cpp">trtexec <span class="token operator">--</span>loadEngine<span class="token operator">=</span>g1<span class="token punctuation">.</span>trt <span class="token operator">--</span>batch<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">--</span>streams<span class="token operator">=</span><span class="token number">2</span>
trtexec <span class="token operator">--</span>loadEngine<span class="token operator">=</span>g1<span class="token punctuation">.</span>trt <span class="token operator">--</span>batch<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">--</span>streams<span class="token operator">=</span><span class="token number">3</span>
trtexec <span class="token operator">--</span>loadEngine<span class="token operator">=</span>g1<span class="token punctuation">.</span>trt <span class="token operator">--</span>batch<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">--</span>streams<span class="token operator">=</span><span class="token number">4</span>
trtexec <span class="token operator">--</span>loadEngine<span class="token operator">=</span>g2<span class="token punctuation">.</span>trt <span class="token operator">--</span>batch<span class="token operator">=</span><span class="token number">2</span> <span class="token operator">--</span>streams<span class="token operator">=</span><span class="token number">2</span>
</code></pre> 
<p>如果有兴趣可以访问我的个站：<a href="https://www.stubbornhuang.com/" rel="nofollow">https://www.stubbornhuang.com/</a>，更多干货！</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/862863b82901a287662460e73846290e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">u盘格式化后数据能恢复吗，此处有妙招！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e5294df24a6e0f8932237837b74d333b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">linux图形栈(0)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>