<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习_CNN - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习_CNN" />
<meta property="og:description" content="CNN反向推导链式法则 链式法则求导示例
卷积神经网络也是这样一层一层从后到前传递梯度的，有了梯度后，就可以更新参数。上图中max模拟了池化过程，此时部分神经元失活。
CNN—卷积层 注意：原图片每个pixel可以看作神经网络的输入，权值则是对应的卷积层的每一个值。故最后需要训练的参数为卷积层的值和神经网络的阈值。
我们通常会使用多层卷积层来得到更深层次的特征图。卷积层主要进行的操作是对图片进行特征提取，随着卷积层的深入它提取到的特征就越高级。如下：
上图有6个5*5*3的卷积核，对应输出的激励特征图为28*28*6的。即对应输出的神经元有28*28*6个。对于任意一个神经元，它对应的连接为5*5*3；故每个神经元有75个权值。
神经元权值共享原则
卷积神经网络引入“权值”共享原则，即一个特征图上每个神经元对应的75个权值参数被每个神经元共享，这样6个核总共需要75*6个权值参数，而每个特征图的阈值也共享，即需要6个阈值，则总共需要75*6&#43;6个参数。
注意若卷积层为3*3*3的则，上图卷积输出为30*30*1，因为边缘不作为卷积核中心计算。n个卷积核产生n个输出（n个激励特征图）（如下图）。
卷积核基本概念：
同输入数据进行计算的二维（一维，三维）算子大小（size）用户定义，深度输入数据定义
大小一般为奇数，深度与原始数据深度相同卷积核“矩阵”值：卷积神经网络的参数卷积核初值随机生成，通过反向传播更新 卷积核参数
步长卷积核大小边界扩充（确保卷积后特征图尺度一致）（扩充方法：卷积核的宽度2i＋1，
添加pad宽度为i）卷积核数目（64、128、256 Why：GPU并行更高效） CNN正向传播，反向计算
CNN正向传播和反向传播的推导
CNN_功能层 Relu：卷积是线性运算，增加非线性描述能力
Pooling：降维，使特征图稀疏，减少数据运算量，保持精度
池化操作具体实现，以最大值池化为例。（将图片按卷积核大小均匀分块，对每一块区域选取最大值，以下图为例）
小小结
CNN=卷积层&#43;Relu&#43;池化&#43;…&#43;全连接层
归一化层：特征的scale保持一致
切分层：不同区域进行独立学习
融合层：对分开的区域合并，方便信息融合
增加图片生成或探测任务中空间信息
卷积神经网络与传统神经网络相比优点？
传统的全连接神经网络，下一层与上一层的所有神经元都有连接，训练参数多；二添加卷积层后，下一层只与卷积区域神经元相关。如下图
CNN优缺点" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/3095df6d3529a2dfbf0245d522919b8f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-01-14T18:31:07+08:00" />
<meta property="article:modified_time" content="2020-01-14T18:31:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习_CNN</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="CNN_0"></a>CNN反向推导链式法则</h3> 
<p><img src="https://images2.imgbox.com/d2/19/LiwXkqpj_o.png" alt="在这里插入图片描述"><br> <strong>链式法则求导示例</strong><br> <img src="https://images2.imgbox.com/bf/97/R7ZOaBCk_o.png" alt="在这里插入图片描述"></p> 
<p>卷积神经网络也是这样一层一层从后到前传递梯度的，有了梯度后，就可以更新参数。上图中max模拟了池化过程，此时部分神经元失活。</p> 
<h3><a id="CNN_7"></a>CNN—卷积层</h3> 
<p><mark>注意：原图片每个pixel可以看作神经网络的输入，权值则是对应的卷积层的每一个值。故最后需要训练的参数为卷积层的值和神经网络的阈值。</mark><br> 我们通常会使用多层卷积层来得到更深层次的特征图。卷积层主要进行的操作是对图片进行特征提取，随着卷积层的深入它提取到的特征就越高级。如下：<br> <img src="https://images2.imgbox.com/dc/e9/j5lO1zxs_o.png" alt="在这里插入图片描述"><br> <em><mark>上图有6个5*5*3的卷积核，对应输出的激励特征图为28*28*6的。即对应输出的神经元有28*28*6个。对于任意一个神经元，它对应的连接为5*5*3；故每个神经元有75个权值。</mark></em></p> 
<p><strong>神经元权值共享原则</strong><br> 卷积神经网络引入“权值”共享原则，即一个特征图上每个神经元对应的75个权值参数被每个神经元共享，这样6个核总共需要75*6个权值参数，而每个特征图的阈值也共享，即需要6个阈值，则总共需要75*6+6个参数。</p> 
<p>注意若卷积层为3*3*3的则，上图卷积输出为30*30*1，因为边缘不作为卷积核中心计算。n个卷积核产生n个输出（n个激励特征图）（如下图）。<br> <img src="https://images2.imgbox.com/55/7b/a1lvJXrk_o.png" alt="在这里插入图片描述"></p> 
<p><strong>卷积核基本概念：</strong></p> 
<ol><li>同输入数据进行计算的二维（一维，三维）算子</li><li>大小（size）用户定义，深度输入数据定义<br> 大小一般为奇数，深度与原始数据深度相同</li><li>卷积核“矩阵”值：<mark>卷积神经网络的参数</mark></li><li>卷积核初值随机生成，通过反向传播更新</li></ol> 
<p><strong>卷积核参数</strong></p> 
<ul><li>步长</li><li>卷积核大小</li><li>边界扩充（确保卷积后特征图尺度一致）（扩充方法：卷积核的宽度2i＋1，<br> 添加pad宽度为i）</li><li>卷积核数目（64、128、256 Why：GPU并行更高效）</li><li></ul> 
<p><strong>CNN正向传播，反向计算</strong><br> <a href="https://blog.csdn.net/Quincuntial/article/details/90412121">CNN正向传播和反向传播的推导</a><br> <img src="https://images2.imgbox.com/01/e9/y19AOEe8_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="CNN__37"></a>CNN_功能层</h3> 
<ul><li>Relu：卷积是线性运算，增加非线性描述能力<br> <img src="https://images2.imgbox.com/94/ba/msqfWVf7_o.png" alt="在这里插入图片描述"></li><li>Pooling：降维，使特征图稀疏，减少数据运算量，保持精度<br> <img src="https://images2.imgbox.com/65/bc/WhFc5fUk_o.png" alt="在这里插入图片描述"><br> 池化操作具体实现，以最大值池化为例。（将图片按卷积核大小均匀分块，对每一块区域选取最大值，以下图为例）<br> <img src="https://images2.imgbox.com/78/6a/vqnG1kHV_o.png" alt="在这里插入图片描述"></li></ul> 
<p><mark>小小结</mark><br> CNN=卷积层+Relu+池化+…+全连接层<br> <img src="https://images2.imgbox.com/50/ca/kynTIS9r_o.png" alt="在这里插入图片描述"></p> 
<ul><li> <p>归一化层：特征的scale保持一致<br> <img src="https://images2.imgbox.com/41/e7/pVPtqJgE_o.png" alt="在这里插入图片描述"></p> </li><li> <p>切分层：不同区域进行独立学习<br> <img src="https://images2.imgbox.com/84/fb/FO7iIMDu_o.png" alt="在这里插入图片描述"></p> </li><li> <p>融合层：对分开的区域合并，方便信息融合<br> <img src="https://images2.imgbox.com/f5/8f/KBHDp4g8_o.png" alt="在这里插入图片描述"></p> </li><li> <p>增加图片生成或探测任务中空间信息</p> </li></ul> 
<p><strong>卷积神经网络与传统神经网络相比优点？</strong><br> 传统的全连接神经网络，下一层与上一层的所有神经元都有连接，训练参数多；二添加卷积层后，下一层只与卷积区域神经元相关。如下图<br> <img src="https://images2.imgbox.com/b1/a7/0iKB0hRo_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/1e/fc/ccMnHRvK_o.png" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-NRDV4At7-1586779723070)(http://ufldl.stanford.edu/wiki/images/thumb/9/99/Network331.png/400px-Network331.png#pic_center)]"><br> <strong>CNN优缺点</strong><br> <img src="https://images2.imgbox.com/79/36/xtPnGWBn_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d6b1f3b5b9b37d4242bea454c661f769/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">程序员成长之旅——文件操作</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5c43fe7e49160a7aeaa278daab1643a5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Word查找替换，批量删除文档中空格、空行、指定符号中的任意内容</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>