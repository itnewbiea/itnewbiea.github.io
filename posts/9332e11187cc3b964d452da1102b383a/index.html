<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>梯度消失与梯度爆炸的问题小结 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="梯度消失与梯度爆炸的问题小结" />
<meta property="og:description" content="本文参考李沐老师动手深度学习,上篇激活函数有遇到这个问题我们来深入探讨一下
文章目录 前言
一、梯度爆炸
二、梯度爆炸的问题
三、梯度消失
四.梯度消失的问题
总结
前言 到目前为止，我们实现的每个模型都是根据某个预先指定的分布来初始化模型的参数。 有人会认为初始化方案是理所当然的，忽略了如何做出这些选择的细节。甚至有人可能会觉得，初始化方案的选择并不是特别重要。 相反，初始化方案的选择在神经网络学习中起着举足轻重的作用， 它对保持数值稳定性至关重要。 此外，这些初始化方案的选择可以与非线性激活函数的选择有趣的结合在一起。 我们选择哪个函数以及如何初始化参数可以决定优化算法收敛的速度有多快。 糟糕选择可能会导致我们在训练时遇到梯度爆炸或梯度消失。
4.8. 数值稳定性和模型初始化 — 动手学深度学习 2.0.0 documentation (d2l.ai)
一、梯度爆炸 首先我们就需要回顾一下反向传播求导的计算.也就是我们的链式法则,以及对梯度下降法的原理大致了解.
这个d-t很大也就是我们的深度很大这样累乘起来就会得到一个很大很大的值.
二、梯度爆炸的问题 三、梯度消失 最典型的例子就是我们的sigmoid函数,这个函数我们在激活函数中简单了解了一下什么叫梯度消失.
蓝色线为sigmoid函数图像,黄色是sigmoid梯度.
可见当梯度很小时,深度越深,这样累乘起来就会得到很小的数.导致梯度变化很小.
四.梯度消失的问题 梯度反向传播时对于底部,通过链式法则的累乘,梯度变化很小,所以跟那些深度很小的神经网络差不多.
总结 当数值过大或过小时会导致数值问题.
常常发生在深度模型当中,因为会对n个累乘." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/9332e11187cc3b964d452da1102b383a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-05T11:25:55+08:00" />
<meta property="article:modified_time" content="2024-01-05T11:25:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">梯度消失与梯度爆炸的问题小结</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p>本文参考李沐老师动手深度学习,上篇激活函数有遇到这个问题我们来深入探讨一下</p> 
</blockquote> 
<p></p> 
<div> 
 <h4 id="%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95">文章目录</h4> 
</div> 
<p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E5%89%8D%E8%A8%80" rel="nofollow">前言</a></p> 
<p id="%E4%B8%80%E3%80%81%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8" rel="nofollow">一、梯度爆炸</a></p> 
<p id="%E4%BA%8C%E3%80%81%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E9%97%AE%E9%A2%98-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E9%97%AE%E9%A2%98" rel="nofollow">二、梯度爆炸的问题</a></p> 
<p id="%E4%B8%89%E3%80%81%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1" rel="nofollow">三、梯度消失</a></p> 
<p id="%E5%9B%9B.%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E7%9A%84%E9%97%AE%E9%A2%98-toc" style="margin-left:0px;"><a href="#%E5%9B%9B.%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E7%9A%84%E9%97%AE%E9%A2%98" rel="nofollow">四.梯度消失的问题</a></p> 
<p id="%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E6%80%BB%E7%BB%93" rel="nofollow">总结</a></p> 
<p></p> 
<hr> 
<h2 id="%E5%89%8D%E8%A8%80"><a id="_7"></a>前言</h2> 
<p>        到目前为止，我们实现的每个模型都是根据某个预先指定的分布来初始化模型的参数。 有人会认为初始化方案是理所当然的，忽略了如何做出这些选择的细节。甚至有人可能会觉得，初始化方案的选择并不是特别重要。 相反，初始化方案的选择在神经网络学习中起着举足轻重的作用， 它对保持数值稳定性至关重要。 此外，这些初始化方案的选择可以与非线性激活函数的选择有趣的结合在一起。 我们选择哪个函数以及如何初始化参数可以决定优化算法收敛的速度有多快。 糟糕选择可能会导致我们在训练时遇到梯度爆炸或梯度消失。</p> 
<hr> 
<p><a href="https://zh.d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html" rel="nofollow" title="4.8. 数值稳定性和模型初始化 — 动手学深度学习 2.0.0 documentation (d2l.ai)">4.8. 数值稳定性和模型初始化 — 动手学深度学习 2.0.0 documentation (d2l.ai)</a></p> 
<h2 id="%E4%B8%80%E3%80%81%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8"><a id="pandas_16"></a>一、梯度爆炸</h2> 
<p>首先我们就需要回顾一下反向传播求导的计算.也就是我们的链式法则,以及对梯度下降法的原理大致了解.</p> 
<p><img alt="" height="716" src="https://images2.imgbox.com/77/ce/e67QBjEx_o.png" width="1000"></p> 
<p><img alt="" height="734" src="https://images2.imgbox.com/00/db/o7emWlLx_o.jpg" width="1200"></p> 
<p>这个d-t很大也就是我们的深度很大这样累乘起来就会得到一个很大很大的值.</p> 
<h2 id="%E4%BA%8C%E3%80%81%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E9%97%AE%E9%A2%98"><a id="_19"></a>二、梯度爆炸的问题</h2> 
<p><img alt="" height="674" src="https://images2.imgbox.com/9e/43/CpHQOJ7w_o.jpg" width="1200"></p> 
<h3><a id="1_20"></a></h3> 
<h2 id="%E4%B8%89%E3%80%81%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1">三、梯度消失</h2> 
<p>最典型的例子就是我们的sigmoid函数,这个函数我们在激活函数中简单了解了一下什么叫梯度消失.</p> 
<p><img alt="" height="832" src="https://images2.imgbox.com/f8/ab/sih2tfb4_o.jpg" width="1200"></p> 
<p></p> 
<p>蓝色线为sigmoid函数图像,黄色是sigmoid梯度.</p> 
<p><img alt="" height="164" src="https://images2.imgbox.com/8a/54/uCxQm8ir_o.png" width="1200"></p> 
<p>可见当梯度很小时,深度越深,这样累乘起来就会得到很小的数.导致梯度变化很小.</p> 
<h2 id="%E5%9B%9B.%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E7%9A%84%E9%97%AE%E9%A2%98">四.梯度消失的问题</h2> 
<p><img alt="" height="736" src="https://images2.imgbox.com/e5/df/fi9ib7Ss_o.jpg" width="1082"></p> 
<p>梯度反向传播时对于底部,通过链式法则的累乘,梯度变化很小,所以跟那些深度很小的神经网络差不多.</p> 
<p></p> 
<hr> 
<h2 id="%E6%80%BB%E7%BB%93"><a id="_45"></a>总结</h2> 
<p>当数值过大或过小时会导致数值问题.</p> 
<p>常常发生在深度模型当中,因为会对n个累乘.</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/32718c884a60051e50a8496d5f7eb826/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">修改安卓apk设置为安卓主屏幕（launcher）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/36bc7d4869a534e143962875468ed66e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">零信任（Zero Trust）：理论与实践</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>