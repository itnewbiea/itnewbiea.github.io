<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【教程】逻辑回归怎么做多分类 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【教程】逻辑回归怎么做多分类" />
<meta property="og:description" content="目录
一、逻辑回归模型介绍
1.1 逻辑回归模型简介
1.2 逻辑回归二分类模型
1.3 逻辑回归多分类模型
二、如何实现逻辑回归二分类
2.1 逻辑回归二分类例子
2.2 逻辑回归二分类实现代码
三、如何实现一个逻辑回归多分类
3.1 逻辑回归多分类问题
3.1 逻辑回归多分类的代码实现
本文部分图文借鉴自《老饼讲解-机器学习》
一、逻辑回归模型介绍 1.1 逻辑回归模型简介 逻辑回归模型是一种广义的线性回归分析模型，常用于数据挖掘，疾病自动诊断，经济预测等领域。它与多重线性回归有很多相同之处，模型形式基本相同，都具有w&#39;x&#43;b，其中w和b是待求参数。重线性回归直接将w&#39;x&#43;b作为因变量即y =w&#39;x&#43;b，而逻辑回归则通过sigmiod函数将w&#39;x&#43;b对应一个概率P，
也就是说，线性回归用于数值预测问题，而逻辑回归则用于分类问题，逻辑回归输出的是属于类别的概率。逻辑回归的意义如下图所示，用直线/超平面将不同类别的数据样本进行划分：
逻辑回归可以用于做二分类(即只有两个类别)，也可以做多分类(2个以上的类别)。二分类是逻辑回归的基本模型，而多分类则是二分类模型的拓展。
1.2 逻辑回归二分类模型 逻辑回归的二分类模型如下：
它的损失函数为最大似然损失函数：
模型中的参数W就是通过求解损失函数，令损失函数取最小值，从而求得W的最优解。模型的求解一般使用梯度下降法。
1.3 逻辑回归多分类模型 逻辑回归多分类模型是二分类模型的拓展。主要有softmax回归和OVR两种拓展方法,其中，OVR是基于二分类模型的一种通用拓展方法。两种方法的原理如下：
softmax回归：softmax回归是逻辑回归在多分类问题上的推广，通过修改逻辑回归的损失函数，将逻辑回归变为softmax回归。softmax回归会有相同于类别数的输出，输出的值为对于样本属于各个类别的概率，最后对于样本进行预测的类型为概率值最高的那个类别。
OVR(基于二分类的逻辑回归)：根据每个类别都建立一个二分类器，本类别的样本标签定义为0，其它分类样本标签定义为1，则有多少个类别就构造多少个逻辑回归分类器。这种方法实际上是将多分类问题划分为多个二分类问题来解决。
上述两种方法都是常用的逻辑回归多分类方法，无论采用哪种方法，逻辑回归多分类模型都需要根据具体问题和数据集进行调整和优化，以获得更好的分类性能。
当为Softmax回归时，逻辑回归多分类的模型表达式如下：
当为OVR模型时，逻辑回归多分类的模型表达式如下
其中，代表属于k类的概率
二、如何实现逻辑回归二分类 2.1 逻辑回归二分类例子 在python中，可以使用sklearn的LogisticRegression实现一个逻辑回归的，例子如下
具体数据如下：
特征：平均平滑度、平均紧凑度、平均凹面、平均凹点，类别：0-恶性、1-良性
即以sk-learn中的breast_cancer的数据，breast_cancer原数据中有30个特征，为方便讲解，我们这里只选4个。下面展示调用sklearn训练一个逻辑回归的DEMO代码
2.2 逻辑回归二分类实现代码 代码简介 ：
1. 数据归一化（用sklearn的逻辑回归一般要作数据归一化）
2. 用归一化数据训练逻辑回归模型 3. 用训练好的逻辑回归模型预测 from sklearn.datasets import load_breast_cancer from sklearn.linear_model import LogisticRegression import numpy as np #----数据加载------ data = load_breast_cancer() X = data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/d7bae55154b729300d9eef41d1052831/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-07T18:56:27+08:00" />
<meta property="article:modified_time" content="2023-12-07T18:56:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【教程】逻辑回归怎么做多分类</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D" rel="nofollow">一、逻辑回归模型介绍</a></p> 
<p id="1.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-toc" style="margin-left:40px;"><a href="#1.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B" rel="nofollow">1.1 逻辑回归模型简介</a></p> 
<p id="1.2%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B-toc" style="margin-left:40px;"><a href="#1.2%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B" rel="nofollow">1.2 逻辑回归二分类模型</a></p> 
<p id="1.3%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B-toc" style="margin-left:40px;"><a href="#1.3%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B" rel="nofollow">1.3 逻辑回归多分类模型</a></p> 
<p id="%E4%BA%8C%E3%80%81%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB" rel="nofollow">二、如何实现逻辑回归二分类</a></p> 
<p id="2.1%C2%A0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB%E4%BE%8B%E5%AD%90-toc" style="margin-left:40px;"><a href="#2.1%C2%A0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB%E4%BE%8B%E5%AD%90" rel="nofollow">2.1 逻辑回归二分类例子</a></p> 
<p id="2.2%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#2.2%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81" rel="nofollow">2.2 逻辑回归二分类实现代码</a></p> 
<p id="%E4%B8%89%E3%80%81%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB" rel="nofollow">三、如何实现一个逻辑回归多分类</a></p> 
<p id="3.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-toc" style="margin-left:40px;"><a href="#3.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98" rel="nofollow">3.1 逻辑回归多分类问题</a></p> 
<p id="3.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-toc" style="margin-left:40px;"><a href="#3.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0" rel="nofollow">3.1 逻辑回归多分类的代码实现</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p><strong><span style="color:#fe2c24;"> 本文部分图文借鉴自</span><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><a href="https://ml.bbbdata.com/?f=wzx" rel="nofollow" title="《老饼讲解-机器学习》">《老饼讲解-机器学习》</a></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D">一、逻辑回归模型介绍</h2> 
<h3 id="1.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B">1.1 逻辑回归模型简介</h3> 
<p>逻辑回归模型是一种广义的线性回归分析模型，常用于数据挖掘，疾病自动诊断，经济预测等领域。它与多重线性回归有很多相同之处，模型形式基本相同，都具有w'x+b，其中w和b是待求参数。重线性回归直接将w'x+b作为因变量即y =w'x+b，而逻辑回归则通过sigmiod函数将w'x+b对应一个概率P，</p> 
<p>也就是说，线性回归用于数值预测问题，而逻辑回归则用于分类问题，逻辑回归输出的是属于类别的概率。逻辑回归的意义如下图所示，用直线/超平面将不同类别的数据样本进行划分：</p> 
<p class="img-center"><img alt="" height="225" src="https://images2.imgbox.com/63/5d/XLTCmaf7_o.png" width="494"></p> 
<p>逻辑回归可以用于做二分类(即只有两个类别)，也可以做多分类(2个以上的类别)。二分类是逻辑回归的基本模型，而多分类则是二分类模型的拓展。</p> 
<h3 id="1.2%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B">1.2 逻辑回归二分类模型</h3> 
<p>逻辑回归的二分类模型如下：</p> 
<p class="img-center"><img alt="" height="35" src="https://images2.imgbox.com/2a/52/bCeCWWbd_o.png" width="206"></p> 
<p>它的损失函数为最大似然损失函数：</p> 
<p class="img-center"><img alt="" height="55" src="https://images2.imgbox.com/2c/05/HQqj4dOu_o.png" width="307"></p> 
<p>模型中的参数W就是通过求解损失函数，令损失函数取最小值，从而求得W的最优解。模型的求解一般使用梯度下降法。</p> 
<h3 id="1.3%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B">1.3 逻辑回归多分类模型</h3> 
<p>逻辑回归多分类模型是二分类模型的拓展。主要有softmax回归和OVR两种拓展方法,其中，OVR是基于二分类模型的一种通用拓展方法。两种方法的原理如下：</p> 
<p><strong>softmax回归：</strong>softmax回归是逻辑回归在多分类问题上的推广，通过修改逻辑回归的损失函数，将逻辑回归变为softmax回归。softmax回归会有相同于类别数的输出，输出的值为对于样本属于各个类别的概率，最后对于样本进行预测的类型为概率值最高的那个类别。<br><strong>OVR(基于二分类的逻辑回归)</strong>：根据每个类别都建立一个二分类器，本类别的样本标签定义为0，其它分类样本标签定义为1，则有多少个类别就构造多少个逻辑回归分类器。这种方法实际上是将多分类问题划分为多个二分类问题来解决。<br> 上述两种方法都是常用的逻辑回归多分类方法，无论采用哪种方法，逻辑回归多分类模型都需要根据具体问题和数据集进行调整和优化，以获得更好的分类性能。</p> 
<p>当为Softmax回归时，逻辑回归多分类的模型表达式如下：</p> 
<p class="img-center"><img alt="" height="25" src="https://images2.imgbox.com/f7/59/fyPGRXgv_o.png" width="245"></p> 
<p>当为OVR模型时，逻辑回归多分类的模型表达式如下</p> 
<p style="text-align:center;"><img alt="P_k(x)=\textbf{sigmoid}(WX)" class="mathcode" src="https://images2.imgbox.com/3a/08/yV2PSoxw_o.png"></p> 
<p style="text-align:center;">其中，<img alt="P_k" class="mathcode" src="https://images2.imgbox.com/a9/42/h5EiyG3n_o.png">代表属于k类的概率</p> 
<h2 id="%E4%BA%8C%E3%80%81%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB">二、如何实现逻辑回归二分类</h2> 
<h3 id="2.1%C2%A0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB%E4%BE%8B%E5%AD%90">2.1 逻辑回归二分类例子</h3> 
<p>在python中，可以使用sklearn的LogisticRegression实现一个逻辑回归的，例子如下</p> 
<p>具体数据如下：<br>  </p> 
<p class="img-center"><img alt="" height="276" src="https://images2.imgbox.com/4d/47/NCAB6Ubw_o.png" width="623"></p> 
<p><br> 特征：平均平滑度、平均紧凑度、平均凹面、平均凹点，类别：0-恶性、1-良性<br>  即以sk-learn中的breast_cancer的数据，breast_cancer原数据中有30个特征，为方便讲解，我们这里只选4个。下面展示调用sklearn训练一个逻辑回归的DEMO代码<br>  </p> 
<h3 id="2.2%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BA%8C%E5%88%86%E7%B1%BB%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81">2.2 逻辑回归二分类实现代码</h3> 
<p>代码简介  ：<br> 1. 数据归一化（用sklearn的逻辑回归一般要作数据归一化）<br> 2. 用归一化数据训练逻辑回归模型                                      <br> 3. 用训练好的逻辑回归模型预测  </p> 
<pre><code class="language-python">from sklearn.datasets import load_breast_cancer
from sklearn.linear_model import LogisticRegression
import numpy as np

#----数据加载------
data = load_breast_cancer()
X    = data.data[:,4:8]  #这里我们只选择4个变量进行建模
y    = data.target
#----数据归一化------
xmin=X.min(axis=0)
xmax=X.max(axis=0)
X_norm=(X-xmin)/(xmax-xmin)

#-----训练模型--------------------
clf = LogisticRegression(random_state=0)            
clf.fit(X_norm,y)

#------模型预测-------------------------------
pred_y      = clf.predict(X_norm)              # 预测类别
pred_prob_y    = clf.predict_proba(X_norm)[:,1]   # 预测属于1类的概率

print( "模型系数(对应归一化数据):",clf.coef_[0])
print( "模型阈值(对应归一化数据):",clf.intercept_)
print( "模型准确率:",(pred_y== y).sum()/len(y))</code></pre> 
<p>运行结果如下：</p> 
<p><img alt="" height="229" src="https://images2.imgbox.com/ce/b5/FddTz1A3_o.png" width="691"></p> 
<p></p> 
<h2 id="%E4%B8%89%E3%80%81%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB">三、如何实现一个逻辑回归多分类</h2> 
<h3 id="3.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98">3.1 逻辑回归多分类问题</h3> 
<p>下面是一个简单的多分类问题<br><strong>问题</strong><br> 现已采集150组 鸢尾花数据，<br> 包括鸢尾花的四个特征与鸢尾花的类别<br> 我们希望通过采集的数据，训练一个决策树模型<br> 之后应用该模型，可以根据鸢尾花的四个特征去预测它的类别<br><strong>数据      </strong><br> 数据如下（即sk-learn中的iris数据）：<br>  </p> 
<p class="img-center"><img alt="" height="339" src="https://images2.imgbox.com/b4/82/sfDj5u8Q_o.png" width="370"></p> 
<p> <br> 花萼长度 sepal length (cm) 、花萼宽度 sepal width (cm)    <br> 花瓣长度 petal length (cm) 、花瓣宽度 petal width (cm)  <br> 山鸢尾：0,杂色鸢尾：1,弗吉尼亚鸢尾：2      <strong>             </strong></p> 
<h3 id="3.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0">3.1 逻辑回归多分类的代码实现</h3> 
<p>用多类别逻辑回归解决该问题的具体思路如下<br><strong> </strong>1. 数据归一化（用sklearn的逻辑回归一般要作数据归一化）<br> 2. 用归一化数据训练逻辑回归模型                                      <br> 3. 用训练好的逻辑回归模型预测                                         <br> 4. 模型参数提取     </p> 
<pre><code class="language-python"># -*- coding: utf-8 -*-
"""
sklearn逻辑回归多分类例子(带模型公式提取)
"""
from sklearn.linear_model import LogisticRegression
import numpy as np
from sklearn.datasets import load_iris
#----数据加载------

iris = load_iris()    
X    = iris.data
y    = iris.target
#----数据归一化------
xmin   = X.min(axis=0)
xmax   = X.max(axis=0)
X_norm = (X-xmin)/(xmax-xmin)

#-----训练模型--------------------
clf = LogisticRegression(random_state=0,multi_class='multinomial')            
clf.fit(X_norm,y)

#------模型预测-------------------------------
pred_y      = clf.predict(X_norm)
pred_prob_y    = clf.predict_proba(X_norm) 

#------------提取系数w与阈值b-----------------------
w_norm = clf.coef_                             # 模型系数(对应归一化数据)
b_norm = clf.intercept_                           # 模型阈值(对应归一化数据)
w    = w_norm/(xmax-xmin)                       # 模型系数(对应原始数据)
b    = b_norm -  (w_norm/(xmax - xmin)).dot(xmin)      # 模型阈值(对应原始数据)
# ------------用公式预测------------------------------
wxb = X.dot(w.T)+ b
wxb = wxb - wxb.sum(axis=1).reshape((-1, 1)) # 由于担心数值过大会溢出，对wxb作调整
self_prob_y = np.exp(wxb)/np.exp(wxb).sum(axis=1).reshape((-1, 1))
self_pred_y = self_prob_y.argmax(axis=1)


#------------打印信息--------------------------
print("\n------模型参数-------")     
print( "模型系数:",w)
print( "模型阈值:",b)
print("\n-----验证准确性-------")  
print("提取公式计算的概率与sklearn自带预测概率的最大误差", abs(pred_prob_y-self_prob_y).max())</code></pre> 
<p>    运行结果如下：</p> 
<p><img alt="" height="310" src="https://images2.imgbox.com/a2/47/SVorRGe6_o.png" width="975"></p> 
<p></p> 
<hr> 
<p><span style="color:#fe2c24;"><strong>如果觉得本文有帮助，点个赞吧！</strong></span></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5d24b9f34d8160b971ecc48065c4d913/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">工作中Hutool包的常用方法总结</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8eaa67dad184de25203917d974e11813/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何在Spring Boot中集成RabbitMQ</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>