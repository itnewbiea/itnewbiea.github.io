<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>自动编码器python_算法进阶(一)之自动编码器 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="自动编码器python_算法进阶(一)之自动编码器" />
<meta property="og:description" content="自动编码器(autoencoder) 是神经网络的一种，该网络可以看作由两部分组成：一个编码器函数h = f(x) 和一个生成重构的解码器r = g(h)。传统上，自动编码器被用于降维或特征学习
自编码器原理示意图
编码器：将原始高维特征数据映射为低维度表征数据
解码器：将低纬度的压缩特征重构回原始数据
核心：输入特征等于输出特征
那么我们就会有一个疑问:压缩特征为什么小于输入特征？这里我们使用的是欠完备自动编码器：输入特征大于压缩特征.
下面我们手动编写一个自动编码器, 我们先来整理一下编写流程:
1. 获取数据
2. 模型搭建
3. 最优化设置
4. 模型训练
5. 数据3D可视化
然后呢, 我们就按照这个流程来编写我们的代码, 此代码的前提是有GPU, 代码才不会报错.
1. 获取数据
import numpy as np
import torch
import torchvision
import torchvision.transforms as tansforms
import torch.nn as nn
import torch.utils.data as data
# 数据集下载和导入
train_data = torchvision.datasets.MNIST(
root=&#34;./data/MNIST_data&#34;,
train=True,
transform=tansforms.ToTensor(),
download=True,
)
print(train_data.data.size()) # [60000,28,28]
print(train_data.targets.size()) # [60000]
# 显示图片
import matplotlib." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/d42dc677d891785bfe937927ebf45443/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-12-08T07:09:27+08:00" />
<meta property="article:modified_time" content="2020-12-08T07:09:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">自动编码器python_算法进阶(一)之自动编码器</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div style="font-size:16px;"> 
 <p>自动编码器(autoencoder) 是神经网络的一种，该网络可以看作由两部分组成：一个编码器函数h = f(x) 和一个生成重构的解码器r = g(h)。传统上，自动编码器被用于降维或特征学习</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>自编码器原理示意图</p> 
 <p>编码器：将原始高维特征数据映射为低维度表征数据</p> 
 <p>解码器：将低纬度的压缩特征重构回原始数据</p> 
 <p>核心：输入特征等于输出特征</p> 
 <p>那么我们就会有一个疑问:压缩特征为什么小于输入特征？这里我们使用的是欠完备自动编码器：输入特征大于压缩特征.</p> 
 <p>下面我们手动编写一个自动编码器, 我们先来整理一下编写流程:</p> 
 <p>1. 获取数据</p> 
 <p>2. 模型搭建</p> 
 <p>3. 最优化设置</p> 
 <p>4. 模型训练</p> 
 <p>5. 数据3D可视化</p> 
 <p>然后呢, 我们就按照这个流程来编写我们的代码, 此代码的前提是有GPU, 代码才不会报错.</p> 
 <p>1. 获取数据</p> 
 <p>import numpy as np</p> 
 <p>import torch</p> 
 <p>import torchvision</p> 
 <p>import torchvision.transforms as tansforms</p> 
 <p>import torch.nn as nn</p> 
 <p>import torch.utils.data as data</p> 
 <p># 数据集下载和导入</p> 
 <p>train_data = torchvision.datasets.MNIST(</p> 
 <p>root="./data/MNIST_data",</p> 
 <p>train=True,</p> 
 <p>transform=tansforms.ToTensor(),</p> 
 <p>download=True,</p> 
 <p>)</p> 
 <p>print(train_data.data.size()) # [60000,28,28]</p> 
 <p>print(train_data.targets.size()) # [60000]</p> 
 <p># 显示图片</p> 
 <p>import matplotlib.pyplot as plt</p> 
 <p># plt.imshow(train_data.data[10].numpy(),cmap="gray")</p> 
 <p># plt.title("img_label:"+str(train_data.targets[10].numpy()))</p> 
 <p># plt.show()</p> 
 <p>2. 模型搭建</p> 
 <p>class AutoEncoder(nn.Module):</p> 
 <p>def __init__(self):</p> 
 <p>super(AutoEncoder, self).__init__()</p> 
 <p>self.encoder = nn.Sequential(</p> 
 <p>nn.Linear(28 * 28, 3),</p> 
 <p>nn.Tanh(),</p> 
 <p>)</p> 
 <p>self.decoder = nn.Sequential(</p> 
 <p>nn.Linear(3, 28 * 28),</p> 
 <p>nn.ReLU(),</p> 
 <p>)</p> 
 <p>def forward(self, x):</p> 
 <p>encode = self.encoder(x)</p> 
 <p>decode = self.decoder(encode)</p> 
 <p>return encode, decode</p> 
 <p>3. 最优化设置</p> 
 <p># 网络初始化</p> 
 <p>EPOCH = 10 # 训练周期</p> 
 <p>BATCH_SIZE = 64</p> 
 <p>LR = 0.005 # 学习率</p> 
 <p>autoencoder = AutoEncoder()</p> 
 <p>if torch.cuda.is_available():</p> 
 <p>autoencoder = autoencoder.cuda()</p> 
 <p>optim = torch.optim.Adam(autoencoder.parameters(), lr=LR)</p> 
 <p>loss_func = nn.MSELoss()</p> 
 <p># 图像初始化，用于动态展示训练结果</p> 
 <p>N_test_img = 5</p> 
 <p>f, a = plt.subplots(2, N_test_img, figsize=(5, 2))</p> 
 <p>plt.ion() # 持续绘图</p> 
 <p># 原始图像</p> 
 <p>view_data = train_data.data[:N_test_img].view(-1, 28 * 28).type(torch.FloatTensor)</p> 
 <p>for i in range(N_test_img):</p> 
 <p>a[0][i].imshow(np.reshape(view_data.data.numpy()[i], (28, 28)), cmap="gray")</p> 
 <p>a[0][i].set_xticks(())</p> 
 <p>a[0][i].set_yticks(())</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>上图为显示的效果图</p> 
 <p>4. 模型训练</p> 
 <p># 训练网络</p> 
 <p>train_loader = data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)</p> 
 <p>for epoch in range(EPOCH):</p> 
 <p>for i, (x, y) in enumerate(train_loader):</p> 
 <p>if torch.cuda.is_available():</p> 
 <p>x = x.cuda()</p> 
 <p>b_x = x.view(-1, 28 * 28) # [batch_size,28*28]</p> 
 <p>encode, decode = autoencoder(b_x)</p> 
 <p>loss = loss_func(decode, b_x) # 均方误差损失函数</p> 
 <p>optim.zero_grad() # 清空梯度缓存</p> 
 <p>loss.backward()</p> 
 <p>optim.step()</p> 
 <p>if i % 500 == 0:</p> 
 <p>print("Epoch:", epoch, " train loss: ", loss.item())</p> 
 <p># 绘制解码图像，第二行</p> 
 <p>_, decode = autoencoder(view_data.cuda())</p> 
 <p>for i in range(N_test_img):</p> 
 <p>a[1][i].clear()</p> 
 <p>a[1][i].imshow(np.reshape(decode.cpu().data.numpy()[i], (28, 28)), cmap="gray")</p> 
 <p>a[1][i].set_xticks(())</p> 
 <p>a[1][i].set_yticks(())</p> 
 <p>plt.draw()</p> 
 <p>plt.pause(0.05)</p> 
 <p>plt.ioff()</p> 
 <p>plt.show()</p> 
 <p>下图为显示的效果图:</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>5. 数据3D可视化</p> 
 <p># 3D可视化</p> 
 <p>from mpl_toolkits.mplot3d import Axes3D</p> 
 <p>from matplotlib import cm</p> 
 <p>view_data = train_data.data[:200].view(-1,28*28).type(torch.FloatTensor)/255.</p> 
 <p>encode,_ = autoencoder(view_data.cuda())</p> 
 <p>fig =plt.figure()</p> 
 <p>ax = Axes3D(fig)</p> 
 <p>X = encode.cpu().data[:,0].numpy()</p> 
 <p>Y = encode.cpu().data[:,1].numpy()</p> 
 <p>Z = encode.cpu().data[:,2].numpy()</p> 
 <p>values = train_data.targets[:200].numpy()</p> 
 <p>for x,y,z,s in zip(X,Y,Z,values):</p> 
 <p>c = cm.rainbow(int(255*s/9))</p> 
 <p>ax.text(x,y,z,s,backgroundcolor=c)</p> 
 <p>ax.set_xlim(X.min(),X.max())</p> 
 <p>ax.set_ylim(Y.min(),Y.max())</p> 
 <p>ax.set_zlim(Z.min(),Z.max())</p> 
 <p>plt.show()</p> 
 <p>plt.pause(50)</p> 
 <p>下图为显示的效果图:</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>原文链接:https://blog.csdn.net/junjunzai123/article/details/107006799</p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a776930e2c90c4825e9b1bed92595dfe/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python集合中的元素不允许重复对吗_python字典中的值为什么不允许重复</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/aad8659b73ee4d9bc7d2a0fad59c66a8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python里import turtle_[转] Python的import初探</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>