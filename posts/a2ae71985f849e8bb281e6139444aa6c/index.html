<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>hdf的基本概念与使用 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="hdf的基本概念与使用" />
<meta property="og:description" content="基本概念 首先，它是一个文件系统，用于存储文件，通过统一的命名空间——目录树来定位文件
其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色；
重要特性如下：
（1）HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M
（2）HDFS文件系统会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data
（3）目录结构及文件分块信息(元数据)的管理由namenode节点承担
——namenode是HDFS集群主节点，负责维护整个hdfs文件系统的目录树，以及每一个路径（文件）所对应的block块信息（block的id，及所在的datanode服务器）
（4）文件的各个block的存储管理由datanode节点承担
---- datanode是HDFS集群从节点，每一个block都可以在多个datanode上存储多个副本（副本数量也可以通过参数设置dfs.replication）
（5）HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改
(注：适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太高)
shell命令行操作放肆 HDFS提供shell命令行客户端，使用方法如下：
命令行客户端支持的命令参数 [-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;] [-cat [-ignoreCrc] &lt;src&gt; ...] [-checksum &lt;src&gt; ...] [-chgrp [-R] GROUP PATH...] [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...] [-chown [-R] [OWNER][:[GROUP]] PATH...] [-copyFromLocal [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;] [-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;] [-count [-q] &lt;path&gt; ...] [-cp [-f] [-p] &lt;src&gt; ... &lt;dst&gt;] [-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]] [-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;] [-df [-h] [&lt;path&gt; ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/a2ae71985f849e8bb281e6139444aa6c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-04-26T15:21:04+08:00" />
<meta property="article:modified_time" content="2019-04-26T15:21:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">hdf的基本概念与使用</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>基本概念</h2> 
<p>首先，它是一个文件系统，用于存储文件，通过统一的命名空间——目录树来定位文件<br> 其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色；<br> 重要特性如下：<br> （1）HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M</p> 
<p>（2）HDFS文件系统会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data</p> 
<p>（3）目录结构及文件分块信息(元数据)的管理由namenode节点承担<br> ——namenode是HDFS集群主节点，负责维护整个hdfs文件系统的目录树，以及每一个路径（文件）所对应的block块信息（block的id，及所在的datanode服务器）</p> 
<p>（4）文件的各个block的存储管理由datanode节点承担<br> ---- datanode是HDFS集群从节点，每一个block都可以在多个datanode上存储多个副本（副本数量也可以通过参数设置dfs.replication）</p> 
<p>（5）HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改</p> 
<p>(注：适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太高)</p> 
<h2><a id="shell_18"></a>shell命令行操作放肆</h2> 
<p>HDFS提供shell命令行客户端，使用方法如下：<br> <img src="https://images2.imgbox.com/a2/2c/WhSrTSV6_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_21"></a>命令行客户端支持的命令参数</h3> 
<pre><code>     [-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]
    [-cat [-ignoreCrc] &lt;src&gt; ...]
    [-checksum &lt;src&gt; ...]
    [-chgrp [-R] GROUP PATH...]
    [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]
    [-chown [-R] [OWNER][:[GROUP]] PATH...]
    [-copyFromLocal [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]
    [-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]
    [-count [-q] &lt;path&gt; ...]
    [-cp [-f] [-p] &lt;src&gt; ... &lt;dst&gt;]
    [-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]
    [-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]
    [-df [-h] [&lt;path&gt; ...]]
    [-du [-s] [-h] &lt;path&gt; ...]
    [-expunge]
    [-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]
    [-getfacl [-R] &lt;path&gt;]
    [-getmerge [-nl] &lt;src&gt; &lt;localdst&gt;]
    [-help [cmd ...]]
    [-ls [-d] [-h] [-R] [&lt;path&gt; ...]]
    [-mkdir [-p] &lt;path&gt; ...]
    [-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]
    [-moveToLocal &lt;src&gt; &lt;localdst&gt;]
    [-mv &lt;src&gt; ... &lt;dst&gt;]
    [-put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]
    [-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]
    [-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]
    [-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]
    [-setfacl [-R] [{-b|-k} {-m|-x &lt;acl_spec&gt;} &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]
    [-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]
    [-stat [format] &lt;path&gt; ...]
    [-tail [-f] &lt;file&gt;]
    [-test -[defsz] &lt;path&gt;]
    [-text [-ignoreCrc] &lt;src&gt; ...]
    [-touchz &lt;path&gt; ...]
    [-usage [cmd ...]]
</code></pre> 
<h3><a id="_58"></a>常用命令参数介绍</h3> 
<p>-help<br> 功能：输出这个命令参数手册<br> -ls<br> 功能：显示目录信息<br> 示例： hadoop fs -ls hdfs://hadoop-server01:9000/<br> 备注：这些参数中，所有的hdfs路径都可以简写<br> –&gt;hadoop fs -ls / 等同于上一条命令的效果<br> -mkdir<br> 功能：在hdfs上创建目录<br> 示例：hadoop fs -mkdir -p /aaa/bbb/cc/dd<br> -moveFromLocal<br> 功能：从本地剪切粘贴到hdfs<br> 示例：hadoop fs - moveFromLocal /home/hadoop/a.txt /aaa/bbb/cc/dd<br> -moveToLocal<br> 功能：从hdfs剪切粘贴到本地<br> 示例：hadoop fs - moveToLocal /aaa/bbb/cc/dd /home/hadoop/a.txt<br> –appendToFile<br> 功能：追加一个文件到已经存在的文件末尾<br> 示例：hadoop fs -appendToFile ./hello.txt hdfs://hadoop-server01:9000/hello.txt<br> 可以简写为：<br> Hadoop fs -appendToFile ./hello.txt /hello.txt</p> 
<p>-cat<br> 功能：显示文件内容<br> 示例：hadoop fs -cat /hello.txt</p> 
<p>-tail<br> 功能：显示一个文件的末尾<br> 示例：hadoop fs -tail /weblog/access_log.1<br> -text<br> 功能：以字符形式打印一个文件的内容<br> 示例：hadoop fs -text /weblog/access_log.1<br> -chgrp<br> -chmod<br> -chown<br> 功能：linux文件系统中的用法一样，对文件所属权限<br> 示例：<br> hadoop fs -chmod 666 /hello.txt<br> hadoop fs -chown someuser:somegrp /hello.txt<br> -copyFromLocal<br> 功能：从本地文件系统中拷贝文件到hdfs路径去<br> 示例：hadoop fs -copyFromLocal ./jdk.tar.gz /aaa/<br> -copyToLocal<br> 功能：从hdfs拷贝到本地<br> 示例：hadoop fs -copyToLocal /aaa/jdk.tar.gz<br> -cp<br> 功能：从hdfs的一个路径拷贝hdfs的另一个路径<br> 示例： hadoop fs -cp /aaa/jdk.tar.gz /bbb/jdk.tar.gz.2</p> 
<p>-mv<br> 功能：在hdfs目录中移动文件<br> 示例： hadoop fs -mv /aaa/jdk.tar.gz /<br> -get<br> 功能：等同于copyToLocal，就是从hdfs下载文件到本地<br> 示例：hadoop fs -get /aaa/jdk.tar.gz<br> -getmerge<br> 功能：合并下载多个文件<br> 示例：比如hdfs的目录 /aaa/下有多个文件:log.1, log.2,log.3,…<br> hadoop fs -getmerge /aaa/log.* ./log.sum<br> -put<br> 功能：等同于copyFromLocal<br> 示例：hadoop fs -put /aaa/jdk.tar.gz /bbb/jdk.tar.gz.2</p> 
<p>-rm<br> 功能：删除文件或文件夹<br> 示例：hadoop fs -rm -r /aaa/bbb/</p> 
<p>-rmdir<br> 功能：删除空目录<br> 示例：hadoop fs -rmdir /aaa/bbb/ccc<br> -df<br> 功能：统计文件系统的可用空间信息<br> 示例：hadoop fs -df -h /</p> 
<p>-du<br> 功能：统计文件夹的大小信息<br> 示例：<br> hadoop fs -du -s -h /aaa/*</p> 
<p>-count<br> 功能：统计一个指定目录下的文件节点数量<br> 示例：hadoop fs -count /aaa/</p> 
<p>-setrep<br> 功能：设置hdfs中文件的副本数量<br> 示例：hadoop fs -setrep 3 /aaa/jdk.tar.gz<br> &lt;这里设置的副本数只是记录在namenode的元数据中，是否真的会有这么多副本，还得看datanode的数量&gt;</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9aa3664976a8d60c477df902365bf125/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java语言调用C&#43;&#43; DLL库方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fe6748bb2eba091c7ddb49564c2745c8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">读书笔记：推荐系统实践-第八章-评分预测问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>