<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Diverse Embedding Expansion Network and Low-Light Cross-Modality Benchmark for V-I Re-ID:如何有效利用生成嵌入？ - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Diverse Embedding Expansion Network and Low-Light Cross-Modality Benchmark for V-I Re-ID:如何有效利用生成嵌入？" />
<meta property="og:description" content="文章目录 题目：Diverse Embedding Expansion Network and Low-Light Cross-Modality Benchmark for Visible-Infrared Person Re-identification （多种嵌入扩展网络和低光交叉模态的可见-红外行人重识别）研究背景论文分析网络框架1、Diverse Embedding Expansion Module（多种嵌入扩展模块）2、Center-Guided Pair Mining Loss（中心引导对挖掘损失）3、Multistage Feature Aggregation Block（多级特征聚合块）4、Multi-Loss Optimization（多重损失优化） 实验 题目：Diverse Embedding Expansion Network and Low-Light Cross-Modality Benchmark for Visible-Infrared Person Re-identification （多种嵌入扩展网络和低光交叉模态的可见-红外行人重识别） 期刊合集：最近五年，包含顶刊，顶会，学报&gt;&gt;网址
文章来源：CVPR 2023
官方代码：GitHub
研究背景 VIS 和 IR 图像之间存在额外的跨模态差异是跨模态行人重识别的巨大挑战。作者系统分析了以往研究，并总结相关的研究方法：第一，特征级方法，思路： 将 VIS 和 IR 特征投影到一个共同的嵌入空间中，最小化模态差异。出现的问题： 由于模态差异较大，难以将跨模态图像直接投影到公共特征空间中。第二，图像级方法，思路： 通过使用Gans网络生成相反图像来减少模态差异。出现的问题： 缺乏 VIS-IR 图像对，生成的跨模态图像通常伴随着一些噪声。
论文分析 网络框架 多样性嵌入的网络模型（DEMN），使用双流的 ResNet-50 网络，将 VIS-IR 特征输入到所提出的多元嵌入扩展(DEE)模块中，以生成更多嵌入，之后，使用了中心引导对挖掘(CPM)损失，使生成的嵌入尽可能多样化，以学习信息特征表示。
1、Diverse Embedding Expansion Module（多种嵌入扩展模块） 提出的DEE模块采用多分支卷积生成结构，生成更多的嵌入，以缓解训练数据不足的问题。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/08a599b67bd56e3fdf2fb3008521eda2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-08T18:28:04+08:00" />
<meta property="article:modified_time" content="2023-06-08T18:28:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Diverse Embedding Expansion Network and Low-Light Cross-Modality Benchmark for V-I Re-ID:如何有效利用生成嵌入？</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#Diverse_Embedding_Expansion_Network_and_LowLight_CrossModality_Benchmark_for_VisibleInfrared_Person_Reidentification__1" rel="nofollow">题目：Diverse Embedding Expansion Network and Low-Light Cross-Modality Benchmark for Visible-Infrared Person Re-identification （多种嵌入扩展网络和低光交叉模态的可见-红外行人重识别）</a></li><li><a href="#_6" rel="nofollow">研究背景</a></li><li><a href="#_8" rel="nofollow">论文分析</a></li><li><ul><li><a href="#_11" rel="nofollow">网络框架</a></li><li><a href="#1Diverse_Embedding_Expansion_Module_14" rel="nofollow">1、Diverse Embedding Expansion Module（多种嵌入扩展模块）</a></li><li><a href="#2CenterGuided_Pair_Mining_Loss_22" rel="nofollow">2、Center-Guided Pair Mining Loss（中心引导对挖掘损失）</a></li><li><a href="#3Multistage_Feature_Aggregation_Block_46" rel="nofollow">3、Multistage Feature Aggregation Block（多级特征聚合块）</a></li><li><a href="#4MultiLoss_Optimization_60" rel="nofollow">4、Multi-Loss Optimization（多重损失优化）</a></li></ul> 
   </li><li><a href="#_63" rel="nofollow">实验</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="Diverse_Embedding_Expansion_Network_and_LowLight_CrossModality_Benchmark_for_VisibleInfrared_Person_Reidentification__1"></a>题目：Diverse Embedding Expansion Network and Low-Light Cross-Modality Benchmark for Visible-Infrared Person Re-identification （多种嵌入扩展网络和低光交叉模态的可见-红外行人重识别）</h3> 
<p>期刊合集：最近五年，包含顶刊，顶会，学报&gt;&gt;<a href="https://blog.csdn.net/JJxiao520/article/details/127701543">网址</a><br> 文章来源：<a href="https://paperswithcode.com/paper/diverse-embedding-expansion-network-and-low" rel="nofollow">CVPR 2023</a><br> 官方代码：<a href="https://github.com/ZYK100/LLCM">GitHub</a></p> 
<h3><a id="_6"></a>研究背景</h3> 
<p>   VIS 和 IR 图像之间存在额外的跨模态差异是跨模态行人重识别的巨大挑战。作者系统分析了以往研究，并总结相关的研究方法：第一，特征级方法，思路： 将 VIS 和 IR 特征投影到一个共同的嵌入空间中，最小化模态差异。出现的问题： 由于模态差异较大，难以将跨模态图像直接投影到公共特征空间中。第二，图像级方法，思路： 通过使用Gans网络生成相反图像来减少模态差异。出现的问题： 缺乏 VIS-IR 图像对，生成的跨模态图像通常伴随着一些噪声。</p> 
<h3><a id="_8"></a>论文分析</h3> 
<p><img src="https://images2.imgbox.com/79/50/kFW2IoPo_o.png" alt="在这里插入图片描述" width="500"></p> 
<h4><a id="_11"></a>网络框架</h4> 
<p><img src="https://images2.imgbox.com/25/55/Kn2vrSUN_o.png" alt="在这里插入图片描述" width="800"><br>  多样性嵌入的网络模型（DEMN），使用双流的 ResNet-50 网络，将 VIS-IR 特征输入到所提出的多元嵌入扩展(DEE)模块中，以生成更多嵌入，之后，使用了中心引导对挖掘(CPM)损失，使生成的嵌入尽可能多样化，以学习信息特征表示。</p> 
<h4><a id="1Diverse_Embedding_Expansion_Module_14"></a>1、Diverse Embedding Expansion Module（多种嵌入扩展模块）</h4> 
<p> 提出的DEE模块采用多分支卷积生成结构，生成更多的嵌入，以缓解训练数据不足的问题。<br> <img src="https://images2.imgbox.com/d6/ee/AlNs6Igd_o.png" alt="在这里插入图片描述" width="400"><br> 具体步骤：<br>  如上图所示，对于DEE的每个分支，使用三个3×3的扩展卷积层，它们具有不同的扩展比(从上往下依次是1,2,3)，将特征映射的数量f减少到其自身大小的1/4，将得到的一个个小特征图组合成新的大特征图 F，再通过ReLU层来提高DEE的非线性表示能力。最后馈送到卷积层θ1×1（核大小为1×1），得到与 f 相同维度的嵌入特征，嵌入函数如下：<br> <img src="https://images2.imgbox.com/01/4c/tqIKEcPI_o.png" alt="在这里插入图片描述"><br> 将所有生成的嵌入连接在一起，作为骨干网下一阶段的输入。</p> 
<h4><a id="2CenterGuided_Pair_Mining_Loss_22"></a>2、Center-Guided Pair Mining Loss（中心引导对挖掘损失）</h4> 
<p>作者认为，经过上面的操作，DEE模块只能使用多分支卷积块生成更多嵌入（只是有了更多的嵌入，但嵌入的内容或者是类型还没做要求），不能有效地获得多样化的嵌入。因此，需要利用以下三个属性来约束生成的嵌入尽可能多样化，以有效减少VIS和IR图像之间的模态差异： <strong>一句话，既然都做了，那就得做好一点才行。</strong></p> 
<p><strong>属性1：生成的嵌入应该尽可能多样化，以有效地学习信息特征表示。</strong> 推开同一模态生成的嵌入与原始嵌入之间的距离（模态都会成生成嵌入），以学习不同的特征并挖掘不同的跨模态线索。（同一模态学够了，再学也没用，已经提不高了，再找找其他模态的东西学习。）<br> <strong>属性2：生成的嵌入应该有助于减少VIS和IR图像之间的模态差异。</strong> 拉近由VIS模态生成的嵌入与原始IR嵌入之间的距离。同样的，拉近由IR模态生成的嵌入与原始VIS嵌入之间的距离。（你找我来，我找你，大家相互学，共同进步。）<br> <strong>属性3：类内距离应小于类间距离。</strong> 利用属性 2，会将生成的嵌入与原始嵌入之间的距离推近（不是我们所希望的），这可能导致不同类别的嵌入变得更近。因此，拉近距离的过程中，要保持类内距离小于类间距离。（把握好尺度关系，学了其他的东西，但是不能忘本，还是要精通自己的东西。）</p> 
<p>这个过程就可以通过损失函数实现，结构和定义如下（图文并茂，很好理解）：<br> <img src="https://images2.imgbox.com/e1/8b/WkzvhGTS_o.png" alt="在这里插入图片描述" width="500"><br> <img src="https://images2.imgbox.com/dd/33/mTDvFJWf_o.png" alt="在这里插入图片描述"><br> 上述式子中的D(·，·)为两个嵌入之间的欧几里得距离，fv和fn是来自VIS和IR模态的原始嵌入，f <sup>i</sup> <sub>v+</sub>是来自 VIS 模态的第 i 个分支生成的嵌入。<br> 3个属性分别在公式中有所体现，<img src="https://images2.imgbox.com/f7/f1/0FM0PQTC_o.png" alt="在这里插入图片描述">这个就是为了将生成的嵌入（逗号后）拉向原始IR的嵌入（逗号前），以减小两者(括号里面的东西)之间的模态差异（属性1）。<img src="https://images2.imgbox.com/e8/db/4ZIEraof_o.png" alt="在这里插入图片描述">将生成的嵌入（逗号后）推离VIS的嵌入（逗号前），使f<sub>v+</sub>能够学习信息特征表示（属性2）。<img src="https://images2.imgbox.com/2a/25/pXRg1h59_o.png" alt="在这里插入图片描述">使类内距离小于类间距离（属性3）。<br> 每个类使用c<sub>n</sub>和c<sub>v</sub>表示中心点的表示，让对应生成的嵌入中心更有判别性，同时使用了一个边际项α来平衡前面的三项，改造如下所示：</p> 
<p><img src="https://images2.imgbox.com/24/68/PLLLlG03_o.png" alt="在这里插入图片描述"></p> 
<p>相似的，对于由 IR 生成的嵌入的类中心损失：</p> 
<p><img src="https://images2.imgbox.com/4a/92/oinmmJhp_o.png" alt="在这里插入图片描述"><br> 因此，最终 CPM 损失可表示为：<br> <img src="https://images2.imgbox.com/51/de/A1uXDU0f_o.png" alt="在这里插入图片描述"><br> 作者还做了一个工作：为了保证不同分支生成的嵌入能够捕获不同的信息特征表示，强制不同分支生成的不同嵌入正交，以最小化重叠元素（在生成嵌入后，做一次嵌入正交，以保证后续操作的有效性）。正交损耗表示为：<br> <img src="https://images2.imgbox.com/48/29/9Rdpjbdu_o.png" alt="在这里插入图片描述"><br> 其中 m 和 n 分别是由原始嵌入生成的第 m 个和第 n 个嵌入。正交损失可以强制生成的嵌入学习更多信息的特征表示。</p> 
<h4><a id="3Multistage_Feature_Aggregation_Block_46"></a>3、Multistage Feature Aggregation Block（多级特征聚合块）</h4> 
<p> 不同层次的特征聚合已被证明有助于语义分割、分类和检测任务。为了聚合来自不同阶段的特征以挖掘不同的通道和空间特征表示，结合了一个有效的<strong>通道-空间</strong>多阶段特征聚合(MFA)块来聚合多阶段特征。（这里主要考虑主干网各阶段通道空间聚合块的两类源特征：阶段前的低级特征图和阶段后的高级特征图，<strong>聚合就是自注意力机制的使用</strong>）<br> <img src="https://images2.imgbox.com/22/7b/pF6UPa2C_o.png" alt="在这里插入图片描述" width="700"><br> 首先，使用三个1×1卷积层ψ 1q， ψ 1v， ψ 1k将 f 转换为三个紧凑嵌入:ψ 1q (fh)， ψ 1v (fl)和ψ 1k (fl)。<br> 1、通道聚合<br> 通道的相似度矩阵Mc∈R C ’ ×C '计算如下（c 代表了是channel，借鉴自注意力机制）：<br> <img src="https://images2.imgbox.com/f1/60/wL2rHfGi_o.png" alt="在这里插入图片描述"><br> 通过ψ1v (fl)和M<sup>c</sup>的矩阵乘法来恢复<strong>通道维度</strong>，从而实现了通道的多级特征聚合。<br> <img src="https://images2.imgbox.com/06/ab/CvPCEOlk_o.png" alt="在这里插入图片描述"><br> 2、空间聚合<br> 然后，利用上述运算得到的 f <sup>c</sup><sub>h</sub> 和底层特征图 f <sub>l</sub> 进行空间特征聚合操作，类似于通道多阶段特征聚合操作。<br> <img src="https://images2.imgbox.com/45/a0/ANXtCCzl_o.png" alt="在这里插入图片描述"><br> 其中 ω <sup>s</sup>和ψ <sup>2</sup> <sub>v</sub>是两个1 × 1卷积层，M <sup>s</sup>是空间相似矩阵。</p> 
<h4><a id="4MultiLoss_Optimization_60"></a>4、Multi-Loss Optimization（多重损失优化）</h4> 
<p> 除了提出 L <sub>cpm</sub>和L <sub>ort</sub>外，文章还结合交叉熵损失L <sub>ce</sub>和三重熵损失L <sub>tri</sub>，通过最小化这四种损失L <sub>total</sub>的总和，以端到端方式共同优化网络，总损失如下：<br> <img src="https://images2.imgbox.com/91/f3/LeRAlUFl_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_63"></a>实验</h3> 
<p> 实验细节：首先在训练阶段采用随机水平翻转和随机擦除操作，将所有输入图像的大小调整为3 × 384 × 144，初始学习率设置为1 × 10−2，通过预热策略（warm-up），10次后学习率增加到1 × 10−1。之后，在20 epoch将学习率衰减到1 × 10−2，在60 epoch和120 epoch分别进一步衰减到1 × 10−3和1 × 10−4，直到总共150 epoch。在每个小批中，随机选择6个身份的4张VIS图像和4张IR图像进行训练。训练采用SGD优化器，动量设置为0.9。特别地，对于RegDB数据集，删除了阶段4，并在阶段2之后将提出的DEE模块插入到DEEN中。</p> 
<p>实验结果：<br> <img src="https://images2.imgbox.com/e8/23/QsI8gxDo_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/73/29/Acm4JtOO_o.png" alt="在这里插入图片描述"><br> 消融实验：总体的设置没做更改，只是删除了特定的模块。<br> <img src="https://images2.imgbox.com/e6/59/Ti5VWSFO_o.png" alt="在这里插入图片描述"><br> 超参数 λ1，λ2，α 设置。<br> <img src="https://images2.imgbox.com/55/f2/zbIKDwp5_o.png" alt="在这里插入图片描述"></p> 
<p>可视化：<br> <img src="https://images2.imgbox.com/87/95/0nsE652S_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7a7652a86c74cc694c5ac43ac4693201/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java自带常用工具类</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7cfeb6535b55e0064e7d760e824742c4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">CentOS 7.6一键安装 nginx及生产跨域配置</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>