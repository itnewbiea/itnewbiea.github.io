<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>GRU时间序列数据分类预测 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="GRU时间序列数据分类预测" />
<meta property="og:description" content="目的：通过一段时间的数据，预测后面一段时间的类别，比如输入数据是1-50步的变量，预测的是50-60步的类别。
输入变量的数目：15
预测的类别数：0,1,2,3,4,10 （1类数目最多，数据不均衡）
GRU模型参数解释： 参考链接：[Pytorch系列-54]：循环神经网络 - torch.nn.GRU（）参数详解_文火冰糖的硅基工坊的博客-CSDN博客_nn.gru参数
input_size: 输入序列的变量的数目。
hidden_size: 隐藏层的特征的数目。
num_layers: GRU层的数目。
bias：是否需要偏置，默认是True（需要）。
batch_first: 用于确定batch size是否需要放到输入输出数据形状的最前面。
若为True， 则输入、输出的tensor的格式为(batch， seq_len， feature)
若为False，则输入、输出的tensor的格式为(seq_len，batch，feature)
默认是False。
为什么需要该参数呢？
在CNN网络和全连接网络，batch通常位于输入数据形状的最前面。
而对于具有时间信息的序列化数据，通常需要把seq放在最前面，需要把序列数据串行地输入网络中。（那我的模型不能设置为True？？？）
seq_len: 输入序列的长度。在我的情形下可以为50。
搭建GRU网络： 参考链接：pytorch使用torch.nn.Sequential快速搭建神经网络 - pytorch中文网
self.gru = nn.GRU(self.input_size, self.hidden_size, self.num_layers, batch_first=True, dropout=self.dropout) self.fc = nn.Sequential(nn.Linear(self.hidden_size, self.output_size), nn.Sigmoid()) self.gru = torch.nn.GRU(self.input_size, self.hidden_size, self.num_layers, batch_first=True) self.fc1 = torch.nn.Linear(self.hidden_size, 4) self.fc2 = torch.nn.Linear(self.hidden_size, 4) self.fc3 = torch.nn.Linear(self.hidden_size, 4) self.fc4 = torch.nn.Linear(self.hidden_size, 4) self.fc5 = torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/9b21e10f634f161958ec71c78e592bd0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-14T16:05:15+08:00" />
<meta property="article:modified_time" content="2022-10-14T16:05:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GRU时间序列数据分类预测</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>目的：通过一段时间的数据，预测后面一段时间的类别，比如输入数据是1-50步的变量，预测的是50-60步的类别。</p> 
<p> </p> 
<p>输入变量的数目：15</p> 
<p>预测的类别数：0,1,2,3,4,10 （1类数目最多，数据不均衡）</p> 
<h2><strong>GRU模型参数解释：</strong></h2> 
<p>参考链接：<a href="https://blog.csdn.net/HiWangWenBing/article/details/121645435" title="[Pytorch系列-54]：循环神经网络 - torch.nn.GRU（）参数详解_文火冰糖的硅基工坊的博客-CSDN博客_nn.gru参数">[Pytorch系列-54]：循环神经网络 - torch.nn.GRU（）参数详解_文火冰糖的硅基工坊的博客-CSDN博客_nn.gru参数</a></p> 
<p><img alt="" src="https://images2.imgbox.com/74/e1/GQqN2b7A_o.png"></p> 
<p> input_size: 输入序列的变量的数目。</p> 
<p>hidden_size: 隐藏层的特征的数目。</p> 
<p>num_layers: GRU层的数目。</p> 
<p>bias：是否需要偏置，默认是True（需要）。</p> 
<p>batch_first: 用于确定batch size是否需要放到输入输出数据形状的最前面。</p> 
<p>若为True， 则输入、输出的tensor的格式为(batch， seq_len， feature)</p> 
<p>若为False，则输入、输出的tensor的格式为(seq_len，batch，feature)</p> 
<p>默认是False。</p> 
<p><u>为什么需要该参数呢？</u></p> 
<p>在CNN网络和全连接网络，batch通常位于输入数据形状的最前面。</p> 
<p>而对于具有时间信息的序列化数据，通常需要把seq放在最前面，需要把序列数据串行地输入网络中。（那我的模型不能设置为True？？？）</p> 
<p>seq_len: 输入序列的长度。在我的情形下可以为50。</p> 
<h2><strong>搭建GRU网络：</strong></h2> 
<p><strong>参考链接：</strong><a href="https://ptorch.com/news/57.html" rel="nofollow" title="pytorch使用torch.nn.Sequential快速搭建神经网络 - pytorch中文网">pytorch使用torch.nn.Sequential快速搭建神经网络 - pytorch中文网</a></p> 
<pre><code>self.gru = nn.GRU(self.input_size, self.hidden_size, self.num_layers, batch_first=True, dropout=self.dropout)
self.fc = nn.Sequential(nn.Linear(self.hidden_size, self.output_size), nn.Sigmoid())</code></pre> 
<pre><code>self.gru = torch.nn.GRU(self.input_size, self.hidden_size, self.num_layers, batch_first=True)
self.fc1 = torch.nn.Linear(self.hidden_size, 4)
self.fc2 = torch.nn.Linear(self.hidden_size, 4)
self.fc3 = torch.nn.Linear(self.hidden_size, 4)
self.fc4 = torch.nn.Linear(self.hidden_size, 4)
self.fc5 = torch.nn.Linear(self.hidden_size, 4)       
self.softmax = torch.nn.Softmax(dim=1)</code></pre> 
<p><strong>nn.Sequential</strong>：是一个Sequential容器，模块将按照构造函数中传递的顺序添加到模块中。另外，也可以传入一个有序模块。使用<code>torch.nn.Sequential</code>会自动加入激励函数。</p> 
<h4>torch.nn.Sequential与torch.nn.Module区别与选择</h4> 
<ul><li> <p>使用<code>torch.nn.Module</code>，我们可以根据自己的需求改变传播过程，如<code>RNN</code>等</p> </li><li>如果你需要快速构建或者不需要过多的过程，直接使用<code>torch.nn.Sequential</code>即可</li></ul> 
<p><strong>nn.Linear(input_dim<em>, </em>output_dim)</strong></p> 
<p><strong>torch.nn.Softmax(dim=1)</strong></p> 
<p>参考链接: <a href="https://blog.csdn.net/qq_41076797/article/details/113111137" title="torch.nn.Softmax_CtrlZ1的博客-CSDN博客_torch.nn.softmax">torch.nn.Softmax_CtrlZ1的博客-CSDN博客_torch.nn.softmax</a></p> 
<blockquote> 
 <p> tensor([[0.3458, 0.0596, 0.5147],</p> 
 <p>              [0.3774, 0.7503, 0.3705],</p> 
 <p>              [0.2768, 0.1901, 0.1148]])</p> 
</blockquote> 
<p> dim=0表示对于第一个维度的对应下标之和是1, 即0.3458+0.3774+0.2768=1、0.0596+0.7503+0.1901=1。</p> 
<blockquote> 
 <p>tensor([[0.3381, 0.1048, 0.5572],</p> 
 <p>            [0.1766, 0.6315, 0.1919],</p> 
 <p>            [0.3711, 0.4586, 0.1704]])</p> 
</blockquote> 
<p>dim=1表示对于第二维度而言，对应下标之和为1，0.3381+0.1048+0.5572=1, 0.1766+0.6315+0.1919=1，即所有列的对应下标之和为1。</p> 
<h2><strong> 一些报错记录：</strong></h2> 
<p><strong>1. 计算交叉熵损失使用的output必须是softmax输出的概率而不是argmax之后得到的类别。</strong></p> 
<pre><code>RuntimeError: Expected floating point type for target with class probabilities, got Long</code></pre> 
<p><a href="https://blog.csdn.net/lwf1881/article/details/123078571" title="语义分割损失函数系列(1):交叉熵损失函数_spectrelwf的博客-CSDN博客_语义分割交叉熵">语义分割损失函数系列(1):交叉熵损失函数_spectrelwf的博客-CSDN博客_语义分割交叉熵</a></p> 
<p><strong>2. 加载生成训练数据集的时候报错。</strong></p> 
<pre><code>Ran out of input</code></pre> 
<p><a href="https://blog.csdn.net/qq_43797487/article/details/121043906" title="python报错Ran out of input_在上树的路上的博客-CSDN博客">python报错Ran out of input_在上树的路上的博客-CSDN博客</a></p> 
<p>因为生成的数据集太大了，要减少数据集。（The actually error is <code>OverflowError: cannot serialize a bytes object larger than 4 GiB</code>. You have to reduce the size of the input.）</p> 
<p><strong>3.  输入张量和隐藏张量不在一个device上。</strong></p> 
<pre>h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)</pre> 
<pre><code>Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu</code></pre> 
<pre>h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(Train.device)</pre> 
<pre><code class="language-python">Input and hidden tensors are not at the same device, found input tensor at cpu and
and hidden tensor at cuda:0 </code></pre> 
<p> 解决方法：</p> 
<pre>output, _ = self.gru(input_seq.to(Train.device), h_0)</pre> 
<p>（input_seq后面加上to(Train.device)）</p> 
<p><strong>4. 预测和真实标签长度不一致。</strong></p> 
<pre><code>报错：Found input variables with inconsistent numbers of samples</code></pre> 
<blockquote> 
 <p>y_true.<a href="https://so.csdn.net/so/search?q=shape&amp;spm=1001.2101.3001.7020" title="shape">shape</a> </p> 
 <p>y_predict.shape</p> 
</blockquote> 
<p>查看真实值和预测值的形状。</p> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5ea56c692dba9a3fac60046c39e43d9a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SpringBoot配置多个DataSource</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3444210ddde71d597ac4fe5b8b24beb5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">git windows 免密操作</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>