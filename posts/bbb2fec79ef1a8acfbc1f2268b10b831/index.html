<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用Transformer训练和测试EEG的公开SEED数据集 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="使用Transformer训练和测试EEG的公开SEED数据集" />
<meta property="og:description" content="下面所有博客是个人对EEG脑电的探索，项目代码是早期版本不完整，需要完整项目代码和资料请私聊。
主要内容：
1、在EEG(脑电)项目中，使用图神经网络对脑电进行处理，具体包括baseline的GCN图架构、复现baseline论文的RGNN架构、注意力机制图架构、Transformer图架构、注重效率的simple图架构等，进行实验和对比。
2、学习图神经网络相关的资料。是学习图神经网络的一个完整项目；
数据集
1、脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED
相关论文阅读分析：
1、EEG-SEED数据集作者的—基线论文阅读和分析
2、图神经网络EEG论文阅读和分析：《EEG-Based Emotion Recognition Using Regularized Graph Neural Networks》
3、EEG-GNN论文阅读和分析：《EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks》
4、论文阅读和分析:Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification
5、论文阅读和分析：《DeepGCNs: Can GCNs Go as Deep as CNNs?》
6、论文阅读和分析： “How Attentive are Graph Attention Networks?”
7、论文阅读和分析：Simplifying Graph Convolutional Networks
8、论文阅读和分析：LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation
9、图神经网络汇总和总结
相关实验和代码实现：
1、用于图神经网络的脑电数据处理实现_图神经网络 脑电
2、使用GCN训练和测试EEG的公开SEED数据集" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/bbb2fec79ef1a8acfbc1f2268b10b831/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-05T12:26:33+08:00" />
<meta property="article:modified_time" content="2023-04-05T12:26:33+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用Transformer训练和测试EEG的公开SEED数据集</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p><strong><font size="3" face="Courier New">下面所有博客是个人对EEG脑电的探索，项目代码是早期版本不完整，需要完整项目代码和资料请私聊。</font></strong><br> <br><br> <strong><font size="3" face="Courier New">主要内容：<br> 1、在EEG(脑电)项目中，使用图神经网络对脑电进行处理，具体包括baseline的GCN图架构、复现baseline论文的RGNN架构、注意力机制图架构、Transformer图架构、注重效率的simple图架构等，进行实验和对比。<br> 2、学习图神经网络相关的资料。是学习图神经网络的一个完整项目；</font></strong><br> <br><br> <strong><font size="3" face="Courier New">数据集</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128589175?spm=1001.2014.3001.5501">脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED</a><br> <strong><font size="3" face="Courier New">相关论文阅读分析：</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128607350?spm=1001.2014.3001.5501">EEG-SEED数据集作者的—基线论文阅读和分析</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/128637894?spm=1001.2014.3001.5501">图神经网络EEG论文阅读和分析：《EEG-Based Emotion Recognition Using Regularized Graph Neural Networks》</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/128679724?spm=1001.2014.3001.5501">EEG-GNN论文阅读和分析：《EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks》</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/128882363?spm=1001.2014.3001.5501">论文阅读和分析:Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/128892103?spm=1001.2014.3001.5501">论文阅读和分析：《DeepGCNs: Can GCNs Go as Deep as CNNs?》</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/128911280?spm=1001.2014.3001.5501">论文阅读和分析： “How Attentive are Graph Attention Networks?”</a><br> 7、<a href="https://blog.csdn.net/KPer_Yang/article/details/128927668?spm=1001.2014.3001.5501">论文阅读和分析：Simplifying Graph Convolutional Networks</a></font></font></p> 
 <p>8、<a href="https://blog.csdn.net/KPer_Yang/article/details/128945159?spm=1001.2014.3001.5501">论文阅读和分析：LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</a><br> 9、<a href="https://blog.csdn.net/KPer_Yang/article/details/129968785?spm=1001.2014.3001.5502">图神经网络汇总和总结</a><br> <strong><font size="3" face="Courier New">相关实验和代码实现：</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128740968?spm=1001.2014.3001.5501">用于图神经网络的脑电数据处理实现_图神经网络 脑电</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/129034169?spm=1001.2014.3001.5501">使用GCN训练和测试EEG的公开SEED数据集</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/129074872?spm=1001.2014.3001.5501">使用GAT训练和测试EEG公开的SEED数据集</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/129094901?spm=1001.2014.3001.5501">使用SGC训练和测试SEED数据集</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/129095088?spm=1001.2014.3001.5501">使用Transformer训练和测试EEG的公开SEED数据集_eeg transformer</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/129133439?spm=1001.2014.3001.5501">使用RGNN训练和测试EEG公开的SEED数据集</a><br> <strong><font size="3" face="Courier New">辅助学习资料：</font></strong><br> 1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128808874?spm=1001.2014.3001.5501">官网三个简单Graph示例说明三种层次的应用_graph 简单示例</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/128810698?spm=1001.2014.3001.5501">PPI数据集示例项目学习图神经网络</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/128859245?spm=1001.2014.3001.5501">geometric库的数据处理详解</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/128880391?spm=1001.2014.3001.5501">NetworkX的dicts of dicts以及解决Seven Bridges of Königsberg问题</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/128889737?spm=1001.2014.3001.5501">geometric源码阅读和分析：MessagePassin类详解和使用</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/129095501?spm=1001.2014.3001.5501">cora数据集示例项目学习图神经网络</a><br> 7、<a href="https://blog.csdn.net/KPer_Yang/article/details/129102055?spm=1001.2014.3001.5501">Graph 聚合</a><br> 8、<a href="https://blog.csdn.net/KPer_Yang/article/details/129105477?spm=1001.2014.3001.5501">QM9数据集示例项目学习图神经网络</a><br> 9、<a href="https://blog.csdn.net/KPer_Yang/article/details/129105010?spm=1001.2014.3001.5501">处理图的开源库</a></font></p> 
</blockquote> 
<p><strong>部分代码如下:</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token comment">#</span>
<span class="token comment"># Copyright (C) 2022 Emperor_Yang, Inc. All Rights Reserved </span>
<span class="token comment">#</span>
<span class="token comment"># @CreateTime    : 2023/2/9 22:15</span>
<span class="token comment"># @Author        : Emperor_Yang </span>
<span class="token comment"># @File          : ECG_Transformer.py</span>
<span class="token comment"># @Software      : PyCharm</span>


<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> easydict <span class="token keyword">import</span> EasyDict
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> TransformerConv<span class="token punctuation">,</span> global_add_pool
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> data_process<span class="token punctuation">.</span>seed_loader_gnn_memory <span class="token keyword">import</span> SeedGnnMemoryDataset

config <span class="token operator">=</span> EasyDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
config<span class="token punctuation">.</span>learn_rate <span class="token operator">=</span> <span class="token number">0.01</span>
config<span class="token punctuation">.</span>epoch <span class="token operator">=</span> <span class="token number">5</span>
config<span class="token punctuation">.</span>note_feature_dim <span class="token operator">=</span> <span class="token number">5</span>
config<span class="token punctuation">.</span>note_num <span class="token operator">=</span> <span class="token number">62</span>
config<span class="token punctuation">.</span>hidden_channels <span class="token operator">=</span> <span class="token number">16</span>
config<span class="token punctuation">.</span>class_num <span class="token operator">=</span> <span class="token number">3</span>
config<span class="token punctuation">.</span>hidden_layers <span class="token operator">=</span> <span class="token number">2</span>
config<span class="token punctuation">.</span>head_num <span class="token operator">=</span> <span class="token number">2</span>
config<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> <span class="token number">16</span>
config<span class="token punctuation">.</span>max_loss_increase_time <span class="token operator">=</span> <span class="token number">3</span>


<span class="token keyword">class</span> <span class="token class-name">EEG_TransformerConv</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    GCN handle ECG
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>EEG_TransformerConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>conv_s <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># output dim is heads * out_channel</span>
        self<span class="token punctuation">.</span>conv_s<span class="token punctuation">.</span>append<span class="token punctuation">(</span>TransformerConv<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> config<span class="token punctuation">.</span>head_num<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>hidden_layers <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>conv_s<span class="token punctuation">.</span>append<span class="token punctuation">(</span>TransformerConv<span class="token punctuation">(</span>hidden_channels <span class="token operator">*</span> config<span class="token punctuation">.</span>head_num<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> config<span class="token punctuation">.</span>head_num<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_channels <span class="token operator">*</span> config<span class="token punctuation">.</span>head_num<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> index<span class="token punctuation">,</span> edge_weight<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        forward
        :param index:
        :param x:note feature
        :param edge_index:edge pair
        :param edge_weight: edge feature
        :return:
        """</span>
        <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>conv_s<span class="token punctuation">:</span>
            x <span class="token operator">=</span> conv<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">,</span> edge_weight<span class="token punctuation">)</span><span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> global_add_pool<span class="token punctuation">(</span>x<span class="token punctuation">,</span> index<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


model <span class="token operator">=</span> EEG_TransformerConv<span class="token punctuation">(</span>config<span class="token punctuation">.</span>note_feature_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hidden_channels<span class="token punctuation">,</span> config<span class="token punctuation">.</span>class_num<span class="token punctuation">)</span>
data_set <span class="token operator">=</span> SeedGnnMemoryDataset<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../data/SEED/'</span><span class="token punctuation">,</span> processed_file<span class="token operator">=</span><span class="token string">'1_20131027.pt'</span><span class="token punctuation">)</span>
train_data_set <span class="token operator">=</span> data_set<span class="token punctuation">[</span><span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> data_set<span class="token punctuation">.</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
test_data_set <span class="token operator">=</span> data_set<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> data_set<span class="token punctuation">.</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
train_data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">.</span>learn_rate<span class="token punctuation">)</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss_sum <span class="token operator">=</span> <span class="token number">0</span>
    data_size <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> mini_batch <span class="token keyword">in</span> train_data_loader<span class="token punctuation">:</span>
        <span class="token keyword">if</span> mini_batch<span class="token punctuation">.</span>num_graphs <span class="token operator">==</span> config<span class="token punctuation">.</span>batch_size<span class="token punctuation">:</span>
            data_size <span class="token operator">+=</span> mini_batch<span class="token punctuation">.</span>num_graphs
            model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            out <span class="token operator">=</span> model<span class="token punctuation">(</span>mini_batch<span class="token punctuation">.</span>x<span class="token punctuation">,</span> mini_batch<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> mini_batch<span class="token punctuation">.</span>batch<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">,</span> mini_batch<span class="token punctuation">.</span>y<span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> mini_batch<span class="token punctuation">.</span>num_graphs
    <span class="token keyword">return</span> loss_sum <span class="token operator">/</span> data_size


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    count <span class="token operator">=</span> <span class="token number">0</span>
    data_size <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> mini_batch <span class="token keyword">in</span> test_data_loader<span class="token punctuation">:</span>
        <span class="token keyword">if</span> mini_batch<span class="token punctuation">.</span>num_graphs <span class="token operator">==</span> config<span class="token punctuation">.</span>batch_size<span class="token punctuation">:</span>
            out <span class="token operator">=</span> model<span class="token punctuation">(</span>mini_batch<span class="token punctuation">.</span>x<span class="token punctuation">,</span> mini_batch<span class="token punctuation">.</span>edge_index<span class="token punctuation">,</span> mini_batch<span class="token punctuation">.</span>batch<span class="token punctuation">)</span>
            predict <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>out<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            count <span class="token operator">+=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>predict<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>mini_batch<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            data_size <span class="token operator">+=</span> mini_batch<span class="token punctuation">.</span>num_graphs
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Test Accuracy:{}%"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>count <span class="token operator">/</span> data_size <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    loss_increase_time <span class="token operator">=</span> <span class="token number">0</span>
    last_lost <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        avg_loss <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch:{}, loss:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> avg_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> avg_loss <span class="token operator">&gt;</span> last_lost<span class="token punctuation">:</span>
            loss_increase_time <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            last_lost <span class="token operator">=</span> avg_loss
        <span class="token comment"># 如果连续增加loss大于config.max_loss_increase_time，则停止训练</span>
        <span class="token keyword">if</span> loss_increase_time <span class="token operator">&gt;</span> config<span class="token punctuation">.</span>max_loss_increase_time<span class="token punctuation">:</span>
            <span class="token keyword">break</span>
    test<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d7f743221f0ea80897411b7c540e97bd/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/361037ec02c48f7ae153b63bacd98823/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">PPI数据集示例项目学习图神经网络</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>