<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>一篇入门深度学习OCR：数据集和算法合集 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="一篇入门深度学习OCR：数据集和算法合集" />
<meta property="og:description" content="转载自CSDN博客：一篇入门深度学习OCR：数据集和算法合集
请去原博点赞！
文章目录 💞1. OCR数据集和数据集生成工具💘1.1 文本检测数据集1.1.1 SynthText (ST)1.1.2 IC03 IC13 IC151.1.3 COCO-Text1.1.4 IIIT1.1.5 SVT1.1.6 CUTE1.1.7 ICDAR 2017 RCTW1.2 数据集总结 💓1.2 文本识别数据集 💌2. 深度学习OCR算法💟2.1 文本检测2.1.1 CTPN2.1.2 CRAFT2.1.3 Seglink2.1.4 EAST 2.1 总结💝2.2 文本识别2.2.1 CRNN：CNN&#43;RNN&#43;CTC2.2.2 CNN&#43;Seq2Seq&#43;Attention 🥪2.3 现成可用的库 3. 深度学习相关博客4. 相关书籍5.识别加速 当前OCR领域基本上已经是深度学习的天下了，近5年，在算法和数据集的双重加持下，OCR已经成为一个解决的问题，要做一个适合于自己的OCR系统，关键在于选择适合于自己场景的数据集和算法。 本文主要记录OCR领域常用的数据集和算法，以及相关的开源项目和博客。
💞1. OCR数据集和数据集生成工具 在任何领域，深度学习成为主流意味着数据集是其中的关键，即使是相同的OCR模型，大规模数据集的训练能带来识别效果上质的提升。
深度学习OCR处理主要分成两步走：
（1）图片中的文本检测，即通过文本框框出图片中的文本。
（2）识别出文本框中的文本。
对应的，公开的数据集也分成这两类。
💘1.1 文本检测数据集 1.1.1 SynthText (ST) 文本检测数据集使用最为广泛的是SynthText (ST)，可以说是OCR领域的 ImageNet，该数据集由牛津大学工程科学系视觉几何组的 Gupta, A. and Vedaldi, A. and Zisserman, A. 于 2016 年在 IEEE 计算机视觉 和模式识别会议 (CVPR) 上发布。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/841f815b95a0c36be3bc25aa43cafbaf/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-17T11:38:13+08:00" />
<meta property="article:modified_time" content="2023-04-17T11:38:13+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">一篇入门深度学习OCR：数据集和算法合集</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>转载自CSDN博客：<a href="https://blog.csdn.net/u012995500/article/details/109403000">一篇入门深度学习OCR：数据集和算法合集</a><br> 请去原博点赞！</p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1_OCR_9" rel="nofollow">💞1. OCR数据集和数据集生成工具</a></li><li><ul><li><a href="#11__20" rel="nofollow">💘1.1 文本检测数据集</a></li><li><ul><li><a href="#111_SynthText_ST_21" rel="nofollow">1.1.1 SynthText (ST)</a></li><li><a href="#112__IC03__IC13_IC15_29" rel="nofollow">1.1.2 IC03 IC13 IC15</a></li><li><a href="#113_COCOText_32" rel="nofollow">1.1.3 COCO-Text</a></li><li><a href="#114_IIIT_35" rel="nofollow">1.1.4 IIIT</a></li><li><a href="#115_SVT_38" rel="nofollow">1.1.5 SVT</a></li><li><a href="#116_CUTE_41" rel="nofollow">1.1.6 CUTE</a></li><li><a href="#117_ICDAR_2017_RCTW_44" rel="nofollow">1.1.7 ICDAR 2017 RCTW</a></li><li><a href="#12__47" rel="nofollow">1.2 数据集总结</a></li></ul> 
   </li><li><a href="#12__52" rel="nofollow">💓1.2 文本识别数据集</a></li></ul> 
  </li><li><a href="#2_OCR_61" rel="nofollow">💌2. 深度学习OCR算法</a></li><li><ul><li><a href="#21__63" rel="nofollow">💟2.1 文本检测</a></li><li><ul><li><a href="#211_CTPN_71" rel="nofollow">2.1.1 CTPN</a></li><li><a href="#212_CRAFT_89" rel="nofollow">2.1.2 CRAFT</a></li><li><a href="#213_Seglink_106" rel="nofollow">2.1.3 Seglink</a></li><li><a href="#214_EAST_116" rel="nofollow">2.1.4 EAST</a></li></ul> 
   </li><li><a href="#21__130" rel="nofollow">2.1 总结</a></li><li><a href="#22__138" rel="nofollow">💝2.2 文本识别</a></li><li><ul><li><a href="#221_CRNNCNNRNNCTC_146" rel="nofollow">2.2.1 CRNN：CNN+RNN+CTC</a></li><li><a href="#222_CNNSeq2SeqAttention_165" rel="nofollow">2.2.2 CNN+Seq2Seq+Attention</a></li></ul> 
   </li><li><a href="#23__179" rel="nofollow">🥪2.3 现成可用的库</a></li></ul> 
  </li><li><a href="#3__226" rel="nofollow">3. 深度学习相关博客</a></li><li><a href="#4__237" rel="nofollow">4. 相关书籍</a></li><li><a href="#5_243" rel="nofollow">5.识别加速</a></li></ul> 
</div> 
<br> 当前OCR领域基本上已经是深度学习的天下了，近5年，在算法和数据集的双重加持下，OCR已经成为一个解决的问题，要做一个适合于自己的OCR系统，关键在于选择适合于自己场景的数据集和算法。 
<p></p> 
<p>本文主要记录OCR领域常用的数据集和算法，以及相关的开源项目和博客。</p> 
<h2><a id="1_OCR_9"></a>💞1. OCR数据集和数据集生成工具</h2> 
<p>在任何领域，深度学习成为主流意味着数据集是其中的关键，即使是相同的OCR模型，大规模数据集的训练能带来识别效果上质的提升。</p> 
<p>深度学习OCR处理主要分成两步走：</p> 
<p>（1）图片中的文本检测，即通过文本框框出图片中的文本。</p> 
<p>（2）识别出文本框中的文本。</p> 
<p>对应的，公开的数据集也分成这两类。</p> 
<h3><a id="11__20"></a>💘1.1 文本检测数据集</h3> 
<h4><a id="111_SynthText_ST_21"></a>1.1.1 SynthText (ST)</h4> 
<p>文本检测数据集使用最为广泛的是SynthText (ST)，可以说是OCR领域的 ImageNet，该数据集由牛津大学工程科学系视觉几何组的 Gupta, A. and Vedaldi, A. and Zisserman, A. 于 2016 年在 IEEE 计算机视觉 和模式识别会议 (CVPR) 上发布。</p> 
<p>数据集采用合成的方式生成，在80万张图片中人工加入了800万个文本，而且这种合成并不是很生硬的叠加，而是作了一些处理，使文字在图片中看起来比较自然。一些案例如下：<br> <img src="https://images2.imgbox.com/23/31/g9ARCf6v_o.png" alt="在这里插入图片描述"><br> 此外，数据集合成的方法也在<a href="https://github.com/ankush-me/SynthText">github</a>上开源了，目前对这个项目的中文支持也已经实现：<a href="https://github.com/JarveeLee/SynthText_Chinese_version">https://github.com/JarveeLee/SynthText_Chinese_version</a></p> 
<h4><a id="112__IC03__IC13_IC15_29"></a>1.1.2 IC03 IC13 IC15</h4> 
<p>ICDAR2003/2013/2015 Robust Reading Challenge 比赛用数据集，数据集的每一张图片都来自真实的场景，并且做好了标注。但是样本比较少，合起来只有几千张。一些样例如下图所示：<br> <img src="https://images2.imgbox.com/c6/de/CPdDiUEZ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="113_COCOText_32"></a>1.1.3 COCO-Text</h4> 
<p>ICDAR2017 Robust Reading Challenge 的数据集，和上面两个数据集类似，是实景采集的图片，但是规模要大不少，有63686个样本。一些样本示例如下图所示：<br> <img src="https://images2.imgbox.com/e6/87/A74WXWuT_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="114_IIIT_35"></a>1.1.4 IIIT</h4> 
<p>IIIT 5k words 数据集是从谷歌图像搜索中获得的。主要包括广告牌，招牌，门牌号，门牌，电影海报被用来收集图像。数据集包含5000个样本，一些示例如下图所示：<br> <img src="https://images2.imgbox.com/85/3a/7qZr29iD_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="115_SVT_38"></a>1.1.5 SVT</h4> 
<p>SVT（Street View Text）为街景中含文本的图片数据集，2012年发布，和 IC13/15/17类似，总共包含350张图片，一些样例如下图所示：<br> <img src="https://images2.imgbox.com/a8/2f/wc3ZOFUb_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="116_CUTE_41"></a>1.1.6 CUTE</h4> 
<p>CUTE（Curve Text ）包含80张含弯曲文本的图像及标注。一些样例如下图所示：<br> <img src="https://images2.imgbox.com/ac/b4/5Ui9iRFJ_o.png" alt="在这里插入图片描述" width="400"></p> 
<h4><a id="117_ICDAR_2017_RCTW_44"></a>1.1.7 ICDAR 2017 RCTW</h4> 
<p>ICDAR 大赛中文识别数据集RCTW（Reading Chinese Text in the Wild），包含一万多张含中文文本的自然场景图片。一些样例如下图所示：<br> <img src="https://images2.imgbox.com/0b/31/bvI822n2_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="12__47"></a>1.2 数据集总结</h4> 
<p>上文还有很多数据集没有覆盖到，除了第一个SynthText (ST)规模较大，其他的数据集大多不足以训练一个模型。通常的做法是，根据具体的识别场景（中文/英文，街景/文档等），先用SynthText (ST)训练，然后再用小规模数据集调优。</p> 
<p>可以参考：<a href="https://github.com/HCIILAB/Scene-Text-Recognition">https://github.com/HCIILAB/Scene-Text-Recognition</a><br> <img src="https://images2.imgbox.com/d8/97/ddDFPkY7_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="12__52"></a>💓1.2 文本识别数据集</h3> 
<p>文本识别数据集和文本检测数据集的区别在于，文本识别数据集中的图片主体是文本，而没有大量的背景。</p> 
<p>文本识别数据集的获取方法有两种，一种是通过文本检测数据集的标注信息，从文本检测数据集中截取含文本的部分，作为文本识别数据集。</p> 
<p>第二种方式是人工合成数据集，其中最经典的数据集是 Synthetic Word Dataset，包含800万张合成图片，同样由牛津大学工程科学系视觉几何组合成，一些图片样例如下： <img src="https://images2.imgbox.com/c3/81/juyiHNqp_o.png" alt="在这里插入图片描述"><br> 此外，可以利用开源项目：<a href="https://github.com/Belval/TextRecognitionDataGenerator">https://github.com/Belval/TextRecognitionDataGenerator</a><br> 来合成自己想要的数据集。还有很多其它的文本合成开源项目，但是方法大同小异，只要熟悉其中一个，即可通过自己的修改达到自己想要的效果。</p> 
<h2><a id="2_OCR_61"></a>💌2. 深度学习OCR算法</h2> 
<p>当前深度学习OCR算法均采用上述的两阶段模式：文本检测+文本识别，端到端的方式虽有研究，但是效果不佳。</p> 
<h3><a id="21__63"></a>💟2.1 文本检测</h3> 
<p>其中文本检测是目标检测算法中的一种，由于目标检测算法发展比较快，所以文本检测算法的发展也比较快。早期，文本检测借鉴目标检测的思想，采用 YOLO V3 和 faster-RCNN 取得了一定的效果，但是由于文本的以下特点：</p> 
<p>（1）文字和文字之前存在空隙<br> （2）文字可能和背景的区分度不够大<br> （3）文本检测要求极高的精度，否则会对后面的识别带来很大的困难。</p> 
<p>所以现在这些常规的目标检测算法基本上在文本检测领域被淘汰，取而代之的是专用的文本检测算法。</p> 
<h4><a id="211_CTPN_71"></a>2.1.1 CTPN</h4> 
<p>CTPN的核心思想是将图片按宽度为16像素分成很多个小格，检测每一个小格中是否包含文本，同时预测文本的高度和宽度。最后将多个检测结果融合，形成最终的文本框。</p> 
<p>原理可以参考：</p> 
<p>自然场景文本检测技术综述（CTPN, SegLink, EAST）</p> 
<p>场景文字检测—CTPN原理与实现</p> 
<p>实现可以参考：</p> 
<p>文本检测CTPN的实现可以参考博客：</p> 
<ul><li>【OCR技术系列之六】文本检测CTPN的代码实现，对应的github地址为：<a href="https://github.com/AstarLight/Lets_OCR/tree/master/detector/ctpn">https://github.com/AstarLight/Lets_OCR/tree/master/detector/ctpn</a>，该实现基于pytorch框架。</li><li>tensorflow的实现：<a href="https://github.com/eragonruan/text-detection-ctpn">https://github.com/eragonruan/text-detection-ctpn</a></li></ul> 
<p>后一个项目的检测效果如下（提供的训练好的模型），可以看到对于水平的文本，检测效果相当不错，我也试了一些模糊的照片，可以说，对于水平文本来说，很少有模型的文本检测效果超过CTPN。<br> <img src="https://images2.imgbox.com/84/71/TySvFu2s_o.png" alt="在这里插入图片描述"><br> 但是CTPN有一个致命的缺点，就是对于倾斜和弯曲的文本检测效果很差，这个是因为模型自身的原理决定，很难通过训练解决。</p> 
<h4><a id="212_CRAFT_89"></a>2.1.2 CRAFT</h4> 
<p>韩国人工智能公司CLOVA AI 公司2019年提出的算法，可以识别任意角度的文本，而且可以给出图片中每一个像素为文本的置信分。一个识别样例如下图所示：<br> <img src="https://images2.imgbox.com/33/e4/gsCZTxy9_o.png" alt="在这里插入图片描述"><br> CRAFT 模型的原理可以参考：</p> 
<ul><li> <p>Character Region Awareness for Text Detection解读</p> </li><li> <p>CRAFT：基于字符区域感知的文本检测</p> </li></ul> 
<p>实现可以参考：</p> 
<ul><li>官方实现：pytorch :https://github.com/clovaai/CRAFT-pytorch</li></ul> 
<p>由于该模型已经商用，所以官方实现只提供了推理部分，没有提供训练部分，没有办法后续优化。</p> 
<ul><li>pytorch 复现：https://github.com/backtime92/CRAFT-Reimplementation 包括训练和推理</li><li>keras实现：https://github.com/RubanSeven/CRAFT_keras</li></ul> 
<h4><a id="213_Seglink_106"></a>2.1.3 Seglink</h4> 
<p>在CTPN基础上进行改进，利用开源项目测试了PAN卡和A卡，由于效果不佳，暂时没有深入研究，从论文的结果来看，在复杂场景下的识别效果要好于CTPN。</p> 
<p>原理参考：</p> 
<ul><li>自然场景文本检测技术综述（CTPN, SegLink, EAST）</li></ul> 
<p>github 开源实现：</p> 
<ul><li>tensorflow 实现 <a href="https://github.com/bgshih/seglink">https://github.com/bgshih/seglink</a></li></ul> 
<h4><a id="214_EAST_116"></a>2.1.4 EAST</h4> 
<p>在Seglink基础上的改进算法，在识别倾斜和弯曲文本的效果上比较好，同样利用开源项目进行了测试，但是项目不是很理想，有待深入研究。从当前的趋势来看，EAST将成为主流的文本检测算法之一。</p> 
<p>原理参考：</p> 
<ul><li> <p>自然场景文本检测技术综述（CTPN, SegLink, EAST）</p> </li><li> <p>文本检测之EAST</p> </li></ul> 
<p>开源实现：</p> 
<ul><li>tensorflow实现：<a href="https://github.com/argman/EAST">https://github.com/argman/EAST</a></li></ul> 
<h3><a id="21__130"></a>2.1 总结</h3> 
<p>当前文本检测算法还在高速发展当中，比如PixelLink、RRPN和TextBoxes等，从论文的对比结果来看都取得了相当不错的结果，后续可以深入研究。</p> 
<p>目前来看，CTPN是应用最为广泛的检测算法，但是由于在倾斜文本上检测的不足，所以使用场景受到一定的限制。</p> 
<p>另外，从CRAFT的测试来看，是一种极为高效的算法（计算耗时也不高），并且由于可以得到每一个像素属于文字的置信分，在不同的场景下可以针对信的调优，所以值得重点研究。</p> 
<h3><a id="22__138"></a>💝2.2 文本识别</h3> 
<p>相对文本检测而言，文本识别的算法比较有限，主要有两种思路：</p> 
<p>（1）CRNN：CNN+RNN+CTC</p> 
<p>（2）CNN+Seq2Seq+Attention</p> 
<h4><a id="221_CRNNCNNRNNCTC_146"></a>2.2.1 CRNN：CNN+RNN+CTC</h4> 
<p>当前应用最为广泛的模型为 CNN+RNN+CTC，其中CNN用于提取图像特征，RNN在CNN提取特征的基础上，通过双向LSTM提取相邻下像素之间的特征，最后CTC用于计算损失函数。</p> 
<p>其中CTC实现不定长输入问题的损失函数计算，在语音识别领域应用广泛。</p> 
<p>原理参考：</p> 
<ul><li> <p>一文读懂CRNN+CTC文字识别</p> </li><li> <p>端到端不定长文字识别CRNN算法详解</p> </li></ul> 
<p>开源实现：</p> 
<p>官方开源：</p> 
<ul><li> <p>tensorflow实现 <a href="https://github.com/bgshih/crnn">https://github.com/bgshih/crnn</a></p> </li><li> <p>pytorch 实现：端到端不定长文本识别CRNN代码实现 对应代码：<a href="https://github.com/AstarLight/Lets_OCR/tree/master/recognizer/crnn">https://github.com/AstarLight/Lets_OCR/tree/master/recognizer/crnn</a></p> </li></ul> 
<h4><a id="222_CNNSeq2SeqAttention_165"></a>2.2.2 CNN+Seq2Seq+Attention</h4> 
<p>引入了attention机制，有待研究，但是通过开源项目的测试，效果相当好，应该会逐渐替代CRNN成为主流。</p> 
<p>开源实现：</p> 
<ul><li><a href="https://github.com/zhang0jhon/AttentionOCR">https://github.com/zhang0jhon/AttentionOCR</a></li></ul> 
<p>另外韩国公司CLOVA AI文字识别项目中也实现了这个方法，且用预训练的模型效果非常好：</p> 
<ul><li><a href="https://github.com/clovaai/deep-text-recognition-benchmark">https://github.com/clovaai/deep-text-recognition-benchmark</a></li></ul> 
<p>这个项目了不起的地方还在于把文本识别模块化（特征提取-序列特征提取-特征转换-预测），使每一个模块可以单独优化，从而量化不同模块的贡献。</p> 
<h3><a id="23__179"></a>🥪2.3 现成可用的库</h3> 
<p>在英文OCR方面，keras开源库实现了文字检测和文字识别的整合，其中文字检测用的事CRAFT，文字识别用的是CRNN。</p> 
<p>而且安装非常方便：pip install keras-ocr</p> 
<p>然后就可以通过以下代码进行测试：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
 
<span class="token keyword">import</span> keras_ocr
 
<span class="token comment"># keras-ocr will automatically download pretrained</span>
<span class="token comment"># weights for the detector and recognizer.</span>
pipeline <span class="token operator">=</span> keras_ocr<span class="token punctuation">.</span>pipeline<span class="token punctuation">.</span>Pipeline<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment"># Get a set of three example images</span>
images <span class="token operator">=</span> <span class="token punctuation">[</span>
    keras_ocr<span class="token punctuation">.</span>tools<span class="token punctuation">.</span>read<span class="token punctuation">(</span>url<span class="token punctuation">)</span> <span class="token keyword">for</span> url <span class="token keyword">in</span> <span class="token punctuation">[</span>
        <span class="token string">'test.jpg'</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">]</span>
 
<span class="token comment"># Each list of predictions in prediction_groups is a list of</span>
<span class="token comment"># (word, box) tuples.</span>
prediction_groups <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>recognize<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
 
<span class="token comment"># Plot the predictions</span>
fig<span class="token punctuation">,</span> axs <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> ax<span class="token punctuation">,</span> image<span class="token punctuation">,</span> predictions <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>axs<span class="token punctuation">,</span> images<span class="token punctuation">,</span> prediction_groups<span class="token punctuation">)</span><span class="token punctuation">:</span>
    keras_ocr<span class="token punctuation">.</span>tools<span class="token punctuation">.</span>drawAnnotations<span class="token punctuation">(</span>image<span class="token operator">=</span>image<span class="token punctuation">,</span> predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>
</code></pre> 
<p>通过简单的几段代码就可以实现完整的OCR识别！识别效果看下图：<br> <img src="https://images2.imgbox.com/47/80/m1oH7Kp8_o.png" alt="在这里插入图片描述" width="300"><br> 英文的识别效果还是相当ok的，中文的话还需要额外训练。<br> 开源地址为：<a href="https://github.com/faustomorales/keras-ocr">https://github.com/faustomorales/keras-ocr</a></p> 
<p>在中文OCR方面，百度开源中英文识别模型，试用下来效果还是不错的：</p> 
<p><a href="https://github.com/paddlepaddle/paddlehub">https://github.com/paddlepaddle/paddlehub</a></p> 
<p>在文本检测上用了DBnet：<a href="https://github.com/MhLiao/DB">https://github.com/MhLiao/DB</a>，文本识别上用了CRNN。<br> <img src="https://images2.imgbox.com/c8/10/D3Id3CK8_o.png" alt="在这里插入图片描述"><br> 在中文OCR需要快速上线的时候可以使用，paddlepaddle的性能也是有保障的。</p> 
<h2><a id="3__226"></a>3. 深度学习相关博客</h2> 
<p>1、博客园：冠军的试炼 博客介绍了很多跟OCR相关的预处理方法（openCV），以及介绍了很多深度学习OCR相关的算法原理和实现。</p> 
<p>2、知乎：白裳 知乎介绍了很多深度学习相关的OCR算法，原理介绍比较清楚，同时有对应的github开源项目，</p> 
<p>3、知乎：燕小花 介绍了很多最新的文本检测成果，偏原理介绍</p> 
<p>3、Pyimagesearch，微软图像大牛做的一个博客，里面有很多openCV和OCR相关的文章，新手友好。</p> 
<p>4、openCV 入门：OpenCV Python中文教程 + 代码</p> 
<h2><a id="4__237"></a>4. 相关书籍</h2> 
<p>1、深度实践OCR：基于深度学习的文字识别</p> 
<p>阿里团队出版的一本图书，介绍了经典的OCR算法，广度够，深度不够，适合建立一个算法体系。<br> <img src="https://images2.imgbox.com/ad/38/BeztUAqR_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="5_243"></a>5.识别加速</h2> 
<p>OCR 因为用到了两阶段的识别方式，用到的模型也比较复杂，所以在识别速度上有一定欠缺。识别一张复杂图片在不做优化的情况下通常都要 1s 以上，对于追求机智性能的场景需要对模型的推理速度进行优化，目前，模型推理速度优化用得比较多的工具主要有腾讯家的ncnn 和阿里的mnn。</p> 
<p>腾讯ncnn: <a href="https://github.com/Tencent/ncnn">https://github.com/Tencent/ncnn</a></p> 
<p>阿里mnn:<a href="https://github.com/alibaba/MNN">https://github.com/alibaba/MNN</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/600d86ac6cb1757c67d2e03ae2255cc0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">GDOUCTF</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3985516f010a9ebf4979e8821fa1ddc6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">new Date()生成 年月日的简易方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>