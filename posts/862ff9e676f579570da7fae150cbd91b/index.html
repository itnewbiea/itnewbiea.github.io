<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>03 decision tree（决策树） - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="03 decision tree（决策树）" />
<meta property="og:description" content="一、decision tree（决策树） 1. classification problems（纯度） i . entropy （熵） ​ 作用：衡量一组数据的纯度是否很纯 ，当五五开时他的熵都是最高的，当全是或者都不是时熵为 0
i i . information gain （信息增益） ​ 父节点到子节点的熵的减少称为信息增益，处理分支熵的时候，选择使用熵的加权平均值来衡量熵值的高低，计算信息增益是为了看两阶之间如果增益太小的话则不需要分了
i i i . 多个&amp;连续特征 a)one hot coding(独热编码) ​ **使用：**如果一个特征有多个可能取值，我们可以将多个取值都变为一种特征，然后取值变为0，1是否
b) 连续特征 ​ **解决：**如果一个特征有连续的取值，类似体重，可以按照信息熵来划分一个界限
2、regression tree（回归树） i. how to choosing a spilt a). 根据方差选择回归树 ​ 先计算出根节点的方差，然后计算不同特征分类以后的方差，选择方差差值较大的一个作为划分条件
i i. weaknesses of desicion tree ​ 改变数据集中的一个数据就会对最后的树造成很大的影响，形成一个根据不同条件划分的树
​ 解决：多构建几个树，使用树的合集来共同决策最后的结果，来投票最后的结果
二、决策森林 i. Sampling with replacement（有放回抽样） ​ **作用：**通过有放回的多次抽样，得到多个和原始训练集大小一样的训练集，与原始的相似但不同的新训练集
i i . Random forest algorithm a) 袋装决策树 ​ 使用 : 使用放回抽样来生成新的dataset，用生成的新的dataset来训练模型，得到新的decision tree，一共重复m次，m 的取值一般为64-228，一般是100往后可能会收益递减。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/862ff9e676f579570da7fae150cbd91b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-03T20:26:55+08:00" />
<meta property="article:modified_time" content="2024-01-03T20:26:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">03 decision tree（决策树）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="decision_tree_0"></a>一、decision tree（决策树）</h2> 
<h3><a id="1_classification_problems_2"></a>1. classification problems（纯度）</h3> 
<h4><a id="i__entropy__4"></a>i . entropy （熵）</h4> 
<p>​ 作用：衡量一组数据的纯度是否很纯 ，当五五开时他的熵都是最高的，当全是或者都不是时熵为 0</p> 
<p><img src="https://images2.imgbox.com/42/35/n5VnmMUJ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="i_i__information_gain__10"></a>i i . information gain （信息增益）</h4> 
<p>​ 父节点到子节点的熵的减少称为信息增益，处理分支熵的时候，选择使用熵的加权平均值来衡量熵值的高低，<strong>计算信息增益是为了看两阶之间如果增益太小的话则不需要分了</strong><br> <img src="https://images2.imgbox.com/eb/cd/4RYAKDGA_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="i_i_i___16"></a>i i i . 多个&amp;连续特征</h4> 
<h5><a id="aone_hot_coding_18"></a>a)one hot coding(独热编码)</h5> 
<p>​ **使用：**如果一个特征有多个可能取值，我们可以将多个取值都变为一种特征，然后取值变为0，1是否</p> 
<h5><a id="b__22"></a>b) 连续特征</h5> 
<p>​ **解决：**如果一个特征有连续的取值，类似体重，可以按照信息熵来划分一个界限</p> 
<h3><a id="2regression_tree_26"></a>2、regression tree（回归树）</h3> 
<h4><a id="i_how_to_choosing_a__spilt_28"></a>i. how to choosing a spilt</h4> 
<h5><a id="a__30"></a>a). 根据方差选择回归树</h5> 
<p>​ 先计算出根节点的方差，然后计算不同特征分类以后的方差，选择方差差值较大的一个作为划分条件</p> 
<p><img src="https://images2.imgbox.com/8f/14/G2mD0gMr_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="i_i_weaknesses_of__desicion_tree_36"></a>i i. weaknesses of desicion tree</h4> 
<p>​ 改变数据集中的一个数据就会对最后的树造成很大的影响，形成一个根据不同条件划分的树</p> 
<p>​ 解决：多构建几个树，使用树的合集来共同决策最后的结果，来投票最后的结果</p> 
<h2><a id="_44"></a>二、决策森林</h2> 
<h4><a id="i_Sampling_with_replacement_46"></a>i. Sampling with replacement（有放回抽样）</h4> 
<p>​ **作用：**通过有放回的多次抽样，得到多个和原始训练集大小一样的训练集，与原始的相似但不同的新训练集</p> 
<h4><a id="i_i__Random_forest_algorithm_50"></a>i i . Random forest algorithm</h4> 
<h5><a id="a__52"></a>a) 袋装决策树</h5> 
<p>​ <strong>使用 :</strong> 使用放回抽样来生成新的dataset，用生成的新的dataset来训练模型，得到新的decision tree，一共重复m次，m 的取值一般为64-228，一般是100往后可能会收益递减。</p> 
<h5><a id="b_random_forest_algorithm_56"></a>b) random forest algorithm</h5> 
<p>​ <strong>与上面的不同：</strong> 袋装决策树会因为dataset的小的改变而改变根节点和附近的划分特征，而这里会选择从n个feature中选择 k 个特征，从中选择entropy最大feature来进行划分。</p> 
<p>​ <strong>为什么比单一的决策树更加健壮：</strong> 因为有放回抽样给了很多个具有微小误差的dataset，训练了不同的决策树，对训练集很多小的变化的求平均</p> 
<h4><a id="i_i_i_XGBoost__62"></a>i i i. XGBoost （极端梯度增强）</h4> 
<p>​ **作用：**在前面创建随机森林过程中，对于每次当前dataset中训练错误，在下一次有放回的dataset中都有更大的机会从错误的例子中取出看，<strong>进行有针对的错误训练，使得更加 的高效</strong></p> 
<p>​ <strong>使用：</strong></p> 
<p><img src="https://images2.imgbox.com/8f/95/LHj3v3NI_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_Conclusion_71"></a>三 、Conclusion</h2> 
<h3><a id="1___73"></a>1 . 决策树，集成树，神经网络的优缺点</h3> 
<h4><a id="i___75"></a>i . 决策树和集成树的优缺点：</h4> 
<ul><li>能够很好的处理表格数据（结构化数据），类似于房价问题，将数据都可以做成一个表格的形式，然后我们可以做出<strong>分类</strong>或者<strong>回归预测</strong>的任务</li><li>不建议在视频，图像，音频和文本等非结构化数据使用，<strong>神经网络</strong>能很好的处理非结构数据</li></ul> 
<h4><a id="i_i__80"></a>i i .神经网络的优缺点</h4> 
<ul><li>决策树的训练时间很快，大型的神经网络的训练时间通常都是很慢</li><li>能够很好的和transfer learning协同工作</li><li>多个机器学习模型协同工作的系统，多个神经网络一起训练比多个决策树更加容易</li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3b8565deb64b97a7485b0ffd36c6abe3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SpringMVC-域对象共享数据</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/489f0fb28d5b1fd1e343df86c072dbf8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43; string用法总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>