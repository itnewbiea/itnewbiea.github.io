<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>层标准化详解（Layer Normalization） - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="层标准化详解（Layer Normalization）" />
<meta property="og:description" content="为什么Batch Normaization难以应用于RNNs？ Batch Normalization使用mini-batch的均值和标准差对深度神经网络的隐藏层输入进行标准化，可有效地提升训练速度。对于前向神经网络应用Batch Norm，使用简单SGD优化器，训练速度也能有较大提升。
BN的效果受制于batch的大小，小batch未必能取得预期效果；
对于前向神经网络可以很直接地应用BN，因为其每一层具有固定的神经元数量，可直接地存储每层网络各神经元的均值、方差统计信息以应用于模型预测，但在RNNs网络中，不同的mini-batch可能具有不同的输入序列长度（深度），计算统计信息比较困难，而且测试序列长度不能大于最大训练序列长度；
Barch Normalization也很难应用于在线学习模型，以及小mini-batch的分布式模型；
torch内部有两种BatchNorm，分别是BatchNorm1D和BatchNorm2D，BatchNorm1D作用于2维张量（B*D，存储D个统计量），BatchNorm2D作用于4维张量（B*C*W*H，存储C个统计量）
NLP任务中的张量多为3维，B*N*D，需存储序列长度上的统计量，而不同batch的序列长度不一致，不好统计，而且推理阶段的序列长度不能大于训练时所用的最大长度。
如何对RNNs网络进行标准化？ 网络层的输出经过线性变换作为下层网络的输入，网络输出直接影响下层网络输入分布，这是一种协变量转移的现象。我们可以通过 固定网络层的输入分布（固定输入的均值和方差） 来降低协变量转移的影响。
BN对同一mini-batch中对不同特征进行标准化（纵向规范化：每一个特征都有自己的分布），受限于batch size，难以处理动态神经网络中的变长序列的mini-bach。
RNNs不同时间步共享权重参数，使得RNNs可以处理不同长度的序列，RNNs使用 Layer Normalization 对不同时间步进行标准化（横向标准化：每一个时间步都有自己的分布），从而可以处理单一样本、变长序列，而且 训练和测试处理方式一致。
Batch Normalization和Layer Normalization的应用
对于CNNs图像x=shape(batch_size, channels, height, weight)，则 bn_mean=np.mean(x, axis=(0, 2, 3)), shape=(1, channels, 1, 1) 对于RNNs序列x=shape(batch_size, seq_len, hidden_size), 则 ln_mean=np.mean(x, axis=2)， shape=(batch_size, seq_len, 1) 对于前向神经网络的第 l l l隐藏层（等价于RNNs时刻 l l l对应的隐藏层），令 a l \boldsymbol a^l al表示输入向量（前层网络输出加权后的向量）， H H H表示隐藏单元数量，则 Layer Normalization 的均值和方差统计量为
μ l = 1 H ∑ i = 1 H a i l , σ l = 1 H ∑ i = 1 H ( a i l − μ l ) 2 \mu^l = \frac{1}{H}\sum_{i=1}^Ha^l_i,\quad \sigma^l=\sqrt{\frac{1}{H}\sum_{i=1}^H(a^l_i-\mu^l)^2} μl=H1​i=1∑H​ail​,σl=H1​i=1∑H​(ail​−μl)2 ​" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/7276a7538dc9506511edc5c83c1d634d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-20T23:31:24+08:00" />
<meta property="article:modified_time" content="2022-05-20T23:31:24+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">层标准化详解（Layer Normalization）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Batch_NormaizationRNNs_0"></a>为什么Batch Normaization难以应用于RNNs？</h2> 
<p><mark><strong>Batch Normalization使用mini-batch的均值和标准差对深度神经网络的隐藏层输入进行标准化</strong></mark>，可有效地提升训练速度。对于前向神经网络应用Batch Norm，使用简单SGD优化器，训练速度也能有较大提升。</p> 
<ul><li> <p><font color="orangered"><strong>BN的效果受制于batch的大小</strong></font>，小batch未必能取得预期效果；</p> </li><li> <p>对于前向神经网络可以很直接地应用BN，因为其每一层具有固定的神经元数量，可直接地存储每层网络各神经元的均值、方差统计信息以应用于模型预测，但在<font color="orangered"><strong>RNNs网络中，不同的mini-batch可能具有不同的输入序列长度（深度）</strong></font>，计算统计信息比较困难，而且<strong>测试序列长度不能大于最大训练序列长度</strong>；</p> </li><li> <p>Barch Normalization也<font color="orangered"><strong>很难应用于在线学习模型</strong></font>，以及<font color="orangered"><strong>小mini-batch的分布式模型</strong></font>；</p> </li></ul> 
<blockquote> 
 <p>torch内部有两种BatchNorm，分别是BatchNorm1D和BatchNorm2D，BatchNorm1D作用于2维张量（B*D，存储D个统计量），BatchNorm2D作用于4维张量（B*C*W*H，存储C个统计量）<br> <br> NLP任务中的张量多为3维，B*N*D，需存储序列长度上的统计量，而不同batch的序列长度不一致，不好统计，而且推理阶段的序列长度不能大于训练时所用的最大长度。<br> <br></p> 
</blockquote> 
<h2><a id="RNNs_14"></a>如何对RNNs网络进行标准化？</h2> 
<p>网络层的输出经过线性变换作为下层网络的输入，网络输出直接影响下层网络输入分布，这是一种<font color="orangered"><strong>协变量转移</strong></font>的现象。我们可以通过 <strong>固定网络层的输入分布（固定输入的均值和方差）</strong> 来降低协变量转移的影响。</p> 
<p>BN对同一mini-batch中对不同特征进行标准化<font color="orangered"><strong>（纵向规范化：每一个特征都有自己的分布）</strong></font>，受限于batch size，难以处理动态神经网络中的变长序列的mini-bach。</p> 
<p>RNNs不同时间步共享权重参数，使得RNNs可以处理不同长度的序列，RNNs使用 <mark><strong>Layer Normalization</strong></mark> 对不同时间步进行标准化<font color="orangered"><strong>（横向标准化：每一个时间步都有自己的分布）</strong></font>，从而可以处理单一样本、变长序列，而且 <mark><strong>训练和测试处理方式一致</strong></mark>。</p> 
<blockquote> 
 <p><strong>Batch Normalization和Layer Normalization的应用</strong></p> 
 <ul><li>对于CNNs图像x=shape(batch_size, channels, height, weight)，则</li></ul> 
 <center>
   bn_mean=np.mean(x, axis=(0, 2, 3)), shape=(1, channels, 1, 1) 
 </center> 
 <ul><li>对于RNNs序列x=shape(batch_size, seq_len, hidden_size), 则</li></ul> 
 <center>
   ln_mean=np.mean(x, axis=2)， shape=(batch_size, seq_len, 1) 
 </center> 
</blockquote> 
<p>对于前向神经网络的第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
      
        l 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span></span></span></span></span>隐藏层（等价于RNNs时刻<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
      
        l 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span></span></span></span></span>对应的隐藏层），令<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          a 
         
        
          l 
         
        
       
      
        \boldsymbol a^l 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.849108em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol">a</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.849108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span></span></span></span></span>表示输入向量（前层网络输出加权后的向量），<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         H 
        
       
      
        H 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span></span></span></span></span>表示隐藏单元数量，则 <mark><strong>Layer Normalization</strong></mark> 的均值和方差统计量为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           μ 
          
         
           l 
          
         
        
          = 
         
         
         
           1 
          
         
           H 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           H 
          
         
         
         
           a 
          
         
           i 
          
         
           l 
          
         
        
          , 
         
         
         
         
           σ 
          
         
           l 
          
         
        
          = 
         
         
          
           
           
             1 
            
           
             H 
            
           
           
           
             ∑ 
            
            
            
              i 
             
            
              = 
             
            
              1 
             
            
           
             H 
            
           
          
            ( 
           
           
           
             a 
            
           
             i 
            
           
             l 
            
           
          
            − 
           
           
           
             μ 
            
           
             l 
            
           
           
           
             ) 
            
           
             2 
            
           
          
         
        
       
         \mu^l = \frac{1}{H}\sum_{i=1}^Ha^l_i,\quad \sigma^l=\sqrt{\frac{1}{H}\sum_{i=1}^H(a^l_i-\mu^l)^2} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.09355em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.899108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 3.10601em; vertical-align: -1.27767em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.82834em;"><span class="" style="top: -1.87233em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05001em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.30001em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.08125em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27767em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.899108em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mspace" style="margin-right: 1em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.899108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 3.33376em; vertical-align: -1.27767em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 2.05609em;"><span class="svg-align" style="top: -5.29375em;"><span class="pstrut" style="height: 5.29375em;"></span><span class="mord" style="padding-left: 1.056em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.82834em;"><span class="" style="top: -1.87233em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05001em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.30001em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.08125em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27767em;"><span class=""></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.830908em;"><span class="" style="top: -2.42314em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.0448em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.276864em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.775108em;"><span class="" style="top: -2.989em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.740108em;"><span class="" style="top: -2.989em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span class="" style="top: -4.01609em;"><span class="pstrut" style="height: 5.29375em;"></span><span class="hide-tail" style="min-width: 0.742em; height: 3.37376em;"> 
            <svg width="400em" height="3.373755em" viewbox="0 0 400000 3373" preserveaspectratio="xMinYMin slice"> 
             <path d="M702 80H400000v40H742v3239l-4 4-4 4c-.667.7
-2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1h-12l-28-84c-16.667-52-96.667
-294.333-240-727l-212 -643 -85 170c-4-3.333-8.333-7.667-13 -13l-13-13l77-155
 77-156c66 199.333 139 419.667 219 661 l218 661zM702 80H400000v40H742z"></path> 
            </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27767em;"><span class=""></span></span></span></span></span></span></span></span></span></span></p> 
<p><font color="orangered"><strong>同层网络的所有隐藏单元共享均值和方差。</strong></font></p> 
<br> 
<p>对于标准RNN，若当前输入为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          t 
         
        
       
      
        \boldsymbol x^t 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.793556em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.793556em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span></span>，上一隐藏状态为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
         
         
           t 
          
         
           − 
          
         
           1 
          
         
        
       
      
        \boldsymbol h^{t-1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.898448em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol">h</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.898448em;"><span class="" style="top: -3.14734em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></span>，则加权输入向量（非线性单元的输入）为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           a 
          
         
           t 
          
         
        
          = 
         
         
         
           W 
          
          
          
            h 
           
          
            h 
           
          
         
         
         
           h 
          
          
          
            t 
           
          
            − 
           
          
            1 
           
          
         
        
          + 
         
         
         
           W 
          
          
          
            x 
           
          
            h 
           
          
         
         
         
           x 
          
         
           t 
          
         
        
       
         \boldsymbol a^t=W_{hh}\boldsymbol h^{t-1}+W_{xh}\boldsymbol x^t 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.843556em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol">a</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.843556em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.04845em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord boldsymbol">h</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.898448em;"><span class="" style="top: -3.14734em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.993556em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.843556em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span></span></span><br> 则对输入向量进行层标准化，再进行 <mark><strong>缩放和平移</strong></mark>（用于恢复非线性）得标准化后输入<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         y 
        
       
      
        \boldsymbol y 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.63888em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.03704em;">y</span></span></span></span></span></span>:<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          y 
         
        
          = 
         
        
          g 
         
        
          ⊙ 
         
         
          
          
            a 
           
          
            ^ 
           
          
         
           t 
          
         
        
          + 
         
        
          b 
         
        
          , 
         
         
         
          
          
            a 
           
          
            ^ 
           
          
         
           t 
          
         
        
          = 
         
         
          
           
           
             a 
            
           
             t 
            
           
          
            − 
           
           
           
             u 
            
           
             t 
            
           
          
          
          
            σ 
           
          
            t 
           
          
         
        
       
         \boldsymbol y= \boldsymbol g\odot\hat \boldsymbol a^t+\boldsymbol b,\quad \hat \boldsymbol a^t=\frac{\boldsymbol a^t-u^t}{\sigma^t} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.63888em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.03704em;">y</span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.77777em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.03704em;">g</span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.974666em; vertical-align: -0.08333em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.70788em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord boldsymbol">a</span></span></span><span class="" style="top: -3.01344em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.891336em;"><span class="" style="top: -3.16078em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.08578em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord boldsymbol">b</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mspace" style="margin-right: 1em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.70788em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord boldsymbol">a</span></span></span><span class="" style="top: -3.01344em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.891336em;"><span class="" style="top: -3.16078em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.15656em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.47056em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.719556em;"><span class="" style="top: -2.989em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">a</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.793556em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.793556em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p> 
<p>对于使用LN的RNNs，<font color="orangered"><strong>每个时刻加权后的输入通过标准化被重新调整在合适的范围</strong></font>，很大程度避免了梯度消失、梯度爆炸问题，隐藏状态的传递更加稳定。</p> 
<center> 
 <img src="https://images2.imgbox.com/ee/79/W1us6a5I_o.png" width="100%"> 
</center> 
<h2><a id="TorchLayerNormBatchNorm1DBatchNorm2D_56"></a>Torch中的LayerNorm、BatchNorm1D和BatchNorm2D对比</h2> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token comment"># LayerNorm基于最后一维统计量执行标准化，即最后一维向量内部执行标准化</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n------ TEST LAYER NORM ------"</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    layernorm <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    layernorm<span class="token punctuation">.</span>training <span class="token operator">=</span> <span class="token boolean">False</span>
    std<span class="token punctuation">,</span> mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>std_mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> unbiased<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> std<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span>
    x2 <span class="token operator">=</span> layernorm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>x1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">==</span> np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>x2<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

	<span class="token comment"># BatchNorm1D基于最后一维统计量执行标准化</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n------ TEST BATCH NORM 1D ------"</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># y = \frac{x - \mathrm{E}[x]}{\sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta</span>
    batchnorm <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> track_running_stats<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    batchnorm<span class="token punctuation">.</span>training <span class="token operator">=</span> <span class="token boolean">False</span>
    std<span class="token punctuation">,</span> mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>std_mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> unbiased<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> std<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    x2 <span class="token operator">=</span> batchnorm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>x1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">==</span> np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>x2<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	
	<span class="token comment"># BatchNorm2D基于第2维（Channel维度）统计量执行标准化</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n------ TEST BATCH NORM 2D ------"</span><span class="token punctuation">)</span>
    <span class="token comment"># shape=(B, C, H, W)</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># y = \frac{x - \mathrm{E}[x]}{\sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta</span>
    batchnorm <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>c<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> track_running_stats<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    batchnorm<span class="token punctuation">.</span>training <span class="token operator">=</span> <span class="token boolean">False</span>

    x1 <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> c<span class="token punctuation">)</span>
    std<span class="token punctuation">,</span> mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>std_mean<span class="token punctuation">(</span>x1<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> unbiased<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> <span class="token punctuation">(</span>x1 <span class="token operator">-</span> mean<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> std<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    x1 <span class="token operator">=</span> x1<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
    x2 <span class="token operator">=</span> batchnorm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>x1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">==</span> np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>x2<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<p>输出如下：</p> 
<pre><code class="prism language-bash">ssh://merlin@192.168.60.56:22/home/merlin/anaconda3/envs/hermes/bin/python -u /data/ao/hermes/norm.py

------ TEST LAYER NORM ------
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span>
  <span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span>
  <span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span>
  <span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span><span class="token punctuation">]</span>

 <span class="token punctuation">[</span><span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span>
  <span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span>
  <span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span>
  <span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

------ TEST BATCH NORM 1D ------
<span class="token punctuation">[</span><span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span>
 <span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span>
 <span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span>
 <span class="token punctuation">[</span> True  True  True  True  True  True<span class="token punctuation">]</span><span class="token punctuation">]</span>

------ TEST BATCH NORM 2D ------
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span><span class="token punctuation">]</span>

  <span class="token punctuation">[</span><span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span><span class="token punctuation">]</span>

  <span class="token punctuation">[</span><span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>


 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span><span class="token punctuation">]</span>

  <span class="token punctuation">[</span><span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span><span class="token punctuation">]</span>

  <span class="token punctuation">[</span><span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span>
   <span class="token punctuation">[</span> True  True  True  True<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

Process finished with <span class="token builtin class-name">exit</span> code <span class="token number">0</span>

</code></pre> 
<p>Reference<br> <a href="https://arxiv.org/abs/1607.06450" rel="nofollow">1.Ba, Jimmy et al. “Layer Normalization.” ArXiv abs/1607.06450 (2016): n. pag.</a><br> <a href="https://blog.csdn.net/qq_39777550/article/details/108038677">2.BatchNorm2d原理、作用及其pytorch中BatchNorm2d函数的参数讲解</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b0548eeb2ed640d7f699a8b19de5d3de/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">1、MPC 算法（模型预测控制算法（MPC算法）轨迹跟踪控制）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/45191892e99c9b6740672dfbc6ee36d0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">win10开启SSH服务通过内网穿透技术实现远程SSH访问</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>