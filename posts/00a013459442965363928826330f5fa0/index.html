<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>YARN 作业 Staging目录的用途及配置 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="YARN 作业 Staging目录的用途及配置" />
<meta property="og:description" content="目录 staging目录的用途MapReduce作业Staging的配置示例 Spark 作业Staging目录的配置示例 staging目录的用途 关于staging目录可能很多人都不太会关注，毕竟日常运行作业也用不到这些配置。不过了解它对于我们理解作业的执行流程也是有所帮助的，比如我们都会使用hadoop jar 或 spark-submit等命令来提交一个MR或Spark作业，然后我们就会看到在集群的某些计算节点上启动executor(MapRedece对应的是mapper和reducer)来执行任务。这些executor都是一个JVM进程，既然如此，那么启动一个JVM进程必然需要用到至少一个jar包，那这些jar包是从哪里来的呢？此时就用到了staging 目录（有人把staging翻译为舞台目录，这也有一定的含义，提交作业，就要登上集群这个舞台了）了。提交作业的时候，会把相关的jar包和配置信息都上传到这个staging目录下，然后在启动executor之前，会从这里将这些信息下载到计算节点本地。
MapReduce作业Staging的配置 yarn.app.mapreduce.am.staging-dir：提交mapreduce作业的staging目录，默认是/tmp/hadoop-yarn/stagingyarn.app.mapreduce.am.staging-dir.erasurecoding.enabled：staging目录下的文件是否使用纠删码方式存储，默认false，这可以在提交作业时指定mapreduce.client.submit.file.replication：提交到staging目录下的文件的副本数，默认是10mapreduce.job.split.metainfo.maxsize：split元数据信息文件的最大大小，默认10000000，超过该大小AppMaster将不会再读取。设置为-1，则表示不限制该文件的大小。这个文件通常不会很大，一般也不会去单独设置 示例 下面从一个实际的MR作业来看一下stageing目录中的内容，可以看到文件job.jar和job.split以及libjars目录中的文件副本数都是10，这个10就是由配置项mapreduce.client.submit.file.replication指定的
下面通过提交一个测试作业验证一下这个配置项，指定mapreduce.client.submit.file.replication为12
作业提交后，查看对应的staging 目录文件，如下，说明配置参数生效了
最后解释一下这些文件的副本为什么是10呢，难道3副本还不能满足数据安全的要求吗？这里其实涉及到MR作业运行时的一个步骤就是资源本地化，本文开头已经介绍过staging目录的作用了，而比如一个MR作业的mapper有几百几千个的时候，那么就意味着会有上千的客户端会同时下载这个jar包，此时将这个jar包的副本数设置的大一点可以提高资源本地化的效率，而反之如果只是一个很小的MR作业，这么高的副本数就是浪费了。这也侧面说明了MR的设计初衷就是面向大规模数据的。
Spark 作业Staging目录的配置 下面是spark on yarn模式下的配置
spark.yarn.submit.file.replication：提交作业时上传到HDFS相关文件的副本数，默认是HDFS的默认副本数，通常是3spark.yarn.stagingDir：提交作业时的staging目录，默认是用户的家目录spark.yarn.preserve.staging.files：在提交作业时的staged 文件(Spark jar, app jar, distributed cache files) 在作业结束时是否保留，默认false，也就是作业执行结束后进行删除 示例 下面从一个实际的Spark作业来看一下stageing目录中的内容
可以看到，和MR作业的Staging目录相比，spark并未将spark的jar包设置为10副本；而且把配置信息和jar包分别进行了压缩，结构相对简单一点。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/00a013459442965363928826330f5fa0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-12-17T23:10:44+08:00" />
<meta property="article:modified_time" content="2020-12-17T23:10:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">YARN 作业 Staging目录的用途及配置</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#staging_1" rel="nofollow">staging目录的用途</a></li><li><a href="#MapReduceStaging_4" rel="nofollow">MapReduce作业Staging的配置</a></li><li><ul><li><a href="#_11" rel="nofollow">示例</a></li></ul> 
  </li><li><a href="#Spark_Staging_20" rel="nofollow">Spark 作业Staging目录的配置</a></li><li><ul><li><a href="#_27" rel="nofollow">示例</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="staging_1"></a>staging目录的用途</h2> 
<p>关于staging目录可能很多人都不太会关注，毕竟日常运行作业也用不到这些配置。不过了解它对于我们理解作业的执行流程也是有所帮助的，比如我们都会使用hadoop jar 或 spark-submit等命令来提交一个MR或Spark作业，然后我们就会看到在集群的某些计算节点上启动executor(MapRedece对应的是mapper和reducer)来执行任务。这些executor都是一个JVM进程，既然如此，那么启动一个JVM进程必然需要用到至少一个jar包，那这些jar包是从哪里来的呢？此时就用到了staging 目录（有人把staging翻译为舞台目录，这也有一定的含义，提交作业，就要登上集群这个舞台了）了。提交作业的时候，会把相关的jar包和配置信息都上传到这个staging目录下，然后在启动executor之前，会从这里将这些信息下载到计算节点本地。</p> 
<h2><a id="MapReduceStaging_4"></a>MapReduce作业Staging的配置</h2> 
<ul><li><strong>yarn.app.mapreduce.am.staging-dir</strong>：提交mapreduce作业的staging目录，默认是/tmp/hadoop-yarn/staging</li><li><strong>yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled</strong>：staging目录下的文件是否使用纠删码方式存储，默认false，这可以在提交作业时指定</li><li><strong>mapreduce.client.submit.file.replication</strong>：提交到staging目录下的文件的副本数，默认是10</li><li><strong>mapreduce.job.split.metainfo.maxsize</strong>：split元数据信息文件的最大大小，默认10000000，超过该大小AppMaster将不会再读取。设置为-1，则表示不限制该文件的大小。这个文件通常不会很大，一般也不会去单独设置</li></ul> 
<h3><a id="_11"></a>示例</h3> 
<p>下面从一个实际的MR作业来看一下stageing目录中的内容，可以看到文件job.jar和job.split以及libjars目录中的文件副本数都是10，这个10就是由配置项mapreduce.client.submit.file.replication指定的<br> <img src="https://images2.imgbox.com/58/e7/LgyOkV5t_o.png" alt="在这里插入图片描述"><br> 下面通过提交一个测试作业验证一下这个配置项，指定mapreduce.client.submit.file.replication为12<br> <img src="https://images2.imgbox.com/23/88/v6smmdVA_o.png" alt="在这里插入图片描述"><br> 作业提交后，查看对应的staging 目录文件，如下，说明配置参数生效了<br> <img src="https://images2.imgbox.com/00/83/D8ftDSWG_o.png" alt="在这里插入图片描述"><br> 最后解释一下这些文件的副本为什么是10呢，难道3副本还不能满足数据安全的要求吗？这里其实涉及到MR作业运行时的一个步骤就是资源本地化，本文开头已经介绍过staging目录的作用了，而比如一个MR作业的mapper有几百几千个的时候，那么就意味着会有上千的客户端会同时下载这个jar包，此时将这个jar包的副本数设置的大一点可以提高资源本地化的效率，而反之如果只是一个很小的MR作业，这么高的副本数就是浪费了。这也侧面说明了MR的设计初衷就是面向大规模数据的。</p> 
<h2><a id="Spark_Staging_20"></a>Spark 作业Staging目录的配置</h2> 
<p>下面是spark on yarn模式下的配置</p> 
<ul><li><strong>spark.yarn.submit.file.replication</strong>：提交作业时上传到HDFS相关文件的副本数，默认是HDFS的默认副本数，通常是3</li><li><strong>spark.yarn.stagingDir</strong>：提交作业时的staging目录，默认是用户的家目录</li><li><strong>spark.yarn.preserve.staging.files</strong>：在提交作业时的staged 文件(Spark jar, app jar, distributed cache files) 在作业结束时是否保留，默认false，也就是作业执行结束后进行删除</li></ul> 
<h3><a id="_27"></a>示例</h3> 
<p>下面从一个实际的Spark作业来看一下stageing目录中的内容<br> <img src="https://images2.imgbox.com/94/1a/2LZsBfPV_o.png" alt="在这里插入图片描述"><br> 可以看到，和MR作业的Staging目录相比，spark并未将spark的jar包设置为10副本；而且把配置信息和jar包分别进行了压缩，结构相对简单一点。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e68ea26a32cccdff1287857126a64b18/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">iphone图片编辑画笔_苹果超强新功能上线！它打开了 iPhone 摄影的新大门</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/330a3430a96fc124c1b1023ddd890e2d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python中round(x、2)是什么意思_python中round函数具体使用详解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>