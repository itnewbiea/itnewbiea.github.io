<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>目标检测：YOLOX 解读 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="目标检测：YOLOX 解读" />
<meta property="og:description" content="摘要 YOLOX把YOLO 系列的检测头换成了anchor free的方式，并且采取了一些优化策略：样本分配策略：simOTA，decoupled head（解耦头）的思想。
1.介绍 YOLO家族一直以来都是把最流行的技术加入，并进行优化，追求精度和速度的最佳平衡（比如YOLOv2中引入的Anchor，YOLOV3中引入的残差块，YOLOv4中的Mosich数据增强）最近出的YOLOv5，性能达到了最高，但是近两年大热的Anchor free、先进的标签分配策略、端到端检测（NMS-free)没有被考虑进去，因此YOLOX诞生了。
由于考虑到YOLOv4、v5基于Anchor base可能有限过度优化，因此YOLOX基于YOLOv3-SPP版本进行改进。加入上述策略之后，我们boost the YOLOv3 to 47.3%；再加入YOLOV5里面的CSP结构和PAN结构，YOLOX-L achieves 50.0%。
2. YOLOX 2.1 YOLOX-DarkNet53 采用Darknet53作为BackBonend an SPP layer，具体训练设置如下：
在YOLOV3的backbone上基础上进行了如下训练策略改进：
添加了EMA权重更新余弦学习率衰减策略，IoU损失和IoU感知分支。 我们使用 BCE Loss 来训练 cls 和 obj 分支，使用 IoU Loss 来训练 reg 分支。这些一般的训练技巧与YOLOX的关键改进是正交的，因此我们把它们放在基线上。只进行RandomHorizontalFlip，ColorJitter（颜色抖动）和多尺度的数据增强。
并放弃了RandomResizeCrop策略，因为我们发现RandomResizeCrop与采用的的Mosich增强有点重叠。 通过这些增强功能，我们的基线在COCO val上实现了38.5%的AP，如下图所示
2.2 Decoupled head 我们的两个分析实验表明，耦合检测头可能会损害性能。
1）用解耦的头代替YOLO的头可以大大提高收敛速度。
2）解耦头对于YOLO的端到端版本至关重要（将在下面描述）。从下图可以看出，对于耦合磁头，端到端属性降低了 4.2% 的 AP，而对于解耦磁头，端到端属性的 AP 降低到 0.8%。因此，我们将YOLO检测头替换为精简版解耦头。
具体而言，它包含一个1×1个Conv层来减小每个FPN对应的输出通道尺寸到256，然后是两个平行分支，分别具有两个3×3个Conv层。
2.3 Strong data augmentation 增加Mosaic and MixUp数据增强，并且在最后15epoch关闭。
实验发现数据增强后，预训练没有意义，因此，实验都是从头开始训练以下所有模型。
2.4 Anchor-free YOLv4和YOLOv5都是基于Anchor base的，基于Anchor的机制有许多缺点：
首先，为了实现最佳检测性能，需要在训练之前进行聚类分析以确定一组最佳锚点。其次，锚定机制增加了检测头的复杂性，以及每个图像的预测数量 Anchor free 机制大大减少了需要手动设计参数的数量和涉及的许多技巧（例如，锚点聚类[24]，网格敏感[11]），以获得良好的性能，使检波器，特别是其训练和解码阶段，相当简单[29]。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/887a0d281ce6de601772de9ecceb7796/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-07T20:37:06+08:00" />
<meta property="article:modified_time" content="2023-07-07T20:37:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">目标检测：YOLOX 解读</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>摘要</h2> 
<p><mark>YOLOX把YOLO 系列的检测头换成了anchor free的方式，并且采取了一些优化策略：样本分配策略：simOTA，decoupled head（解耦头）的思想。</mark></p> 
<h2><a id="1_3"></a>1.介绍</h2> 
<p>YOLO家族一直以来都是把最流行的技术加入，并进行优化，追求精度和速度的最佳平衡（比如YOLOv2中引入的Anchor，YOLOV3中引入的残差块，YOLOv4中的Mosich数据增强）最近出的YOLOv5，性能达到了最高，但是近两年大热的Anchor free、先进的标签分配策略、端到端检测（NMS-free)没有被考虑进去，因此YOLOX诞生了。<br> 由于考虑到YOLOv4、v5基于Anchor base可能有限过度优化，因此YOLOX基于YOLOv3-SPP版本进行改进。加入上述策略之后，我们boost the YOLOv3 to 47.3%；再加入YOLOV5里面的CSP结构和PAN结构，YOLOX-L achieves 50.0%。</p> 
<h2><a id="2_YOLOX_8"></a>2. YOLOX</h2> 
<h3><a id="21_YOLOXDarkNet53_9"></a>2.1 YOLOX-DarkNet53</h3> 
<p>采用Darknet53作为BackBonend an SPP layer，具体训练设置如下：<br> <img src="https://images2.imgbox.com/fd/4e/84QwF8vO_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ce/1d/8jam2hBU_o.png" alt="在这里插入图片描述"></p> 
<p>在YOLOV3的backbone上基础上进行了如下训练策略改进：</p> 
<ol><li>添加了<strong>EMA权重更新</strong></li><li><strong>余弦学习率衰减策略</strong></li><li>，IoU损失和IoU感知分支。 我们<strong>使用 BCE Loss 来训练 cls 和 obj 分支</strong>，使用 <strong>IoU Loss 来训练 reg 分支</strong>。这些一般的训练技巧与YOLOX的关键改进是正交的，因此我们把它们放在基线上。</li><li>只进行<strong>RandomHorizontalFlip，ColorJitter（颜色抖动）和多尺度的数据增强</strong>。<br> 并放弃了RandomResizeCrop策略，因为我们发现RandomResizeCrop与采用的的Mosich增强有点重叠。</li></ol> 
<p>通过这些增强功能，我们的基线在COCO val上实现了38.5%的AP，如下图所示<br> <img src="https://images2.imgbox.com/de/84/bbjUTFfI_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22_Decoupled_head_25"></a>2.2 Decoupled head</h3> 
<p>我们的两个分析实验表明，耦合检测头可能会损害性能。<br> 1）<strong>用解耦的头代替YOLO的头可以大大提高收敛速度</strong>。<br> 2）解耦头对于YOLO的<strong>端到端</strong>版本至关重要（将在下面描述）。从下图可以看出，对于耦合磁头，端到端属性降低了 4.2% 的 AP，而对于解耦磁头，端到端属性的 AP 降低到 0.8%。因此，我们将YOLO检测头替换为精简版解耦头。</p> 
<p>具体而言，它包含一个1×1个Conv层来减小每个FPN对应的输出通道尺寸到256，然后是两个平行分支，分别具有两个3×3个Conv层。</p> 
<p><img src="https://images2.imgbox.com/85/27/G1KYlcAz_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6f/d2/1qKi4103_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/8a/09/GUGibNUj_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="23_Strong_data_augmentation_36"></a>2.3 Strong data augmentation</h3> 
<p>增加Mosaic and MixUp数据增强，并且在最后15epoch关闭。<br> 实验发现数据增强后，预训练没有意义，因此，实验都是从头开始训练以下所有模型。</p> 
<h3><a id="24_Anchorfree_40"></a>2.4 Anchor-free</h3> 
<p>YOLv4和YOLOv5都是基于Anchor base的，基于Anchor的机制有许多缺点：</p> 
<ol><li>首先，为了实现最佳检测性能，需要在训练之前进行聚类分析以确定一组最佳锚点。</li><li>其次，锚定机制增加了检测头的复杂性，以及每个图像的预测数量</li></ol> 
<p>Anchor free 机制大大减少了需要手动设计参数的数量和涉及的许多技巧（例如，锚点聚类[24]，网格敏感[11]），以获得良好的性能，使检波器，特别是其训练和解码阶段，相当简单[29]。</p> 
<pre><code>1. 对每个位置只进行1次预测，生成一个预测框（YOLO系列是3次），预测四个信息（左上角和右下角信息，预测框的高、宽）
2. 我们将每个物体的中心位置指定为正样本并预先定义一个范围，对于每个对象设计一个FPN尺寸。这种修改减少了检测头的参数和GFLOP，并使其更快，同时获得更好的性能 – 42.9% AP。
</code></pre> 
<p><img src="https://images2.imgbox.com/06/fb/nsT4c4vT_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="25_Multi_positives_52"></a>2.5 Multi positives</h3> 
<ol><li>对每个目标选择多个正样本，如FCOS一样，设置3*3大小的区域为正样本区域，命名为“center sampling” 。</li><li>多个正样本能减缓训练时正负样本之间的不平衡现象。</li></ol> 
<h3><a id="26_SimOTA_56"></a>2.6 SimOTA</h3> 
<pre><code>优秀的标签分配是近年来目标检测的另一个重要进步。基于我们自己的研究OTA [4]，我们总结了先进的标签分配的四个关键点：
	1）.损失/质量感知，
	2）中心先验，
	3）每个ground-truth的positive anchor的动态数量（缩写为动态top-k），
	4）全局视图。
OTA符合上述所有四条规则，因此我们选择它作为候选标签分配策略。
</code></pre> 
<p>具体而言，OTA 从全局角度分析标签分配，并将分配过程表述为最佳传输（OT）问题，从而在当前分配策略中产生SOTA性能。<br> 然而，在实践中，我们发现通过Sinkhorn-Knopp算法解决OT问题会带来25%的额外训练时间，这对于训练300个epoch来说是相当昂贵的。因此，我们将其简化为名为<mark>SimOTA</mark>的动态top-k策略，以获得近似的解决方案。</p> 
<p>SimOTA首先计算成对匹配度，用每个predict-gt对的成本或质量表示。例如，在 SimOTA 中，gt g <sub> i </sub>和 prediction p<sub>j </sub>之间的成本计算公式为：<br> <img src="https://images2.imgbox.com/e4/56/3vC6mS69_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<p>其中 λ 是平衡系数。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
         
         
           i 
          
         
           j 
          
         
         
         
           c 
          
         
           l 
          
         
           s 
          
         
        
       
      
        L^{cls}_{ij} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.2439em; vertical-align: -0.3948em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -2.4413em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3948em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
         
         
           i 
          
         
           j 
          
         
         
         
           r 
          
         
           e 
          
         
           g 
          
         
        
       
      
        L^{reg}_{ij} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1953em; vertical-align: -0.413em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7823em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.413em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 是 gt <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          g 
         
        
          i 
         
        
       
      
        g^i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0191em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span></span> 和 prediction <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          p 
         
        
          j 
         
        
       
      
        p^j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0191em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span></span></span></span></span></span></span></span></span> 之间的分类损失和回归损失。<br> 然后，对于 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          g 
         
        
          t 
         
        
        
        
          g 
         
        
          i 
         
        
       
      
        g^t g^i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0191em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7936em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span></span> ，我们选择固定中心区域内成本最低的前 k 个预测作为其正样本。最后，这些正预测的相应网格被指定为正数，而其余网格为负数。注意值 k 因不同的ground truth而异。有关更多详细信息，请参阅 OTA 中的动态 k 估计策略。</p> 
<hr> 
<p>SimOTA不仅减少了训练时间，还避免了SinkhornKnopp算法中额外的求解器超参数。</p> 
<h3><a id="27_Endtoend_YOLO_79"></a>2.7 End-to-end YOLO</h3> 
<p>我们按照 [39] 添加两个额外的 conv 层、一对一标签分配和停止渐变。 这使得检测器能够以端到端的方式执行，<mark>但性能和推理速度会略有下降</mark>，如表 2 中所列。<mark>因此，end-to-end的设计没有加入YOLOX的最终模型。</mark></p> 
<h2><a id="3_Other_Backbones_83"></a>3. Other Backbones</h2> 
<p>将YOLOX的Backbone替换成其他不同size的Backbone，均在原始数据的基础上带来了的提升。（论文中无数据）</p> 
<h3><a id="31_Modified_CSPNet_in_YOLOv5_85"></a>3.1 Modified CSPNet in YOLOv5</h3> 
<p>为了进行公平的比较，我们采用了YOLOv5的Backbone，包括改进的CSPNet [31]，SiLU激活和PAN [19]头。我们还遵循其缩放规则来生产YOLOXS，YOLOX-M，YOLOX-L和YOLOX-X型号。与表 3 中的 YOLOv5 相比，我们的模型以 ∼3.0% 至 ∼1.0% AP 持续改进，只有边际时间增加（来自解耦头）。<br> <img src="https://images2.imgbox.com/2f/5d/RhsbAt5S_o.png" alt="YOLOX的主干部分是YOLOv5的backbone"></p> 
<h3><a id="32_Tiny_and_Nano_detectors_90"></a>3.2 Tiny and Nano detectors</h3> 
<p>对于移动设备，我们采用<mark>深度卷积来构建YOLOX-Nano模型</mark>，该模型只有0.91M参数量和1.08G FLOPS。<br> 如表 4 所示，YOLOX 在模型尺寸更小的情况下表现良好。<br> <img src="https://images2.imgbox.com/12/09/Hvhl5ENh_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="33_Model_size_and_data_augmentation_94"></a>3.3 Model size and data augmentation</h3> 
<p>数据增强对于大的模型来说是有用的。<br> 事实上，我们的 MixUp 实现比的原始版本更复杂。受Copypaste 的启发，<mark>我们在图像进行混合之前通过随机采样的比例因子对两个图像进行了抖动</mark>。为了理解具有尺度抖动的Mixup的强大功能，我们将它与YOLOX-L上的Copypaste进行了比较。请注意，Copypaste需要额外的实例掩码标签，而 MixUp 则不需要。但如表 5 所示，这两种方法实现了具有竞争力的性能，这表明在没有实例掩码注释可用时，具有缩放抖动的 MixUp 是 Copypaste 的合格替代品。</p> 
<p><img src="https://images2.imgbox.com/61/34/hyEhwGqq_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="4_Comparison_with_the_SOTA_99"></a>4 Comparison with the SOTA</h2> 
<p><img src="https://images2.imgbox.com/d1/fc/yRL5LMrW_o.png" alt="在这里插入图片描述"><br> 在不同的软件和硬件设备上推理时间会不同。因此，实验在相同的软硬件上，实现了YOLO系列的精度/速度的曲线图。</p> 
<h2><a id="6_Conclusion_103"></a>6 Conclusion</h2> 
<p>在这文章中，我们对YOLO系列进行了一些经验更新，它拥有一个高性能的Anchor free 的检测器，命名为YOLOX。<mark>它配备了一些先进的检测技术，如解耦头，Anchor free，和先进的标签分配策略( decoupled head,<br> anchor-free, and advanced label assigning strategy)</mark>。<br> YOLOX实现了速度和精度之间的更好的权衡。值得注意的是,我们改进的YOLOv3的架构,仍然是最广泛使用的detector之一，行业由于其广泛的兼容性,在COCO 数据集上 47.3% AP,超越当前的最佳实践 3.0% AP。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/faa15a69aa6ab07f1ec31734eb4a137b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">干货|如何生成和展示二维码(前后端)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c61cbf29510d31a75d49663c08a057f7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">.Net Core 如何数据导出 Excel？（EPPlus-＞OfficeOpenXml 实现固定列和动态列导出）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>