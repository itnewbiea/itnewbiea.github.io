<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>中文词性标注学习笔记（二）---分词 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="中文词性标注学习笔记（二）---分词" />
<meta property="og:description" content="词性标注（二） 分词 词的概念
分词是自然语言处理的基础，分词准确度直接决定了后面的词性标注、句法分析、词向量以及文本分析的质量。英文语句使用空格将单词进行分隔，除了某些特定词，如how many，New York等外，大部分情况下不需要考虑分词问题。但中文不同，天然缺少分隔符，需要读者自行分词和断句。故在做中文自然语言处理时，我们需要先进行分词。
中文分词的三个难点 中文分词不像英文那样，天然有空格作为分隔。而且中文词语组合繁多，分词很容易产生歧义。因此中文分词一直以来都是NLP的一个重点，也是一个难点。难点主要集中在分词标准，切分歧义和未登录词三部分。
1.分词标准
比如人名，有的算法认为姓和名应该分开，有的认为不应该分开。这需要制定一个相对统一的标准。又例如“花草”，有的人认为是一个词，有的人认为应该划分开为两个词“花/草”。某种意义上，中文分词可以说是一个没有明确定义的问题。
2.切分歧义
1.组合型歧义：分词粒度不同导致的不同切分结果。比如“中华人民共和国”，粗粒度的分词结果为“中华人民共和国”，细粒度的分词结果为“中华/人民/共和国”。这种问题需.用场景来选择。
2.交集型歧义：不同切分结果共用相同的字，前后组合的不同导致不同的切分结果。比如“商务处女干事”，可以划分为“商务处/女干事”，也可以划分为“商务/处女/干事”。这也需要通过整句话来区分。
3.真歧义：本身语法或语义没有问题，即使人工切分也会产生歧义。比如“下雨天留客天天留人不留”，可以划分为“下雨天/留客天/天留/人不留”，也可以划分为“下雨天/留客天/天留人不/留”。此时通过整句话还没法切分，只能通过上下文语境来进行切分。如果是不想留客，则切分为前一个。否则切分为后一个。
3.未登录词
也叫新词发现，或者生词，未被词典收录的词。
中文分词算法 当前的分词算法主要分为两类，基于词典的规则匹配方法，和基于统计的机器学习方法。
基于词典的分词算法
基于词典的分词算法，本质上就是字符串匹配。将待匹配的字符串基于一定的算法策略，和一个足够大的词典进行字符串匹配，如果匹配命中，则可以分词。根据不同的匹配策略，又分为正向最大匹配法，逆向最大匹配法，双向匹配分词，全切分路径选择等。
基于统计的分词算法
本质上是一个序列标注问题。我们将语句中的字，按照他们在词中的位置进行标注。标注主要有：B（词开始的一个字），E（词最后一个字），M（词中间的字，可能多个），S（一个字表示的词）。例如“网商银行是蚂蚁金服微贷事业部的最重要产品”，标注后结果为“BMMESBMMEBMMMESBMEBE”，对应的分词结果为“网商银行/是/蚂蚁金服/微贷事业部/的/最重要/产品”。
这类算法基于机器学习或者现在火热的深度学习，主要有HMM，CRF，SVM，以及深度学习等。
总结 中文分词是中文自然语言处理中的一个重要环节，为后面的词向量编码，词性标注，句法分析以及文本分析打下了坚实的基础。同时，由于中文缺少空格等分隔符，并且汉字间的组合特别多，很容易产生歧义，这些都加大了中文分词的难度。基于词典的字符串匹配算法和基于统计的分词算法，二者各有优缺点，我们可以考虑结合使用。
相关学习连接 http://ssvideo.superlib.com/cxvideo/play/page?sid=1586&amp;vid=28434&amp;d=77edee6d216507e5ece667cef95799ea&amp;cid=236
https://blog.csdn.net/u013510838/article/details/81673016" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/e3334e030c07223c9ac726d2f7950e0f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-08-05T10:23:57+08:00" />
<meta property="article:modified_time" content="2019-08-05T10:23:57+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">中文词性标注学习笔记（二）---分词</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>词性标注（二）</h2> 
<h3><a id="_2"></a>分词</h3> 
<p><strong>词的概念</strong><br> <img alt="词的概念" src="https://images2.imgbox.com/94/d3/eVkgU8CB_o.png"><br> 分词是自然语言处理的基础，分词准确度直接决定了后面的词性标注、句法分析、词向量以及文本分析的质量。英文语句使用空格将单词进行分隔，除了某些特定词，如how many，New York等外，大部分情况下不需要考虑分词问题。但中文不同，天然缺少分隔符，需要读者自行分词和断句。故在做中文自然语言处理时，我们需要先进行分词。</p> 
<h3><a id="_7"></a>中文分词的三个难点</h3> 
<p>中文分词不像英文那样，天然有空格作为分隔。而且中文词语组合繁多，分词很容易产生歧义。因此中文分词一直以来都是NLP的一个重点，也是一个难点。难点主要集中在分词标准，切分歧义和未登录词三部分。<br> <strong>1.分词标准</strong><br> 比如人名，有的算法认为姓和名应该分开，有的认为不应该分开。这需要制定一个相对统一的标准。又例如“花草”，有的人认为是一个词，有的人认为应该划分开为两个词“花/草”。某种意义上，中文分词可以说是一个没有明确定义的问题。<br> <strong>2.切分歧义</strong><br> 1.<em>组合型歧义</em>：分词粒度不同导致的不同切分结果。比如“中华人民共和国”，粗粒度的分词结果为“中华人民共和国”，细粒度的分词结果为“中华/人民/共和国”。这种问题需.用场景来选择。<br> 2.<em>交集型歧义</em>：不同切分结果共用相同的字，前后组合的不同导致不同的切分结果。比如“商务处女干事”，可以划分为“商务处/女干事”，也可以划分为“商务/处女/干事”。这也需要通过整句话来区分。<br> 3.<em>真歧义</em>：本身语法或语义没有问题，即使人工切分也会产生歧义。比如“下雨天留客天天留人不留”，可以划分为“下雨天/留客天/天留/人不留”，也可以划分为“下雨天/留客天/天留人不/留”。此时通过整句话还没法切分，只能通过上下文语境来进行切分。如果是不想留客，则切分为前一个。否则切分为后一个。</p> 
<p><strong>3.未登录词</strong></p> 
<p>也叫新词发现，或者生词，未被词典收录的词。</p> 
<h3><a id="_20"></a>中文分词算法</h3> 
<p>当前的分词算法主要分为两类，基于词典的规则匹配方法，和基于统计的机器学习方法。<br> <strong>基于词典的分词算法</strong><br> 基于词典的分词算法，本质上就是字符串匹配。将待匹配的字符串基于一定的算法策略，和一个足够大的词典进行字符串匹配，如果匹配命中，则可以分词。根据不同的匹配策略，又分为正向最大匹配法，逆向最大匹配法，双向匹配分词，全切分路径选择等。<br> <strong>基于统计的分词算法</strong><br> 本质上是一个序列标注问题。我们将语句中的字，按照他们在词中的位置进行标注。标注主要有：B（词开始的一个字），E（词最后一个字），M（词中间的字，可能多个），S（一个字表示的词）。例如“网商银行是蚂蚁金服微贷事业部的最重要产品”，标注后结果为“BMMESBMMEBMMMESBMEBE”，对应的分词结果为“网商银行/是/蚂蚁金服/微贷事业部/的/最重要/产品”。<br> <em>这类算法基于机器学习或者现在火热的深度学习，主要有HMM，CRF，SVM，以及深度学习等。</em></p> 
<h3><a id="_29"></a>总结</h3> 
<p>中文分词是中文自然语言处理中的一个重要环节，为后面的词向量编码，词性标注，句法分析以及文本分析打下了坚实的基础。同时，由于中文缺少空格等分隔符，并且汉字间的组合特别多，很容易产生歧义，这些都加大了中文分词的难度。基于词典的字符串匹配算法和基于统计的分词算法，二者各有优缺点，我们可以考虑结合使用。</p> 
<h3><a id="_32"></a>相关学习连接</h3> 
<p><a href="http://ssvideo.superlib.com/cxvideo/play/page?sid=1586&amp;vid=28434&amp;d=77edee6d216507e5ece667cef95799ea&amp;cid=236" rel="nofollow">http://ssvideo.superlib.com/cxvideo/play/page?sid=1586&amp;vid=28434&amp;d=77edee6d216507e5ece667cef95799ea&amp;cid=236</a><br> <a href="https://blog.csdn.net/u013510838/article/details/81673016">https://blog.csdn.net/u013510838/article/details/81673016</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ed00ebbe9171870d238396bcfc7f18e2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">云原生微服务框架——Helidon</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/72057f0a0f3862360a4ae39023fd2b90/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">1、SQL注入语句之Mysql（1）Basic info</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>