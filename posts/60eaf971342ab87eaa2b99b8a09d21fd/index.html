<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python变长数组_tensorflow 变长序列存储实例 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python变长数组_tensorflow 变长序列存储实例" />
<meta property="og:description" content="问题
问题是这样的，要把一个数组存到tfrecord中，然后读取
a = np.array([[0, 54, 91, 153, 177,1],
[0, 50, 89, 147, 196],
[0, 38, 79, 157],
[0, 49, 89, 147, 177],
[0, 32, 73, 145]])
图片我都存储了，这个不还是小意思，一顿操作
import tensorflow as tf
import numpy as np
def _int64_feature(value):
if not isinstance(value,list):
value = [value]
return tf.train.Feature(int64_list=tf.train.Int64List(value=value))
# Write an array to TFrecord.
# a is an array which contains lists of variant length.
a = np.array([[0, 54, 91, 153, 177,1]," />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/60eaf971342ab87eaa2b99b8a09d21fd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-29T15:27:12+08:00" />
<meta property="article:modified_time" content="2021-01-29T15:27:12+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python变长数组_tensorflow 变长序列存储实例</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div style="font-size:16px;"> 
 <p>问题</p> 
 <p>问题是这样的，要把一个数组存到tfrecord中，然后读取</p> 
 <p>a = np.array([[0, 54, 91, 153, 177,1],</p> 
 <p>[0, 50, 89, 147, 196],</p> 
 <p>[0, 38, 79, 157],</p> 
 <p>[0, 49, 89, 147, 177],</p> 
 <p>[0, 32, 73, 145]])</p> 
 <p>图片我都存储了，这个不还是小意思，一顿操作</p> 
 <p>import tensorflow as tf</p> 
 <p>import numpy as np</p> 
 <p>def _int64_feature(value):</p> 
 <p>if not isinstance(value,list):</p> 
 <p>value = [value]</p> 
 <p>return tf.train.Feature(int64_list=tf.train.Int64List(value=value))</p> 
 <p># Write an array to TFrecord.</p> 
 <p># a is an array which contains lists of variant length.</p> 
 <p>a = np.array([[0, 54, 91, 153, 177,1],</p> 
 <p>[0, 50, 89, 147, 196],</p> 
 <p>[0, 38, 79, 157],</p> 
 <p>[0, 49, 89, 147, 177],</p> 
 <p>[0, 32, 73, 145]])</p> 
 <p>writer = tf.python_io.TFRecordWriter('file')</p> 
 <p>for i in range(a.shape[0]):</p> 
 <p>feature = {'i' : _int64_feature(i),</p> 
 <p>'data': _int64_feature(a[i])}</p> 
 <p># Create an example protocol buffer</p> 
 <p>example = tf.train.Example(features=tf.train.Features(feature=feature))</p> 
 <p># Serialize to string and write on the file</p> 
 <p>writer.write(example.SerializeToString())</p> 
 <p>writer.close()</p> 
 <p># Use Dataset API to read the TFRecord file.</p> 
 <p>filenames = ["file"]</p> 
 <p>dataset = tf.data.TFRecordDataset(filenames)</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {'i':tf.FixedLenFeature([],tf.int64),</p> 
 <p>'data':tf.FixedLenFeature([],tf.int64)}</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>return parsed_features['i'], parsed_features['data']</p> 
 <p>dataset = dataset.map(_parse_function)</p> 
 <p>dataset = dataset.shuffle(buffer_size=1)</p> 
 <p>dataset = dataset.repeat()</p> 
 <p>dataset = dataset.batch(1)</p> 
 <p>iterator = dataset.make_one_shot_iterator()</p> 
 <p>i, data = iterator.get_next()</p> 
 <p>with tf.Session() as sess:</p> 
 <p>print(sess.run([i, data]))</p> 
 <p>print(sess.run([i, data]))</p> 
 <p>print(sess.run([i, data]))</p> 
 <p>报了奇怪的错误，Name: , Key: data, Index: 0. Number of int64 values != expected. Values size: 6 but output shape: [] 这意思是我数据长度为6，但是读出来的是[]，这到底是哪里错了，我先把读取的代码注释掉，看看tfreocrd有没有写成功，发现写成功了，这就表明是读取的问题，我怀疑是因为每次写入的长度是变化的原因，但是又有觉得不是，因为图片的尺寸都是不同的，我还是可以读取的，百思不得其解的时候我发现存储图片的时候是img.tobytes(),我把一个数组转换成了bytes，而且用的也是bytes存储，是不是tensorflow会把这个bytes当成一个元素，虽然每个图片的size不同，但是tobytes后tensorflow都会当成一个元素，然后读取的时候再根据(height,width,channel)来解析成图片。</p> 
 <p>我来试试不存为int64，而是存为bytes。 又是一顿厉害的操作</p> 
 <p>数据转为bytes</p> 
 <p># -*- coding: utf-8 -*-</p> 
 <p>import tensorflow as tf</p> 
 <p>import numpy as np</p> 
 <p>def _byte_feature(value):</p> 
 <p>return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</p> 
 <p>def _int64_feature(value):</p> 
 <p>if not isinstance(value,list):</p> 
 <p>value = [value]</p> 
 <p>return tf.train.Feature(int64_list=tf.train.Int64List(value=value))</p> 
 <p># Write an array to TFrecord.</p> 
 <p># a is an array which contains lists of variant length.</p> 
 <p>a = np.array([[0, 54, 91, 153, 177,1],</p> 
 <p>[0, 50, 89, 147, 196],</p> 
 <p>[0, 38, 79, 157],</p> 
 <p>[0, 49, 89, 147, 177],</p> 
 <p>[0, 32, 73, 145]])</p> 
 <p>writer = tf.python_io.TFRecordWriter('file')</p> 
 <p>for i in range(a.shape[0]): # i = 0 ~ 4</p> 
 <p>feature = {'len' : _int64_feature(len(a[i])), # 将无意义的i改成len，为了后面还原</p> 
 <p>'data': _byte_feature(np.array(a[i]).tobytes())} # 我也不知道为什么a[i]是list(后面就知道了)，要存bytes需要numpy一下</p> 
 <p># Create an example protocol buffer</p> 
 <p>example = tf.train.Example(features=tf.train.Features(feature=feature))</p> 
 <p># Serialize to string and write on the file</p> 
 <p>writer.write(example.SerializeToString())</p> 
 <p>writer.close()</p> 
 <p>#</p> 
 <p># Use Dataset API to read the TFRecord file.</p> 
 <p>filenames = ["file"]</p> 
 <p>dataset = tf.data.TFRecordDataset(filenames)</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {'len':tf.FixedLenFeature([],tf.int64),</p> 
 <p>'data':tf.FixedLenFeature([],tf.string)} # 改成string</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>return parsed_features['len'], parsed_features['data']</p> 
 <p>dataset = dataset.map(_parse_function)</p> 
 <p>dataset = dataset.shuffle(buffer_size=1)</p> 
 <p>dataset = dataset.repeat()</p> 
 <p>dataset = dataset.batch(1)</p> 
 <p>iterator = dataset.make_one_shot_iterator()</p> 
 <p>i, data = iterator.get_next()</p> 
 <p>with tf.Session() as sess:</p> 
 <p>print(sess.run([i, data]))</p> 
 <p>print(sess.run([i, data]))</p> 
 <p>print(sess.run([i, data]))</p> 
 <p>"""</p> 
 <p>[array([6], dtype=int64), array([b'\x00\x00\x00\x006\x00\x00\x00[\x00\x00\x00\x99\x00\x00\x00\xb1\x00\x00\x00\x01\x00\x00\x00'],</p> 
 <p>dtype=object)]</p> 
 <p>[array([5], dtype=int64), array([b'\x00\x00\x00\x002\x00\x00\x00Y\x00\x00\x00\x93\x00\x00\x00\xc4\x00\x00\x00'],</p> 
 <p>dtype=object)]</p> 
 <p>[array([4], dtype=int64), array([b'\x00\x00\x00\x00&amp;\x00\x00\x00O\x00\x00\x00\x9d\x00\x00\x00'],</p> 
 <p>dtype=object)]</p> 
 <p>"""</p> 
 <p>bytes数据解码</p> 
 <p>如愿的输出来了，但是这个bytes我该如何解码呢</p> 
 <p>方法一，我们自己解析</p> 
 <p>a,b= sess.run([i,data])</p> 
 <p>c = np.frombuffer(b[0],dtype=np.int,count=a[0])</p> 
 <p>方法二使用tensorflow的解析函数</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {'len':tf.FixedLenFeature([],tf.int64),</p> 
 <p>'data':tf.FixedLenFeature([],tf.string)} # 改成string</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>dat = tf.decode_raw(parsed_features['data'],tf.int64) # 用的是这个解析函数，我们使用int64的格式存储的，解析的时候也是转换为int64</p> 
 <p>return parsed_features['len'], dat</p> 
 <p>"""</p> 
 <p>[array([6]), array([[ 0, 54, 91, 153, 177, 1]])]</p> 
 <p>[array([5]), array([[ 0, 50, 89, 147, 196]])]</p> 
 <p>[array([4]), array([[ 0, 38, 79, 157]])]</p> 
 <p>"""</p> 
 <p>可以看到是二维数组，这是因为我们使用的是batch输出，虽然我们的bathc_size=1，但是还是会以二维list的格式输出。我手贱再来修改点东西，</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {'len':tf.FixedLenFeature([1],tf.int64),</p> 
 <p>'data':tf.FixedLenFeature([1],tf.string)}</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>dat = tf.decode_raw(parsed_features['data'],tf.int64)</p> 
 <p>return parsed_features['len'], dat</p> 
 <p>"""</p> 
 <p>[array([[6]]), array([[[ 0, 54, 91, 153, 177, 1]]])]</p> 
 <p>[array([[5]]), array([[[ 0, 50, 89, 147, 196]]])]</p> 
 <p>[array([[4]]), array([[[ 0, 38, 79, 157]]])]</p> 
 <p>"""</p> 
 <p>呦呵，又变成3维的了，让他报个错试试</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {'len':tf.FixedLenFeature([2],tf.int64), # 1 修改为 2</p> 
 <p>'data':tf.FixedLenFeature([1],tf.string)} # 改成string</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>return parsed_features['len'], parsed_features['data']</p> 
 <p>"""</p> 
 <p>InvalidArgumentError: Key: len. Can't parse serialized Example.</p> 
 <p>[[Node: ParseSingleExample/ParseSingleExample = ParseSingleExample[Tdense=[DT_STRING, DT_INT64], dense_keys=["data", "len"], dense_shapes=[[1], [2]], num_sparse=0, sparse_keys=[], sparse_types=[]](arg0, ParseSingleExample/Const, ParseSingleExample/Const_1)]]</p> 
 <p>[[Node: IteratorGetNext_22 = IteratorGetNext[output_shapes=[[?,2], [?,1]], output_types=[DT_INT64, DT_STRING], _device="/job:localhost/replica:0/task:0/device:CPU:0"](OneShotIterator_22)]]</p> 
 <p>"""</p> 
 <p>可以看到dense_keys=["data", "len"], dense_shapes=[[1], [2]],，tf.FixedLenFeature是读取固定长度的数据，我猜测[]的意思就是读取全部数据，[1]就是读取一个数据，每个数据可能包含多个数据，形如[[1，2],[3，3，4],[2]....]，哈哈这都是我瞎猜的，做我女朋友好不好。</p> 
 <p>tensorflow 变长数组存储</p> 
 <p>反正是可以读取了。但是如果是自己定义的变长数组，每次都要自己解析，这样很麻烦(我瞎遍的)，所以tensorflow就定义了变长数组的解析方法tf.VarLenFeature，我们就不需要把边长数组变为bytes再解析了，又是一顿操作</p> 
 <p>import tensorflow as tf</p> 
 <p>import numpy as np</p> 
 <p>def _int64_feature(value):</p> 
 <p>if not isinstance(value,list):</p> 
 <p>value = [value]</p> 
 <p>return tf.train.Feature(int64_list=tf.train.Int64List(value=value))</p> 
 <p># Write an array to TFrecord.</p> 
 <p># a is an array which contains lists of variant length.</p> 
 <p>a = np.array([[0, 54, 91, 153, 177,1],</p> 
 <p>[0, 50, 89, 147, 196],</p> 
 <p>[0, 38, 79, 157],</p> 
 <p>[0, 49, 89, 147, 177],</p> 
 <p>[0, 32, 73, 145]])</p> 
 <p>writer = tf.python_io.TFRecordWriter('file')</p> 
 <p>for i in range(a.shape[0]): # i = 0 ~ 4</p> 
 <p>feature = {'i' : _int64_feature(i),</p> 
 <p>'data': _int64_feature(a[i])}</p> 
 <p># Create an example protocol buffer</p> 
 <p>example = tf.train.Example(features=tf.train.Features(feature=feature))</p> 
 <p># Serialize to string and write on the file</p> 
 <p>writer.write(example.SerializeToString())</p> 
 <p>writer.close()</p> 
 <p># Use Dataset API to read the TFRecord file.</p> 
 <p>filenames = ["file"]</p> 
 <p>dataset = tf.data.TFRecordDataset(filenames)</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {'i':tf.FixedLenFeature([],tf.int64),</p> 
 <p>'data':tf.VarLenFeature(tf.int64)}</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>return parsed_features['i'], tf.sparse_tensor_to_dense(parsed_features['data'])</p> 
 <p>dataset = dataset.map(_parse_function)</p> 
 <p>dataset = dataset.shuffle(buffer_size=1)</p> 
 <p>dataset = dataset.repeat()</p> 
 <p>dataset = dataset.batch(1)</p> 
 <p>iterator = dataset.make_one_shot_iterator()</p> 
 <p>i, data = iterator.get_next()</p> 
 <p>with tf.Session() as sess:</p> 
 <p>print(sess.run([i, data]))</p> 
 <p>print(sess.run([i, data]))</p> 
 <p>print(sess.run([i, data]))</p> 
 <p>"""</p> 
 <p>[array([0], dtype=int64), array([[ 0, 54, 91, 153, 177, 1]], dtype=int64)]</p> 
 <p>[array([1], dtype=int64), array([[ 0, 50, 89, 147, 196]], dtype=int64)]</p> 
 <p>[array([2], dtype=int64), array([[ 0, 38, 79, 157]], dtype=int64)]</p> 
 <p>"""</p> 
 <p>batch输出</p> 
 <p>输出还是数组，哈哈哈。再来一波操作</p> 
 <p>dataset = dataset.batch(2)</p> 
 <p>"""</p> 
 <p>Cannot batch tensors with different shapes in component 1. First element had shape [6] and element 1 had shape [5].</p> 
 <p>"""</p> 
 <p>这是因为一个batch中数据的shape必须是一致的，第一个元素长度为6，第二个元素长度为5，就会报错。办法就是补成一样的长度，在这之前先测试点别的</p> 
 <p>a = np.array([[0, 54, 91, 153, 177,1],</p> 
 <p>[0, 50, 89, 147, 196],</p> 
 <p>[0, 38, 79, 157],</p> 
 <p>[0, 49, 89, 147, 177],</p> 
 <p>[0, 32, 73, 145]])</p> 
 <p>for i in range(a.shape[0]):</p> 
 <p>print(type(a[i]))</p> 
 <p>"""</p> 
 <p>"""</p> 
 <p>可以发现长度不一的array每一个数据是list(一开始我以为是object)。然后补齐</p> 
 <p>a = np.array([[0, 54, 91, 153, 177,1],</p> 
 <p>[0, 50, 89, 147, 196,0],</p> 
 <p>[0, 38, 79, 157,0,0],</p> 
 <p>[0, 49, 89, 147, 177,0],</p> 
 <p>[0, 32, 73, 145,0,0]])</p> 
 <p>for i in range(a.shape[0]):</p> 
 <p>print(type(a[i]))</p> 
 <p>"""</p> 
 <p>"""</p> 
 <p>返回的是numpy。为什么要做这件事呢？</p> 
 <p>def _int64_feature(value):</p> 
 <p>if not isinstance(value,list):</p> 
 <p>value = [value]</p> 
 <p>return tf.train.Feature(int64_list=tf.train.Int64List(value=value))</p> 
 <p>tensorflow要求我们输入的是list或者直接是numpy.ndarry，如果是list中包含numpy.ndarry [numpy.ndarry]就会报错。上面的那个数组时边长的，返回的时list，没有什么错误，我们补齐看看</p> 
 <p>a = np.array([[0, 54, 91, 153, 177,1],</p> 
 <p>[0, 50, 89, 147, 196,0],</p> 
 <p>[0, 38, 79, 157,0,0],</p> 
 <p>[0, 49, 89, 147, 177,0],</p> 
 <p>[0, 32, 73, 145,0,0]])</p> 
 <p>"""</p> 
 <p>TypeError: only size-1 arrays can be converted to Python scalars</p> 
 <p>"""</p> 
 <p>这就是因为返回的不是list，而是numpy.ndarry,而_int64_feature函数中先判断numpy.ndarry不是list，所以转成了[numpy.ndarry]就报错了。可以做些修改，一种方法是将numpy.ndarry转为list</p> 
 <p>for i in range(a.shape[0]): # i = 0 ~ 4</p> 
 <p>feature = {'i' : _int64_feature(i),</p> 
 <p>'data': _int64_feature(a[i].tolist())}</p> 
 <p>这样补齐了我们就可以修改batch的值了</p> 
 <p>dataset = dataset.batch(2)</p> 
 <p>"""</p> 
 <p>[array([0, 2], dtype=int64), array([[ 0, 54, 91, 153, 177, 1],</p> 
 <p>[ 0, 38, 79, 157, 0, 0]], dtype=int64)]</p> 
 <p>[array([1, 3], dtype=int64), array([[ 0, 50, 89, 147, 196, 0],</p> 
 <p>[ 0, 49, 89, 147, 177, 0]], dtype=int64)]</p> 
 <p>[array([4, 0], dtype=int64), array([[ 0, 32, 73, 145, 0, 0],</p> 
 <p>[ 0, 54, 91, 153, 177, 1]], dtype=int64)]</p> 
 <p>"""</p> 
 <p>当然tensorflow不会让我自己补齐，已经提供了补齐函数padded_batch，</p> 
 <p># -*- coding: utf-8 -*-</p> 
 <p>import tensorflow as tf</p> 
 <p>def _int64_feature(value):</p> 
 <p>if not isinstance(value,list):</p> 
 <p>value = [value]</p> 
 <p>return tf.train.Feature(int64_list=tf.train.Int64List(value=value))</p> 
 <p>a = [[0, 54, 91, 153, 177,1],</p> 
 <p>[0, 50, 89, 147, 196],</p> 
 <p>[0, 38, 79, 157],</p> 
 <p>[0, 49, 89, 147, 177],</p> 
 <p>[0, 32, 73, 145]]</p> 
 <p>writer = tf.python_io.TFRecordWriter('file')</p> 
 <p>for v in a: # i = 0 ~ 4</p> 
 <p>feature = {'data': _int64_feature(v)}</p> 
 <p># Create an example protocol buffer</p> 
 <p>example = tf.train.Example(features=tf.train.Features(feature=feature))</p> 
 <p># Serialize to string and write on the file</p> 
 <p>writer.write(example.SerializeToString())</p> 
 <p>writer.close()</p> 
 <p># Use Dataset API to read the TFRecord file.</p> 
 <p>filenames = ["file"]</p> 
 <p>dataset = tf.data.TFRecordDataset(filenames)</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {'data':tf.VarLenFeature(tf.int64)}</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>return tf.sparse_tensor_to_dense( parsed_features['data'])</p> 
 <p>dataset = dataset.map(_parse_function)</p> 
 <p>dataset = dataset.shuffle(buffer_size=1)</p> 
 <p>dataset = dataset.repeat()</p> 
 <p>dataset = dataset.padded_batch(2,padded_shapes=([None]))</p> 
 <p>iterator = dataset.make_one_shot_iterator()</p> 
 <p>data = iterator.get_next()</p> 
 <p>with tf.Session() as sess:</p> 
 <p>print(sess.run([data]))</p> 
 <p>print(sess.run([data]))</p> 
 <p>print(sess.run([data]))</p> 
 <p>"""</p> 
 <p>[array([[ 0, 54, 91, 153, 177, 1],</p> 
 <p>[ 0, 50, 89, 147, 196, 0]])]</p> 
 <p>[array([[ 0, 38, 79, 157, 0],</p> 
 <p>[ 0, 49, 89, 147, 177]])]</p> 
 <p>[array([[ 0, 32, 73, 145, 0, 0],</p> 
 <p>[ 0, 54, 91, 153, 177, 1]])]</p> 
 <p>"""</p> 
 <p>可以看到的确是自动补齐了。</p> 
 <p>图片batch</p> 
 <p>直接来测试一下图片数据</p> 
 <p># -*- coding: utf-8 -*-</p> 
 <p>import tensorflow as tf</p> 
 <p>import matplotlib.pyplot as plt</p> 
 <p>def _byte_feature(value):</p> 
 <p>return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</p> 
 <p>files = tf.gfile.Glob('*.jpeg')</p> 
 <p>writer = tf.python_io.TFRecordWriter('file')</p> 
 <p>for file in files:</p> 
 <p>with tf.gfile.FastGFile(file,'rb') as f:</p> 
 <p>img_buff = f.read()</p> 
 <p>feature = {'img': _byte_feature(tf.compat.as_bytes(img_buff))}</p> 
 <p>example = tf.train.Example(features=tf.train.Features(feature=feature))</p> 
 <p>writer.write(example.SerializeToString())</p> 
 <p>writer.close()</p> 
 <p>filenames = ["file"]</p> 
 <p>dataset = tf.data.TFRecordDataset(filenames)</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {'img':tf.FixedLenFeature([], tf.string)}</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>image = tf.image.decode_jpeg(parsed_features['img'])</p> 
 <p>return image</p> 
 <p>dataset = dataset.map(_parse_function)</p> 
 <p>dataset = dataset.shuffle(buffer_size=1)</p> 
 <p>dataset = dataset.repeat()</p> 
 <p>dataset = dataset.batch(2)</p> 
 <p>iterator = dataset.make_one_shot_iterator()</p> 
 <p>image = iterator.get_next()</p> 
 <p>with tf.Session() as sess:</p> 
 <p>img = sess.run([image])</p> 
 <p>print(len(img))</p> 
 <p>print(img[0].shape)</p> 
 <p>plt.imshow(img[0][0])</p> 
 <p>"""</p> 
 <p>Cannot batch tensors with different shapes in component 0. First element had shape [440,440,3] and element 1 had shape [415,438,3].</p> 
 <p>"""</p> 
 <p>看到了没有，一个batch中图片的尺寸不同，就不可以batch了，我们必须要将一个batch的图片resize成相同的代大小。</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {'img':tf.FixedLenFeature([], tf.string)}</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>image = tf.image.decode_jpeg(parsed_features['img'])</p> 
 <p>image = tf.image.convert_image_dtype(image,tf.float32)# 直接resize，会将uint8转为float类型，但是plt.imshow只能显示uint8或者0-1之间float类型，这个函数就是将uint8转为0-1之间的float类型，相当于除以255.0</p> 
 <p>image = tf.image.resize_images(image,(224,224))</p> 
 <p>return image</p> 
 <p>但是有时候我们希望输入图片尺寸是不一样的，不需要reize，这样只能将batch_size=1。一个batch中的图片shape必须是一样的，我们可以这样折中训练，使用tensorflow提供的动态填充接口，将一个batch中的图片填充为相同的shape。</p> 
 <p>dataset = dataset.padded_batch(2,padded_shapes=([None,None,3]))</p> 
 <p>如果我们想要将图片的名称作为标签保存下来要怎么做呢？</p> 
 <p># -*- coding: utf-8 -*-</p> 
 <p>import tensorflow as tf</p> 
 <p>import matplotlib.pyplot as plt</p> 
 <p>import os</p> 
 <p>out_charset="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789"</p> 
 <p>def _byte_feature(value):</p> 
 <p>return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</p> 
 <p>def _int64_feature(values):</p> 
 <p>if not isinstance(values,list):</p> 
 <p>values = [values]</p> 
 <p>return tf.train.Feature(int64_list=tf.train.Int64List(value=values))</p> 
 <p>files = tf.gfile.Glob('*.jpg')</p> 
 <p>writer = tf.python_io.TFRecordWriter('file')</p> 
 <p>for file in files:</p> 
 <p>with tf.gfile.FastGFile(file,'rb') as f:</p> 
 <p>img_buff = f.read()</p> 
 <p>filename = os.path.basename(file).split('.')[0]</p> 
 <p>label = list(map(lambda x:out_charset.index(x),filename))</p> 
 <p>feature = {'label':_int64_feature(label),</p> 
 <p>'filename':_byte_feature(tf.compat.as_bytes(filename)),</p> 
 <p>'img': _byte_feature(tf.compat.as_bytes(img_buff))}</p> 
 <p>example = tf.train.Example(features=tf.train.Features(feature=feature))</p> 
 <p>writer.write(example.SerializeToString())</p> 
 <p>writer.close()</p> 
 <p>filenames = ["file"]</p> 
 <p>dataset = tf.data.TFRecordDataset(filenames)</p> 
 <p>def _parse_function(example_proto):</p> 
 <p>keys_to_features = {<!-- --></p> 
 <p>'label':tf.VarLenFeature(tf.int64),</p> 
 <p>'filename':tf.FixedLenFeature([],tf.string),</p> 
 <p>'img':tf.FixedLenFeature([], tf.string)}</p> 
 <p>parsed_features = tf.parse_single_example(example_proto, keys_to_features)</p> 
 <p>label = tf.sparse_tensor_to_dense(parsed_features['label'])</p> 
 <p>filename = parsed_features['filename']</p> 
 <p>image = tf.image.decode_jpeg(parsed_features['img'])</p> 
 <p>return image,label,filename</p> 
 <p>dataset = dataset.map(_parse_function)</p> 
 <p>dataset = dataset.shuffle(buffer_size=1)</p> 
 <p>dataset = dataset.repeat()</p> 
 <p>dataset = dataset.padded_batch(3,padded_shapes=([None,None,3],[None],[]))</p> 
 <p>#因为返回有三个，所以每一个都要有padded_shapes,但是解码后的image和label都是变长的</p> 
 <p>#所以需要pad None,而filename没有解码，返回来是byte类型的，只有一个值，所以不需要pad</p> 
 <p>iterator = dataset.make_one_shot_iterator()</p> 
 <p>image,label,filename = iterator.get_next()</p> 
 <p>with tf.Session() as sess:</p> 
 <p>print(label.eval())</p> 
 <p>瞎试</p> 
 <p>如果写入的数据是一个list会是怎样呢</p> 
 <p>a = np.arange(16).reshape(2,4,2)</p> 
 <p>"""</p> 
 <p>TypeError: [0, 1] has type list, but expected one of: int, long</p> 
 <p>"""</p> 
 <p>不过想想也是，tf.train.Feature(int64_list=tf.train.Int64List(value=value))这个函数就是存储数据类型为int64的list的。但是如果我们要存储词向量该怎么办呢？例如一句话是一个样本s1='我爱你',假如使用one-hot编码，我=[0,0,1],爱=[0,1,0],你=[1,0,0],s1=[[0,0,1],[0,1,0],[1,0,0]]。这一个样本该怎么存储呢？</p> 
 <p>以上这篇tensorflow 变长序列存储实例就是小编分享给大家的全部内容了，希望能给大家一个参考，也希望大家多多支持脚本之家。</p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b1d8bf66d63cf1e1062ef910dda14188/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Swagger2集成SpringBoot,Swagger-ui页面怎么把Object的返回值类型（实际是泛型类）对应的属性展示到Example Value 区中？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1bcb08725a9fb4f6e64d992bed906c23/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue 中 event.stopPropagation() 和event.preventDefault() 使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>