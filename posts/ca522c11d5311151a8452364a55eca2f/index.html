<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【论文阅读】Swin-transformer网络结构详解 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【论文阅读】Swin-transformer网络结构详解" />
<meta property="og:description" content="引言 之前的Transformer主要应用在NLP领域，从ViT开始在应用在视觉领域后，也逐渐出现更多Transformer在视觉领域的研究工作，今天介绍的Swin-transformer可以作为计算机视觉上的一种通用backbone。
优点 提出了一种层级式网络结构，解决视觉图像的多尺度问题。
提出了Shifted Windows，极大降低了transformer的计算复杂度。
可以广泛应用到所有计算机视觉领域(包括分类任务、分割任务、目标检测任务等)
解决的问题 和NLP领域不同，视觉领域同类的物体，在不同图像上/同意图像上的尺度会相差很大。
相较于文本，图像的尺寸过大，计算复杂度更高。
创新处 使用任意尺度的输入，计算复杂度和图像大小是线性关系而非平方级增长。
在小窗口内计算自注意力，特征图大小递减。好处是当窗口大小固定时，自注意力的复杂度就固定，复杂度和尺度呈线性关系，利用了图像的局部性的先验知识。
局部性指的是同一个物体不同部位或者语义相近的不同物体，大概率会出现在相邻的地方，所以对视觉任务来说，在小窗口内计算自注意力是合理的，在全局计算会造成计算的浪费。
和ViT区别 整体架构 网络架构 下图是Swin-transformer的网络架构：
整体架构分为多个stage，输入图片大小为H*W*3；(默认为224*224*3)
经过patch partition操作将输入图片打成多个patch；patch size=4*4，则操作后得到的图片大小为56*56*48；
stage1：包括一个Linear Embedding操作和2个swi-transformer block，C代表一个超参数，即Transformer可以接受的值，对于Swin-Tiny 网络来说，C默认为96，此时维度变成56*56*96；(transformer block块不改变图片大小)
这里的patch partition操作和Linear Embedding操作相当于ViT的Linear Projection操作，而在代码中，利用一次卷积操作即可完成。
stage2：包括Patch Merging和2个block，Patch Merging相当于pixel shuffle的逆操作；具体如下图所示，此时维度为28*28*192；对于Patch Merging操作整体来说，空间维度减半，通道数量×2，这样和卷积神经网络完全对等；
stage3：重复stage2，维度为14*14*384；
stage4：重复stage2，维度为7*7*768.
上述架构图中b图是两个连续的Swin Transformer Block。一个Swin Transformer Block由一个带两层MLP的shifted window based MSA组成。在每个MSA模块和每个MLP之前使用LayerNorm(LN)层，并在每个MSA和MLP之后使用残差连接。两层属于一个组合使用，所以stage中的block块是双数。
滑动窗口(shifted Windows) 论文中一个主要亮点是提出了滑动窗口的概念。
同时给出普通MSA和基于窗口的W-MSA(计算复杂度)的比较：
W-MSA虽然降低了计算复杂度，但是不重合的window之间缺乏信息交流，于是进一步引入shifted window partition：一种基于掩码的方式来解决不同window的信息交流问题，该方法在连续的Swin Transformer块中的两个Swin Transformer Block之间交替进行。
移动窗口达到了窗口与窗口之间的通信，但窗口数量增多（从原来的4个到之后的9个）且增多后各个窗口元素大小不同，而基于掩码的方式可以很好的解决这一问题。经过循环移位后在切分四宫格，则得到的还是4个窗口，再各个窗口做基于掩码的Mutil-Self Attention，最后操作是还原循环移位。
关于掩码的操作：
实验结果 分类实验 目标检测实验 语义分割实验 在多个任务中均可以达到很好的效果，也证明了Transformer完全可以在多个领域取代CNN。
论文地址及代码 论文：Swin Transformer: Hierarchical Vision Transformer using Shifted Windows" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/ca522c11d5311151a8452364a55eca2f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-20T10:39:43+08:00" />
<meta property="article:modified_time" content="2023-11-20T10:39:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【论文阅读】Swin-transformer网络结构详解</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div> 
 <h2>引言</h2> 
 <p><span style="color:#080f17;">之前的Transformer主要应用在NLP领域，从ViT开始在应用在视觉领域后，也逐渐出现更多Transformer在视觉领域的研究工作，今天介绍的Swin-transformer可以作为计算机视觉上的一种通用backbone。</span></p> 
 <h4>优点</h4> 
 <ul><li style="margin-left:1.4em;"> <p>提出了一种层级式网络结构，解决视觉图像的多尺度问题。</p> </li></ul> 
 <ul><li style="margin-left:1.4em;"> <p>提出了Shifted Windows，极大降低了transformer的计算复杂度。</p> </li></ul> 
 <ul><li style="margin-left:1.4em;"> <p>可以广泛应用到所有计算机视觉领域(包括分类任务、分割任务、目标检测任务等)</p> </li></ul> 
 <h4>解决的问题</h4> 
 <ul><li style="margin-left:1.4em;"> <p>和NLP领域不同，视觉领域同类的物体，在不同图像上/同意图像上的尺度会相差很大。</p> </li></ul> 
 <ul><li style="margin-left:1.4em;"> <p>相较于文本，图像的尺寸过大，计算复杂度更高。</p> </li></ul> 
 <h4>创新处</h4> 
 <ul><li style="margin-left:1.4em;"> <p>使用任意尺度的输入，计算复杂度和图像大小是线性关系而非平方级增长。</p> </li></ul> 
 <ul><li style="margin-left:1.4em;"> <p>在小窗口内计算自注意力，特征图大小递减。好处是当窗口大小固定时，自注意力的复杂度就固定，复杂度和尺度呈线性关系，利用了图像的局部性的先验知识。</p> </li></ul> 
 <ul><li style="margin-left:1.4em;"> <p>局部性指的是同一个物体不同部位或者语义相近的不同物体，大概率会出现在相邻的地方，所以对视觉任务来说，在小窗口内计算自注意力是合理的，在全局计算会造成计算的浪费。</p> </li></ul> 
 <h4>和ViT区别</h4> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/3b/3e/QeiAirnG_o.jpg" width="1066"> 
   </div> 
  </div> 
 </div> 
 <p></p> 
 <h2>整体架构</h2> 
 <h4>网络架构</h4> 
 <p>下图是Swin-transformer的网络架构：</p> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/79/4c/m0JAv9Gq_o.jpg" width="1066"> 
   </div> 
  </div> 
 </div> 
 <p>整体架构分为多个stage，输入图片大小为H*W*3；(默认为224*224*3)</p> 
 <ul><li style="margin-left:1.4em;"> <p>经过patch partition操作将输入图片打成多个patch；patch size=4*4，则操作后得到的图片大小为56*56*48；</p> </li></ul> 
 <ul><li style="margin-left:1.4em;"> <p><strong>stage1：</strong>包括一个Linear Embedding操作和2个swi-transformer block，C代表一个超参数，即Transformer可以接受的值，对于Swin-Tiny 网络来说，C默认为96，此时维度变成56*56*96；(transformer block块不改变图片大小)</p> </li></ul> 
 <p>这里的patch partition操作和Linear Embedding操作相当于ViT的Linear Projection操作，而在代码中，利用一次卷积操作即可完成。</p> 
 <ul><li style="margin-left:1.4em;"> <p><strong>stage2：</strong>包括Patch Merging和2个block，Patch Merging相当于pixel shuffle的逆操作；具体如下图所示，此时维度为28*28*192；对于Patch Merging操作整体来说，空间维度减半，通道数量×2，这样和卷积神经网络完全对等；</p> </li></ul> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/21/f2/SOP6q0iV_o.jpg" style="margin-left:21.869781%;" width="337"> 
   </div> 
  </div> 
 </div> 
 <ul><li style="margin-left:1.4em;"> <p><strong>stage3：</strong>重复stage2，维度为14*14*384；</p> </li></ul> 
 <ul><li style="margin-left:1.4em;"> <p><strong>stage4：</strong>重复stage2，维度为7*7*768.</p> </li></ul> 
 <p>上述架构图中b图是两个连续的Swin Transformer Block。一个Swin Transformer Block由一个带两层MLP的shifted window based MSA组成。在每个MSA模块和每个MLP之前使用LayerNorm(LN)层，并在每个MSA和MLP之后使用残差连接。两层属于一个组合使用，所以stage中的block块是双数。</p> 
 <h4>滑动窗口(shifted Windows)</h4> 
 <p>论文中一个主要亮点是提出了滑动窗口的概念。</p> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/ad/ce/jdErHQAD_o.png" width="755"> 
   </div> 
  </div> 
 </div> 
 <p>同时给出普通MSA和基于窗口的W-MSA(计算复杂度)的比较：</p> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/05/0b/bLtTxM24_o.png" width="984"> 
   </div> 
  </div> 
 </div> 
 <p>W-MSA虽然降低了计算复杂度，但是不重合的window之间缺乏信息交流，于是进一步引入shifted window partition：一种基于掩码的方式来解决不同window的信息交流问题，该方法在连续的Swin Transformer块中的两个Swin Transformer Block之间交替进行。</p> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/36/60/nkmcKItn_o.png" width="906"> 
   </div> 
  </div> 
 </div> 
 <p>移动窗口达到了窗口与窗口之间的通信，但窗口数量增多（从原来的4个到之后的9个）且增多后各个窗口元素大小不同，而基于掩码的方式可以很好的解决这一问题。经过循环移位后在切分四宫格，则得到的还是4个窗口，再各个窗口做基于掩码的Mutil-Self Attention，最后操作是还原循环移位。</p> 
 <p><strong>关于掩码的操作：</strong></p> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/5f/7f/hxHGiN8d_o.jpg" width="1066"> 
   </div> 
  </div> 
 </div> 
 <p></p> 
 <h2>实验结果</h2> 
 <h4>分类实验</h4> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/71/7d/I1mj27so_o.png" width="488"> 
   </div> 
  </div> 
 </div> 
 <h4>目标检测实验</h4> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/bf/42/tWOTXtMW_o.png" width="379"> 
   </div> 
  </div> 
 </div> 
 <h4>语义分割实验</h4> 
 <div> 
  <div> 
   <div> 
    <img alt="" src="https://images2.imgbox.com/13/d8/xx4iLqLg_o.png" width="673"> 
   </div> 
  </div> 
 </div> 
 <p>在多个任务中均可以达到很好的效果，也证明了Transformer完全可以在多个领域取代CNN。</p> 
 <h4>论文地址及代码</h4> 
 <p>论文：<a class="kdocs-link" href="https://arxiv.org/pdf/2103.14030v1.pdf" rel="nofollow" title="Swin Transformer: Hierarchical Vision Transformer using Shifted Windows">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a></p> 
 <p>代码：<a class="kdocs-link" href="https://github.com/microsoft/Swin-Transformer" title="Swin-Transformer ">Swin-Transformer </a></p> 
 <p></p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8cd3d5e2766d108da89f7f43c54c5ff9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">深度学习系列54：使用 MMDETECTION 和 LABEL-STUDIO 进行半自动化目标检测标注</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/77a89663f62531adb04b2132ca992a84/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">报错：Error creating bean with name ‘Controller‘，Unsatisfied dependency expressed through field ‘Servic</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>