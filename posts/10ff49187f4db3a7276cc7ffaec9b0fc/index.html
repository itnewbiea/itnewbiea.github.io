<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>详细及易读懂的  大津法（OTSU）原理 和 比opencv自带更快的算法实现 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="详细及易读懂的  大津法（OTSU）原理 和 比opencv自带更快的算法实现" />
<meta property="og:description" content="OTSU算法原理简述：
最大类间方差是由日本学者大津(Nobuyuki Otsu)于1979年提出，是一种自适应的阈值确定方法。算法假设图像像素能够根据阈值，被分成背景[background]和目标[objects]两部分。然后，计算该最佳阈值来区分这两类像素，使得两类像素区分度最大。
公式： 记 M = 256 单通道灰度分级 Sum = 像素总数
背景像素占比 前景像素占比背景的平均灰度值前景的平均灰度值0~M灰度区间的灰度累计值类间方差：将公式3.4.5带入公式6 可得最终简化公式： 3、4的意思：每个灰度（0~255）比例 * 当前灰度的和。
代码：
#include &lt;opencv2\opencv.hpp&gt; #include &lt;iostream&gt; #include &lt;time.h&gt; using namespace std; using namespace cv; int myOtsu(Mat &amp; src, Mat &amp;dst) { int th = 0; const int GrayScale = 256;	//单通道图像总灰度256级 int pixCount[GrayScale] = { 0 };//每个灰度值所占像素个数 int pixSum = src.cols * src.rows;//图像总像素点 float pixPro[GrayScale] = { 0 };//每个灰度值所占总像素比例 float SumpixPro[GrayScale] = { 0 }; // 比例的和 float WpixPro[GrayScale] = { 0 }; //比例 * 权重 float SumWpixPro[GrayScale] = { 0 };//比例 * 权重 的 和 float w0, w1, u0tmp, u1tmp, u0, u1, deltaTmp, deltaMax = 0; double start = getTickCount(); //开始时间 for (int i = 0; i &lt; src." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/10ff49187f4db3a7276cc7ffaec9b0fc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-07-20T16:38:21+08:00" />
<meta property="article:modified_time" content="2018-07-20T16:38:21+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">详细及易读懂的  大津法（OTSU）原理 和 比opencv自带更快的算法实现</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>OTSU算法原理简述：</p> 
<p>最大类间方差是由日本学者<span style="color:#f33b45;">大津</span>(Nobuyuki Otsu)于1979年提出，是一种自适应的阈值确定方法。算法假设图像像素能够根据阈值，被分成<u>背景</u>[background]和<u>目标</u>[objects]两部分。然后，计算该<span style="color:#f33b45;">最佳阈值</span>来区分这两类像素，使得两类像素区分度最大。</p> 
<p>公式：  记 M = 256 单通道灰度分级 Sum = 像素总数</p> 
<ol><li>背景像素占比 <img alt="\omega1 = \frac{N1}{Sum}" class="mathcode" src="https://images2.imgbox.com/a8/06/gvuUNpu2_o.gif">  </li><li>前景像素占比<img alt="\omega2 = 1- \omega1 = \frac{N2}{Sum} =1- \frac{N1}{Sum}" class="mathcode" src="https://images2.imgbox.com/bd/d7/8k3CAJYf_o.gif"></li><li>背景的平均灰度值<img alt="\mu 1 = \sum_{i = 0}^{t} i *Pr(i | C_{0}) = \sum_{i = 0}^{t} i *Pi / \sum_{i = 0}^{t} Pi = \frac{\mu(t))}{\omega_{1}}" class="mathcode" src="https://images2.imgbox.com/2b/44/hVLMG9D0_o.gif"></li><li>前景的平均灰度值<img alt="\mu 2 = \sum_{i = t+1}^{M - 1} i *Pr(i | C_{1}) = \sum_{i = t+1}^{M - 1} i *Pi / \sum_{i = t+1}^{M - 1} Pi = \frac{\mu - \mu(t))}{\omega _{2}}" class="mathcode" src="https://images2.imgbox.com/d1/06/dwRcjmbg_o.gif"></li><li>0~M灰度区间的灰度累计值<img alt="\mu = \mu1*\omega 1 + \mu2*\omega 2" class="mathcode" src="https://images2.imgbox.com/40/2b/MNJykPSm_o.gif"></li><li>类间方差：<img alt="g = \omega 1 * (\mu - \mu1)^{2} + \omega 2 * (\mu - \mu2)^{2}" class="mathcode" src="https://images2.imgbox.com/d4/ca/LTG9ihiL_o.gif"></li><li>将公式3.4.5带入公式6 可得最终简化公式： <img alt="g = \omega 1 * \omega2 * (\mu1 - \mu2)^{2}" class="mathcode" src="https://images2.imgbox.com/1c/b1/r7P1L22s_o.gif"></li></ol> 
<p> 3、4的意思：每个灰度（0~255）比例 * 当前灰度的和。</p> 
<p>代码：</p> 
<pre class="has"><code class="language-cpp">#include &lt;opencv2\opencv.hpp&gt;
#include &lt;iostream&gt;
#include &lt;time.h&gt;
using namespace std;
using namespace cv;

int myOtsu(Mat &amp; src, Mat &amp;dst)
{
	
	int th = 0;
	const int GrayScale = 256;	//单通道图像总灰度256级
	int pixCount[GrayScale] = { 0 };//每个灰度值所占像素个数
	int pixSum = src.cols * src.rows;//图像总像素点
	float pixPro[GrayScale] = { 0 };//每个灰度值所占总像素比例
	float SumpixPro[GrayScale] = { 0 }; // 比例的和
	float WpixPro[GrayScale] = { 0 }; //比例 * 权重
	float SumWpixPro[GrayScale] = { 0 };//比例 * 权重 的 和
	float w0, w1, u0tmp, u1tmp, u0, u1, deltaTmp, deltaMax = 0;
	double start = getTickCount(); //开始时间
	for (int i = 0; i &lt; src.rows; i++)
	{
		for (int j = 0; j &lt; src.cols; j++)
		{
			int index = i * src.cols + j;
			pixCount[src.data[index]]++;//统计每个灰度级中像素的个数  
		}
	}
	double c1 = getTickCount(); 
	//cout &lt;&lt; "c1 &gt;&gt; " &lt;&lt; (c1 - start) / getTickFrequency() &lt;&lt; endl;//输出时间
	for (int i = 0; i &lt; GrayScale; i++)
	{
		pixPro[i] = pixCount[i] * 1.0 / pixSum;//计算每个灰度级的像素数目占整幅图像的比例  
		WpixPro[i] = i * pixPro[i];
		if (i == 0)
		{
			SumWpixPro[i] += WpixPro[i];
			SumpixPro[i] += pixPro[i];
		}
		else
		{
			SumWpixPro[i] = WpixPro[i] + SumWpixPro[i - 1];
			SumpixPro[i] = pixPro[i] + SumpixPro[i - 1];
		}
	}

	for (int i = 0; i &lt; GrayScale; i++)//遍历所有从0到255灰度级的阈值分割条件，测试哪一个的类间方差最大
	{
		w0 = w1 = u0tmp = u1tmp = u0 = u1 = deltaTmp = 0;
		/*for (int j = 0; j &lt; GrayScale; j++)
		{
			if (j &lt;= i)//背景
			{
				w0 += pixPro[j];
				u0tmp += WpixPro[j];
			}
			else//前景
			{
				w1 += pixPro[j];
				u1tmp += WpixPro[j];
			}
		}*/
		w0 = SumpixPro[i];
		w1 = 1 - w0;
		
		if (w0 == 0 || w1 == 0)
			continue;
		u0tmp = SumWpixPro[i];
		u1tmp = SumWpixPro[255] - SumWpixPro[i];
		
		u0 = u0tmp / w0;
		u1 = u1tmp / w1;
		deltaTmp = (float)(w0 *w1* pow((u0 - u1), 2)); //类间方差公式 g = w1 * w2 * (u1 - u2) ^ 2
		if (deltaTmp &gt; deltaMax)
		{
			deltaMax = deltaTmp;
			th = i;
		}
	}
	double c2 = getTickCount();
	//cout &lt;&lt; "c2 &gt;&gt; " &lt;&lt; (c2 - c1) / getTickFrequency() &lt;&lt; endl;//输出时间
	for (int i = 0; i &lt; src.rows; i++)
	{
		for (int j = 0; j &lt; src.cols; j++)
		{
			int index = i * src.cols + j;
			if (src.data[index] &gt; th)
				dst.data[index] = 255;
			else
				dst.data[index] = 0;
		}
	}
	double c3 = getTickCount();
	//cout &lt;&lt; "c3 &gt;&gt; " &lt;&lt; (c3 - c2) / getTickFrequency() &lt;&lt; endl;//输出时间
	return th;
}

int main()
{
	Mat src = imread("scene.jpg", IMREAD_GRAYSCALE);//单通道读取图像
												   /*my_dst: 自己实现的大津法 得到的处理图像
												   otsu_dst：opencv自带的大津法 得到的处理图像
												   sub：两个处理图像相差图
												   */
	Mat my_dst, otsu_dst, sub;
	/*my_th: 自己实现的大津法 得到的最大类件方差 即阈值
	th：opencv自带的大津法 得到的最大类件方差 即阈值
	*/
	int my_th, th;

	/*计算开销时间，对比两个算法效率*/
	int times = 100;
	
	double start = getTickCount(); //开始时间
	my_dst = Mat::zeros(src.size(), CV_8UC1);
	while(times--)
	{
		
		my_th = myOtsu(src, my_dst);
	}
	double end = getTickCount();   //结束时间
	cout &lt;&lt; "myOtsu end algorithm &gt;&gt; " &lt;&lt; (end - start) / getTickFrequency() &lt;&lt; endl; //输出时间
	cout &lt;&lt; "myOtsu threshold &gt;&gt; " &lt;&lt; my_th &lt;&lt; endl;

	start = getTickCount(); //开始时间
	times = 100;
	while(times--)
	{
		th = threshold(src, otsu_dst, 0, 255, THRESH_OTSU);
	}
	end = getTickCount();   //结束时间
	cout &lt;&lt; "Otsu end algorithm &gt;&gt; " &lt;&lt; (end - start) / getTickFrequency() &lt;&lt; endl;//输出时间
	cout &lt;&lt; "Otsu threshold &gt;&gt; " &lt;&lt; th &lt;&lt; endl;


	waitKey();
	system("pause");
	return 0;
}</code></pre> 
<p>原图：用的是1920*1080的图像，循环100次得到测试结果和图像。</p> 
<p><img alt="" height="107" src="https://images2.imgbox.com/ee/8a/CqyBojMM_o.png" width="295"></p> 
<p>结论：可以看到自己实现的otsu和opencv自带的自适应阈值算法效率上相差大约3倍左右。</p> 
<p>分析：遍历图片没有加速，opencv内部有加速。</p> 
<p>分析时间慢的原因：第一次遍历整张图片，统计每个灰度级像素个数，第二次遍历整张图片进行阈值操作。</p> 
<p>似曾相识第一次遍历不就是灰度直方图吗，然后第二次遍历不就是LUT图像压缩。</p> 
<p>改进后源码：</p> 
<pre><code class="language-cpp">#if 1
#include &lt;opencv2\opencv.hpp&gt;
#include &lt;iostream&gt;
#include &lt;time.h&gt;
using namespace std;
using namespace cv;

void getHistogram(Mat &amp;src, int *dst)
{
	Mat hist;
	int channels[1] = { 0 };
	int histSize[1] = { 256 };
	float hranges[2] = { 0, 256.0 };
	const float *ranges[1] = { hranges };
	calcHist(&amp;src, 1, channels, Mat(), hist, 1, histSize, ranges);
	//cout &lt;&lt; hist ;
	for (int i = 0; i &lt; 256; i++)
	{ 
		float binVal = hist.at&lt;float&gt;(i);
		dst[i] = int(binVal);
	}
}


int myOtsu(Mat &amp; src, Mat &amp;dst)
{
	
	int th = 0;
	const int GrayScale = 256;	//单通道图像总灰度256级
	int pixCount[GrayScale] = { 0 };//每个灰度值所占像素个数
	int pixSum = src.cols * src.rows;//图像总像素点
	float pixPro[GrayScale] = { 0 };//每个灰度值所占总像素比例
	float SumpixPro[GrayScale] = { 0 }; // 比例的和
	float WpixPro[GrayScale] = { 0 }; //比例 * 权重
	float SumWpixPro[GrayScale] = { 0 };//比例 * 权重 的 和
	float w0, w1, u0tmp, u1tmp, u0, u1, deltaTmp, deltaMax = 0;
	double start = getTickCount(); //开始时间
	
	/*for (int i = 0; i &lt; src.rows; i++)
	{
		for (int j = 0; j &lt; src.cols; j++)
		{
			int index = i * src.cols + j;
			pixCount[src.data[index]]++;//统计每个灰度级中像素的个数  
		}
	}*/
	getHistogram(src, pixCount);

	double c1 = getTickCount(); 
	//cout &lt;&lt; "c1 &gt;&gt; " &lt;&lt; (c1 - start) / getTickFrequency() &lt;&lt; endl;//输出时间
	for (int i = 0; i &lt; GrayScale; i++)
	{
		pixPro[i] = pixCount[i] * 1.0 / pixSum;//计算每个灰度级的像素数目占整幅图像的比例  
		WpixPro[i] = i * pixPro[i];
		if (i == 0)
		{
			SumWpixPro[i] += WpixPro[i];
			SumpixPro[i] += pixPro[i];
		}
		else
		{
			SumWpixPro[i] = WpixPro[i] + SumWpixPro[i - 1];
			SumpixPro[i] = pixPro[i] + SumpixPro[i - 1];
		}
	}

	for (int i = 0; i &lt; GrayScale; i++)//遍历所有从0到255灰度级的阈值分割条件，测试哪一个的类间方差最大
	{
		w0 = w1 = u0tmp = u1tmp = u0 = u1 = deltaTmp = 0;
		/*for (int j = 0; j &lt; GrayScale; j++)
		{
			if (j &lt;= i)//背景
			{
				w0 += pixPro[j];
				u0tmp += WpixPro[j];
			}
			else//前景
			{
				w1 += pixPro[j];
				u1tmp += WpixPro[j];
			}
		}*/
		w0 = SumpixPro[i];
		w1 = 1 - w0;
		
		if (w0 == 0 || w1 == 0)
			continue;
		u0tmp = SumWpixPro[i];
		u1tmp = SumWpixPro[255] - SumWpixPro[i];
		
		u0 = u0tmp / w0;
		u1 = u1tmp / w1;
		deltaTmp = (float)(w0 *w1* pow((u0 - u1), 2)); //类间方差公式 g = w1 * w2 * (u1 - u2) ^ 2
		if (deltaTmp &gt; deltaMax)
		{
			deltaMax = deltaTmp;
			th = i;
		}
	}
	double c2 = getTickCount();
	//cout &lt;&lt; "c2 &gt;&gt; " &lt;&lt; (c2 - c1) / getTickFrequency() &lt;&lt; endl;//输出时间
	uchar lutData[256];
	for (int i = 0; i &lt; 256; i++)
	{ 
		if (i &gt; th)
			lutData[i] = 255;
		else
			lutData[i] = 0;
	}
	Mat lut(1, 256, CV_8UC1, lutData);
	LUT(src, lut, dst);
	/*for (int i = 0; i &lt; src.rows; i++)
	{
		for (int j = 0; j &lt; src.cols; j++)
		{
			int index = i * src.cols + j;
			if (src.data[index] &gt; th)
				dst.data[index] = 255;
			else
				dst.data[index] = 0;
		}
	}*/
	double c3 = getTickCount();
	//cout &lt;&lt; "c3 &gt;&gt; " &lt;&lt; (c3 - c2) / getTickFrequency() &lt;&lt; endl;//输出时间
	return th;
}

int main()
{
	Mat src = imread("scene.jpg", IMREAD_GRAYSCALE);//单通道读取图像
												   /*my_dst: 自己实现的大津法 得到的处理图像
												   otsu_dst：opencv自带的大津法 得到的处理图像
												   sub：两个处理图像相差图
												   */
	//Mat src = Mat(Size(3000, 3000), CV_8UC1, Scalar(127));
	Mat my_dst, otsu_dst, sub;
	/*my_th: 自己实现的大津法 得到的最大类件方差 即阈值
	th：opencv自带的大津法 得到的最大类件方差 即阈值
	*/
	int my_th, th;

	/*计算开销时间，对比两个算法效率*/
	int times = 100;
	
	double start = getTickCount(); //开始时间
	my_dst = Mat::zeros(src.size(), CV_8UC1);
	while(times--)
	{
		
		my_th = myOtsu(src, my_dst);
	}
	double end = getTickCount();   //结束时间
	cout &lt;&lt; "myOtsu end algorithm &gt;&gt; " &lt;&lt; (end - start) / getTickFrequency() &lt;&lt; endl; //输出时间
	cout &lt;&lt; "myOtsu threshold &gt;&gt; " &lt;&lt; my_th &lt;&lt; endl;

	start = getTickCount(); //开始时间
	times = 100;
	while(times--)
	{
		th = threshold(src, otsu_dst, 0, 255, THRESH_OTSU);
	}
	end = getTickCount();   //结束时间
	cout &lt;&lt; "Otsu end algorithm &gt;&gt; " &lt;&lt; (end - start) / getTickFrequency() &lt;&lt; endl;//输出时间
	cout &lt;&lt; "Otsu threshold &gt;&gt; " &lt;&lt; th &lt;&lt; endl;


	waitKey();
	system("pause");
	return 0;
}
#endif</code></pre> 
<p><img alt="" height="111" src="https://images2.imgbox.com/29/fc/W6WFDDCg_o.png" width="306"></p> 
<p>发现优化后的效率比opencv自带的还快。</p> 
<p>最后：欢迎大家的批评，很高心与大家分享，谢谢大家。</p> 
<p> </p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1d95f1d3809606212e6eb1c77247f485/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Eureka 虽然闭源了，但注册中心还有更多选择：Consul 使用详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4acc78fe6c859a9fedf75e84301e8168/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">animate.css在vue项目中的使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>