<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LLaMa - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="LLaMa" />
<meta property="og:description" content="文章目录 Problems403 代码文件LLaMA: Open and Efficient Foundation Language Models方法预训练数据结构优化器一些加速的方法 结果Common Sense ReasoningClosed-book Question AnsweringReading ComprehensionMassive Multitask Language Understanding Instruction Finetuning附录Question AnsweringGenerations from LLaMA-65BGenerations from LLaMA-I Llama 2: Open Foundation and Fine-Tuned Chat Modelspretraining methodologyPretraining DataTraining Details fine-tuning methodologySupervised Fine-Tuning(SFT)Reinforcement Learning with Human Feedback (RLHF) Problems 403 reclone and request.
代码文件 两个测试样例:
example_text_completion.py: 文本补全示例;example_chat_completion.py: 对话生成示例. torchrun --nproc_per_node 1 example_text_completion.py \ --ckpt_dir llama-2-7b/ \ --tokenizer_path tokenizer.model \ --max_seq_len 128 --max_batch_size 4 torchrun --nproc_per_node 1 example_chat_completion." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/28c773d943d636f81e943d1a5f2ae0a8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-22T17:10:55+08:00" />
<meta property="article:modified_time" content="2023-09-22T17:10:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LLaMa</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Problems_1" rel="nofollow">Problems</a></li><li><ul><li><a href="#403_2" rel="nofollow">403</a></li></ul> 
  </li><li><a href="#_5" rel="nofollow">代码文件</a></li><li><a href="#LLaMA_Open_and_Efficient_Foundation_Language_Models_32" rel="nofollow">LLaMA: Open and Efficient Foundation Language Models</a></li><li><ul><li><a href="#_39" rel="nofollow">方法</a></li><li><ul><li><a href="#_41" rel="nofollow">预训练数据</a></li><li><a href="#_48" rel="nofollow">结构</a></li><li><a href="#_54" rel="nofollow">优化器</a></li><li><a href="#_59" rel="nofollow">一些加速的方法</a></li></ul> 
   </li><li><a href="#_65" rel="nofollow">结果</a></li><li><ul><li><a href="#Common_Sense_Reasoning_66" rel="nofollow">Common Sense Reasoning</a></li><li><a href="#Closedbook_Question_Answering_75" rel="nofollow">Closed-book Question Answering</a></li><li><a href="#Reading_Comprehension_84" rel="nofollow">Reading Comprehension</a></li><li><a href="#Massive_Multitask_Language_Understanding_89" rel="nofollow">Massive Multitask Language Understanding</a></li></ul> 
   </li><li><a href="#Instruction_Finetuning_98" rel="nofollow">Instruction Finetuning</a></li><li><a href="#_101" rel="nofollow">附录</a></li><li><ul><li><a href="#Question_Answering_102" rel="nofollow">Question Answering</a></li><li><a href="#Generations_from_LLaMA65B_107" rel="nofollow">Generations from LLaMA-65B</a></li><li><a href="#Generations_from_LLaMAI_118" rel="nofollow">Generations from LLaMA-I</a></li></ul> 
  </li></ul> 
  </li><li><a href="#Llama_2_Open_Foundation_and_FineTuned_Chat_Models_121" rel="nofollow">Llama 2: Open Foundation and Fine-Tuned Chat Models</a></li><li><ul><li><a href="#pretraining_methodology_127" rel="nofollow">pretraining methodology</a></li><li><ul><li><a href="#Pretraining_Data_128" rel="nofollow">Pretraining Data</a></li><li><a href="#Training_Details_133" rel="nofollow">Training Details</a></li></ul> 
   </li><li><a href="#finetuning_methodology_137" rel="nofollow">fine-tuning methodology</a></li><li><ul><li><a href="#Supervised_FineTuningSFT_138" rel="nofollow">Supervised Fine-Tuning(SFT)</a></li><li><a href="#Reinforcement_Learning_with_Human_Feedback_RLHF_152" rel="nofollow">Reinforcement Learning with Human Feedback (RLHF)</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="Problems_1"></a>Problems</h2> 
<h3><a id="403_2"></a>403</h3> 
<p>reclone and request.</p> 
<h2><a id="_5"></a>代码文件</h2> 
<p>两个测试样例:</p> 
<ol><li><code>example_text_completion.py</code>: 文本补全示例;</li><li><code>example_chat_completion.py</code>: 对话生成示例.</li></ol> 
<pre><code>torchrun --nproc_per_node 1 example_text_completion.py \
    --ckpt_dir llama-2-7b/ \
    --tokenizer_path tokenizer.model \
    --max_seq_len 128 --max_batch_size 4
</code></pre> 
<pre><code>torchrun --nproc_per_node 1 example_chat_completion.py \
    --ckpt_dir llama-2-7b-chat/ \
    --tokenizer_path tokenizer.model \
    --max_seq_len 512 --max_batch_size 6
</code></pre> 
<p><code>ckpt_dir</code>: 模型文件路径<br> <code>tokenizer_path</code>: 分词器文件路径</p> 
<p>对于示例一, prompt中提供了需要补全的文本.</p> 
<p>对于示例二, prompt以字典形式组织对话. 每个item包含<code>role</code>和<code>content</code>两个关键字.</p> 
<ol><li><code>role:user</code>: 用户, 用以输入文本;</li><li><code>role:assistant</code>: 系统, 用以输出文本;</li><li><code>role:system</code>: 对系统生成对话的要求;</li></ol> 
<h2><a id="LLaMA_Open_and_Efficient_Foundation_Language_Models_32"></a>LLaMA: Open and Efficient Foundation Language Models</h2> 
<p>发展:<br> scale models -&gt; scale data -&gt; fast inference and scale tokens</p> 
<p>本文的要点:<br> 通过在更多的token上训练, 使得在不同推理开销下, 达到最佳的性能.</p> 
<h3><a id="_39"></a>方法</h3> 
<p>LLaMA采用Auto Regression的方式进行预训练.</p> 
<h4><a id="_41"></a>预训练数据</h4> 
<p>公开数据.</p> 
<p><img src="https://images2.imgbox.com/f9/a0/Prnwj6yb_o.png" alt="请添加图片描述"></p> 
<p>tokenizer的方法为: bytepair encoding(BPE). 总共包含1.4T个tokens.</p> 
<h4><a id="_48"></a>结构</h4> 
<p>采用了之前一些被证明可行的方法:</p> 
<ol><li>RMSNorm from GPT3;</li><li>SwiGLU from PaLM;</li><li>RoPE from GPTNeo.</li></ol> 
<h4><a id="_54"></a>优化器</h4> 
<ol><li>AdamW ( <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           β 
          
         
           1 
          
         
        
          = 
         
        
          0.9 
         
        
          , 
         
         
         
           β 
          
         
           2 
          
         
        
          = 
         
        
          0.95 
         
        
          , 
         
        
          w 
         
        
          e 
         
        
          i 
         
        
          g 
         
        
          h 
         
        
          t 
         
        
            
         
        
          d 
         
        
          e 
         
        
          c 
         
        
          a 
         
        
          y 
         
        
          = 
         
        
          0.1 
         
        
       
         \beta_1=0.9, \beta_2=0.95, weight~decay=0.1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span style="margin-right: 0.0528em;" class="mord mathnormal">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord">0.9</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span style="margin-right: 0.0528em;" class="mord mathnormal">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0528em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord">0.95</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span style="margin-right: 0.0269em;" class="mord mathnormal">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span style="margin-right: 0.0359em;" class="mord mathnormal">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace nobreak"> </span><span class="mord mathnormal">d</span><span class="mord mathnormal">ec</span><span class="mord mathnormal">a</span><span style="margin-right: 0.0359em;" class="mord mathnormal">y</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.1</span></span></span></span></span>);</li><li>warmup 2000 step and cosine learning rate schedule;</li><li>gradient clippping = 1.0;</li></ol> 
<h4><a id="_59"></a>一些加速的方法</h4> 
<ol><li>causal multi-head attention;</li><li>reduce the amount of activations that recomputed during the backward pass.</li></ol> 
<p>2048块80G的A100训练21天.</p> 
<h3><a id="_65"></a>结果</h3> 
<h4><a id="Common_Sense_Reasoning_66"></a>Common Sense Reasoning</h4> 
<p><img src="https://images2.imgbox.com/7b/26/AjxpxOQ8_o.png" alt="请添加图片描述"></p> 
<p>zero-shot.</p> 
<p>CSR : 基于问题和常识性选择, 让模型做出判断.</p> 
<p><img src="https://images2.imgbox.com/fd/02/N8NbzpEM_o.png" alt="请添加图片描述"></p> 
<h4><a id="Closedbook_Question_Answering_75"></a>Closed-book Question Answering</h4> 
<p><img src="https://images2.imgbox.com/4c/1a/0KFZvpI5_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/a0/4b/BMt74U1C_o.png" alt="请添加图片描述"></p> 
<p>不依赖于外部信息源, 只凭借训练时学习得到的信息完成问答任务.</p> 
<p>自由文本的评估指标. exact match perfromance</p> 
<h4><a id="Reading_Comprehension_84"></a>Reading Comprehension</h4> 
<p><img src="https://images2.imgbox.com/4e/d7/Bxn1wEBF_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/6f/af/C7PzajnQ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Massive_Multitask_Language_Understanding_89"></a>Massive Multitask Language Understanding</h4> 
<p><img src="https://images2.imgbox.com/94/28/Zm4bvook_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/55/a3/ecCKZ99y_o.png" alt="在这里插入图片描述"></p> 
<p>Mathematical reasoning 和 Code Generation就不再赘述.</p> 
<h3><a id="Instruction_Finetuning_98"></a>Instruction Finetuning</h3> 
<p>待补充</p> 
<h3><a id="_101"></a>附录</h3> 
<h4><a id="Question_Answering_102"></a>Question Answering</h4> 
<p><img src="https://images2.imgbox.com/ca/82/Vq112YeC_o.png" alt="请添加图片描述"><br> 对于Natural Questions 和 TriviaQA 使用1-shot设定. 预先打印字符串:<code>Answer these questions:\n</code>在问题和答案之前.</p> 
<h4><a id="Generations_from_LLaMA65B_107"></a>Generations from LLaMA-65B</h4> 
<p>Without instruction finetuning.</p> 
<p>Prompts are in bold.</p> 
<p>Only present part of them.</p> 
<p><img src="https://images2.imgbox.com/f5/5f/uUeXEZtW_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/f7/3b/kFY1iaZI_o.png" alt="请添加图片描述"></p> 
<h4><a id="Generations_from_LLaMAI_118"></a>Generations from LLaMA-I</h4> 
<p><img src="https://images2.imgbox.com/56/8e/Lxjdr1c2_o.png" alt="请添加图片描述"></p> 
<h2><a id="Llama_2_Open_Foundation_and_FineTuned_Chat_Models_121"></a>Llama 2: Open Foundation and Fine-Tuned Chat Models</h2> 
<p>LLAMA2 : 新的训练数据组织形式, 更大的预训练语料库, 更长的上下文, grouped-query attention.</p> 
<p>LLAMA2 : 针对对话场景的微调版本.</p> 
<h3><a id="pretraining_methodology_127"></a>pretraining methodology</h3> 
<h4><a id="Pretraining_Data_128"></a>Pretraining Data</h4> 
<ol><li>a new mix of data , not including data from Meta’s products or services;</li><li>移除包含私人信息的数据;</li><li>2 trillion tokens and up-sampling the most factual sources.</li></ol> 
<h4><a id="Training_Details_133"></a>Training Details</h4> 
<p>除了RMSNorm, RoPE and SwiGLU, 增加了GQA.</p> 
<p>其余与LLaMA 1一致.</p> 
<h3><a id="finetuning_methodology_137"></a>fine-tuning methodology</h3> 
<h4><a id="Supervised_FineTuningSFT_138"></a>Supervised Fine-Tuning(SFT)</h4> 
<p>使用公开的instruction tuning data.</p> 
<p>提取高质量的部分数据, 模型的效果仍然得到提升. Quality is All You Need.</p> 
<p>发现人类写的注释和模型生成+人工检查的注释效果差不多.</p> 
<p>微调细节:</p> 
<ol><li>cosine learning rate schedule;</li><li>initial lr = 2e-5;</li><li>weight decay = 0.1;</li><li>batch size = 64;</li><li>sequence length = 4096.</li></ol> 
<h4><a id="Reinforcement_Learning_with_Human_Feedback_RLHF_152"></a>Reinforcement Learning with Human Feedback (RLHF)</h4> 
<p>人类从模型的两个输出中选择喜欢的一个. 该反馈随后用于训练一个奖励模型. 该模型学习人类的偏好模式.</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5c41bbefcc31130209aa1a76c2310908/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C#线程间控件操作--解决错误：线程间操作无效，从不是创建控件的线程访问它</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9b17cfedd796aecca4736e37f65482d2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue new Date() 转换为年月日时分秒以及星期几(padStart补零) - 附完整示例</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>