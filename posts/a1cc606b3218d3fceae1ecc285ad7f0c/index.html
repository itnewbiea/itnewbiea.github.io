<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CRFill：Generative Image Inpainting with Auxiliary Contextual Reconstruction论文阅读笔记 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CRFill：Generative Image Inpainting with Auxiliary Contextual Reconstruction论文阅读笔记" />
<meta property="og:description" content="- ICCV 2021
- 提出问题：当前inpainting任务中缺乏对缺失区域与已知区域之间对应关系的监督信号，可能无法找到合适的参考特征，这往往会导致结果中的伪影。
-本文主要工作：①提出了一个辅助上下文重建任务（训练CR loss），训练网络学习已知区域和缺失区域之间patch的相似性 - 网络结构
主要工作：
Generative inpainting network生成网络
① 利用PathchGAN discriminatpr 网络生成对抗进行训练，该部分是的损失函数为：
其中D为判别器，G为生成器，U为失真图像，M为mask（1代表invalid，0代表valid）
②coarse to fine generator 由粗到细的生成器
生成器部分与deepfillv2相似，差别就在于移除了CA层，并加入了CRloss。
在coarse阶段，作者希望它能够学习到全局特征，所以只用在coarse阶段只使用了L1 loss。
在refine阶段，为了能使网络学习到更多细节，使用了l1 loss，adversarial loss 和作者提出的CR loss。refine 阶段的损失函数如下：
其中Y代表refine的输出，Lcr代表CR loss。
Contextual reconstruction 上下文重建 基于注意力的inpainting方法需要将patch-borrowing的方式加入生成器当中，但如果选取的区域不对，则会导致图像出现伪影。这些伪影是基于来自参考区域的特征而产生的，因此类似于它们在图像空间中的外观。
基于上述的结论，我们提出了一种CR Loss，通过最小化由已知区域的图像补丁组成的辅助结果的对抗性损失来鼓励网络找到最优参考区域。之前提出的方法都是将patch-borrow（我个人理解为算出注意力之后，根据注意力权重重新组合特征图）直接嵌入到生成器中。CR loss不一样，它是直接通过loss的方式将信息传递给 attention-free没有注意力的生成器。
Contextual reconstruction Loss
CR Loss计算方式如下图所示：
训练系统由一个相似性编码器和一个辅助的encoder-decoder网络组成。
其中相似性编码器的输入为refine network encoder的特征，然后生成区域之间的相似性分数图。辅助编码器解码器网络生成辅助图像，其中已知区域不变，而缺失区域根据相似性编码器提供的相似性填充相似的已知区域。
CRLoss定义为辅助图像的L1 loss和adversarial loss。通过最小化CR loss以此鼓励refine 网络生成器生成与参考区域联系紧密的图像。
相似性编码器的计算如下：
计算patch之间的相似性：
辅助编码器解码器网络生成辅助图像，其中已知区域不变，而缺失区域根据相似性，用已知区域中patch的加权和替换。
再进行解码，得到辅助输出图像
CRLoss定义为辅助图像的L1 loss和adversarial loss。通过最小化CR loss以此鼓励refine 网络生成器生成与参考区域联系紧密的图像。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/a1cc606b3218d3fceae1ecc285ad7f0c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-18T14:54:03+08:00" />
<meta property="article:modified_time" content="2023-04-18T14:54:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CRFill：Generative Image Inpainting with Auxiliary Contextual Reconstruction论文阅读笔记</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p> <img alt="" height="271" src="https://images2.imgbox.com/c2/3b/IF4I0Ztp_o.png" width="1200"></p> 
<p> </p> 
<p> - ICCV 2021</p> 
<p>- 提出问题：当前inpainting任务中缺乏对缺失区域与已知区域之间对应关系的监督信号，可能无法找到合适的参考特征，这往往会导致结果中的伪影。</p> 
<p> -本文主要工作：①提出了一个辅助上下文重建任务（训练CR loss），训练网络学习已知区域和缺失区域之间patch的相似性   </p> 
<p> - 网络结构</p> 
<p class="img-center"><img alt="" height="285" src="https://images2.imgbox.com/ee/88/MbSTCP5S_o.png" width="614"></p> 
<p> </p> 
<p>主要工作：</p> 
<p><strong>Generative inpainting network生成网络</strong></p> 
<p>  ① 利用PathchGAN discriminatpr 网络生成对抗进行训练，该部分是的损失函数为：</p> 
<p class="img-center"><img alt="" height="100" src="https://images2.imgbox.com/56/40/K8sZHcEI_o.png" width="555"></p> 
<p>         其中D为判别器，G为生成器，U为失真图像，M为mask（1代表invalid，0代表valid）</p> 
<p></p> 
<p>   ②coarse to fine generator 由粗到细的生成器</p> 
<p>        生成器部分与deepfillv2相似，差别就在于移除了CA层，并加入了CRloss。</p> 
<p>        在coarse阶段，作者希望它能够学习到全局特征，所以只用在coarse阶段只使用了L1 loss。</p> 
<p>        在refine阶段，为了能使网络学习到更多细节，使用了l1 loss，adversarial loss 和作者提出的CR loss。refine 阶段的损失函数如下：</p> 
<p class="img-center"><img alt="" height="154" src="https://images2.imgbox.com/6b/e6/PBU8mleg_o.png" width="489"></p> 
<p>         其中Y代表refine的输出，Lcr代表CR loss。</p> 
<p></p> 
<p><strong>Contextual reconstruction 上下文重建</strong> </p> 
<p>        基于注意力的inpainting方法需要将patch-borrowing的方式加入生成器当中，但如果选取的区域不对，则会导致图像出现伪影。这些伪影是基于来自参考区域的特征而产生的，因此类似于它们在图像空间中的外观。</p> 
<p>        基于上述的结论，我们提出了一种CR Loss，通过最小化由已知区域的图像补丁组成的辅助结果的对抗性损失来鼓励网络找到最优参考区域。之前提出的方法都是将patch-borrow（我个人理解为算出注意力之后，根据注意力权重重新组合特征图）直接嵌入到生成器中。CR loss不一样，它是直接通过loss的方式将信息传递给 attention-free没有注意力的生成器。</p> 
<p><img alt="" height="295" src="https://images2.imgbox.com/e2/47/Rzgjl8IC_o.png" width="1200"></p> 
<p>         Contextual reconstruction Loss</p> 
<p>        CR Loss计算方式如下图所示：</p> 
<p class="img-center"><img alt="" height="709" src="https://images2.imgbox.com/e2/a7/53HG8k04_o.png" width="971"></p> 
<p>         训练系统由一个相似性编码器和一个辅助的encoder-decoder网络组成。</p> 
<p>        其中相似性编码器的输入为refine network encoder的特征，然后生成区域之间的相似性分数图。辅助编码器解码器网络生成辅助图像，其中已知区域不变，而缺失区域根据相似性编码器提供的相似性填充相似的已知区域。</p> 
<p>        CRLoss定义为辅助图像的L1 loss和adversarial loss。通过最小化CR loss以此鼓励refine 网络生成器生成与参考区域联系紧密的图像。</p> 
<p>相似性编码器的计算如下：</p> 
<p>计算patch之间的相似性：</p> 
<p class="img-center"><img alt="" height="96" src="https://images2.imgbox.com/59/0b/x4jQ5v0b_o.png" width="301"></p> 
<p> 辅助编码器解码器网络生成辅助图像，其中已知区域不变，而缺失区域根据相似性，用已知区域中patch的加权和替换。</p> 
<p class="img-center"><img alt="" height="99" src="https://images2.imgbox.com/95/16/Ginj20LQ_o.png" width="406"></p> 
<p> <img alt="" height="50" src="https://images2.imgbox.com/98/ba/RsAKkLh3_o.png" width="641"></p> 
<p>       再进行解码，得到辅助输出图像</p> 
<p class="img-center"><img alt="" height="74" src="https://images2.imgbox.com/22/f1/c4fJppKI_o.png" width="290"></p> 
<p> CRLoss定义为辅助图像的L1 loss和adversarial loss。通过最小化CR loss以此鼓励refine 网络生成器生成与参考区域联系紧密的图像。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f8d2eee46ab419acb39e428b0e8c0c09/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">HDFS学习笔记</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/43e2d88c925f296720dcbd2778b077ce/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">微信小程序使用webview内嵌h5页面 wx.miniProgram.getEnv失效问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>