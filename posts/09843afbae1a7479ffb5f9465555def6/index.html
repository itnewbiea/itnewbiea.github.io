<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【转】Apache Doris介绍 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【转】Apache Doris介绍" />
<meta property="og:description" content="转：Apache Doris介绍_wapecheng的博客-CSDN博客_apache doris 一、关于 Apache Doris 和 DorisDB、StarRocks 的关系 Doris 最早是解决百度凤巢统计报表的专用系统，随着百度业务的飞速发展对系统进行了多次迭代，逐渐承担起百度内部业务的统计报表和多维分析需求。2013 年，我们把 Doris 进行了 MPP 框架的升级，并将新系统命名为 Palo ，2017 年我们以百度 Palo 的名字在 GitHub 上进行了开源，2018 年贡献给 Apache 基金会时，由于与国外数据库厂商重名，因此选择用回最初的名字，这就是 Apache Doris 的由来。
那么 StarRocks 以及 DorisDB 是什么？
2020 年 2 月，百度 Doris 团队的个别同学离职创业，基于 Apache Doris 之前的版本做了自己的商业化闭源产品 DorisDB ，这就是 StarRocks 的前身。
按照 Apache License，基于开源产品进行商业化是被允许的。
但是 DorisDB 团队在对外宣传时，会宣称自己“是 Apache Doris 的主创团队”、“ Apache Doris 的核心开发人员大部分在任职”等诸类话术。
实际上， GitHub 上公开的数据显示，Apache Doris 贡献代码前三的 Contributor 全部在百度 Doris 团队就职，不知所谓的“大部分”和“主创”从何说起。
实际上，从 2020 年初起， DorisDB 团队几乎没有向 Apache Doris 提交过一行代码。少部分开发者原本是 Apache Doris 的 Contributor ，在加入 DorisDB 团队后，同样不再向 Apache Doris 贡献一行代码。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/09843afbae1a7479ffb5f9465555def6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-08T18:05:30+08:00" />
<meta property="article:modified_time" content="2022-07-08T18:05:30+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【转】Apache Doris介绍</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>转：<a href="https://blog.csdn.net/wapecheng/article/details/121110237" title="Apache Doris介绍_wapecheng的博客-CSDN博客_apache doris">Apache Doris介绍_wapecheng的博客-CSDN博客_apache doris</a></h2> 
<h2>一、<strong>关于 Apache Doris 和 DorisDB、StarRocks 的关系</strong></h2> 
<p>Doris 最早是解决百度凤巢统计报表的专用系统，随着百度业务的飞速发展对系统进行了多次迭代，逐渐承担起百度内部业务的统计报表和多维分析需求。2013 年，我们把 Doris 进行了 MPP <a href="https://so.csdn.net/so/search?q=%E6%A1%86%E6%9E%B6&amp;spm=1001.2101.3001.7020" title="框架">框架</a>的升级，并将新系统命名为 Palo ，2017 年我们以百度 Palo 的名字在 GitHub 上进行了开源，2018 年贡献给 Apache 基金会时，由于与国外数据库厂商重名，因此选择用回最初的名字，这就是 Apache Doris 的由来。</p> 
<p><strong>那么 StarRocks 以及 DorisDB 是什么？</strong></p> 
<p>2020 年 2 月，百度 Doris 团队的个别同学离职创业，基于 <a href="https://so.csdn.net/so/search?q=Apache&amp;spm=1001.2101.3001.7020" title="Apache">Apache</a> Doris 之前的版本做了自己的商业化闭源产品 DorisDB ，这就是 StarRocks 的前身。</p> 
<p>按照 Apache License，基于开源产品进行商业化是被允许的。</p> 
<p>但是 DorisDB 团队在对外宣传时，会宣称自己“是 Apache Doris 的主创团队”、“ Apache Doris 的核心开发人员大部分在任职”等诸类话术。</p> 
<p>实际上， <a href="https://so.csdn.net/so/search?q=GitHub&amp;spm=1001.2101.3001.7020" title="GitHub">GitHub</a> 上公开的数据显示，<strong>Apache Doris 贡献代码前三的 Contributor 全部在百度 Doris 团队就职</strong>，不知所谓的“大部分”和“主创”从何说起。</p> 
<p>实际上，<strong>从 2020 年初起， DorisDB 团队几乎没有向 Apache Doris 提交过一行代码</strong>。<strong>少部分开发者原本是 Apache Doris 的 Contributor ，在加入 DorisDB 团队后，同样不再向 Apache Doris 贡献一行代码</strong>。</p> 
<p>比如 DorisDB 团队在人员扩张时，会故意定向挖 Apache Doris 企业用户的员工。开源社区的发展离不开用户的支持，挖用户墙角更无异于自掘坟墓。对于员工个人主动的选择我们不去评判，但这让企业用户对自己员工的培养做了嫁衣。而短视的人是不会看到这些的，更认为与他们毫无关系， Apache Doris 的死活与他们无关，只要自己能招到人就行。</p> 
<p>比如 DorisDB 的商标问题，从品牌角度来说，开源项目与商业化产品的品牌必须存在区分度，比如 Linux 和 RedHat 、 Hadoop 与 Cloudera 、Apache Kylin 和 Kyligence 。</p> 
<p>因为他们最初将产品命名为 DorisDB 就受到了 Apache 基金会的质疑，进而阻碍了 Apache Doris 的毕业进程，也给 Apache Doris 社区带来了困扰。最终在 Apache 基金会的施压和我们的抗议下，不得已作出了改名的行为。</p> 
<p>总结下来他们三个的关系是</p> 
<p><strong>Apache Doris 不等于 DorisDB(更名后：StarRocks)</strong></p> 
<h2><a name="t1"></a></h2> 
<h2><a name="t2"></a>二、原理剖析</h2> 
<h3><a name="t3"></a>数据驱动的新趋势</h3> 
<p>目前数据需求对速度和性能要求越来越高: 查询(亚秒级别返回)，快速开发，</p> 
<p>传统的方式进行预计算kylin、clickhouse, 星型模型--宽表模型--预聚合--(聚合度越高就会丧失一些灵活性，业务变更、维度变化就要重新刷新数据)</p> 
<p>星型和雪花模型的多表关联, 高效的即席查询,预计算;</p> 
<p><img alt="" src="https://images2.imgbox.com/31/4b/AJYCjGUc_o.png"></p> 
<p></p> 
<p>传统方式：</p> 
<p>kylin+hbase做预处理</p> 
<p>实时分析druid-聚合模型(对宽表支持度不高)</p> 
<p>宽表选用clickhouse(对更新不友好)</p> 
<p>Impala+kudu实现更新+多表关联</p> 
<p>ES <a href="https://so.csdn.net/so/search?q=%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2&amp;spm=1001.2101.3001.7020" title="全文检索">全文检索</a>、倒排索引;</p> 
<p>现在只需一个Doris，<strong>解决不同系统之间的差异;</strong></p> 
<p><img alt="" src="https://images2.imgbox.com/78/75/tmDN0GVk_o.png"></p> 
<h3><a name="t4"></a> 整体架构 - MPP架构</h3> 
<h4><a name="t5"></a>弹性MPP架构-极简架构</h4> 
<p><img alt="" src="https://images2.imgbox.com/d1/85/OrLjBByt_o.png"></p> 
<p>FE前端节点-主要负责元数据的管理、查询调度,解析sql的执行计划给BE，</p> 
<p>BE-数据的存储和执行的引擎，这里存储和计算还是在一起的；</p> 
<p>FE:leader 、follower(参与选举)，水平扩容</p> 
<p>对外提供了mysql兼容的协议;</p> 
<p><img alt="" src="https://images2.imgbox.com/5e/de/fgwUX7Jg_o.png"></p> 
<p>跟传统架构的区别:</p> 
<p>通过分布式拆分成不同的task，再在中心节点汇聚；</p> 
<p>druid、clickhouse都是类型；<br><br> MR是任务的拆分、落盘；</p> 
<p>doris是MPP架构，任务之间分成task、全都在内存中执行和传输，所有任务都是流水线，没有磁盘IO，适用于低延迟亚秒级查询；</p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p><br>  </p> 
<h2><a name="t6"></a><strong>三、编译、安装与部署</strong></h2> 
<h3><a name="t7"></a>直接编译（CentOS/Ubuntu）</h3> 
<p>你可以在自己的 linux 环境中直接尝试编译 Doris。</p> 
<ol><li> <p>系统依赖 不同的版本依赖也不相同</p> 
  <ul><li> <p>在 <a href="https://github.com/apache/incubator-doris/commit/ad67dd34a04c1ca960cff38e5b335b30fc7d559f" title="ad67dd3 (opens new window)">ad67dd3 (opens new window)</a>之前版本依赖如下：</p> <pre><code>GCC 7.3+, Oracle JDK 1.8+, Python 2.7+, Apache Maven 3.5+, CMake 3.11+ Bison 3.0+</code></pre> <p>如果使用Ubuntu 16.04 及以上系统 可以执行以下命令来安装依赖</p> <pre><code>sudo apt-get install build-essential openjdk-8-jdk maven cmake byacc flex automake libtool-bin bison binutils-dev libiberty-dev zip unzip libncurses5-dev curl git ninja-build python autopoint pkg-config</code></pre> <p>如果是CentOS 可以执行以下命令</p> <pre><code>sudo yum groupinstall 'Development Tools' &amp;&amp; sudo yum install maven cmake byacc flex automake libtool bison binutils-devel zip unzip ncurses-devel curl git wget python2 glibc-static libstdc++-static java-1.8.0-openjdk</code></pre> </li><li> <p>在 <a href="https://github.com/apache/incubator-doris/commit/ad67dd34a04c1ca960cff38e5b335b30fc7d559f" title="ad67dd3 (opens new window)">ad67dd3 (opens new window)</a>之后版本依赖如下：</p> <pre><code>GCC 10+, Oracle JDK 1.8+, Python 2.7+, Apache Maven 3.5+, CMake 3.19.2+ Bison 3.0+</code></pre> <p>如果使用Ubuntu 16.04 及以上系统 可以执行以下命令来安装依赖</p> <pre></pre> 
    <ol><li> <p><code>sudo apt install build-essential openjdk-8-jdk maven cmake byacc flex automake libtool-bin bison binutils-dev libiberty-dev zip unzip libncurses5-dev curl git ninja-build python</code></p> </li><li> <p><code>sudo add-apt-repository ppa:ubuntu-toolchain-r/ppa</code></p> </li><li> <p><code>sudo apt update</code></p> </li><li> <p><code>sudo apt install gcc-10 g++-10 </code></p> </li><li> <p><code>sudo apt-get install autoconf automake libtool autopoint</code></p> </li></ol><p>如果是CentOS 可以执行以下命令</p> <pre></pre> 
    <ol><li> <p><code>sudo yum groupinstall 'Development Tools' &amp;&amp; sudo yum install maven cmake byacc flex automake libtool bison binutils-devel zip unzip ncurses-devel curl git wget python2 glibc-static libstdc++-static java-1.8.0-openjdk</code></p> </li><li> <p><code>sudo yum install centos-release-scl</code></p> </li><li> <p><code>sudo yum install devtoolset-10</code></p> </li><li> <p><code>scl enable devtoolset-10 bash</code></p> </li></ol><p>如果当前仓库没有提供devtoolset-10 可以添加如下repo 使用oracle 提供 package</p> <pre></pre> 
    <ol><li> <p><code>[ol7_software_collections]</code></p> </li><li> <p><code>name=Software Collection packages for Oracle Linux 7 ($basearch)</code></p> </li><li> <p><code>baseurl=http://yum.oracle.com/repo/OracleLinux/OL7/SoftwareCollections/$basearch/</code></p> </li><li> <p><code>gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle</code></p> </li><li> <p><code>gpgcheck=1</code></p> </li><li> <p><code>enabled=1</code></p> </li></ol></li></ul><p>安装完成后，自行设置环境变量 <code>PATH</code>, <code>JAVA_HOME</code> 等。 注意： Doris 0.14.0 的版本仍然使用gcc7 的依赖编译，之后的代码将使用gcc10 的依赖</p> </li><li> <p>编译 Doris</p> <pre><code>$ sh build.sh
</code></pre> <p>编译完成后，产出文件在 <code>output/</code> 目录中。</p> </li></ol> 
<h2 id="安装与部署"><a name="t8"></a>安装与部署</h2> 
<p>Doris 作为一款开源的 MPP 架构 OLAP 数据库，能够运行在绝大多数主流的商用服务器上。为了能够充分运用 MPP 架构的并发优势，以及 Doris 的高可用特性，我们建议 Doris 的部署遵循以下需求：</p> 
<p>Linux 操作系统版本需求</p> 
<table><thead><tr><th>Linux 系统</th><th>版本</th></tr></thead><tbody><tr><td>CentOS</td><td>7.1 及以上</td></tr><tr><td>Ubuntu</td><td>16.04 及以上</td></tr></tbody></table> 
<p>软件需求</p> 
<table><thead><tr><th>软件</th><th>版本</th></tr></thead><tbody><tr><td>Java</td><td>1.8 及以上</td></tr><tr><td>GCC</td><td>4.8.2 及以上</td></tr></tbody></table> 
<p>开发测试环境</p> 
<table><thead><tr><th>模块</th><th>CPU</th><th>内存</th><th>磁盘</th><th>网络</th><th>实例数量</th></tr></thead><tbody><tr><td>Frontend</td><td>8核+</td><td>8GB+</td><td>SSD 或 SATA，10GB+ *</td><td>千兆网卡</td><td>1</td></tr><tr><td>Backend</td><td>8核+</td><td>16GB+</td><td>SSD 或 SATA，50GB+ *</td><td>千兆网卡</td><td>1-3 *</td></tr></tbody></table> 
<p></p> 
<p>生产环境</p> 
<table><thead><tr><th>模块</th><th>CPU</th><th>内存</th><th>磁盘</th><th>网络</th><th>实例数量（最低要求）</th></tr></thead><tbody><tr><td>Frontend</td><td>16核+</td><td>64GB+</td><td>SSD 或 RAID 卡，100GB+ *</td><td>万兆网卡</td><td>1-5 *</td></tr><tr><td>Backend</td><td>16核+</td><td>64GB+</td><td>SSD 或 SATA，100G+ *</td><td>万兆网卡</td><td>10-100 *</td></tr></tbody></table> 
<blockquote> 
 <p>注1：</p> 
 <ol><li>FE 的磁盘空间主要用于存储元数据，包括日志和 image。通常从几百 MB 到几个 GB 不等。</li><li>BE 的磁盘空间主要用于存放用户数据，总磁盘空间按用户总数据量 * 3（3副本）计算，然后再预留额外 40% 的空间用作后台 compaction 以及一些中间数据的存放。</li><li>一台机器上可以部署多个 BE 实例，但是<strong>只能部署一个 FE</strong>。如果需要 3 副本数据，那么至少需要 3 台机器各部署一个 BE 实例（而不是1台机器部署3个BE实例）。<strong>多个FE所在服务器的时钟必须保持一致（允许最多5秒的时钟偏差）</strong></li><li>测试环境也可以仅适用一个 BE 进行测试。实际生产环境，BE 实例数量直接决定了整体查询延迟。</li><li>所有部署节点关闭 Swap。</li></ol> 
</blockquote> 
<p></p> 
<h3 id="集群部署"><a name="t9"></a>集群部署</h3> 
<h4 id="手动部署"><a name="t10"></a>手动部署</h4> 
<h4><a name="t11"></a>FE 部署</h4> 
<ul><li> <p>拷贝 FE 部署文件到指定节点</p> <p>将源码编译生成的 output 下的 fe 文件夹拷贝到 FE 的节点指定部署路径下并进入该目录。</p> </li><li> <p>配置 FE</p> 
  <ol><li> <p>配置文件为 conf/fe.conf。其中注意：<code>meta_dir</code>是元数据存放位置。默认值为 <code>${DORIS_HOME}/doris-meta</code>。需<strong>手动创建</strong>该目录。</p> <p><strong>注意：生产环境强烈建议单独指定目录不要放在Doris安装目录下，最好是单独的磁盘（如果有SSD最好），测试开发环境可以使用默认配置</strong></p> </li><li> <p>fe.conf 中 JAVA_OPTS 默认 java 最大堆内存为 4GB，<strong>建议生产环境调整至 8G 以上</strong>。</p> </li></ol></li><li> <p>启动FE</p> <p><code>sh bin/start_fe.sh --daemon</code></p> <p>FE进程启动进入后台执行。日志默认存放在 log/ 目录下。如启动失败，可以通过查看 log/fe.log 或者 log/fe.out 查看错误信息。</p> </li><li> <p>如需部署多 FE，请参见 "FE 扩容和缩容" 章节</p> </li></ul> 
<p>BE 部署</p> 
<ul><li> <p>拷贝 BE 部署文件到所有要部署 BE 的节点</p> <p>将源码编译生成的 output 下的 be 文件夹拷贝到 BE 的节点的指定部署路径下。</p> </li><li> <p>修改所有 BE 的配置</p> <p>修改 be/conf/be.conf。主要是配置 <code>storage_root_path</code>：数据存放目录。默认在be/storage下，需要<strong>手动创建</strong>该目录。多个路径之间使用英文状态的分号 <code>;</code> 分隔（<strong>最后一个目录后不要加 <code>;</code></strong>）。可以通过路径区别存储目录的介质，HDD或SSD。可以添加容量限制在每个路径的末尾，通过英文状态逗号<code>,</code>隔开。</p> <p>示例1如下：</p> <p><strong>注意：如果是SSD磁盘要在目录后面加上<code>.SSD</code>,HDD磁盘在目录后面加<code>.HDD</code></strong></p> <p><code>storage_root_path=/home/disk1/doris.HDD,50;/home/disk2/doris.SSD,10;/home/disk2/doris</code></p> <p><strong>说明</strong></p> 
  <ul><li>/home/disk1/doris.HDD, 50，表示存储限制为50GB, HDD;</li><li>/home/disk2/doris.SSD 10， 存储限制为10GB，SSD；</li><li>/home/disk2/doris，存储限制为磁盘最大容量，默认为HDD</li></ul><p>示例2如下：</p> <p><strong>注意：不论HHD磁盘目录还是SSD磁盘目录，都无需添加后缀，storage_root_path参数里指定medium即可</strong></p> <p><code>storage_root_path=/home/disk1/doris,medium:hdd,capacity:50;/home/disk2/doris,medium:ssd,capacity:50</code></p> <p><strong>说明</strong></p> 
  <ul><li>/home/disk1/doris,medium:hdd,capacity:10，表示存储限制为10GB, HHD;</li><li>/home/disk2/doris,medium:ssd,capacity:50，表示存储限制为50GB, SSD;</li></ul></li><li> <p>BE webserver_port端口配置</p> <p>如果 be 部署在 hadoop 集群中，注意调整 be.conf 中的 <code>webserver_port = 8040</code> ,以免造成端口冲突</p> </li><li> <p>在 FE 中添加所有 BE 节点</p> <p>BE 节点需要先在 FE 中添加，才可加入集群。可以使用 mysql-client(<a href="https://dev.mysql.com/downloads/mysql/5.7.html" rel="nofollow" title="下载MySQL 5.7 (opens new window)">下载MySQL 5.7 (opens new window)</a>) 连接到 FE：</p> <p><code>./mysql-client -h host -P port -uroot</code></p> <p>其中 host 为 FE 所在节点 ip；port 为 fe/conf/fe.conf 中的 query_port；默认使用 root 账户，无密码登录。</p> <p>登录后，执行以下命令来添加每一个 BE：</p> <p><code>ALTER SYSTEM ADD BACKEND "host:port";</code></p> <pre><code>	其中 host 为 BE 所在节点 ip；port 为 be/conf/be.conf 中的 heartbeat_service_port。
</code></pre> </li><li> <p>启动 BE</p> <p><code>sh bin/start_be.sh --daemon</code></p> <p>BE 进程将启动并进入后台执行。日志默认存放在 be/log/ 目录下。如启动失败，可以通过查看 be/log/be.log 或者 be/log/be.out 查看错误信息。</p> </li><li> <p>查看BE状态</p> <p>使用 mysql-client 连接到 FE，并执行 <code>SHOW PROC '/backends';</code> 查看 BE 运行情况。如一切正常，<code>isAlive</code> 列应为 <code>true</code>。</p> </li></ul> 
<h3 id="扩容缩容"><a name="t12"></a>扩容缩容</h3> 
<p>Doris 可以很方便的扩容和缩容 FE、BE、Broker 实例。</p> 
<h4 id="fe-扩容和缩容"><a name="t13"></a><a href="http://doris.apache.org/master/zh-CN/installing/install-deploy.html#fe-%E6%89%A9%E5%AE%B9%E5%92%8C%E7%BC%A9%E5%AE%B9" rel="nofollow" title="#">#</a>FE 扩容和缩容</h4> 
<p>可以通过将 FE 扩容至 3 个以上节点来实现 FE 的高可用。</p> 
<p>用户可以通过 mysql 客户端登陆 Master FE。通过:</p> 
<p><code>SHOW PROC '/frontends';</code></p> 
<p>来查看当前 FE 的节点情况。</p> 
<p>也可以通过前端页面连接：<code>http://fe_hostname:fe_http_port/frontend</code> 或者 <code>http://fe_hostname:fe_http_port/system?path=//frontends</code> 来查看 FE 节点的情况。</p> 
<p>以上方式，都需要 Doris 的 root 用户权限。</p> 
<p>FE 节点的扩容和缩容过程，不影响当前系统运行。</p> 
<p><a href="http://doris.apache.org/master/zh-CN/installing/install-deploy.html#%E5%A2%9E%E5%8A%A0-fe-%E8%8A%82%E7%82%B9" rel="nofollow" title="#">#</a>增加 FE 节点</p> 
<p>FE 分为 Leader，Follower 和 Observer 三种角色。 默认一个集群，只能有一个 Leader，可以有多个 Follower 和 Observer。其中 Leader 和 Follower 组成一个 Paxos 选择组，如果 Leader 宕机，则剩下的 Follower 会自动选出新的 Leader，保证写入高可用。Observer 同步 Leader 的数据，但是不参加选举。如果只部署一个 FE，则 FE 默认就是 Leader。</p> 
<p>第一个启动的 FE 自动成为 Leader。在此基础上，可以添加若干 Follower 和 Observer。</p> 
<p>添加 Follower 或 Observer。使用 mysql-client 连接到已启动的 FE，并执行：</p> 
<p><code>ALTER SYSTEM ADD FOLLOWER "host:port";</code></p> 
<p>或</p> 
<p><code>ALTER SYSTEM ADD OBSERVER "host:port";</code></p> 
<p>其中 host 为 Follower 或 Observer 所在节点 ip，port 为其配置文件 fe.conf 中的 edit_log_port。</p> 
<p>配置及启动 Follower 或 Observer。Follower 和 Observer 的配置同 Leader 的配置。第一次启动时，需执行以下命令：</p> 
<p><code>./bin/start_fe.sh --helper host:port --daemon</code></p> 
<p>其中 host 为 Leader 所在节点 ip, port 为 Leader 的配置文件 fe.conf 中的 edit_log_port。--helper 参数仅在 follower 和 observer 第一次启动时才需要。</p> 
<p>查看 Follower 或 Observer 运行状态。使用 mysql-client 连接到任一已启动的 FE，并执行：SHOW PROC '/frontends'; 可以查看当前已加入集群的 FE 及其对应角色。</p> 
<blockquote> 
 <p>FE 扩容注意事项：</p> 
 <ol><li>Follower FE（包括 Leader）的数量必须为奇数，建议最多部署 3 个组成高可用（HA）模式即可。</li><li>当 FE 处于高可用部署时（1个 Leader，2个 Follower），我们建议通过增加 Observer FE 来扩展 FE 的读服务能力。当然也可以继续增加 Follower FE，但几乎是不必要的。</li><li>通常一个 FE 节点可以应对 10-20 台 BE 节点。建议总的 FE 节点数量在 10 个以下。而通常 3 个即可满足绝大部分需求。</li><li>helper 不能指向 FE 自身，必须指向一个或多个已存在并且正常运行中的 Master/Follower FE。</li></ol> 
</blockquote> 
<p><a href="http://doris.apache.org/master/zh-CN/installing/install-deploy.html#%E5%88%A0%E9%99%A4-fe-%E8%8A%82%E7%82%B9" rel="nofollow" title="#">#</a>删除 FE 节点</p> 
<p>使用以下命令删除对应的 FE 节点：</p> 
<p><code>ALTER SYSTEM DROP FOLLOWER[OBSERVER] "fe_host:edit_log_port";</code></p> 
<blockquote> 
 <p>FE 缩容注意事项：</p> 
 <ol><li>删除 Follower FE 时，确保最终剩余的 Follower（包括 Leader）节点为奇数。</li></ol> 
</blockquote> 
<h4 id="be-扩容和缩容"><a name="t14"></a><a href="http://doris.apache.org/master/zh-CN/installing/install-deploy.html#be-%E6%89%A9%E5%AE%B9%E5%92%8C%E7%BC%A9%E5%AE%B9" rel="nofollow" title="#">#</a>BE 扩容和缩容</h4> 
<p>用户可以通过 mysql-client 登陆 Leader FE。通过:</p> 
<p><code>SHOW PROC '/backends';</code></p> 
<p>来查看当前 BE 的节点情况。</p> 
<p>也可以通过前端页面连接：<code>http://fe_hostname:fe_http_port/backend</code> 或者 <code>http://fe_hostname:fe_http_port/system?path=//backends</code> 来查看 BE 节点的情况。</p> 
<p>以上方式，都需要 Doris 的 root 用户权限。</p> 
<p>BE 节点的扩容和缩容过程，不影响当前系统运行以及正在执行的任务，并且不会影响当前系统的性能。数据均衡会自动进行。根据集群现有数据量的大小，集群会在几个小时到1天不等的时间内，恢复到负载均衡的状态。集群负载情况，可以参见 <a href="http://doris.apache.org/master/zh-CN/administrator-guide/operation/tablet-repair-and-balance.html" rel="nofollow" title="Tablet 负载均衡文档">Tablet 负载均衡文档</a>。</p> 
<p><a href="http://doris.apache.org/master/zh-CN/installing/install-deploy.html#%E5%A2%9E%E5%8A%A0-be-%E8%8A%82%E7%82%B9" rel="nofollow" title="#">#</a>增加 BE 节点</p> 
<p>BE 节点的增加方式同 <strong>BE 部署</strong> 一节中的方式，通过 <code>ALTER SYSTEM ADD BACKEND</code> 命令增加 BE 节点。</p> 
<blockquote> 
 <p>BE 扩容注意事项：</p> 
 <ol><li>BE 扩容后，Doris 会自动根据负载情况，进行数据均衡，期间不影响使用。</li></ol> 
</blockquote> 
<p><a href="http://doris.apache.org/master/zh-CN/installing/install-deploy.html#%E5%88%A0%E9%99%A4-be-%E8%8A%82%E7%82%B9" rel="nofollow" title="#">#</a>删除 BE 节点</p> 
<p>删除 BE 节点有两种方式：DROP 和 DECOMMISSION</p> 
<p>DROP 语句如下：</p> 
<p><code>ALTER SYSTEM DROP BACKEND "be_host:be_heartbeat_service_port";</code></p> 
<p><strong>注意：DROP BACKEND 会直接删除该 BE，并且其上的数据将不能再恢复！！！所以我们强烈不推荐使用 DROP BACKEND 这种方式删除 BE 节点。当你使用这个语句时，会有对应的防误操作提示。</strong></p> 
<p>DECOMMISSION 语句如下：</p> 
<p><code>ALTER SYSTEM DECOMMISSION BACKEND "be_host:be_heartbeat_service_port";</code></p> 
<blockquote> 
 <p>DECOMMISSION 命令说明：</p> 
 <ol><li>该命令用于安全删除 BE 节点。命令下发后，Doris 会尝试将该 BE 上的数据向其他 BE 节点迁移，当所有数据都迁移完成后，Doris 会自动删除该节点。</li><li>该命令是一个异步操作。执行后，可以通过 <code>SHOW PROC '/backends';</code> 看到该 BE 节点的 isDecommission 状态为 true。表示该节点正在进行下线。</li><li>该命令<strong>不一定执行成功</strong>。比如剩余 BE 存储空间不足以容纳下线 BE 上的数据，或者剩余机器数量不满足最小副本数时，该命令都无法完成，并且 BE 会一直处于 isDecommission 为 true 的状态。</li><li>DECOMMISSION 的进度，可以通过 <code>SHOW PROC '/backends';</code> 中的 TabletNum 查看，如果正在进行，TabletNum 将不断减少。</li><li>该操作可以通过:<br><code>CANCEL DECOMMISSION BACKEND "be_host:be_heartbeat_service_port";</code><br> 命令取消。取消后，该 BE 上的数据将维持当前剩余的数据量。后续 Doris 重新进行负载均衡</li></ol> 
</blockquote> 
<p></p> 
<h2><a name="t15"></a>四、使用指南</h2> 
<h2 id="基础使用指南"><a name="t16"></a>基础使用指南</h2> 
<p>Doris 采用 MySQL 协议进行通信，用户可通过 MySQL client 或者 MySQL JDBC连接到 Doris 集群。选择 MySQL client 版本时建议采用5.1 之后的版本，因为 5.1 之前不能支持长度超过 16 个字符的用户名。本文以 MySQL client 为例，通过一个完整的流程向用户展示 Doris 的基本使用方法。</p> 
<h3 id="_1-创建用户"><a name="t17"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_1-%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7" rel="nofollow" title="#">#</a>1 创建用户</h3> 
<h4 id="_1-1-root-用户登录与密码修改"><a name="t18"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_1-1-root-%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E4%B8%8E%E5%AF%86%E7%A0%81%E4%BF%AE%E6%94%B9" rel="nofollow" title="#">#</a>1.1 Root 用户登录与密码修改</h4> 
<p>Doris 内置 root 和 admin 用户，密码默认都为空。启动完 Doris 程序之后，可以通过 root 或 admin 用户连接到 Doris 集群。 使用下面命令即可登录 Doris：</p> 
<pre><code>mysql -h FE_HOST -P9030 -uroot
</code></pre> 
<blockquote> 
 <p><code>fe_host</code> 是任一 FE 节点的 ip 地址。<code>9030</code> 是 fe.conf 中的 query_port 配置。</p> 
</blockquote> 
<p>登陆后，可以通过以下命令修改 root 密码</p> 
<pre><code>SET PASSWORD FOR 'root' = PASSWORD('your_password');
</code></pre> 
<h4 id="_1-3-创建新用户"><a name="t19"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_1-3-%E5%88%9B%E5%BB%BA%E6%96%B0%E7%94%A8%E6%88%B7" rel="nofollow" title="#">#</a>1.3 创建新用户</h4> 
<p>通过下面的命令创建一个普通用户。</p> 
<pre><code>CREATE USER 'test' IDENTIFIED BY 'test_passwd';
</code></pre> 
<p>后续登录时就可以通过下列连接命令登录。</p> 
<pre><code>mysql -h FE_HOST -P9030 -utest -ptest_passwd
</code></pre> 
<blockquote> 
 <p>新创建的普通用户默认没有任何权限。权限授予可以参考后面的权限授予。</p> 
</blockquote> 
<h3 id="_2-数据表的创建与数据导入"><a name="t20"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_2-%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5" rel="nofollow" title="#">#</a>2 数据表的创建与数据导入</h3> 
<h4 id="_2-1-创建数据库"><a name="t21"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_2-1-%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93" rel="nofollow" title="#">#</a>2.1 创建数据库</h4> 
<p>初始可以通过 root 或 admin 用户创建数据库：</p> 
<p><code>CREATE DATABASE example_db;</code></p> 
<blockquote> 
 <p>所有命令都可以使用 'HELP command;' 查看到详细的语法帮助。如：<code>HELP CREATE DATABASE;</code></p> 
</blockquote> 
<blockquote> 
 <p>如果不清楚命令的全名，可以使用 "help 命令某一字段" 进行模糊查询。如键入 'HELP CREATE'，可以匹配到 <code>CREATE DATABASE</code>, <code>CREATE TABLE</code>, <code>CREATE USER</code> 等命令。</p> 
</blockquote> 
<p>数据库创建完成之后，可以通过 <code>SHOW DATABASES;</code> 查看数据库信息。</p> 
<pre></pre> 
<ol><li> <p><code>MySQL&gt; SHOW DATABASES;</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| Database |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| example_db |</code></p> </li><li> <p><code>| information_schema |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>2 rows in set (0.00 sec)</code></p> </li></ol> 
<p>information_schema是为了兼容MySQL协议而存在，实际中信息可能不是很准确，所以关于具体数据库的信息建议通过直接查询相应数据库而获得。</p> 
<h4 id="_2-2-账户授权"><a name="t22"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_2-2-%E8%B4%A6%E6%88%B7%E6%8E%88%E6%9D%83" rel="nofollow" title="#">#</a>2.2 账户授权</h4> 
<p>example_db 创建完成之后，可以通过 root/admin 账户将 example_db 读写权限授权给普通账户，如 test。授权之后采用 test 账户登录就可以操作 example_db 数据库了。</p> 
<p><code>GRANT ALL ON example_db TO test;</code></p> 
<h4 id="_2-3-建表"><a name="t23"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_2-3-%E5%BB%BA%E8%A1%A8" rel="nofollow" title="#">#</a>2.3 建表</h4> 
<p>使用 <code>CREATE TABLE</code> 命令建立一个表(Table)。更多详细参数可以查看:</p> 
<p><code>HELP CREATE TABLE;</code></p> 
<p>首先切换数据库:</p> 
<p><code>USE example_db;</code></p> 
<p>Doris支持支持单分区和复合分区两种建表方式。</p> 
<p>在复合分区中：</p> 
<ul><li> <p>第一级称为 Partition，即分区。用户可以指定某一维度列作为分区列（当前只支持整型和时间类型的列），并指定每个分区的取值范围。</p> </li><li> <p>第二级称为 Distribution，即分桶。用户可以指定一个或多个维度列以及桶数对数据进行 HASH 分布。</p> </li></ul> 
<p>以下场景推荐使用复合分区</p> 
<ul><li>有时间维度或类似带有有序值的维度，可以以这类维度列作为分区列。分区粒度可以根据导入频次、分区数据量等进行评估。</li><li>历史数据删除需求：如有删除历史数据的需求（比如仅保留最近N 天的数据）。使用复合分区，可以通过删除历史分区来达到目的。也可以通过在指定分区内发送 DELETE 语句进行数据删除。</li><li>解决数据倾斜问题：每个分区可以单独指定分桶数量。如按天分区，当每天的数据量差异很大时，可以通过指定分区的分桶数，合理划分不同分区的数据,分桶列建议选择区分度大的列。</li></ul> 
<p>用户也可以不使用复合分区，即使用单分区。则数据只做 HASH 分布。</p> 
<p>下面以聚合模型为例，分别演示两种分区的建表语句。</p> 
<p><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#%E5%8D%95%E5%88%86%E5%8C%BA" rel="nofollow" title="#">#</a>单分区</p> 
<p>建立一个名字为 table1 的逻辑表。分桶列为 siteid，桶数为 10。</p> 
<p>这个表的 schema 如下：</p> 
<ul><li>siteid：类型是INT（4字节）, 默认值为10</li><li>citycode：类型是SMALLINT（2字节）</li><li>username：类型是VARCHAR, 最大长度为32, 默认值为空字符串</li><li>pv：类型是BIGINT（8字节）, 默认值是0; 这是一个指标列, Doris内部会对指标列做聚合操作, 这个列的聚合方法是求和（SUM）</li></ul> 
<p>建表语句如下:</p> 
<pre></pre> 
<ol><li> <p><code>CREATE TABLE table1</code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>siteid INT DEFAULT '10',</code></p> </li><li> <p><code>citycode SMALLINT,</code></p> </li><li> <p><code>username VARCHAR(32) DEFAULT '',</code></p> </li><li> <p><code>pv BIGINT SUM DEFAULT '0'</code></p> </li><li> <p><code>)</code></p> </li><li> <p><code>AGGREGATE KEY(siteid, citycode, username)</code></p> </li><li> <p><code>DISTRIBUTED BY HASH(siteid) BUCKETS 10</code></p> </li><li> <p><code>PROPERTIES("replication_num" = "1");</code></p> </li></ol> 
<p><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#%E5%A4%8D%E5%90%88%E5%88%86%E5%8C%BA" rel="nofollow" title="#">#</a>复合分区</p> 
<p>建立一个名字为 table2 的逻辑表。</p> 
<p>这个表的 schema 如下：</p> 
<ul><li>event_day：类型是DATE，无默认值</li><li>siteid：类型是INT（4字节）, 默认值为10</li><li>citycode：类型是SMALLINT（2字节）</li><li>username：类型是VARCHAR, 最大长度为32, 默认值为空字符串</li><li>pv：类型是BIGINT（8字节）, 默认值是0; 这是一个指标列, Doris 内部会对指标列做聚合操作, 这个列的聚合方法是求和（SUM）</li></ul> 
<p>我们使用 event_day 列作为分区列，建立3个分区: p201706, p201707, p201708</p> 
<ul><li>p201706：范围为 [最小值, 2017-07-01)</li><li>p201707：范围为 [2017-07-01, 2017-08-01)</li><li>p201708：范围为 [2017-08-01, 2017-09-01)</li></ul> 
<blockquote> 
 <p>注意区间为左闭右开。</p> 
</blockquote> 
<p>每个分区使用 siteid 进行哈希分桶，桶数为10</p> 
<p>建表语句如下:</p> 
<pre></pre> 
<ol><li> <p><code>CREATE TABLE table2</code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>event_day DATE,</code></p> </li><li> <p><code>siteid INT DEFAULT '10',</code></p> </li><li> <p><code>citycode SMALLINT,</code></p> </li><li> <p><code>username VARCHAR(32) DEFAULT '',</code></p> </li><li> <p><code>pv BIGINT SUM DEFAULT '0'</code></p> </li><li> <p><code>)</code></p> </li><li> <p><code>AGGREGATE KEY(event_day, siteid, citycode, username)</code></p> </li><li> <p><code>PARTITION BY RANGE(event_day)</code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>PARTITION p201706 VALUES LESS THAN ('2017-07-01'),</code></p> </li><li> <p><code>PARTITION p201707 VALUES LESS THAN ('2017-08-01'),</code></p> </li><li> <p><code>PARTITION p201708 VALUES LESS THAN ('2017-09-01')</code></p> </li><li> <p><code>)</code></p> </li><li> <p><code>DISTRIBUTED BY HASH(siteid) BUCKETS 10</code></p> </li><li> <p><code>PROPERTIES("replication_num" = "1");</code></p> </li></ol> 
<p>表建完之后，可以查看 example_db 中表的信息:</p> 
<pre></pre> 
<ol><li> <p><code>MySQL&gt; SHOW TABLES;</code></p> </li><li> <p><code>+----------------------+</code></p> </li><li> <p><code>| Tables_in_example_db |</code></p> </li><li> <p><code>+----------------------+</code></p> </li><li> <p><code>| table1 |</code></p> </li><li> <p><code>| table2 |</code></p> </li><li> <p><code>+----------------------+</code></p> </li><li> <p><code>2 rows in set (0.01 sec)</code></p> </li><li><li> <p><code>MySQL&gt; DESC table1;</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| Field | Type | Null | Key | Default | Extra |</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| siteid | int(11) | Yes | true | 10 | |</code></p> </li><li> <p><code>| citycode | smallint(6) | Yes | true | N/A | |</code></p> </li><li> <p><code>| username | varchar(32) | Yes | true | | |</code></p> </li><li> <p><code>| pv | bigint(20) | Yes | false | 0 | SUM |</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>4 rows in set (0.00 sec)</code></p> </li><li><li> <p><code>MySQL&gt; DESC table2;</code></p> </li><li> <p><code>+-----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| Field | Type | Null | Key | Default | Extra |</code></p> </li><li> <p><code>+-----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| event_day | date | Yes | true | N/A | |</code></p> </li><li> <p><code>| siteid | int(11) | Yes | true | 10 | |</code></p> </li><li> <p><code>| citycode | smallint(6) | Yes | true | N/A | |</code></p> </li><li> <p><code>| username | varchar(32) | Yes | true | | |</code></p> </li><li> <p><code>| pv | bigint(20) | Yes | false | 0 | SUM |</code></p> </li><li> <p><code>+-----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>5 rows in set (0.00 sec)</code></p> </li></ol> 
<blockquote> 
 <p>注意事项：</p> 
 <ol><li>上述表通过设置 replication_num 建的都是单副本的表，Doris建议用户采用默认的 3 副本设置，以保证高可用。</li><li>可以对复合分区表动态的增删分区。详见 <code>HELP ALTER TABLE</code> 中 Partition 相关部分。</li><li>数据导入可以导入指定的 Partition。详见 <code>HELP LOAD</code>。</li><li>可以动态修改表的 Schema。</li><li>可以对 Table 增加上卷表（Rollup）以提高查询性能，这部分可以参见高级使用指南关于 Rollup 的描述。</li><li>表的列的Null属性默认为true，会对查询性能有一定的影响。</li></ol> 
</blockquote> 
<h4 id="_2-4-导入数据"><a name="t24"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_2-4-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE" rel="nofollow" title="#">#</a>2.4 导入数据</h4> 
<p>Doris 支持多种数据导入方式。具体可以参阅数据导入文档。这里我们使用流式导入和 Broker 导入做示例。</p> 
<p><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#%E6%B5%81%E5%BC%8F%E5%AF%BC%E5%85%A5" rel="nofollow" title="#">#</a>流式导入</p> 
<p>流式导入通过 HTTP 协议向 Doris 传输数据，可以不依赖其他系统或组件直接导入本地数据。详细语法帮助可以参阅 <code>HELP STREAM LOAD;</code>。</p> 
<p>示例1：以 "table1_20170707" 为 Label，使用本地文件 table1_data 导入 table1 表。</p> 
<pre><code>curl --location-trusted -u test:test_passwd -H "label:table1_20170707" -H "column_separator:," -T table1_data http://FE_HOST:8030/api/example_db/table1/_stream_load
</code></pre> 
<blockquote> 
 <ol><li>FE_HOST 是任一 FE 所在节点 IP，8030 为 fe.conf 中的 http_port。</li><li>可以使用任一 BE 的 IP，以及 be.conf 中的 webserver_port 进行导入。如：<code>BE_HOST:8040</code></li></ol> 
</blockquote> 
<p>本地文件 <code>table1_data</code> 以 <code>,</code> 作为数据之间的分隔，具体内容如下：</p> 
<pre></pre> 
<ol><li> <p><code>1,1,jim,2</code></p> </li><li> <p><code>2,1,grace,2</code></p> </li><li> <p><code>3,2,tom,2</code></p> </li><li> <p><code>4,3,bush,3</code></p> </li><li> <p><code>5,3,helen,3</code></p> </li></ol> 
<p>示例2: 以 "table2_20170707" 为 Label，使用本地文件 table2_data 导入 table2 表。</p> 
<pre><code>curl --location-trusted -u test:test -H "label:table2_20170707" -H "column_separator:|" -T table2_data http://127.0.0.1:8030/api/example_db/table2/_stream_load
</code></pre> 
<p>本地文件 <code>table2_data</code> 以 <code>|</code> 作为数据之间的分隔，具体内容如下：</p> 
<pre></pre> 
<ol><li> <p><code>2017-07-03|1|1|jim|2</code></p> </li><li> <p><code>2017-07-05|2|1|grace|2</code></p> </li><li> <p><code>2017-07-12|3|2|tom|2</code></p> </li><li> <p><code>2017-07-15|4|3|bush|3</code></p> </li><li> <p><code>2017-07-12|5|3|helen|3</code></p> </li></ol> 
<blockquote> 
 <p>注意事项：</p> 
 <ol><li>采用流式导入建议文件大小限制在 10GB 以内，过大的文件会导致失败重试代价变大。</li><li>每一批导入数据都需要取一个 Label，Label 最好是一个和一批数据有关的字符串，方便阅读和管理。Doris 基于 Label 保证在一个Database 内，同一批数据只可导入成功一次。失败任务的 Label 可以重用。</li><li>流式导入是同步命令。命令返回成功则表示数据已经导入，返回失败表示这批数据没有导入。</li></ol> 
</blockquote> 
<p><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#broker-%E5%AF%BC%E5%85%A5" rel="nofollow" title="#">#</a>Broker 导入</p> 
<p>Broker 导入通过部署的 Broker 进程，读取外部存储上的数据进行导入。更多帮助请参阅 <code>HELP BROKER LOAD;</code></p> 
<p>示例：以 "table1_20170708" 为 Label，将 HDFS 上的文件导入 table1 表</p> 
<pre></pre> 
<ol><li> <p><code>LOAD LABEL table1_20170708</code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>DATA INFILE("hdfs://your.namenode.host:port/dir/table1_data")</code></p> </li><li> <p><code>INTO TABLE table1</code></p> </li><li> <p><code>)</code></p> </li><li> <p><code>WITH BROKER hdfs </code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>"username"="hdfs_user",</code></p> </li><li> <p><code>"password"="hdfs_password"</code></p> </li><li> <p><code>)</code></p> </li><li> <p><code>PROPERTIES</code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>"timeout"="3600",</code></p> </li><li> <p><code>"max_filter_ratio"="0.1"</code></p> </li><li> <p><code>);</code></p> </li></ol> 
<p>Broker 导入是异步命令。以上命令执行成功只表示提交任务成功。导入是否成功需要通过 <code>SHOW LOAD;</code> 查看。如：</p> 
<p><code>SHOW LOAD WHERE LABEL = "table1_20170708";</code></p> 
<p>返回结果中，<code>State</code> 字段为 FINISHED 则表示导入成功。</p> 
<p>关于 <code>SHOW LOAD</code> 的更多说明，可以参阅 <code>HELP SHOW LOAD;</code></p> 
<p>异步的导入任务在结束前可以取消：</p> 
<p><code>CANCEL LOAD WHERE LABEL = "table1_20170708";</code></p> 
<h3 id="_3-数据的查询"><a name="t25"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_3-%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9F%A5%E8%AF%A2" rel="nofollow" title="#">#</a>3 数据的查询</h3> 
<h4 id="_3-1-简单查询"><a name="t26"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_3-1-%E7%AE%80%E5%8D%95%E6%9F%A5%E8%AF%A2" rel="nofollow" title="#">#</a>3.1 简单查询</h4> 
<p>示例:</p> 
<pre></pre> 
<ol><li> <p><code>MySQL&gt; SELECT * FROM table1 LIMIT 3;</code></p> </li><li> <p><code>+--------+----------+----------+------+</code></p> </li><li> <p><code>| siteid | citycode | username | pv |</code></p> </li><li> <p><code>+--------+----------+----------+------+</code></p> </li><li> <p><code>| 2 | 1 | 'grace' | 2 |</code></p> </li><li> <p><code>| 5 | 3 | 'helen' | 3 |</code></p> </li><li> <p><code>| 3 | 2 | 'tom' | 2 |</code></p> </li><li> <p><code>+--------+----------+----------+------+</code></p> </li><li> <p><code>3 rows in set (0.01 sec)</code></p> </li><li><li> <p><code>MySQL&gt; SELECT * FROM table1 ORDER BY citycode;</code></p> </li><li> <p><code>+--------+----------+----------+------+</code></p> </li><li> <p><code>| siteid | citycode | username | pv |</code></p> </li><li> <p><code>+--------+----------+----------+------+</code></p> </li><li> <p><code>| 2 | 1 | 'grace' | 2 |</code></p> </li><li> <p><code>| 1 | 1 | 'jim' | 2 |</code></p> </li><li> <p><code>| 3 | 2 | 'tom' | 2 |</code></p> </li><li> <p><code>| 4 | 3 | 'bush' | 3 |</code></p> </li><li> <p><code>| 5 | 3 | 'helen' | 3 |</code></p> </li><li> <p><code>+--------+----------+----------+------+</code></p> </li><li> <p><code>5 rows in set (0.01 sec)</code></p> </li></ol> 
<h4 id="_3-3-join-查询"><a name="t27"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_3-3-join-%E6%9F%A5%E8%AF%A2" rel="nofollow" title="#">#</a>3.3 Join 查询</h4> 
<p>示例:</p> 
<pre></pre> 
<ol><li> <p><code>MySQL&gt; SELECT SUM(table1.pv) FROM table1 JOIN table2 WHERE table1.siteid = table2.siteid;</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| sum(`table1`.`pv`) |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| 12 |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>1 row in set (0.20 sec)</code></p> </li></ol> 
<h4 id="_3-4-子查询"><a name="t28"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_3-4-%E5%AD%90%E6%9F%A5%E8%AF%A2" rel="nofollow" title="#">#</a>3.4 子查询</h4> 
<p>示例:</p> 
<pre></pre> 
<ol><li> <p><code>MySQL&gt; SELECT SUM(pv) FROM table2 WHERE siteid IN (SELECT siteid FROM table1 WHERE siteid &gt; 2);</code></p> </li><li> <p><code>+-----------+</code></p> </li><li> <p><code>| sum(`pv`) |</code></p> </li><li> <p><code>+-----------+</code></p> </li><li> <p><code>| 8 |</code></p> </li><li> <p><code>+-----------+</code></p> </li><li> <p><code>1 row in set (0.13 sec)</code></p> </li></ol> 
<h2 id="高级使用指南"><a name="t29"></a>高级使用指南</h2> 
<p>这里我们介绍 Doris 的一些高级特性。</p> 
<h3 id="_1-表结构变更"><a name="t30"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/advance-usage.html#_1-%E8%A1%A8%E7%BB%93%E6%9E%84%E5%8F%98%E6%9B%B4" rel="nofollow" title="#">#</a>1 表结构变更</h3> 
<p>使用 ALTER TABLE 命令可以修改表的 Schema，包括如下修改：</p> 
<ul><li>增加列</li><li>删除列</li><li>修改列类型</li><li>改变列顺序</li></ul> 
<p>以下举例说明。</p> 
<p>原表 table1 的 Schema 如下:</p> 
<pre></pre> 
<ol><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| Field | Type | Null | Key | Default | Extra |</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| siteid | int(11) | No | true | 10 | |</code></p> </li><li> <p><code>| citycode | smallint(6) | No | true | N/A | |</code></p> </li><li> <p><code>| username | varchar(32) | No | true | | |</code></p> </li><li> <p><code>| pv | bigint(20) | No | false | 0 | SUM |</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li></ol> 
<p>我们新增一列 uv，类型为 BIGINT，聚合类型为 SUM，默认值为 0:</p> 
<p><code>ALTER TABLE table1 ADD COLUMN uv BIGINT SUM DEFAULT '0' after pv;</code></p> 
<p>提交成功后，可以通过以下命令查看作业进度:</p> 
<p><code>SHOW ALTER TABLE COLUMN;</code></p> 
<p>当作业状态为 FINISHED，则表示作业完成。新的 Schema 已生效。</p> 
<p>ALTER TABLE 完成之后, 可以通过 <code>DESC TABLE</code> 查看最新的 Schema。</p> 
<pre></pre> 
<ol><li> <p><code>mysql&gt; DESC table1;</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| Field | Type | Null | Key | Default | Extra |</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| siteid | int(11) | No | true | 10 | |</code></p> </li><li> <p><code>| citycode | smallint(6) | No | true | N/A | |</code></p> </li><li> <p><code>| username | varchar(32) | No | true | | |</code></p> </li><li> <p><code>| pv | bigint(20) | No | false | 0 | SUM |</code></p> </li><li> <p><code>| uv | bigint(20) | No | false | 0 | SUM |</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>5 rows in set (0.00 sec)</code></p> </li></ol> 
<p>可以使用以下命令取消当前正在执行的作业:</p> 
<p><code>CANCEL ALTER TABLE COLUMN FROM table1</code></p> 
<p>更多帮助，可以参阅 <code>HELP ALTER TABLE</code>。</p> 
<h3 id="_2-rollup"><a name="t31"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/advance-usage.html#_2-rollup" rel="nofollow" title="#">#</a>2 Rollup</h3> 
<p>Rollup 可以理解为 Table 的一个物化索引结构。<strong>物化</strong> 是因为其数据在物理上独立存储，而 <strong>索引</strong> 的意思是，Rollup可以调整列顺序以增加前缀索引的命中率，也可以减少key列以增加数据的聚合度。</p> 
<p>以下举例说明。</p> 
<p>原表table1的Schema如下:</p> 
<pre></pre> 
<ol><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| Field | Type | Null | Key | Default | Extra |</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| siteid | int(11) | No | true | 10 | |</code></p> </li><li> <p><code>| citycode | smallint(6) | No | true | N/A | |</code></p> </li><li> <p><code>| username | varchar(32) | No | true | | |</code></p> </li><li> <p><code>| pv | bigint(20) | No | false | 0 | SUM |</code></p> </li><li> <p><code>| uv | bigint(20) | No | false | 0 | SUM |</code></p> </li><li> <p><code>+----------+-------------+------+-------+---------+-------+</code></p> </li></ol> 
<p>对于 table1 明细数据是 siteid, citycode, username 三者构成一组 key，从而对 pv 字段进行聚合；如果业务方经常有看城市 pv 总量的需求，可以建立一个只有 citycode, pv 的rollup。</p> 
<p><code>ALTER TABLE table1 ADD ROLLUP rollup_city(citycode, pv);</code></p> 
<p>提交成功后，可以通过以下命令查看作业进度：</p> 
<p><code>SHOW ALTER TABLE ROLLUP;</code></p> 
<p>当作业状态为 FINISHED，则表示作业完成。</p> 
<p>Rollup 建立完成之后可以使用 <code>DESC table1 ALL</code> 查看表的 Rollup 信息。</p> 
<pre></pre> 
<ol><li> <p><code>mysql&gt; desc table1 all;</code></p> </li><li> <p><code>+-------------+----------+-------------+------+-------+--------+-------+</code></p> </li><li> <p><code>| IndexName | Field | Type | Null | Key | Default | Extra |</code></p> </li><li> <p><code>+-------------+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| table1 | siteid | int(11) | No | true | 10 | |</code></p> </li><li> <p><code>| | citycode | smallint(6) | No | true | N/A | |</code></p> </li><li> <p><code>| | username | varchar(32) | No | true | | |</code></p> </li><li> <p><code>| | pv | bigint(20) | No | false | 0 | SUM |</code></p> </li><li> <p><code>| | uv | bigint(20) | No | false | 0 | SUM |</code></p> </li><li> <p><code>| | | | | | | |</code></p> </li><li> <p><code>| rollup_city | citycode | smallint(6) | No | true | N/A | |</code></p> </li><li> <p><code>| | pv | bigint(20) | No | false | 0 | SUM |</code></p> </li><li> <p><code>+-------------+----------+-------------+------+-------+---------+-------+</code></p> </li><li> <p><code>8 rows in set (0.01 sec)</code></p> </li></ol> 
<p>可以使用以下命令取消当前正在执行的作业:</p> 
<p><code>CANCEL ALTER TABLE ROLLUP FROM table1;</code></p> 
<p>Rollup 建立之后，查询不需要指定 Rollup 进行查询。还是指定原有表进行查询即可。程序会自动判断是否应该使用 Rollup。是否命中 Rollup可以通过 <code>EXPLAIN your_sql;</code> 命令进行查看。</p> 
<p>更多帮助，可以参阅 <code>HELP ALTER TABLE</code>。</p> 
<h3 id="_2-数据表的查询"><a name="t32"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/advance-usage.html#_2-%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E6%9F%A5%E8%AF%A2" rel="nofollow" title="#">#</a>2 数据表的查询</h3> 
<h4 id="_2-1-内存限制"><a name="t33"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/advance-usage.html#_2-1-%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6" rel="nofollow" title="#">#</a>2.1 内存限制</h4> 
<p>为了防止用户的一个查询可能因为消耗内存过大。查询进行了内存控制，一个查询任务，在单个 BE 节点上默认使用不超过 2GB 内存。</p> 
<p>用户在使用时，如果发现报 <code>Memory limit exceeded</code> 错误，一般是超过内存限制了。</p> 
<p>遇到内存超限时，用户应该尽量通过优化自己的 sql 语句来解决。</p> 
<p>如果确切发现2GB内存不能满足，可以手动设置内存参数。</p> 
<p>显示查询内存限制:</p> 
<pre></pre> 
<ol><li> <p><code>mysql&gt; SHOW VARIABLES LIKE "%mem_limit%";</code></p> </li><li> <p><code>+---------------+------------+</code></p> </li><li> <p><code>| Variable_name | Value |</code></p> </li><li> <p><code>+---------------+------------+</code></p> </li><li> <p><code>| exec_mem_limit| 2147483648 |</code></p> </li><li> <p><code>+---------------+------------+</code></p> </li><li> <p><code>1 row in set (0.00 sec)</code></p> </li></ol> 
<p><code>exec_mem_limit</code> 的单位是 byte，可以通过 <code>SET</code> 命令改变 <code>exec_mem_limit</code> 的值。如改为 8GB。</p> 
<p><code>SET exec_mem_limit = 8589934592;</code></p> 
<pre></pre> 
<ol><li> <p><code>mysql&gt; SHOW VARIABLES LIKE "%mem_limit%";</code></p> </li><li> <p><code>+---------------+------------+</code></p> </li><li> <p><code>| Variable_name | Value |</code></p> </li><li> <p><code>+---------------+------------+</code></p> </li><li> <p><code>| exec_mem_limit| 8589934592 |</code></p> </li><li> <p><code>+---------------+------------+</code></p> </li><li> <p><code>1 row in set (0.00 sec)</code></p> </li></ol> 
<blockquote> 
 <ul><li>以上该修改为 session 级别，仅在当前连接 session 内有效。断开重连则会变回默认值。</li><li>如果需要修改全局变量，可以这样设置：<code>SET GLOBAL exec_mem_limit = 8589934592;</code>。设置完成后，断开 session 重新登录，参数将永久生效。</li></ul> 
</blockquote> 
<h4 id="_2-2-查询超时"><a name="t34"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/advance-usage.html#_2-2-%E6%9F%A5%E8%AF%A2%E8%B6%85%E6%97%B6" rel="nofollow" title="#">#</a>2.2 查询超时</h4> 
<p>当前默认查询时间设置为最长为 300 秒，如果一个查询在 300 秒内没有完成，则查询会被 Doris 系统 cancel 掉。用户可以通过这个参数来定制自己应用的超时时间，实现类似 wait(timeout) 的阻塞方式。</p> 
<p>查看当前超时设置:</p> 
<pre></pre> 
<ol><li> <p><code>mysql&gt; SHOW VARIABLES LIKE "%query_timeout%";</code></p> </li><li> <p><code>+---------------+-------+</code></p> </li><li> <p><code>| Variable_name | Value |</code></p> </li><li> <p><code>+---------------+-------+</code></p> </li><li> <p><code>| QUERY_TIMEOUT | 300 |</code></p> </li><li> <p><code>+---------------+-------+</code></p> </li><li> <p><code>1 row in set (0.00 sec)</code></p> </li></ol> 
<p>修改超时时间到1分钟:</p> 
<p><code>SET query_timeout = 60;</code></p> 
<blockquote> 
 <ul><li>当前超时的检查间隔为 5 秒，所以小于 5 秒的超时不会太准确。</li><li>以上修改同样为 session 级别。可以通过 <code>SET GLOBAL</code> 修改全局有效。</li></ul> 
</blockquote> 
<h4 id="_2-3-broadcast-shuffle-join"><a name="t35"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/advance-usage.html#_2-3-broadcast-shuffle-join" rel="nofollow" title="#">#</a>2.3 Broadcast/Shuffle Join</h4> 
<p>系统默认实现 Join 的方式，是将小表进行条件过滤后，将其广播到大表所在的各个节点上，形成一个内存 Hash 表，然后流式读出大表的数据进行Hash Join。但是如果当小表过滤后的数据量无法放入内存的话，此时 Join 将无法完成，通常的报错应该是首先造成内存超限。</p> 
<p>如果遇到上述情况，建议显式指定 Shuffle Join，也被称作 Partitioned Join。即将小表和大表都按照 Join 的 key 进行 Hash，然后进行分布式的 Join。这个对内存的消耗就会分摊到集群的所有计算节点上。</p> 
<p>Doris会自动尝试进行 Broadcast Join，如果预估小表过大则会自动切换至 Shuffle Join。注意，如果此时显式指定了 Broadcast Join 也会自动切换至 Shuffle Join。</p> 
<p>使用 Broadcast Join（默认）:</p> 
<pre></pre> 
<ol><li> <p><code>mysql&gt; select sum(table1.pv) from table1 join table2 where table1.siteid = 2;</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| sum(`table1`.`pv`) |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| 10 |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>1 row in set (0.20 sec)</code></p> </li></ol> 
<p>使用 Broadcast Join（显式指定）:</p> 
<pre></pre> 
<ol><li> <p><code>mysql&gt; select sum(table1.pv) from table1 join [broadcast] table2 where table1.siteid = 2;</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| sum(`table1`.`pv`) |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| 10 |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>1 row in set (0.20 sec)</code></p> </li></ol> 
<p>使用 Shuffle Join:</p> 
<pre></pre> 
<ol><li> <p><code>mysql&gt; select sum(table1.pv) from table1 join [shuffle] table2 where table1.siteid = 2;</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| sum(`table1`.`pv`) |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>| 10 |</code></p> </li><li> <p><code>+--------------------+</code></p> </li><li> <p><code>1 row in set (0.15 sec)</code></p> </li></ol> 
<h4 id="_2-4-查询重试和高可用"><a name="t36"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/advance-usage.html#_2-4-%E6%9F%A5%E8%AF%A2%E9%87%8D%E8%AF%95%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8" rel="nofollow" title="#">#</a>2.4 查询重试和高可用</h4> 
<p>当部署多个 FE 节点时，用户可以在多个 FE 之上部署负载均衡层来实现 Doris 的高可用。</p> 
<p>以下提供一些高可用的方案：</p> 
<p><strong>第一种</strong></p> 
<p>自己在应用层代码进行重试和负载均衡。比如发现一个连接挂掉，就自动在其他连接上进行重试。应用层代码重试需要应用自己配置多个doris前端节点地址。</p> 
<p><strong>第二种</strong></p> 
<p>如果使用 mysql jdbc connector 来连接Doris，可以使用 jdbc 的自动重试机制:</p> 
<pre><code>jdbc:mysql://[host:port],[host:port].../[database][?propertyName1][=propertyValue1][&amp;propertyName2][=propertyValue2]...
</code></pre> 
<p><strong>第三种</strong></p> 
<p>应用可以连接到和应用部署到同一机器上的 MySQL Proxy，通过配置 MySQL Proxy 的 Failover 和 Load Balance 功能来达到目的。</p> 
<p><code>http://dev.mysql.com/doc/refman/5.6/en/mysql-proxy-using.html</code></p> 
<p></p> 
<h2 id="数据模型、rollup-及前缀索引"><a name="t37"></a>数据模型、ROLLUP 及前缀索引</h2> 
<p>本文档主要从逻辑层面，描述 Doris 的数据模型、 ROLLUP 以及前缀索引的概念，以帮助用户更好的使用 Doris 应对不同的业务场景。</p> 
<h3 id="基本概念"><a name="t38"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5" rel="nofollow" title="#">#</a>基本概念</h3> 
<p>在 Doris 中，数据以表（Table）的形式进行逻辑上的描述。<br> 一张表包括行（Row）和列（Column）。Row 即用户的一行数据。Column 用于描述一行数据中不同的字段。</p> 
<p>Column 可以分为两大类：Key 和 Value。从业务角度看，Key 和 Value 可以分别对应维度列和指标列。</p> 
<p>Doris 的数据模型主要分为3类:</p> 
<ul><li>Aggregate</li><li>Uniq</li><li>Duplicate</li></ul> 
<p>下面我们分别介绍。</p> 
<h3 id="aggregate-模型"><a name="t39"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#aggregate-%E6%A8%A1%E5%9E%8B" rel="nofollow" title="#">#</a>Aggregate 模型</h3> 
<p>我们以实际的例子来说明什么是聚合模型，以及如何正确的使用聚合模型。</p> 
<h4 id="示例1-导入数据聚合"><a name="t40"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#%E7%A4%BA%E4%BE%8B1-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E8%81%9A%E5%90%88" rel="nofollow" title="#">#</a>示例1：导入数据聚合</h4> 
<p>假设业务有如下数据表模式：</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th><th>AggregationType</th><th>Comment</th></tr></thead><tbody><tr><td>user_id</td><td>LARGEINT</td><td></td><td>用户id</td></tr><tr><td>date</td><td>DATE</td><td></td><td>数据灌入日期</td></tr><tr><td>city</td><td>VARCHAR(20)</td><td></td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td></td><td>用户年龄</td></tr><tr><td>sex</td><td>TINYINT</td><td></td><td>用户性别</td></tr><tr><td>last_visit_date</td><td>DATETIME</td><td>REPLACE</td><td>用户最后一次访问时间</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr><tr><td>max_dwell_time</td><td>INT</td><td>MAX</td><td>用户最大停留时间</td></tr><tr><td>min_dwell_time</td><td>INT</td><td>MIN</td><td>用户最小停留时间</td></tr></tbody></table> 
<p>如果转换成建表语句则如下（省略建表语句中的 Partition 和 Distribution 信息）</p> 
<pre></pre> 
<ol><li> <p><code>CREATE TABLE IF NOT EXISTS example_db.expamle_tbl</code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>`user_id` LARGEINT NOT NULL COMMENT "用户id",</code></p> </li><li> <p><code>`date` DATE NOT NULL COMMENT "数据灌入日期时间",</code></p> </li><li> <p><code>`city` VARCHAR(20) COMMENT "用户所在城市",</code></p> </li><li> <p><code>`age` SMALLINT COMMENT "用户年龄",</code></p> </li><li> <p><code>`sex` TINYINT COMMENT "用户性别",</code></p> </li><li> <p><code>`last_visit_date` DATETIME REPLACE DEFAULT "1970-01-01 00:00:00" COMMENT "用户最后一次访问时间",</code></p> </li><li> <p><code>`cost` BIGINT SUM DEFAULT "0" COMMENT "用户总消费",</code></p> </li><li> <p><code>`max_dwell_time` INT MAX DEFAULT "0" COMMENT "用户最大停留时间",</code></p> </li><li> <p><code>`min_dwell_time` INT MIN DEFAULT "99999" COMMENT "用户最小停留时间"</code></p> </li><li> <p><code>)</code></p> </li><li> <p><code>AGGREGATE KEY(`user_id`, `date`, `city`, `age`, `sex`)</code></p> </li><li> <p><code>... /* 省略 Partition 和 Distribution 信息 */</code></p> </li><li> <p><code>；</code></p> </li></ol> 
<p>可以看到，这是一个典型的用户信息和访问行为的事实表。<br> 在一般星型模型中，用户信息和访问行为一般分别存放在维度表和事实表中。这里我们为了更加方便的解释 Doris 的数据模型，将两部分信息统一存放在一张表中。</p> 
<p>表中的列按照是否设置了 <code>AggregationType</code>，分为 Key (维度列) 和 Value（指标列）。没有设置 <code>AggregationType</code> 的，如 <code>user_id</code>、<code>date</code>、<code>age</code> ... 等称为 <strong>Key</strong>，而设置了 <code>AggregationType</code> 的称为 <strong>Value</strong>。</p> 
<p>当我们导入数据时，对于 Key 列相同的行会聚合成一行，而 Value 列会按照设置的 <code>AggregationType</code> 进行聚合。 <code>AggregationType</code> 目前有以下四种聚合方式：</p> 
<ol><li>SUM：求和，多行的 Value 进行累加。</li><li>REPLACE：替代，下一批数据中的 Value 会替换之前导入过的行中的 Value。</li><li>MAX：保留最大值。</li><li>MIN：保留最小值。</li></ol> 
<p>假设我们有以下导入数据（原始数据）：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>city</th><th>age</th><th>sex</th><th>last_visit_date</th><th>cost</th><th>max_dwell_time</th><th>min_dwell_time</th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 06:00:00</td><td>20</td><td>10</td><td>10</td></tr><tr><td>10000</td><td>2017-10-01</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>15</td><td>2</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 10:20:22</td><td>11</td><td>6</td><td>6</td></tr></tbody></table> 
<p>我们假设这是一张记录用户访问某商品页面行为的表。我们以第一行数据为例，解释如下：</p> 
<table><thead><tr><th>数据</th><th>说明</th></tr></thead><tbody><tr><td>10000</td><td>用户id，每个用户唯一识别id</td></tr><tr><td>2017-10-01</td><td>数据入库时间，精确到日期</td></tr><tr><td>北京</td><td>用户所在城市</td></tr><tr><td>20</td><td>用户年龄</td></tr><tr><td>0</td><td>性别男（1 代表女性）</td></tr><tr><td>2017-10-01 06:00:00</td><td>用户本次访问该页面的时间，精确到秒</td></tr><tr><td>20</td><td>用户本次访问产生的消费</td></tr><tr><td>10</td><td>用户本次访问，驻留该页面的时间</td></tr><tr><td>10</td><td>用户本次访问，驻留该页面的时间（冗余）</td></tr></tbody></table> 
<p>那么当这批数据正确导入到 Doris 中后，Doris 中最终存储如下：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>city</th><th>age</th><th>sex</th><th>last_visit_date</th><th>cost</th><th>max_dwell_time</th><th>min_dwell_time</th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>35</td><td>10</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 10:20:22</td><td>11</td><td>6</td><td>6</td></tr></tbody></table> 
<p>可以看到，用户 10000 只剩下了一行<strong>聚合后</strong>的数据。而其余用户的数据和原始数据保持一致。这里先解释下用户 10000 聚合后的数据：</p> 
<p>前5列没有变化，从第6列 <code>last_visit_date</code> 开始：</p> 
<ul><li> <p><code>2017-10-01 07:00:00</code>：因为 <code>last_visit_date</code> 列的聚合方式为 REPLACE，所以 <code>2017-10-01 07:00:00</code> 替换了 <code>2017-10-01 06:00:00</code> 保存了下来。</p> 
  <blockquote> 
   <p>注：在同一个导入批次中的数据，对于 REPLACE 这种聚合方式，替换顺序不做保证。如在这个例子中，最终保存下来的，也有可能是 <code>2017-10-01 06:00:00</code>。而对于不同导入批次中的数据，可以保证，后一批次的数据会替换前一批次。</p> 
  </blockquote> </li><li> <p><code>35</code>：因为 <code>cost</code> 列的聚合类型为 SUM，所以由 20 + 15 累加获得 35。</p> </li><li> <p><code>10</code>：因为 <code>max_dwell_time</code> 列的聚合类型为 MAX，所以 10 和 2 取最大值，获得 10。</p> </li><li> <p><code>2</code>：因为 <code>min_dwell_time</code> 列的聚合类型为 MIN，所以 10 和 2 取最小值，获得 2。</p> </li></ul> 
<p>经过聚合，Doris 中最终只会存储聚合后的数据。换句话说，即明细数据会丢失，用户不能够再查询到聚合前的明细数据了。</p> 
<h4 id="示例2-保留明细数据"><a name="t41"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#%E7%A4%BA%E4%BE%8B2-%E4%BF%9D%E7%95%99%E6%98%8E%E7%BB%86%E6%95%B0%E6%8D%AE" rel="nofollow" title="#">#</a>示例2：保留明细数据</h4> 
<p>接示例1，我们将表结构修改如下：</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th><th>AggregationType</th><th>Comment</th></tr></thead><tbody><tr><td>user_id</td><td>LARGEINT</td><td></td><td>用户id</td></tr><tr><td>date</td><td>DATE</td><td></td><td>数据灌入日期</td></tr><tr><td>timestamp</td><td>DATETIME</td><td></td><td>数据灌入时间，精确到秒</td></tr><tr><td>city</td><td>VARCHAR(20)</td><td></td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td></td><td>用户年龄</td></tr><tr><td>sex</td><td>TINYINT</td><td></td><td>用户性别</td></tr><tr><td>last_visit_date</td><td>DATETIME</td><td>REPLACE</td><td>用户最后一次访问时间</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr><tr><td>max_dwell_time</td><td>INT</td><td>MAX</td><td>用户最大停留时间</td></tr><tr><td>min_dwell_time</td><td>INT</td><td>MIN</td><td>用户最小停留时间</td></tr></tbody></table> 
<p>即增加了一列 <code>timestamp</code>，记录精确到秒的数据灌入时间。</p> 
<p>导入数据如下：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>timestamp</th><th>city</th><th>age</th><th>sex</th><th>last_visit_date</th><th>cost</th><th>max_dwell_time</th><th>min_dwell_time</th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>2017-10-01 08:00:05</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 06:00:00</td><td>20</td><td>10</td><td>10</td></tr><tr><td>10000</td><td>2017-10-01</td><td>2017-10-01 09:00:05</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>15</td><td>2</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>2017-10-01 18:12:10</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>2017-10-02 13:10:00</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>2017-10-02 13:15:00</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>2017-10-01 12:12:48</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>2017-10-03 12:38:20</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 10:20:22</td><td>11</td><td>6</td><td>6</td></tr></tbody></table> 
<p>那么当这批数据正确导入到 Doris 中后，Doris 中最终存储如下：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>timestamp</th><th>city</th><th>age</th><th>sex</th><th>last_visit_date</th><th>cost</th><th>max_dwell_time</th><th>min_dwell_time</th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>2017-10-01 08:00:05</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 06:00:00</td><td>20</td><td>10</td><td>10</td></tr><tr><td>10000</td><td>2017-10-01</td><td>2017-10-01 09:00:05</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>15</td><td>2</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>2017-10-01 18:12:10</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>2017-10-02 13:10:00</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>2017-10-02 13:15:00</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>2017-10-01 12:12:48</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>2017-10-03 12:38:20</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 10:20:22</td><td>11</td><td>6</td><td>6</td></tr></tbody></table> 
<p>我们可以看到，存储的数据，和导入数据完全一样，没有发生任何聚合。这是因为，这批数据中，因为加入了 <code>timestamp</code> 列，所有行的 Key 都<strong>不完全相同</strong>。也就是说，只要保证导入的数据中，每一行的 Key 都不完全相同，那么即使在聚合模型下，Doris 也可以保存完整的明细数据。</p> 
<h4 id="示例3-导入数据与已有数据聚合"><a name="t42"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#%E7%A4%BA%E4%BE%8B3-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%B7%B2%E6%9C%89%E6%95%B0%E6%8D%AE%E8%81%9A%E5%90%88" rel="nofollow" title="#">#</a>示例3：导入数据与已有数据聚合</h4> 
<p>接示例1。假设现在表中已有数据如下：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>city</th><th>age</th><th>sex</th><th>last_visit_date</th><th>cost</th><th>max_dwell_time</th><th>min_dwell_time</th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>35</td><td>10</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 10:20:22</td><td>11</td><td>6</td><td>6</td></tr></tbody></table> 
<p>我们再导入一批新的数据：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>city</th><th>age</th><th>sex</th><th>last_visit_date</th><th>cost</th><th>max_dwell_time</th><th>min_dwell_time</th></tr></thead><tbody><tr><td>10004</td><td>2017-10-03</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 11:22:00</td><td>44</td><td>19</td><td>19</td></tr><tr><td>10005</td><td>2017-10-03</td><td>长沙</td><td>29</td><td>1</td><td>2017-10-03 18:11:02</td><td>3</td><td>1</td><td>1</td></tr></tbody></table> 
<p>那么当这批数据正确导入到 Doris 中后，Doris 中最终存储如下：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>city</th><th>age</th><th>sex</th><th>last_visit_date</th><th>cost</th><th>max_dwell_time</th><th>min_dwell_time</th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>35</td><td>10</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 11:22:00</td><td>55</td><td>19</td><td>6</td></tr><tr><td>10005</td><td>2017-10-03</td><td>长沙</td><td>29</td><td>1</td><td>2017-10-03 18:11:02</td><td>3</td><td>1</td><td>1</td></tr></tbody></table> 
<p>可以看到，用户 10004 的已有数据和新导入的数据发生了聚合。同时新增了 10005 用户的数据。</p> 
<p>数据的聚合，在 Doris 中有如下三个阶段发生：</p> 
<ol><li>每一批次数据导入的 ETL 阶段。该阶段会在每一批次导入的数据内部进行聚合。</li><li>底层 BE 进行数据 Compaction 的阶段。该阶段，BE 会对已导入的不同批次的数据进行进一步的聚合。</li><li>数据查询阶段。在数据查询时，对于查询涉及到的数据，会进行对应的聚合。</li></ol> 
<p>数据在不同时间，可能聚合的程度不一致。比如一批数据刚导入时，可能还未与之前已存在的数据进行聚合。但是对于用户而言，用户<strong>只能查询到</strong>聚合后的数据。即不同的聚合程度对于用户查询而言是透明的。用户需始终认为数据以<strong>最终的完成的聚合程度</strong>存在，而<strong>不应假设某些聚合还未发生</strong>。（可参阅<strong>聚合模型的局限性</strong>一节获得更多详情。）</p> 
<h3 id="uniq-模型"><a name="t43"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#uniq-%E6%A8%A1%E5%9E%8B" rel="nofollow" title="#">#</a>Uniq 模型</h3> 
<p>在某些多维分析场景下，用户更关注的是如何保证 Key 的唯一性，即如何获得 Primary Key 唯一性约束。因此，我们引入了 Uniq 的数据模型。该模型本质上是聚合模型的一个特例，也是一种简化的表结构表示方式。我们举例说明。</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th><th>IsKey</th><th>Comment</th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td><td>Yes</td><td>用户id</td></tr><tr><td>username</td><td>VARCHAR(50)</td><td>Yes</td><td>用户昵称</td></tr><tr><td>city</td><td>VARCHAR(20)</td><td>No</td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td>No</td><td>用户年龄</td></tr><tr><td>sex</td><td>TINYINT</td><td>No</td><td>用户性别</td></tr><tr><td>phone</td><td>LARGEINT</td><td>No</td><td>用户电话</td></tr><tr><td>address</td><td>VARCHAR(500)</td><td>No</td><td>用户住址</td></tr><tr><td>register_time</td><td>DATETIME</td><td>No</td><td>用户注册时间</td></tr></tbody></table> 
<p>这是一个典型的用户基础信息表。这类数据没有聚合需求，只需保证主键唯一性。（这里的主键为 user_id + username）。那么我们的建表语句如下：</p> 
<pre></pre> 
<ol><li> <p><code>CREATE TABLE IF NOT EXISTS example_db.expamle_tbl</code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>`user_id` LARGEINT NOT NULL COMMENT "用户id",</code></p> </li><li> <p><code>`username` VARCHAR(50) NOT NULL COMMENT "用户昵称",</code></p> </li><li> <p><code>`city` VARCHAR(20) COMMENT "用户所在城市",</code></p> </li><li> <p><code>`age` SMALLINT COMMENT "用户年龄",</code></p> </li><li> <p><code>`sex` TINYINT COMMENT "用户性别",</code></p> </li><li> <p><code>`phone` LARGEINT COMMENT "用户电话",</code></p> </li><li> <p><code>`address` VARCHAR(500) COMMENT "用户地址",</code></p> </li><li> <p><code>`register_time` DATETIME COMMENT "用户注册时间"</code></p> </li><li> <p><code>)</code></p> </li><li> <p><code>UNIQUE KEY(`user_id`, `username`)</code></p> </li><li> <p><code>... /* 省略 Partition 和 Distribution 信息 */</code></p> </li><li> <p><code>；</code></p> </li></ol> 
<p>而这个表结构，完全同等于以下使用聚合模型描述的表结构：</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th><th>AggregationType</th><th>Comment</th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td><td></td><td>用户id</td></tr><tr><td>username</td><td>VARCHAR(50)</td><td></td><td>用户昵称</td></tr><tr><td>city</td><td>VARCHAR(20)</td><td>REPLACE</td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td>REPLACE</td><td>用户年龄</td></tr><tr><td>sex</td><td>TINYINT</td><td>REPLACE</td><td>用户性别</td></tr><tr><td>phone</td><td>LARGEINT</td><td>REPLACE</td><td>用户电话</td></tr><tr><td>address</td><td>VARCHAR(500)</td><td>REPLACE</td><td>用户住址</td></tr><tr><td>register_time</td><td>DATETIME</td><td>REPLACE</td><td>用户注册时间</td></tr></tbody></table> 
<p>及建表语句：</p> 
<pre></pre> 
<ol><li> <p><code>CREATE TABLE IF NOT EXISTS example_db.expamle_tbl</code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>`user_id` LARGEINT NOT NULL COMMENT "用户id",</code></p> </li><li> <p><code>`username` VARCHAR(50) NOT NULL COMMENT "用户昵称",</code></p> </li><li> <p><code>`city` VARCHAR(20) REPLACE COMMENT "用户所在城市",</code></p> </li><li> <p><code>`age` SMALLINT REPLACE COMMENT "用户年龄",</code></p> </li><li> <p><code>`sex` TINYINT REPLACE COMMENT "用户性别",</code></p> </li><li> <p><code>`phone` LARGEINT REPLACE COMMENT "用户电话",</code></p> </li><li> <p><code>`address` VARCHAR(500) REPLACE COMMENT "用户地址",</code></p> </li><li> <p><code>`register_time` DATETIME REPLACE COMMENT "用户注册时间"</code></p> </li><li> <p><code>)</code></p> </li><li> <p><code>AGGREGATE KEY(`user_id`, `username`)</code></p> </li><li> <p><code>... /* 省略 Partition 和 Distribution 信息 */</code></p> </li><li> <p><code>；</code></p> </li></ol> 
<p>即 Uniq 模型完全可以用聚合模型中的 REPLACE 方式替代。其内部的实现方式和数据存储方式也完全一样。这里不再继续举例说明。</p> 
<h3 id="duplicate-模型"><a name="t44"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#duplicate-%E6%A8%A1%E5%9E%8B" rel="nofollow" title="#">#</a>Duplicate 模型</h3> 
<p>在某些多维分析场景下，数据既没有主键，也没有聚合需求。因此，我们引入 Duplicate 数据模型来满足这类需求。举例说明。</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th><th>SortKey</th><th>Comment</th></tr></thead><tbody><tr><td>timestamp</td><td>DATETIME</td><td>Yes</td><td>日志时间</td></tr><tr><td>type</td><td>INT</td><td>Yes</td><td>日志类型</td></tr><tr><td>error_code</td><td>INT</td><td>Yes</td><td>错误码</td></tr><tr><td>error_msg</td><td>VARCHAR(1024)</td><td>No</td><td>错误详细信息</td></tr><tr><td>op_id</td><td>BIGINT</td><td>No</td><td>负责人id</td></tr><tr><td>op_time</td><td>DATETIME</td><td>No</td><td>处理时间</td></tr></tbody></table> 
<p>建表语句如下：</p> 
<pre></pre> 
<ol><li> <p><code>CREATE TABLE IF NOT EXISTS example_db.expamle_tbl</code></p> </li><li> <p><code>(</code></p> </li><li> <p><code>`timestamp` DATETIME NOT NULL COMMENT "日志时间",</code></p> </li><li> <p><code>`type` INT NOT NULL COMMENT "日志类型",</code></p> </li><li> <p><code>`error_code` INT COMMENT "错误码",</code></p> </li><li> <p><code>`error_msg` VARCHAR(1024) COMMENT "错误详细信息",</code></p> </li><li> <p><code>`op_id` BIGINT COMMENT "负责人id",</code></p> </li><li> <p><code>`op_time` DATETIME COMMENT "处理时间"</code></p> </li><li> <p><code>)</code></p> </li><li> <p><code>DUPLICATE KEY(`timestamp`, `type`)</code></p> </li><li> <p><code>... /* 省略 Partition 和 Distribution 信息 */</code></p> </li><li> <p><code>；</code></p> </li></ol> 
<p>这种数据模型区别于 Aggregate 和 Uniq 模型。数据完全按照导入文件中的数据进行存储，不会有任何聚合。即使两行数据完全相同，也都会保留。 而在建表语句中指定的 DUPLICATE KEY，只是用来指明底层数据按照那些列进行排序。（更贴切的名称应该为 “Sorted Column”，这里取名 “DUPLICATE KEY” 只是用以明确表示所用的数据模型。关于 “Sorted Column”的更多解释，可以参阅<strong>前缀索引</strong>小节）。在 DUPLICATE KEY 的选择上，我们建议适当的选择前 2-4 列就可以。</p> 
<p>这种数据模型适用于既没有聚合需求，又没有主键唯一性约束的原始数据的存储。更多使用场景，可参阅<strong>聚合模型的局限性</strong>小节。</p> 
<h3 id="rollup"><a name="t45"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#rollup" rel="nofollow" title="#">#</a>ROLLUP</h3> 
<p>ROLLUP 在多维分析中是“上卷”的意思，即将数据按某种指定的粒度进行进一步聚合。</p> 
<h4 id="基本概念-2"><a name="t46"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-2" rel="nofollow" title="#">#</a>基本概念</h4> 
<p>在 Doris 中，我们将用户通过建表语句创建出来的表称为 Base 表（Base Table）。Base 表中保存着按用户建表语句指定的方式存储的基础数据。</p> 
<p>在 Base 表之上，我们可以创建任意多个 ROLLUP 表。这些 ROLLUP 的数据是基于 Base 表产生的，并且在物理上是<strong>独立存储</strong>的。</p> 
<p>ROLLUP 表的基本作用，在于在 Base 表的基础上，获得更粗粒度的聚合数据。</p> 
<p>下面我们用示例详细说明在不同数据模型中的 ROLLUP 表及其作用。</p> 
<p><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#aggregate-%E5%92%8C-uniq-%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84-rollup" rel="nofollow" title="#">#</a>Aggregate 和 Uniq 模型中的 ROLLUP</p> 
<p>因为 Uniq 只是 Aggregate 模型的一个特例，所以这里我们不加以区别。</p> 
<ol><li>示例1：获得每个用户的总消费</li></ol> 
<p>接<strong>Aggregate 模型</strong>小节的<strong>示例2</strong>，Base 表结构如下：</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th><th>AggregationType</th><th>Comment</th></tr></thead><tbody><tr><td>user_id</td><td>LARGEINT</td><td></td><td>用户id</td></tr><tr><td>date</td><td>DATE</td><td></td><td>数据灌入日期</td></tr><tr><td>timestamp</td><td>DATETIME</td><td></td><td>数据灌入时间，精确到秒</td></tr><tr><td>city</td><td>VARCHAR(20)</td><td></td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td></td><td>用户年龄</td></tr><tr><td>sex</td><td>TINYINT</td><td></td><td>用户性别</td></tr><tr><td>last_visit_date</td><td>DATETIME</td><td>REPLACE</td><td>用户最后一次访问时间</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr><tr><td>max_dwell_time</td><td>INT</td><td>MAX</td><td>用户最大停留时间</td></tr><tr><td>min_dwell_time</td><td>INT</td><td>MIN</td><td>用户最小停留时间</td></tr></tbody></table> 
<p>存储的数据如下：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>timestamp</th><th>city</th><th>age</th><th>sex</th><th>last_visit_date</th><th>cost</th><th>max_dwell_time</th><th>min_dwell_time</th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>2017-10-01 08:00:05</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 06:00:00</td><td>20</td><td>10</td><td>10</td></tr><tr><td>10000</td><td>2017-10-01</td><td>2017-10-01 09:00:05</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>15</td><td>2</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>2017-10-01 18:12:10</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>2017-10-02 13:10:00</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>2017-10-02 13:15:00</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>2017-10-01 12:12:48</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>2017-10-03 12:38:20</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 10:20:22</td><td>11</td><td>6</td><td>6</td></tr></tbody></table> 
<p>在此基础上，我们创建一个 ROLLUP：</p> 
<table><thead><tr><th>ColumnName</th></tr></thead><tbody><tr><td>user_id</td></tr><tr><td>cost</td></tr></tbody></table> 
<p>该 ROLLUP 只包含两列：user_id 和 cost。则创建完成后，该 ROLLUP 中存储的数据如下：</p> 
<table><thead><tr><th>user_id</th><th>cost</th></tr></thead><tbody><tr><td>10000</td><td>35</td></tr><tr><td>10001</td><td>2</td></tr><tr><td>10002</td><td>200</td></tr><tr><td>10003</td><td>30</td></tr><tr><td>10004</td><td>111</td></tr></tbody></table> 
<p>可以看到，ROLLUP 中仅保留了每个 user_id，在 cost 列上的 SUM 的结果。那么当我们进行如下查询时:</p> 
<p><code>SELECT user_id, sum(cost) FROM table GROUP BY user_id;</code></p> 
<p>Doris 会自动命中这个 ROLLUP 表，从而只需扫描极少的数据量，即可完成这次聚合查询。</p> 
<ol><li>示例2：获得不同城市，不同年龄段用户的总消费、最长和最短页面驻留时间</li></ol> 
<p>紧接示例1。我们在 Base 表基础之上，再创建一个 ROLLUP：</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th><th>AggregationType</th><th>Comment</th></tr></thead><tbody><tr><td>city</td><td>VARCHAR(20)</td><td></td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td></td><td>用户年龄</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr><tr><td>max_dwell_time</td><td>INT</td><td>MAX</td><td>用户最大停留时间</td></tr><tr><td>min_dwell_time</td><td>INT</td><td>MIN</td><td>用户最小停留时间</td></tr></tbody></table> 
<p>则创建完成后，该 ROLLUP 中存储的数据如下：</p> 
<table><thead><tr><th>city</th><th>age</th><th>cost</th><th>max_dwell_time</th><th>min_dwell_time</th></tr></thead><tbody><tr><td>北京</td><td>20</td><td>0</td><td>30</td><td>10</td></tr><tr><td>北京</td><td>30</td><td>1</td><td>2</td><td>22</td></tr><tr><td>上海</td><td>20</td><td>1</td><td>200</td><td>5</td></tr><tr><td>广州</td><td>32</td><td>0</td><td>30</td><td>11</td></tr><tr><td>深圳</td><td>35</td><td>0</td><td>111</td><td>6</td></tr></tbody></table> 
<p>当我们进行如下这些查询时:</p> 
<ul><li><code>SELECT city, age, sum(cost), max(max_dwell_time), min(min_dwell_time) FROM table GROUP BY city, age;</code></li><li><code>SELECT city, sum(cost), max(max_dwell_time), min(min_dwell_time) FROM table GROUP BY city;</code></li><li><code>SELECT city, age, sum(cost), min(min_dwell_time) FROM table GROUP BY city, age;</code></li></ul> 
<p>Doris 会自动命中这个 ROLLUP 表。</p> 
<p><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#duplicate-%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84-rollup" rel="nofollow" title="#">#</a>Duplicate 模型中的 ROLLUP</p> 
<p>因为 Duplicate 模型没有聚合的语意。所以该模型中的 ROLLUP，已经失去了“上卷”这一层含义。而仅仅是作为调整列顺序，以命中前缀索引的作用。我们将在接下来的小节中，详细介绍前缀索引，以及如何使用ROLLUP改变前缀索引，以获得更好的查询效率。</p> 
<h4 id="前缀索引与-rollup"><a name="t47"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95%E4%B8%8E-rollup" rel="nofollow" title="#">#</a>前缀索引与 ROLLUP</h4> 
<p><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95" rel="nofollow" title="#">#</a>前缀索引</p> 
<p>不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。<br> 本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作为条件进行查找，会非常的高效。</p> 
<p>在 Aggregate、Uniq 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表语句中，AGGREGATE KEY、UNIQ KEY 和 DUPLICATE KEY 中指定的列进行排序存储的。</p> 
<p>而前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方式。</p> 
<p>我们将一行数据的前 <strong>36 个字节</strong> 作为这行数据的前缀索引。当遇到 VARCHAR 类型时，前缀索引会直接截断。我们举例说明：</p> 
<ol><li>以下表结构的前缀索引为 user_id(8Byte) + age(4Bytes) + message(prefix 20 Bytes)。</li></ol> 
<table><thead><tr><th>ColumnName</th><th>Type</th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td></tr><tr><td>age</td><td>INT</td></tr><tr><td>message</td><td>VARCHAR(100)</td></tr><tr><td>max_dwell_time</td><td>DATETIME</td></tr><tr><td>min_dwell_time</td><td>DATETIME</td></tr></tbody></table> 
<ol><li>以下表结构的前缀索引为 user_name(20 Bytes)。即使没有达到 36 个字节，因为遇到 VARCHAR，所以直接截断，不再往后继续。</li></ol> 
<table><thead><tr><th>ColumnName</th><th>Type</th></tr></thead><tbody><tr><td>user_name</td><td>VARCHAR(20)</td></tr><tr><td>age</td><td>INT</td></tr><tr><td>message</td><td>VARCHAR(100)</td></tr><tr><td>max_dwell_time</td><td>DATETIME</td></tr><tr><td>min_dwell_time</td><td>DATETIME</td></tr></tbody></table> 
<p>当我们的查询条件，是<strong>前缀索引的前缀</strong>时，可以极大的加快查询速度。比如在第一个例子中，我们执行如下查询：</p> 
<p><code>SELECT * FROM table WHERE user_id=1829239 and age=20；</code></p> 
<p>该查询的效率会<strong>远高于</strong>如下查询：</p> 
<p><code>SELECT * FROM table WHERE age=20；</code></p> 
<p>所以在建表时，<strong>正确的选择列顺序，能够极大地提高查询效率</strong>。</p> 
<p><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#rollup-%E8%B0%83%E6%95%B4%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95" rel="nofollow" title="#">#</a>ROLLUP 调整前缀索引</p> 
<p>因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过创建 ROLLUP 来人为的调整列顺序。举例说明。</p> 
<p>Base 表结构如下：</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td></tr><tr><td>age</td><td>INT</td></tr><tr><td>message</td><td>VARCHAR(100)</td></tr><tr><td>max_dwell_time</td><td>DATETIME</td></tr><tr><td>min_dwell_time</td><td>DATETIME</td></tr></tbody></table> 
<p>我们可以在此基础上创建一个 ROLLUP 表：</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th></tr></thead><tbody><tr><td>age</td><td>INT</td></tr><tr><td>user_id</td><td>BIGINT</td></tr><tr><td>message</td><td>VARCHAR(100)</td></tr><tr><td>max_dwell_time</td><td>DATETIME</td></tr><tr><td>min_dwell_time</td><td>DATETIME</td></tr></tbody></table> 
<p>可以看到，ROLLUP 和 Base 表的列完全一样，只是将 user_id 和 age 的顺序调换了。那么当我们进行如下查询时：</p> 
<p><code>SELECT * FROM table where age=20 and message LIKE "%error%";</code></p> 
<p>会优先选择 ROLLUP 表，因为 ROLLUP 的前缀索引匹配度更高。</p> 
<h4 id="rollup-的几点说明"><a name="t48"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#rollup-%E7%9A%84%E5%87%A0%E7%82%B9%E8%AF%B4%E6%98%8E" rel="nofollow" title="#">#</a>ROLLUP 的几点说明</h4> 
<ul><li>ROLLUP 最根本的作用是提高某些查询的查询效率（无论是通过聚合来减少数据量，还是修改列顺序以匹配前缀索引）。因此 ROLLUP 的含义已经超出了 “上卷” 的范围。这也是为什么我们在源代码中，将其命名为 Materialized Index（物化索引）的原因。</li><li>ROLLUP 是附属于 Base 表的，可以看做是 Base 表的一种辅助数据结构。用户可以在 Base 表的基础上，创建或删除 ROLLUP，但是不能在查询中显式的指定查询某 ROLLUP。是否命中 ROLLUP 完全由 Doris 系统自动决定。</li><li>ROLLUP 的数据是独立物理存储的。因此，创建的 ROLLUP 越多，占用的磁盘空间也就越大。同时对导入速度也会有影响（导入的ETL阶段会自动产生所有 ROLLUP 的数据），但是不会降低查询效率（只会更好）。</li><li>ROLLUP 的数据更新与 Base 表示完全同步的。用户无需关心这个问题。</li><li>ROLLUP 中列的聚合方式，与 Base 表完全相同。在创建 ROLLUP 无需指定，也不能修改。</li><li>查询能否命中 ROLLUP 的一个必要条件（非充分条件）是，查询所涉及的<strong>所有列</strong>（包括 select list 和 where 中的查询条件列等）都存在于该 ROLLUP 的列中。否则，查询只能命中 Base 表。</li><li>某些类型的查询（如 count(*)）在任何条件下，都无法命中 ROLLUP。具体参见接下来的 <strong>聚合模型的局限性</strong> 一节。</li><li>可以通过 <code>EXPLAIN your_sql;</code> 命令获得查询执行计划，在执行计划中，查看是否命中 ROLLUP。</li><li>可以通过 <code>DESC tbl_name ALL;</code> 语句显示 Base 表和所有已创建完成的 ROLLUP。</li></ul> 
<p>在这篇文档中可以查看 <a href="http://doris.apache.org/master/zh-CN/getting-started/hit-the-rollup" rel="nofollow" title="查询如何命中 Rollup">查询如何命中 Rollup</a></p> 
<h3 id="聚合模型的局限性"><a name="t49"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#%E8%81%9A%E5%90%88%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7" rel="nofollow" title="#">#</a>聚合模型的局限性</h3> 
<p>这里我们针对 Aggregate 模型（包括 Uniq 模型），来介绍下聚合模型的局限性。</p> 
<p>在聚合模型中，模型对外展现的，是<strong>最终聚合后的</strong>数据。也就是说，任何还未聚合的数据（比如说两个不同导入批次的数据），必须通过某种方式，以保证对外展示的一致性。我们举例说明。</p> 
<p>假设表结构如下：</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th><th>AggregationType</th><th>Comment</th></tr></thead><tbody><tr><td>user_id</td><td>LARGEINT</td><td></td><td>用户id</td></tr><tr><td>date</td><td>DATE</td><td></td><td>数据灌入日期</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr></tbody></table> 
<p>假设存储引擎中有如下两个已经导入完成的批次的数据：</p> 
<p><strong>batch 1</strong></p> 
<table><thead><tr><th>user_id</th><th>date</th><th>cost</th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>50</td></tr><tr><td>10002</td><td>2017-11-21</td><td>39</td></tr></tbody></table> 
<p><strong>batch 2</strong></p> 
<table><thead><tr><th>user_id</th><th>date</th><th>cost</th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>1</td></tr><tr><td>10001</td><td>2017-11-21</td><td>5</td></tr><tr><td>10003</td><td>2017-11-22</td><td>22</td></tr></tbody></table> 
<p>可以看到，用户 10001 分属在两个导入批次中的数据还没有聚合。但是为了保证用户只能查询到如下最终聚合后的数据：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>cost</th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>51</td></tr><tr><td>10001</td><td>2017-11-21</td><td>5</td></tr><tr><td>10002</td><td>2017-11-21</td><td>39</td></tr><tr><td>10003</td><td>2017-11-22</td><td>22</td></tr></tbody></table> 
<p>我们在查询引擎中加入了聚合算子，来保证数据对外的一致性。</p> 
<p>另外，在聚合列（Value）上，执行与聚合类型不一致的聚合类查询时，要注意语意。比如我们在如上示例中执行如下查询：</p> 
<p><code>SELECT MIN(cost) FROM table;</code></p> 
<p>得到的结果是 5，而不是 1。</p> 
<p>同时，这种一致性保证，在某些查询中，会极大的降低查询效率。</p> 
<p>我们以最基本的 count(*) 查询为例：</p> 
<p><code>SELECT COUNT(*) FROM table;</code></p> 
<p>在其他数据库中，这类查询都会很快的返回结果。因为在实现上，我们可以通过如“导入时对行进行计数，保存count的统计信息”，或者在查询时“仅扫描某一列数据，获得count值”的方式，只需很小的开销，即可获得查询结果。但是在 Doris 的聚合模型中，这种查询的开销<strong>非常大</strong>。</p> 
<p>我们以刚才的数据为例：</p> 
<p><strong>batch 1</strong></p> 
<table><thead><tr><th>user_id</th><th>date</th><th>cost</th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>50</td></tr><tr><td>10002</td><td>2017-11-21</td><td>39</td></tr></tbody></table> 
<p><strong>batch 2</strong></p> 
<table><thead><tr><th>user_id</th><th>date</th><th>cost</th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>1</td></tr><tr><td>10001</td><td>2017-11-21</td><td>5</td></tr><tr><td>10003</td><td>2017-11-22</td><td>22</td></tr></tbody></table> 
<p>因为最终的聚合结果为：</p> 
<table><thead><tr><th>user_id</th><th>date</th><th>cost</th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>51</td></tr><tr><td>10001</td><td>2017-11-21</td><td>5</td></tr><tr><td>10002</td><td>2017-11-21</td><td>39</td></tr><tr><td>10003</td><td>2017-11-22</td><td>22</td></tr></tbody></table> 
<p>所以，<code>select count(*) from table;</code> 的正确结果应该为 <strong>4</strong>。但如果我们只扫描 <code>user_id</code> 这一列，如果加上查询时聚合，最终得到的结果是 <strong>3</strong>（10001, 10002, 10003）。而如果不加查询时聚合，则得到的结果是 <strong>5</strong>（两批次一共5行数据）。可见这两个结果都是不对的。</p> 
<p>为了得到正确的结果，我们必须同时读取 <code>user_id</code> 和 <code>date</code> 这两列的数据，<strong>再加上查询时聚合</strong>，才能返回 <strong>4</strong> 这个正确的结果。也就是说，在 count(*) 查询中，Doris 必须扫描所有的 AGGREGATE KEY 列（这里就是 <code>user_id</code> 和 <code>date</code>），并且聚合后，才能得到语意正确的结果。当聚合列非常多时，count(*) 查询需要扫描大量的数据。</p> 
<p>因此，当业务上有频繁的 count(*) 查询时，我们建议用户通过增加一个<strong>值恒为 1 的，聚合类型为 SUM 的列来模拟 count(*)</strong>。如刚才的例子中的表结构，我们修改如下：</p> 
<table><thead><tr><th>ColumnName</th><th>Type</th><th>AggregateType</th><th>Comment</th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td><td></td><td>用户id</td></tr><tr><td>date</td><td>DATE</td><td></td><td>数据灌入日期</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr><tr><td>count</td><td>BIGINT</td><td>SUM</td><td>用于计算count</td></tr></tbody></table> 
<p>增加一个 count 列，并且导入数据中，该列值<strong>恒为 1</strong>。则 <code>select count(*) from table;</code> 的结果等价于 <code>select sum(count) from table;</code>。而后者的查询效率将远高于前者。不过这种方式也有使用限制，就是用户需要自行保证，不会重复导入 AGGREGATE KEY 列都相同的行。否则，<code>select sum(count) from table;</code> 只能表述原始导入的行数，而不是 <code>select count(*) from table;</code> 的语义。</p> 
<p>另一种方式，就是 <strong>将如上的 <code>count</code> 列的聚合类型改为 REPLACE，且依然值恒为 1</strong>。那么 <code>select sum(count) from table;</code> 和 <code>select count(*) from table;</code> 的结果将是一致的。并且这种方式，没有导入重复行的限制。</p> 
<h4 id="duplicate-模型-2"><a name="t50"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#duplicate-%E6%A8%A1%E5%9E%8B-2" rel="nofollow" title="#">#</a>Duplicate 模型</h4> 
<p>Duplicate 模型没有聚合模型的这个局限性。因为该模型不涉及聚合语意，在做 count(*) 查询时，任意选择一列查询，即可得到语意正确的结果。</p> 
<h3 id="数据模型的选择建议"><a name="t51"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/data-model-rollup.html#%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E6%8B%A9%E5%BB%BA%E8%AE%AE" rel="nofollow" title="#">#</a>数据模型的选择建议</h3> 
<p>因为数据模型在建表时就已经确定，且<strong>无法修改</strong>。所以，选择一个合适的数据模型<strong>非常重要</strong>。</p> 
<ol><li>Aggregate 模型可以通过预聚合，极大地降低聚合查询时所需扫描的数据量和查询的计算量，非常适合有固定模式的报表类查询场景。但是该模型对 count(*) 查询很不友好。同时因为固定了 Value 列上的聚合方式，在进行其他类型的聚合查询时，需要考虑语意正确性。</li><li>Uniq 模型针对需要唯一主键约束的场景，可以保证主键唯一性约束。但是无法利用 ROLLUP 等预聚合带来的查询优势（因为本质是 REPLACE，没有 SUM 这种聚合方式）。</li><li>Duplicate 适合任意维度的 Ad-hoc 查询。虽然同样无法利用预聚合的特性，但是不受聚合模型的约束，可以发挥列存模型的优势（只读取相关列，而不需要读取所有 Key 列）。</li></ol> 
<p></p> 
<h2 id="rollup-与查询"><a name="t52"></a>Rollup 与查询</h2> 
<p>在 Doris 里 Rollup 作为一份聚合物化视图，其在查询中可以起到两个作用：</p> 
<ul><li>索引</li><li>聚合数据（仅用于聚合模型，即aggregate key）</li></ul> 
<p>但是为了命中 Rollup 需要满足一定的条件，并且可以通过执行计划中 ScanNode 节点的 PreAggregation 的值来判断是否可以命中 Rollup，以及 Rollup 字段来判断命中的是哪一张 Rollup 表。</p> 
<h3 id="名词解释"><a name="t53"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/hit-the-rollup.html#%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A" rel="nofollow" title="#">#</a>名词解释</h3> 
<p>Base：基表。</p> 
<p>Rollup：一般指基于 Base 表创建的 Rollup 表，但在一些场景包括 Base 以及 Rollup 表。</p> 
<h3 id="索引"><a name="t54"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/hit-the-rollup.html#%E7%B4%A2%E5%BC%95" rel="nofollow" title="#">#</a>索引</h3> 
<p>前面的查询实践中已经介绍过 Doris 的前缀索引，即 Doris 会把 Base/Rollup 表中的前 36 个字节（有 varchar 类型则可能导致前缀索引不满 36 个字节，varchar 会截断前缀索引，并且最多使用 varchar 的 20 个字节）在底层存储引擎单独生成一份排序的稀疏索引数据(数据也是排序的，用索引定位，然后在数据中做二分查找)，然后在查询的时候会根据查询中的条件来匹配每个 Base/Rollup 的前缀索引，并且选择出匹配前缀索引最长的一个 Base/Rollup。</p> 
<pre></pre> 
<ol><li> <p><code>-----&gt; 从左到右匹配</code></p> </li><li> <p><code>+----+----+----+----+----+----+</code></p> </li><li> <p><code>| c1 | c2 | c3 | c4 | c5 |... |</code></p> </li></ol> 
<p>如上图，取查询中 where 以及 on 上下推到 ScanNode 的条件，从前缀索引的第一列开始匹配，检查条件中是否有这些列，有则累计匹配的长度，直到匹配不上或者36字节结束（varchar类型的列只能匹配20个字节，并且会匹配不足36个字节截断前缀索引），然后选择出匹配长度最长的一个 Base/Rollup，下面举例说明，创建了一张Base表以及四张rollup：</p> 
<pre></pre> 
<ol><li> <p><code>+---------------+-------+--------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| IndexName | Field | Type | Null | Key | Default | Extra |</code></p> </li><li> <p><code>+---------------+-------+--------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| test | k1 | TINYINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k2 | SMALLINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k3 | INT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k4 | BIGINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k5 | DECIMAL(9,3) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k6 | CHAR(5) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k7 | DATE | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k8 | DATETIME | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k9 | VARCHAR(20) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k10 | DOUBLE | Yes | false | N/A | MAX |</code></p> </li><li> <p><code>| | k11 | FLOAT | Yes | false | N/A | SUM |</code></p> </li><li> <p><code>| | | | | | | |</code></p> </li><li> <p><code>| rollup_index1 | k9 | VARCHAR(20) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k1 | TINYINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k2 | SMALLINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k3 | INT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k4 | BIGINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k5 | DECIMAL(9,3) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k6 | CHAR(5) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k7 | DATE | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k8 | DATETIME | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k10 | DOUBLE | Yes | false | N/A | MAX |</code></p> </li><li> <p><code>| | k11 | FLOAT | Yes | false | N/A | SUM |</code></p> </li><li> <p><code>| | | | | | | |</code></p> </li><li> <p><code>| rollup_index2 | k9 | VARCHAR(20) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k2 | SMALLINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k1 | TINYINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k3 | INT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k4 | BIGINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k5 | DECIMAL(9,3) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k6 | CHAR(5) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k7 | DATE | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k8 | DATETIME | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k10 | DOUBLE | Yes | false | N/A | MAX |</code></p> </li><li> <p><code>| | k11 | FLOAT | Yes | false | N/A | SUM |</code></p> </li><li> <p><code>| | | | | | | |</code></p> </li><li> <p><code>| rollup_index3 | k4 | BIGINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k5 | DECIMAL(9,3) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k6 | CHAR(5) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k1 | TINYINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k2 | SMALLINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k3 | INT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k7 | DATE | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k8 | DATETIME | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k9 | VARCHAR(20) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k10 | DOUBLE | Yes | false | N/A | MAX |</code></p> </li><li> <p><code>| | k11 | FLOAT | Yes | false | N/A | SUM |</code></p> </li><li> <p><code>| | | | | | | |</code></p> </li><li> <p><code>| rollup_index4 | k4 | BIGINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k6 | CHAR(5) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k5 | DECIMAL(9,3) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k1 | TINYINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k2 | SMALLINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k3 | INT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k7 | DATE | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k8 | DATETIME | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k9 | VARCHAR(20) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k10 | DOUBLE | Yes | false | N/A | MAX |</code></p> </li><li> <p><code>| | k11 | FLOAT | Yes | false | N/A | SUM |</code></p> </li><li> <p><code>+---------------+-------+--------------+------+-------+---------+-------+</code></p> </li></ol> 
<p>这五张表的前缀索引分别为</p> 
<pre></pre> 
<ol><li> <p><code>Base(k1 ,k2, k3, k4, k5, k6, k7)</code></p> </li><li><li> <p><code>rollup_index1(k9)</code></p> </li><li><li> <p><code>rollup_index2(k9)</code></p> </li><li><li> <p><code>rollup_index3(k4, k5, k6, k1, k2, k3, k7)</code></p> </li><li><li> <p><code>rollup_index4(k4, k6, k5, k1, k2, k3, k7)</code></p> </li><li></ol> 
<p>能用的上前缀索引的列上的条件需要是 <code>=</code> <code>&lt;</code> <code>&gt;</code> <code>&lt;=</code> <code>&gt;=</code> <code>in</code> <code>between</code> 这些并且这些条件是并列的且关系使用 <code>and</code> 连接，对于<code>or</code>、<code>!=</code> 等这些不能命中，然后看以下查询：</p> 
<p><code>SELECT * FROM test WHERE k1 = 1 AND k2 &gt; 3;</code></p> 
<p>有 k1 以及 k2 上的条件，检查只有 Base 的第一列含有条件里的 k1，所以匹配最长的前缀索引即 test，explain一下：</p> 
<pre></pre> 
<ol><li> <p><code>| 0:OlapScanNode </code></p> </li><li> <p><code>| TABLE: test </code></p> </li><li> <p><code>| PREAGGREGATION: OFF. Reason: No AggregateInfo </code></p> </li><li> <p><code>| PREDICATES: `k1` = 1, `k2` &gt; 3 </code></p> </li><li> <p><code>| partitions=1/1 </code></p> </li><li> <p><code>| rollup: test </code></p> </li><li> <p><code>| buckets=1/10 </code></p> </li><li> <p><code>| cardinality=-1 </code></p> </li><li> <p><code>| avgRowSize=0.0 </code></p> </li><li> <p><code>| numNodes=0 </code></p> </li><li> <p><code>| tuple ids: 0</code></p> </li></ol> 
<p>再看以下查询：</p> 
<p><code>SELECT * FROM test WHERE k4 = 1 AND k5 &gt; 3;</code></p> 
<p>有 k4 以及 k5 的条件，检查 rollup_index3、rollup_index4 的第一列含有 k4，但是 rollup_index3 的第二列含有k5，所以匹配的前缀索引最长。</p> 
<pre></pre> 
<ol><li> <p><code>| 0:OlapScanNode </code></p> </li><li> <p><code>| TABLE: test </code></p> </li><li> <p><code>| PREAGGREGATION: OFF. Reason: No AggregateInfo </code></p> </li><li> <p><code>| PREDICATES: `k4` = 1, `k5` &gt; 3 </code></p> </li><li> <p><code>| partitions=1/1 </code></p> </li><li> <p><code>| rollup: rollup_index3 </code></p> </li><li> <p><code>| buckets=10/10 </code></p> </li><li> <p><code>| cardinality=-1 </code></p> </li><li> <p><code>| avgRowSize=0.0 </code></p> </li><li> <p><code>| numNodes=0 </code></p> </li><li> <p><code>| tuple ids: 0</code></p> </li></ol> 
<p>现在我们尝试匹配含有 varchar 列上的条件，如下：</p> 
<p><code>SELECT * FROM test WHERE k9 IN ("xxx", "yyyy") AND k1 = 10;</code></p> 
<p>有 k9 以及 k1 两个条件，rollup_index1 以及 rollup_index2 的第一列都含有 k9，按理说这里选择这两个 rollup 都可以命中前缀索引并且效果是一样的随机选择一个即可（因为这里 varchar 刚好20个字节，前缀索引不足36个字节被截断），但是当前策略这里还会继续匹配 k1，因为 rollup_index1 的第二列为 k1，所以选择了 rollup_index1，其实后面的 k1 条件并不会起到加速的作用。(如果对于前缀索引外的条件需要其可以起到加速查询的目的，可以通过建立 Bloom Filter 过滤器加速。一般对于字符串类型建立即可，因为 Doris 针对列存在 Block 级别对于整形、日期已经有 Min/Max 索引) 以下是 explain 的结果。</p> 
<pre></pre> 
<ol><li> <p><code>| 0:OlapScanNode </code></p> </li><li> <p><code>| TABLE: test </code></p> </li><li> <p><code>| PREAGGREGATION: OFF. Reason: No AggregateInfo </code></p> </li><li> <p><code>| PREDICATES: `k9` IN ('xxx', 'yyyy'), `k1` = 10 </code></p> </li><li> <p><code>| partitions=1/1 </code></p> </li><li> <p><code>| rollup: rollup_index1 </code></p> </li><li> <p><code>| buckets=1/10 </code></p> </li><li> <p><code>| cardinality=-1 </code></p> </li><li> <p><code>| avgRowSize=0.0 </code></p> </li><li> <p><code>| numNodes=0 </code></p> </li><li> <p><code>| tuple ids: 0</code></p> </li></ol> 
<p>最后看一个多张Rollup都可以命中的查询：</p> 
<p><code>SELECT * FROM test WHERE k4 &lt; 1000 AND k5 = 80 AND k6 &gt;= 10000;</code></p> 
<p>有 k4,k5,k6 三个条件，rollup_index3 以及 rollup_index4 的前3列分别含有这三列，所以两者匹配的前缀索引长度一致，选取两者都可以，当前默认的策略为选取了比较早创建的一张 rollup，这里为 rollup_index3。</p> 
<pre></pre> 
<ol><li> <p><code>| 0:OlapScanNode </code></p> </li><li> <p><code>| TABLE: test </code></p> </li><li> <p><code>| PREAGGREGATION: OFF. Reason: No AggregateInfo </code></p> </li><li> <p><code>| PREDICATES: `k4` &lt; 1000, `k5` = 80, `k6` &gt;= 10000.0 </code></p> </li><li> <p><code>| partitions=1/1 </code></p> </li><li> <p><code>| rollup: rollup_index3 </code></p> </li><li> <p><code>| buckets=10/10 </code></p> </li><li> <p><code>| cardinality=-1 </code></p> </li><li> <p><code>| avgRowSize=0.0 </code></p> </li><li> <p><code>| numNodes=0 </code></p> </li><li> <p><code>| tuple ids: 0</code></p> </li></ol> 
<p>如果稍微修改上面的查询为：</p> 
<p><code>SELECT * FROM test WHERE k4 &lt; 1000 AND k5 = 80 OR k6 &gt;= 10000;</code></p> 
<p>则这里的查询不能命中前缀索引。（甚至 Doris 存储引擎内的任何 Min/Max,BloomFilter 索引都不能起作用)</p> 
<h3 id="聚合数据"><a name="t55"></a><a href="http://doris.apache.org/master/zh-CN/getting-started/hit-the-rollup.html#%E8%81%9A%E5%90%88%E6%95%B0%E6%8D%AE" rel="nofollow" title="#">#</a>聚合数据</h3> 
<p>当然一般的聚合物化视图其聚合数据的功能是必不可少的，这类物化视图对于聚合类查询或报表类查询都有非常大的帮助，要命中聚合物化视图需要下面一些前提：</p> 
<ol><li>查询或者子查询中涉及的所有列都存在一张独立的 Rollup 中。</li><li>如果查询或者子查询中有 Join，则 Join 的类型需要是 Inner join。</li></ol> 
<p>以下是可以命中Rollup的一些聚合查询的种类，</p> 
<table><thead><tr><th>列类型 查询类型</th><th>Sum</th><th>Distinct/Count Distinct</th><th>Min</th><th>Max</th><th>APPROX_COUNT_DISTINCT</th></tr></thead><tbody><tr><td>Key</td><td>false</td><td>true</td><td>true</td><td>true</td><td>true</td></tr><tr><td>Value(Sum)</td><td>true</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>Value(Replace)</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>Value(Min)</td><td>false</td><td>false</td><td>true</td><td>false</td><td>false</td></tr><tr><td>Value(Max)</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td></tr></tbody></table> 
<p>如果符合上述条件，则针对聚合模型在判断命中 Rollup 的时候会有两个阶段：</p> 
<ol><li>首先通过条件匹配出命中前缀索引索引最长的 Rollup 表，见上述索引策略。</li><li>然后比较 Rollup 的行数，选择最小的一张 Rollup。</li></ol> 
<p>如下 Base 表以及 Rollup：</p> 
<pre></pre> 
<ol><li> <p><code>+-------------+-------+--------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| IndexName | Field | Type | Null | Key | Default | Extra |</code></p> </li><li> <p><code>+-------------+-------+--------------+------+-------+---------+-------+</code></p> </li><li> <p><code>| test_rollup | k1 | TINYINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k2 | SMALLINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k3 | INT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k4 | BIGINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k5 | DECIMAL(9,3) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k6 | CHAR(5) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k7 | DATE | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k8 | DATETIME | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k9 | VARCHAR(20) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k10 | DOUBLE | Yes | false | N/A | MAX |</code></p> </li><li> <p><code>| | k11 | FLOAT | Yes | false | N/A | SUM |</code></p> </li><li> <p><code>| | | | | | | |</code></p> </li><li> <p><code>| rollup2 | k1 | TINYINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k2 | SMALLINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k3 | INT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k10 | DOUBLE | Yes | false | N/A | MAX |</code></p> </li><li> <p><code>| | k11 | FLOAT | Yes | false | N/A | SUM |</code></p> </li><li> <p><code>| | | | | | | |</code></p> </li><li> <p><code>| rollup1 | k1 | TINYINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k2 | SMALLINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k3 | INT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k4 | BIGINT | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k5 | DECIMAL(9,3) | Yes | true | N/A | |</code></p> </li><li> <p><code>| | k10 | DOUBLE | Yes | false | N/A | MAX |</code></p> </li><li> <p><code>| | k11 | FLOAT | Yes | false | N/A | SUM |</code></p> </li><li> <p><code>+-------------+-------+--------------+------+-------+---------+-------+</code></p> </li></ol> 
<p>看以下查询：</p> 
<p><code>SELECT SUM(k11) FROM test_rollup WHERE k1 = 10 AND k2 &gt; 200 AND k3 in (1,2,3);</code></p> 
<p>首先判断查询是否可以命中聚合的 Rollup表，经过查上面的图是可以的，然后条件中含有 k1,k2,k3 三个条件，这三个条件 test_rollup、rollup1、rollup2 的前三列都含有，所以前缀索引长度一致，然后比较行数显然 rollup2 的聚合程度最高行数最少所以选取 rollup2。</p> 
<pre></pre> 
<ol><li> <p><code>| 0:OlapScanNode |</code></p> </li><li> <p><code>| TABLE: test_rollup |</code></p> </li><li> <p><code>| PREAGGREGATION: ON |</code></p> </li><li> <p><code>| PREDICATES: `k1` = 10, `k2` &gt; 200, `k3` IN (1, 2, 3) |</code></p> </li><li> <p><code>| partitions=1/1 |</code></p> </li><li> <p><code>| rollup: rollup2 |</code></p> </li><li> <p><code>| buckets=1/10 |</code></p> </li><li> <p><code>| cardinality=-1 |</code></p> </li><li> <p><code>| avgRowSize=0.0 |</code></p> </li><li> <p><code>| numNodes=0 |</code></p> </li><li> <p><code>| tuple ids: 0 |</code></p> </li></ol> 
<p></p> 
<h2><a name="t56"></a>五、备份与恢复</h2> 
<p>Doris 支持将当前数据以文件的形式，通过 broker 备份到远端存储系统中。之后可以通过 恢复 命令，从远端存储系统中将数据恢复到任意 Doris 集群。通过这个功能，Doris 可以支持将数据定期的进行快照备份。也可以通过这个功能，在不同集群间进行数据迁移。</p> 
<p>该功能需要 Doris 版本 0.8.2+</p> 
<p>使用该功能，需要部署对应远端存储的 broker。如 BOS、HDFS 等。可以通过 <code>SHOW BROKER;</code> 查看当前部署的 broker。</p> 
<h3 id="简要原理说明"><a name="t57"></a><a href="http://doris.apache.org/master/zh-CN/administrator-guide/backup-restore.html#%E7%AE%80%E8%A6%81%E5%8E%9F%E7%90%86%E8%AF%B4%E6%98%8E" rel="nofollow" title="#">#</a>简要原理说明</h3> 
<h4 id="备份-backup"><a name="t58"></a><a href="http://doris.apache.org/master/zh-CN/administrator-guide/backup-restore.html#%E5%A4%87%E4%BB%BD-backup" rel="nofollow" title="#">#</a>备份（Backup）</h4> 
<p>备份操作是将指定表或分区的数据，直接以 Doris 存储的文件的形式，上传到远端仓库中进行存储。当用户提交 Backup 请求后，系统内部会做如下操作：</p> 
<ol><li> <p>快照及快照上传</p> <p>快照阶段会对指定的表或分区数据文件进行快照。之后，备份都是对快照进行操作。在快照之后，对表进行的更改、导入等操作都不再影响备份的结果。快照只是对当前数据文件产生一个硬链，耗时很少。快照完成后，会开始对这些快照文件进行逐一上传。快照上传由各个 Backend 并发完成。</p> </li><li> <p>元数据准备及上传</p> <p>数据文件快照上传完成后，Frontend 会首先将对应元数据写成本地文件，然后通过 broker 将本地元数据文件上传到远端仓库。完成最终备份作业。</p> </li></ol> 
<h4 id="恢复-restore"><a name="t59"></a><a href="http://doris.apache.org/master/zh-CN/administrator-guide/backup-restore.html#%E6%81%A2%E5%A4%8D-restore" rel="nofollow" title="#">#</a>恢复（Restore）</h4> 
<p>恢复操作需要指定一个远端仓库中已存在的备份，然后将这个备份的内容恢复到本地集群中。当用户提交 Restore 请求后，系统内部会做如下操作：</p> 
<ol><li> <p>在本地创建对应的元数据</p> <p>这一步首先会在本地集群中，创建恢复对应的表分区等结构。创建完成后，该表可见，但是不可访问。</p> </li><li> <p>本地snapshot</p> <p>这一步是将上一步创建的表做一个快照。这其实是一个空快照（因为刚创建的表是没有数据的），其目的主要是在 Backend 上产生对应的快照目录，用于之后接收从远端仓库下载的快照文件。</p> </li><li> <p>下载快照</p> <p>远端仓库中的快照文件，会被下载到对应的上一步生成的快照目录中。这一步由各个 Backend 并发完成。</p> </li><li> <p>生效快照</p> <p>快照下载完成后，我们要将各个快照映射为当前本地表的元数据。然后重新加载这些快照，使之生效，完成最终的恢复作业。</p> </li></ol> 
<h3 id="最佳实践"><a name="t60"></a><a href="http://doris.apache.org/master/zh-CN/administrator-guide/backup-restore.html#%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5" rel="nofollow" title="#">#</a>最佳实践</h3> 
<h4 id="备份"><a name="t61"></a><a href="http://doris.apache.org/master/zh-CN/administrator-guide/backup-restore.html#%E5%A4%87%E4%BB%BD" rel="nofollow" title="#">#</a>备份</h4> 
<p>当前我们支持最小分区（Partition）粒度的全量备份（增量备份有可能在未来版本支持）。如果需要对数据进行定期备份，首先需要在建表时，合理的规划表的分区及分桶，比如按时间进行分区。然后在之后的运行过程中，按照分区粒度进行定期的数据备份。</p> 
<h4 id="数据迁移"><a name="t62"></a><a href="http://doris.apache.org/master/zh-CN/administrator-guide/backup-restore.html#%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB" rel="nofollow" title="#">#</a>数据迁移</h4> 
<p>用户可以先将数据备份到远端仓库，再通过远端仓库将数据恢复到另一个集群，完成数据迁移。因为数据备份是通过快照的形式完成的，所以，在备份作业的快照阶段之后的新的导入数据，是不会备份的。因此，在快照完成后，到恢复作业完成这期间，在原集群上导入的数据，都需要在新集群上同样导入一遍。</p> 
<p>建议在迁移完成后，对新旧两个集群并行导入一段时间。完成数据和业务正确性校验后，再将业务迁移到新的集群。</p> 
<h3 id="重点说明"><a name="t63"></a><a href="http://doris.apache.org/master/zh-CN/administrator-guide/backup-restore.html#%E9%87%8D%E7%82%B9%E8%AF%B4%E6%98%8E" rel="nofollow" title="#">#</a>重点说明</h3> 
<ol><li>备份恢复相关的操作目前只允许拥有 ADMIN 权限的用户执行。</li><li>一个 Database 内，只允许有一个正在执行的备份或恢复作业。</li><li>备份和恢复都支持最小分区（Partition）级别的操作，当表的数据量很大时，建议按分区分别执行，以降低失败重试的代价。</li><li>因为备份恢复操作，操作的都是实际的数据文件。所以当一个表的分片过多，或者一个分片有过多的小版本时，可能即使总数据量很小，依然需要备份或恢复很长时间。用户可以通过 <code>SHOW PARTITIONS FROM table_name;</code> 和 <code>SHOW TABLET FROM table_name;</code> 来查看各个分区的分片数量，以及各个分片的文件版本数量，来预估作业执行时间。文件数量对作业执行的时间影响非常大，所以建议在建表时，合理规划分区分桶，以避免过多的分片。</li><li>当通过 <code>SHOW BACKUP</code> 或者 <code>SHOW RESTORE</code> 命令查看作业状态时。有可能会在 <code>TaskErrMsg</code> 一列中看到错误信息。但只要 <code>State</code> 列不为 <code>CANCELLED</code>，则说明作业依然在继续。这些 Task 有可能会重试成功。当然，有些 Task 错误，也会直接导致作业失败。</li><li>如果恢复作业是一次覆盖操作（指定恢复数据到已经存在的表或分区中），那么从恢复作业的 <code>COMMIT</code> 阶段开始，当前集群上被覆盖的数据有可能不能再被还原。此时如果恢复作业失败或被取消，有可能造成之前的数据已损坏且无法访问。这种情况下，只能通过再次执行恢复操作，并等待作业完成。因此，我们建议，如无必要，尽量不要使用覆盖的方式恢复数据，除非确认当前数据已不再使用。</li></ol> 
<h3 id="相关命令"><a name="t64"></a><a href="http://doris.apache.org/master/zh-CN/administrator-guide/backup-restore.html#%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4" rel="nofollow" title="#">#</a>相关命令</h3> 
<p>和备份恢复功能相关的命令如下。以下命令，都可以通过 mysql-client 连接 Doris 后，使用 <code>help cmd;</code> 的方式查看详细帮助。</p> 
<ol><li> <p>CREATE REPOSITORY</p> <p>创建一个远端仓库路径，用于备份或恢复。该命令需要借助 Broker 进程访问远端存储，不同的 Broker 需要提供不同的参数，具体请参阅 <a href="http://doris.apache.org/master/zh-CN/administrator-guide/broker.html" rel="nofollow" title="Broker文档">Broker文档</a>，也可以直接通过S3 协议备份到支持AWS S3协议的远程存储上去，具体参考 [创建远程仓库文档](../sql-reference/sql-statements/Data Definition/CREATE REPOSITORY.md)</p> </li><li> <p>BACKUP</p> <p>执行一次备份操作。</p> </li><li> <p>SHOW BACKUP</p> <p>查看最近一次 backup 作业的执行情况，包括：</p> 
  <ul><li>JobId：本次备份作业的 id。</li><li>SnapshotName：用户指定的本次备份作业的名称（Label）。</li><li>DbName：备份作业对应的 Database。</li><li>State：备份作业当前所在阶段： 
    <ul><li>PENDING：作业初始状态。</li><li>SNAPSHOTING：正在进行快照操作。</li><li>UPLOAD_SNAPSHOT：快照结束，准备上传。</li><li>UPLOADING：正在上传快照。</li><li>SAVE_META：正在本地生成元数据文件。</li><li>UPLOAD_INFO：上传元数据文件和本次备份作业的信息。</li><li>FINISHED：备份完成。</li><li>CANCELLED：备份失败或被取消。</li></ul></li><li>BackupObjs：本次备份涉及的表和分区的清单。</li><li>CreateTime：作业创建时间。</li><li>SnapshotFinishedTime：快照完成时间。</li><li>UploadFinishedTime：快照上传完成时间。</li><li>FinishedTime：本次作业完成时间。</li><li>UnfinishedTasks：在 <code>SNAPSHOTTING</code>，<code>UPLOADING</code> 等阶段，会有多个子任务在同时进行，这里展示的当前阶段，未完成的子任务的 task id。</li><li>TaskErrMsg：如果有子任务执行出错，这里会显示对应子任务的错误信息。</li><li>Status：用于记录在整个作业过程中，可能出现的一些状态信息。</li><li>Timeout：作业的超时时间，单位是秒。</li></ul></li><li> <p>SHOW SNAPSHOT</p> <p>查看远端仓库中已存在的备份。</p> 
  <ul><li>Snapshot：备份时指定的该备份的名称（Label）。</li><li>Timestamp：备份的时间戳。</li><li>Status：该备份是否正常。</li></ul><p>如果在 <code>SHOW SNAPSHOT</code> 后指定了 where 子句，则可以显示更详细的备份信息。</p> 
  <ul><li>Database：备份时对应的 Database。</li><li>Details：展示了该备份完整的数据目录结构。</li></ul></li><li> <p>RESTORE</p> <p>执行一次恢复操作。</p> </li><li> <p>SHOW RESTORE</p> <p>查看最近一次 restore 作业的执行情况，包括：</p> 
  <ul><li>JobId：本次恢复作业的 id。</li><li>Label：用户指定的仓库中备份的名称（Label）。</li><li>Timestamp：用户指定的仓库中备份的时间戳。</li><li>DbName：恢复作业对应的 Database。</li><li>State：恢复作业当前所在阶段： 
    <ul><li>PENDING：作业初始状态。</li><li>SNAPSHOTING：正在进行本地新建表的快照操作。</li><li>DOWNLOAD：正在发送下载快照任务。</li><li>DOWNLOADING：快照正在下载。</li><li>COMMIT：准备生效已下载的快照。</li><li>COMMITTING：正在生效已下载的快照。</li><li>FINISHED：恢复完成。</li><li>CANCELLED：恢复失败或被取消。</li></ul></li><li>AllowLoad：恢复期间是否允许导入。</li><li>ReplicationNum：恢复指定的副本数。</li><li>RestoreObjs：本次恢复涉及的表和分区的清单。</li><li>CreateTime：作业创建时间。</li><li>MetaPreparedTime：本地元数据生成完成时间。</li><li>SnapshotFinishedTime：本地快照完成时间。</li><li>DownloadFinishedTime：远端快照下载完成时间。</li><li>FinishedTime：本次作业完成时间。</li><li>UnfinishedTasks：在 <code>SNAPSHOTTING</code>，<code>DOWNLOADING</code>, <code>COMMITTING</code> 等阶段，会有多个子任务在同时进行，这里展示的当前阶段，未完成的子任务的 task id。</li><li>TaskErrMsg：如果有子任务执行出错，这里会显示对应子任务的错误信息。</li><li>Status：用于记录在整个作业过程中，可能出现的一些状态信息。</li><li>Timeout：作业的超时时间，单位是秒。</li></ul></li><li> <p>CANCEL BACKUP</p> <p>取消当前正在执行的备份作业。</p> </li><li> <p>CANCEL RESTORE</p> <p>取消当前正在执行的恢复作业。</p> </li><li> <p>DROP REPOSITORY</p> <p>删除已创建的远端仓库。删除仓库，仅仅是删除该仓库在 Doris 中的映射，不会删除实际的仓库数据。</p> </li></ol>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9d0d135d471d69885aa092ae379d0add/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">关于js内部处理方法的那点事</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a69fe03bad9ed069047e5135269f2ba5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">js数组去重</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>