<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>李宏毅机器学习第十八周周报GAN2 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="李宏毅机器学习第十八周周报GAN2" />
<meta property="og:description" content="文章目录 week 18 GAN2摘要Abstract一、Theory behind GAN1. 训练目的2. Wasserstein distance 二、文献阅读1. 题目2. abstract3. 网络架构3.1 Wasserstein Distance3.2 Wassertein GANs3.3 Gradient penalty 4. 文献解读4.1 Introduction4.2 创新点4.3 实验过程4.3.1 Difficulties with weight constraint4.3.2 单一数据集上训练随机架构4.3.3 LSUN上训练多种框架4.3.4 改进权重裁剪的性能4.3.5 CIFAR-10和LSUN的样本质量4.3.6 使用连续的生成器对离散数据进行建模 4.4 结论 三、WGAN小结参考文献 week 18 GAN2 注：关于wasserstein的详细解释见第二部分3.1
摘要 本文主要讨论了生成式对抗神经网络。首先，本文介绍了Original GAN的缺点。在此基础下，本文阐述了多种改进GAN的方案。例如，以Wasserstein distance为评价标准构建WGAN。其次本文展示了题为Improved training of wasserstein GANs的论文主要内容。这篇论文探讨了WGAN的结构，并给出了其在训练过程中难以收敛，或者收敛后效果不佳的原因。在此基础上，该文提出了基于gradient penalty的新框架，该框架能够充分利用网络容量以及降低梯度爆炸以及消失。最后，本文基于pytorch以及MNIST数据集实现了WGAN绘制手写数字。
Abstract This article mainly discusses Generative Adversarial Networks (GANs). Firstly, this article introduces disadvantage of Generative Adversarial Networks. Building upon this foundation, the article elucidates the improvement scenarios of GANs." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/c08a91e8a49dc9ad59995dfbb3a84f8c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-25T20:51:47+08:00" />
<meta property="article:modified_time" content="2023-11-25T20:51:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">李宏毅机器学习第十八周周报GAN2</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#week_18_GAN2_3" rel="nofollow">week 18 GAN2</a></li><li><a href="#_7" rel="nofollow">摘要</a></li><li><a href="#Abstract_11" rel="nofollow">Abstract</a></li><li><a href="#Theory_behind_GAN_15" rel="nofollow">一、Theory behind GAN</a></li><li><ul><li><a href="#1__17" rel="nofollow">1. 训练目的</a></li><li><a href="#2_Wasserstein_distance_55" rel="nofollow">2. Wasserstein distance</a></li></ul> 
  </li><li><a href="#_105" rel="nofollow">二、文献阅读</a></li><li><ul><li><a href="#1__107" rel="nofollow">1. 题目</a></li><li><a href="#2_abstract_115" rel="nofollow">2. abstract</a></li><li><a href="#3__121" rel="nofollow">3. 网络架构</a></li><li><ul><li><a href="#31_Wasserstein_Distance_132" rel="nofollow">3.1 Wasserstein Distance</a></li><li><a href="#32_Wassertein_GANs_149" rel="nofollow">3.2 Wassertein GANs</a></li><li><a href="#33_Gradient_penalty_168" rel="nofollow">3.3 Gradient penalty</a></li></ul> 
   </li><li><a href="#4__189" rel="nofollow">4. 文献解读</a></li><li><ul><li><a href="#41_Introduction_191" rel="nofollow">4.1 Introduction</a></li><li><a href="#42__197" rel="nofollow">4.2 创新点</a></li><li><a href="#43__202" rel="nofollow">4.3 实验过程</a></li><li><ul><li><a href="#431_Difficulties_with_weight_constraint_204" rel="nofollow">4.3.1 Difficulties with weight constraint</a></li><li><a href="#432__226" rel="nofollow">4.3.2 单一数据集上训练随机架构</a></li><li><a href="#433_LSUN_236" rel="nofollow">4.3.3 LSUN上训练多种框架</a></li><li><a href="#434__255" rel="nofollow">4.3.4 改进权重裁剪的性能</a></li><li><a href="#435_CIFAR10LSUN_263" rel="nofollow">4.3.5 CIFAR-10和LSUN的样本质量</a></li><li><a href="#436__273" rel="nofollow">4.3.6 使用连续的生成器对离散数据进行建模</a></li></ul> 
    </li><li><a href="#44__279" rel="nofollow">4.4 结论</a></li></ul> 
  </li></ul> 
  </li><li><a href="#WGAN_283" rel="nofollow">三、WGAN</a></li><li><ul><li><a href="#_479" rel="nofollow">小结</a></li><li><a href="#_483" rel="nofollow">参考文献</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="week_18_GAN2_3"></a>week 18 GAN2</h2> 
<blockquote> 
 <p>注：关于wasserstein的详细解释见第二部分3.1</p> 
</blockquote> 
<h2><a id="_7"></a>摘要</h2> 
<p>本文主要讨论了生成式对抗神经网络。首先，本文介绍了Original GAN的缺点。在此基础下，本文阐述了多种改进GAN的方案。例如，以Wasserstein distance为评价标准构建WGAN。其次本文展示了题为Improved training of wasserstein GANs的论文主要内容。这篇论文探讨了WGAN的结构，并给出了其在训练过程中难以收敛，或者收敛后效果不佳的原因。在此基础上，该文提出了基于gradient penalty的新框架，该框架能够充分利用网络容量以及降低梯度爆炸以及消失。最后，本文基于pytorch以及MNIST数据集实现了WGAN绘制手写数字。</p> 
<h2><a id="Abstract_11"></a>Abstract</h2> 
<p>This article mainly discusses Generative Adversarial Networks (GANs). Firstly, this article introduces disadvantage of Generative Adversarial Networks. Building upon this foundation, the article elucidates the improvement scenarios of GANs. For example, WGAN’s evaluation criterion is the Wasserstein distance. Next, the article presents the key contents of the paper titled “Improved training of wasserstein GANs”. This paper explores the structure of WGAN and gives the reasons why it is difficult to converge during training, or does not work well after convergence. On this basis, this paper proposes a new framework based on gradient penalty, which can make full use of network capacity and reduce gradient explosion and disappearance. Finally, based on PyTorch and the MNIST dataset, this article implements WGAN to generate hand-written digits.</p> 
<h2><a id="Theory_behind_GAN_15"></a>一、Theory behind GAN</h2> 
<h3><a id="1__17"></a>1. 训练目的</h3> 
<p><img src="https://images2.imgbox.com/bc/b4/a6AN5Yuk_o.png" alt="在这里插入图片描述"></p> 
<p>生成器的目标是使得生成数据分布<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
        
          G 
         
        
       
      
        P_G 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>尽可能逼近真实数据分布<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
         
         
           d 
          
         
           a 
          
         
           t 
          
         
           a 
          
         
        
       
      
        P_{data} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></p> 
<p>使用公式表达，即<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
        
          ∗ 
         
        
       
         = 
        
       
         a 
        
       
         r 
        
       
         g 
        
        
         
         
           min 
          
         
           ⁡ 
          
         
        
          G 
         
        
       
         D 
        
       
         i 
        
       
         v 
        
       
         ( 
        
        
        
          P 
         
        
          G 
         
        
       
         , 
        
        
        
          P 
         
         
         
           d 
          
         
           a 
          
         
           t 
          
         
           a 
          
         
        
       
         ) 
        
       
      
        G^*=arg\min_GDiv(P_G,P_{data}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6887em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>，</p> 
<p>或称使得真实分布与生成分布之间的差异尽可能小</p> 
<p>在其他模型中，难以对生成式目标的数据分布进行拟合，但在GAN中提供了计算了拟合分布与真实分布之间差异的方案</p> 
<p>该方案依赖于生成式对抗网络的结构。首先数据获取，从数据库采样一部分真实数据，然后将简单向量取样并输入生成器，生成器会根据输入向量以及当前的拟合分布输出样本。其次是下文讲解的辨别器部分</p> 
<p><img src="https://images2.imgbox.com/af/6e/k2ZCZ4EQ_o.png" alt="在这里插入图片描述"></p> 
<p>以下按照原文中二元分类器的思路进行讲解辨别器</p> 
<p>训练目标<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          D 
         
        
          ∗ 
         
        
       
         = 
        
       
         a 
        
       
         r 
        
       
         g 
        
        
         
         
           max 
          
         
           ⁡ 
          
         
        
          D 
         
        
       
         V 
        
       
         ( 
        
       
         D 
        
       
         , 
        
       
         G 
        
       
         ) 
        
       
      
        D^*=arg\max_DV(D,G) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">G</span><span class="mclose">)</span></span></span></span></span>，即该值与JS差异相近（具体推导详见week17）</p> 
<p>由此设计对应的目标函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         V 
        
       
         ( 
        
       
         G 
        
       
         , 
        
       
         D 
        
       
         ) 
        
       
         = 
        
        
        
          E 
         
         
         
           y 
          
         
           ∼ 
          
          
          
            P 
           
           
           
             d 
            
           
             a 
            
           
             t 
            
           
             a 
            
           
          
         
        
       
         [ 
        
       
         l 
        
       
         o 
        
       
         g 
        
       
         D 
        
       
         ( 
        
       
         y 
        
       
         ) 
        
       
         ] 
        
       
         + 
        
        
        
          E 
         
         
         
           y 
          
         
           ∼ 
          
          
          
            P 
           
          
            G 
           
          
         
        
       
         [ 
        
       
         l 
        
       
         o 
        
       
         g 
        
       
         ( 
        
       
         1 
        
       
         − 
        
       
         D 
        
       
         ( 
        
       
         y 
        
       
         ) 
        
       
         ) 
        
       
         ] 
        
       
      
        V(G,D)=E_{y\sim P_{data}}[logD(y)]+E_{y\sim P_G}[log(1-D(y))] 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0576em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: -0.1389em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mclose">)]</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0576em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3567em; margin-left: -0.1389em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1433em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mclose">))]</span></span></span></span></span></p> 
<p>上述函数的目的是增强分辨器识别真实分布的能力，从而当取真实数据时D(y)越大，当取生成数据时D(y)越小</p> 
<p>也可以将其理解为负的交叉熵，而训练的目的是使得两个分布之间的交叉熵尽可能小</p> 
<p><img src="https://images2.imgbox.com/78/9a/p2mHuIzN_o.png" alt="在这里插入图片描述"></p> 
<p>简单来说，在初始阶段两个分布的差异较大，分类器能够很简单的分辨出两个分布。因此生成器能够趋近真实分布，即缩小两者的差异。此时，分类器难以分辨出真实分布与生成分布。（具体推导详见week17）</p> 
<p>综上，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          G 
         
        
          ∗ 
         
        
       
         = 
        
       
         a 
        
       
         r 
        
       
         g 
        
        
         
         
           min 
          
         
           ⁡ 
          
         
        
          G 
         
        
        
         
         
           max 
          
         
           ⁡ 
          
         
        
          D 
         
        
       
         V 
        
       
         ( 
        
       
         G 
        
       
         , 
        
       
         D 
        
       
         ) 
        
       
      
        G^*=arg\min_G\max_DV(G,D) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6887em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mclose">)</span></span></span></span></span>，从而可以按照week17第一部分中阐述的训练过程训练模型</p> 
<p>且<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          D 
         
        
          ∗ 
         
        
       
         = 
        
       
         a 
        
       
         r 
        
       
         g 
        
        
         
         
           max 
          
         
           ⁡ 
          
         
        
          D 
         
        
       
         V 
        
       
         ( 
        
       
         D 
        
       
         , 
        
       
         G 
        
       
         ) 
        
       
      
        D^*=arg\max_DV(D,G) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">G</span><span class="mclose">)</span></span></span></span></span>，该最大目标值与JS差异相关</p> 
<p>当然也可以使用其他的目标函数，详见<a href="https://arxiv.org/abs/1606.00709" rel="nofollow">divergence</a>。该文针对目标函数的选取对GAN训练难度的影响进行了研究。</p> 
<p>根据该文的研究，GAN并不能通过更换目标函数变得特别容易训练，GAN难以训练</p> 
<h3><a id="2_Wasserstein_distance_55"></a>2. Wasserstein distance</h3> 
<p><img src="https://images2.imgbox.com/95/e4/U9UMwN2V_o.png" alt="在这里插入图片描述"></p> 
<p>在大部分情况下，二者均未重叠。首先，从数据的本质来看，两个分布均是高维空间的低维流形。这使得两个分布的重叠部分极少。其次，通过采样的方式来训练网络，但通常采样仅占分布的极小部分，这使得模型无法通过样本感知两个分布已经重叠的部分。</p> 
<p><img src="https://images2.imgbox.com/36/e3/OysxbM1V_o.png" alt="在这里插入图片描述"></p> 
<p>若从损失函数的角度来解释，JS差异在两个分布没有重叠的时候通常是log2，因此训练并不一定能使得模型变得越来越好，相反通常模型并不会有改进</p> 
<p>更进一步的，在两个分布并未重叠的情况下，二元分类器仍然可能达到100%准确率。例如上文中阐述的情况，二维平面中两个线相交，但相交的部分仅占分布的极小部分。此时两个分布并没有实质重叠，但对于分类器而言，其仅能感知到两条线的重叠部分，故此时分类器收敛。</p> 
<p>上述部分分别从数据特征以及损失函数角度，阐述了JS差异在该类模型上难以取得较好效果的原因。接下来，给出wasserstein distance的解释以及该损失函数能够通过怎样的操作提高模型的效果</p> 
<p><img src="https://images2.imgbox.com/05/b3/8I0f9XfY_o.png" alt="在这里插入图片描述"></p> 
<p>简单来说，该类损失函数计算将生成分布还原为真实分布的距离均值。但对于高维的情况，可能存在多种解决方案，此时需要遍历所有的解决方案，选取其中距离均值最小的一个方案执行。</p> 
<p>该损失函数相较于JS divergence能够更好的表达两个分布之间的差异，从而能够趋势两个分布从距离上的接近，而非直接判断两个分布是否重合。</p> 
<p>下面给出评估真实部分与生成分布之间wassertein distance的公式<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            max 
           
          
            ⁡ 
           
          
          
          
            D 
           
          
            ∈ 
           
          
            1 
           
          
            − 
           
          
            L 
           
          
            i 
           
          
            p 
           
          
            s 
           
          
            c 
           
          
            h 
           
          
            i 
           
          
            t 
           
          
            z 
           
          
         
        
          { 
         
         
         
           E 
          
          
          
            y 
           
          
            ∼ 
           
           
           
             P 
            
            
            
              d 
             
            
              a 
             
            
              t 
             
            
              a 
             
            
           
          
         
        
          [ 
         
        
          D 
         
        
          ( 
         
        
          y 
         
        
          ) 
         
        
          ] 
         
        
          − 
         
         
         
           E 
          
          
          
            y 
           
          
            ∼ 
           
           
           
             P 
            
           
             G 
            
           
          
         
        
          [ 
         
        
          D 
         
        
          ( 
         
        
          y 
         
        
          ) 
         
        
          ] 
         
        
          } 
         
        
       
         \max_{D\in 1-Lipschitz}\{E_{y\sim P_{data}}[D(y)]-E_{y\sim P_G}[D(y)]\} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.6382em; vertical-align: -0.8882em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.4306em;"><span class="" style="top: -2.3479em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span><span class="mrel mtight">∈</span><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">sc</span><span class="mord mathnormal mtight">hi</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right: 0.044em;">z</span></span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.8882em;"><span class=""></span></span></span></span></span><span class="mopen">{<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0576em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: -0.1389em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mclose">)]</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0576em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3567em; margin-left: -0.1389em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1433em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mclose">)]}</span></span></span></span></span></span><br> 分辨器的训练目标是当数据来自真实分布时D(y)取值更大，当数据来自生成分布时D(y)取值更小</p> 
<p>分辨器的函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         D 
        
       
         ( 
        
       
         y 
        
       
         ) 
        
       
      
        D(y) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mclose">)</span></span></span></span></span>选取也是有要求的，该函数应当足够平滑。</p> 
<p>若函数不满足上述要求，例如在真实分布区域无穷大，生成分布区域无穷小，则模型无论怎么控制其学习率都难以收敛。相反当满足要求时，当两个分布距离较近时，算出的wassertein distance较小。</p> 
<p>以下给出几种实现上述目标函数的方案</p> 
<p><img src="https://images2.imgbox.com/14/d8/EF1Lk5dq_o.png" alt="在这里插入图片描述"></p> 
<p>在原文中（Original WGAN），主要针对<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
       
         − 
        
       
         L 
        
       
         i 
        
       
         p 
        
       
         s 
        
       
         c 
        
       
         h 
        
       
         i 
        
       
         t 
        
       
         z 
        
       
      
        1-Lipschitz 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">i</span><span class="mord mathnormal">p</span><span class="mord mathnormal">sc</span><span class="mord mathnormal">hi</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right: 0.044em;">z</span></span></span></span></span>给出了方程，但相对粗糙</p> 
<p>即将参数w强制设置在<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         [ 
        
       
         c 
        
       
         , 
        
       
         − 
        
       
         c 
        
       
         ] 
        
       
      
        [c,-c] 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">−</span><span class="mord mathnormal">c</span><span class="mclose">]</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
         f 
        
       
           
        
       
         w 
        
       
         &gt; 
        
       
         c 
        
       
         , 
        
       
           
        
       
         w 
        
       
         = 
        
       
         c 
        
       
         ; 
        
       
           
        
       
         i 
        
       
         f 
        
       
           
        
       
         w 
        
       
         &lt; 
        
       
         − 
        
       
         c 
        
       
         , 
        
       
           
        
       
         w 
        
       
         = 
        
       
         − 
        
       
         c 
        
       
      
        if\ w&gt;c,\ w=c;\ if\ w&lt;-c,\ w=-c 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">c</span><span class="mpunct">;</span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7778em; vertical-align: -0.1944em;"></span><span class="mord">−</span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6667em; vertical-align: -0.0833em;"></span><span class="mord">−</span><span class="mord mathnormal">c</span></span></span></span></span></p> 
<p>而在<a href="https://arxiv.org/abs/1704.00028" rel="nofollow">improved WGAN</a>中，使用了gradient penalty的策略，将真实分布与生成分布之间的梯度保持在1附近</p> 
<p><a href="https://arxiv.org/abs/1802.05957" rel="nofollow">Spectral Normalization</a>中实现了上述要求，且达到了较好的效果</p> 
<h2><a id="_105"></a>二、文献阅读</h2> 
<h3><a id="1__107"></a>1. 题目</h3> 
<p>题目：<a href="https://dl.acm.org/doi/10.5555/3295222.3295327" rel="nofollow">Improved training of wasserstein GANs</a></p> 
<p>作者：Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville</p> 
<p>期刊：NIPS’17(In Proceedings of the 31st International Conference on Neural Information Processing Systems)</p> 
<h3><a id="2_abstract_115"></a>2. abstract</h3> 
<p>作者发现WGAN的问题是由其在权重修正过程中判别器强制实施的Lipschitz约束导致的。从而进一步提出权重修正的替代方案，通过输入的梯度范数来控制判别器。该文证明了其方法相较于WGAN的优越性。该方法能够在不经过超参数调整的情况下稳定训练各种GAN框架。</p> 
<p>The authors found that the Lipschitz constraints imposed by the discriminator during weight correction causes the problem with WGAN. Therefore, this article proposes an alternative to weight correction, which controls the discriminator by the input gradient norm. This paper proves the superiority of the proposed method over WGAN. This method can stably train various GAN frameworks without hyperparameter adjustment.</p> 
<h3><a id="3__121"></a>3. 网络架构</h3> 
<p>该文的分辨器并没有分类行为，因此其在文中将其称为criticz批评器，但本文依然采用分辨器的说法。</p> 
<p>GAN网络的目标为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
             
             
               min 
              
             
               ⁡ 
              
             
            
              G 
             
            
            
             
             
               max 
              
             
               ⁡ 
              
             
            
              D 
             
            
            
            
              E 
             
             
             
               x 
              
             
               ∼ 
              
              
              
                P 
               
              
                r 
               
              
             
            
           
             [ 
            
           
             log 
            
           
             ⁡ 
            
           
             ( 
            
           
             D 
            
           
             ( 
            
           
             x 
            
           
             ) 
            
           
             ) 
            
           
             ] 
            
           
             + 
            
            
            
              E 
             
             
              
              
                x 
               
              
                ~ 
               
              
             
               ∼ 
              
              
              
                P 
               
              
                g 
               
              
             
            
           
             [ 
            
           
             log 
            
           
             ⁡ 
            
           
             ( 
            
           
             1 
            
           
             − 
            
           
             D 
            
           
             ( 
            
            
            
              x 
             
            
              ~ 
             
            
           
             ) 
            
           
             ) 
            
           
             ] 
            
           
             , 
            
           
          
          
          
          
            (1) 
           
          
         
        
       
         \min_G\max_D \mathbb E_{\mathcal x\sim\mathbb P_r}[\log(D(\mathcal x))]+\mathbb E_{\tilde {\mathcal x}\sim \mathbb P_g}[\log(1-D(\tilde {\mathcal x}))], \tag{1} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.4943em; vertical-align: -0.7443em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -2.3557em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7443em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.4306em;"><span class="" style="top: -2.3557em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7443em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3322em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathbb mtight">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1645em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2501em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))]</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0973em; vertical-align: -0.3473em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3322em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="mord mathnormal mtight">x</span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathbb mtight">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1645em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2819em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3473em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">x</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mclose">))]</span><span class="mpunct">,</span></span><span class="tag"><span class="strut" style="height: 1.4943em; vertical-align: -0.7443em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 前文以及上周周报中已经多次给出详细解释，因此不再解释</p> 
<h4><a id="31_Wasserstein_Distance_132"></a>3.1 Wasserstein Distance</h4> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          Total Variation:  
         
         
          
          
            sup 
           
          
            ⁡ 
           
          
         
           A 
          
         
        
          ∣ 
         
        
          P 
         
        
          ( 
         
        
          A 
         
        
          ) 
         
        
          − 
         
        
          Q 
         
        
          ( 
         
        
          A 
         
        
          ) 
         
        
          ∣ 
         
        
          = 
         
         
         
           1 
          
         
           2 
          
         
        
          ∫ 
         
        
          ∣ 
         
        
          p 
         
        
          − 
         
        
          q 
         
        
          ∣ 
         
         
        
          Hellinger:  
         
         
          
          
            ∫ 
           
          
            ( 
           
           
           
             p 
            
           
          
            − 
           
           
           
             q 
            
           
           
           
             ) 
            
           
             2 
            
           
          
         
         
         
         
           L 
          
         
           2 
          
         
        
          : 
         
        
          ∫ 
         
        
          ( 
         
        
          p 
         
        
          − 
         
        
          q 
         
         
         
           ) 
          
         
           2 
          
         
         
         
         
           χ 
          
         
           2 
          
         
        
          : 
         
        
            
         
        
          ∫ 
         
         
          
          
            ( 
           
          
            p 
           
          
            − 
           
          
            q 
           
           
           
             ) 
            
           
             2 
            
           
          
         
           q 
          
         
        
       
         \text{Total Variation:}\ \sup_A|P(A)-Q(A)|=\frac12\int|p-q|\\ \text{Hellinger:}\ \sqrt{\int(\sqrt p-\sqrt q)^2}\\ L_2:\int(p-q)^2\\ \chi^2:\ \int{\frac{(p-q)^2}{q}} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.6888em; vertical-align: -0.9388em;"></span><span class="mord text"><span class="mord">Total Variation:</span></span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.4306em;"><span class="" style="top: -2.1612em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">sup</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.9388em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mord">∣</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.2222em; vertical-align: -0.8622em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">2</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-symbol large-op" style="margin-right: 0.4445em; position: relative; top: -0.0011em;">∫</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">∣</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mord">∣</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 3.04em; vertical-align: -1.1572em;"></span><span class="mord text"><span class="mord">Hellinger:</span></span><span class="mspace"> </span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8828em;"><span class="svg-align" style="top: -5em;"><span class="pstrut" style="height: 5em;"></span><span class="mord" style="padding-left: 1em;"><span class="mop op-symbol large-op" style="margin-right: 0.4445em; position: relative; top: -0.0011em;">∫</span><span class="mopen">(</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="svg-align" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="padding-left: 0.833em;">p</span></span><span class="" style="top: -2.7119em;"><span class="pstrut" style="height: 3em;"></span><span class="hide-tail" style="min-width: 0.853em; height: 1.08em;"> 
                  <svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"> 
                   <path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path> 
                  </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2881em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="svg-align" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em; padding-left: 0.833em;">q</span></span><span class="" style="top: -2.7119em;"><span class="pstrut" style="height: 3em;"></span><span class="hide-tail" style="min-width: 0.853em; height: 1.08em;"> 
                  <svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"> 
                   <path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path> 
                  </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2881em;"><span class=""></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7401em;"><span class="" style="top: -2.989em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.8428em;"><span class="pstrut" style="height: 5em;"></span><span class="hide-tail" style="min-width: 1.02em; height: 3.08em;"> 
            <svg width="400em" height="3.08em" viewbox="0 0 400000 3240" preserveaspectratio="xMinYMin slice"> 
             <path d="M473,2793
c339.3,-1799.3,509.3,-2700,510,-2702 l0 -0
c3.3,-7.3,9.3,-11,18,-11 H400000v40H1017.7
s-90.5,478,-276.2,1466c-185.7,988,-279.5,1483,-281.5,1485c-2,6,-10,9,-24,9
c-8,0,-12,-0.7,-12,-2c0,-1.3,-5.3,-32,-16,-92c-50.7,-293.3,-119.7,-693.3,-207,-1200
c0,-1.3,-5.3,8.7,-16,30c-10.7,21.3,-21.3,42.7,-32,64s-16,33,-16,33s-26,-26,-26,-26
s76,-153,76,-153s77,-151,77,-151c0.7,0.7,35.7,202,105,604c67.3,400.7,102,602.7,104,
606zM1001 80h400000v40H1017.7z"></path> 
            </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.1572em;"><span class=""></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.2222em; vertical-align: -0.8622em;"></span><span class="mop op-symbol large-op" style="margin-right: 0.4445em; position: relative; top: -0.0011em;">∫</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1141em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 1.0585em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:</span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.3715em; vertical-align: -0.8804em;"></span><span class="mop op-symbol large-op" style="margin-right: 0.4445em; position: relative; top: -0.0011em;">∫</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.4911em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">q</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.8804em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></span></p> 
<p>上述距离度量忽略了概率分布之间的几何特性，均是对应点的概率密度函数相比较。但Wasserstein距离具备这种能力</p> 
<p>Wasserstein距离不仅告诉两个分布之间的距离，而且能够告诉我们它们具体如何不一样，即如何从一个分布转化为另一个分布</p> 
<p>下图对Wassertein Distance给出了较为详细的介绍，接下来给出WGAN对于GAN的修正</p> 
<p><img src="https://images2.imgbox.com/b8/b7/EvGMcbTv_o.jpg" alt="在这里插入图片描述"></p> 
<h4><a id="32_Wassertein_GANs_149"></a>3.2 Wassertein GANs</h4> 
<p>使用 Kantorovich-Rubinstein对偶性构造WGAN值函数<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
             
             
               min 
              
             
               ⁡ 
              
             
            
              G 
             
            
            
             
             
               max 
              
             
               ⁡ 
              
             
             
             
               D 
              
             
               ∈ 
              
             
               D 
              
             
            
            
            
              E 
             
             
             
               x 
              
             
               ∼ 
              
              
              
                P 
               
              
                r 
               
              
             
            
           
             [ 
            
           
             D 
            
           
             ( 
            
           
             x 
            
           
             ) 
            
           
             ] 
            
           
             − 
            
            
            
              E 
             
             
              
              
                x 
               
              
                ~ 
               
              
             
               ∼ 
              
              
              
                P 
               
              
                g 
               
              
             
            
           
             [ 
            
           
             D 
            
           
             ( 
            
            
            
              x 
             
            
              ~ 
             
            
           
             ) 
            
           
             ] 
            
           
          
          
          
          
            (2) 
           
          
         
        
       
         \min_G\max_{D\in \mathcal D}\mathbb E_{\mathcal x\sim \mathbb P_r}[D(\mathcal x)]-\mathbb E_{\tilde{\mathcal x}\sim \mathbb P_g}[D(\tilde{\mathcal x})] \tag{2} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.5217em; vertical-align: -0.7717em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -2.3557em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7443em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.4306em;"><span class="" style="top: -2.3557em; margin-left: 0em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">D</span><span class="mrel mtight">∈</span><span class="mord mathcal mtight" style="margin-right: 0.0278em;">D</span></span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class=""><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7717em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3322em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathbb mtight">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1645em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2501em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)]</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0973em; vertical-align: -0.3473em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3322em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="mord mathnormal mtight">x</span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathbb mtight">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1645em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2819em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3473em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">x</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mclose">)]</span></span><span class="tag"><span class="strut" style="height: 1.5217em; vertical-align: -0.7717em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         D 
        
       
      
        \mathcal D 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathcal" style="margin-right: 0.0278em;">D</span></span></span></span></span>是1-Lipschitz函数的集合，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
        
          g 
         
        
       
      
        \mathbb P_g 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.975em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是由<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          ~ 
         
        
       
         = 
        
       
         G 
        
       
         ( 
        
       
         z 
        
       
         ) 
        
       
         , 
        
       
         z 
        
       
         ← 
        
       
         p 
        
       
         ( 
        
       
         z 
        
       
         ) 
        
       
      
        \tilde x=G(z),z\leftarrow p(z) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6679em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">x</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="mclose">)</span></span></span></span></span>隐式定义的模型分布</p> 
<p>在最优判别器下，最小化相对于生成器参数的价值函数可以最小化<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         W 
        
       
         ( 
        
        
        
          P 
         
        
          r 
         
        
       
         , 
        
        
        
          P 
         
        
          y 
         
        
       
         ) 
        
       
      
        W(\mathbb P_r,\mathbb P_y) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="mopen">(</span><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p> 
<p>WGAN 值函数产生一个损失函数，其相对于其输入的梯度比GAN的损失函数表现得更好，从而使生成器的优化变得更加容易。</p> 
<p>为了对辨别器实施 Lipschitz 约束，原文建议将辨别器的权重限制在一个紧凑的空间内 [-c, c]。满足此约束的函数集是某些 k 的 k-Lipschitz 函数的子集，这取决于 c 和辨别器的架构。</p> 
<p>在了解了WHGAN辨别器的属性之后，该文提出了如下假设，并推出</p> 
<p><img src="https://images2.imgbox.com/d5/50/LSxRGR47_o.jpg" alt="在这里插入图片描述"></p> 
<h4><a id="33_Gradient_penalty_168"></a>3.3 Gradient penalty</h4> 
<p><img src="https://images2.imgbox.com/e0/f1/O3i9LFPZ_o.jpg" alt="在这里插入图片描述"></p> 
<p>该文提出了一种WGAN的惩罚函数的替代方案，直接约束分辨器的输出相对于其输入的梯度范数。对随机样本<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          ^ 
         
        
       
         ∼ 
        
        
        
          P 
         
         
         
           x 
          
         
           ^ 
          
         
        
       
      
        \hat x\sim \mathbb P_{\hat x} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">x</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8389em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbb">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="mord mathnormal mtight">x</span></span><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord mtight">^</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的梯度范数进行惩罚。有新目标函数<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
           
             L 
            
           
             = 
            
            
            
              E 
             
             
              
              
                x 
               
              
                ~ 
               
              
             
               ∼ 
              
              
              
                P 
               
              
                y 
               
              
             
            
           
             [ 
            
           
             D 
            
           
             ( 
            
            
            
              x 
             
            
              ~ 
             
            
           
             ) 
            
           
             ] 
            
           
             − 
            
            
            
              E 
             
             
             
               x 
              
             
               ∼ 
              
              
              
                P 
               
              
                r 
               
              
             
            
           
             [ 
            
           
             D 
            
           
             ( 
            
           
             x 
            
           
             ) 
            
           
             ] 
            
           
             + 
            
           
             λ 
            
            
            
              E 
             
             
              
              
                x 
               
              
                ^ 
               
              
             
               ∼ 
              
              
              
                P 
               
               
               
                 x 
                
               
                 ^ 
                
               
              
             
            
           
             [ 
            
           
             ( 
            
           
             ∣ 
            
           
             ∣ 
            
            
            
              ∇ 
             
             
             
               x 
              
             
               ^ 
              
             
            
           
             D 
            
           
             ( 
            
            
            
              x 
             
            
              ^ 
             
            
           
             ) 
            
           
             ∣ 
            
            
            
              ∣ 
             
            
              2 
             
            
           
             − 
            
           
             1 
            
            
            
              ) 
             
            
              2 
             
            
           
             ] 
            
           
          
          
          
          
            (3) 
           
          
         
        
       
         L=\mathbb E_{\tilde x\sim \mathbb P_y}[D(\tilde x)]-\mathbb E_{x\sim \mathbb P_r}[D(x)]+\lambda\mathbb E_{\hat x\sim \mathbb P_{\hat x}}[(||\nabla_{\hat x}D(\hat x)||_2-1)^2] \tag{3} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0973em; vertical-align: -0.3473em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3322em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="mord mathnormal mtight">x</span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathbb mtight">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1645em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2819em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3473em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">x</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mclose">)]</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0001em; vertical-align: -0.2501em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3322em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathbb mtight">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1645em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2501em;"><span class=""></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)]</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0059em; vertical-align: -0.2559em;"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="mord mathnormal mtight">x</span></span><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord mtight">^</span></span></span></span></span></span></span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathbb mtight">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -2.6944em;"><span class="pstrut" style="height: 2.6944em;"></span><span class="mord mathnormal mtight">x</span></span><span class="" style="top: -2.6944em;"><span class="pstrut" style="height: 2.6944em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord mtight">^</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2559em;"><span class=""></span></span></span></span></span></span><span class="mopen">[(</span><span class="mord">∣∣</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="mord mathnormal mtight">x</span></span><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord mtight">^</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">x</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1141em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span><span class="tag"><span class="strut" style="height: 1.2114em; vertical-align: -0.3473em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">3</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 第一项为原分辨器损失，第二项为梯度惩罚</p> 
<p><strong>Sampling distribution</strong> 隐式定义 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
         
         
           x 
          
         
           ^ 
          
         
        
       
      
        P_{\hat x} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="mord mathnormal mtight">x</span></span><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord mtight">^</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 沿从数据分布 Pr 和生成器分布 Pg 采样的点对之间的直线均匀采样。沿着直线强制执行单位梯度范数约束。</p> 
<p><strong>Penalty coefficient</strong> 本文中的所有实验都使用 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         λ 
        
       
      
        \lambda 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span></span> = 10，它在从玩具任务到大型 ImageNet CNN 的各种架构和数据集上都能很好地工作。</p> 
<p><strong>No critic batch normalization</strong> 批量归一化改变了判别器问题的形式，从将单个输入映射到单个输出到从整个数据映射一批输入到一批输出。原惩罚训练目标在这种情况下不再有效，因为独立地对每个输入而不是整个批次的分辨器梯度范数进行惩罚。为了解决这个问题，只需在模型的分辨器中省略批量归一化。特别地，将层归一化作为批量归一化的直接替代品</p> 
<p><strong>Two-sided penalty</strong> 梯度范数趋向于 1（两侧惩罚），而不是仅仅保持在 1 以下（一侧惩罚）。从经验上看，这似乎不会对分辨器造成太大限制，可能是因为无论如何，最优 WGAN 批评家在 Pr 和 Pg 下以及之间的大部分区域中几乎到处都具有范数 1 的梯度。</p> 
<h3><a id="4__189"></a>4. 文献解读</h3> 
<h4><a id="41_Introduction_191"></a>4.1 Introduction</h4> 
<p>GAN网络能够生成视觉效果经验的结果，但缺乏稳定的训练方法。而WGAN要求判别器必须位于1-Lipschitz函数的空间内，该约束通过权重修正强制执行</p> 
<p>该文展示了判别器权重修正的弊端，并提出梯度惩罚（WGAN-GP），从而避免了发现的弊端。在此基础上，该文展示了各种GAN框架的稳定训练、权重裁剪的性能改进、高质量图像生成以及无需任何离散采样的字符级GAN语言模型</p> 
<h4><a id="42__197"></a>4.2 创新点</h4> 
<ol><li>研究并展示了WGAN中的权重裁剪问题</li><li>在分辨器损失中引入了新的惩罚项</li></ol> 
<h4><a id="43__202"></a>4.3 实验过程</h4> 
<h5><a id="431_Difficulties_with_weight_constraint_204"></a>4.3.1 Difficulties with weight constraint</h5> 
<p>本节主要介绍该文在验证WGAN的权重裁剪方面的研究，该文发现WGAN中的权重裁剪会导致优化困难，且既是成功，所获得的辨别其也可能由病态的value surface。但以下提及的容量未充分利用以及梯度爆炸和消失可以采用该文文中提出的方法解决</p> 
<p>实验使用[2]中的特定形式的权重约束（每个权重大小的强制裁剪），也包括其他权重约束（L2范数裁剪、权重归一化）以及软约束（L1和L2权重衰减）并发现它们表现出类似的问题。</p> 
<p>在某种程度上，这些问题可以通过分辨器中的批量归一化来缓解，[2]的所有实验中都使用了批量归一化。然而，即使使用批量归一化也观察到深层的 WGAN 辨别器常常无法收敛。</p> 
<p><strong>Capacity underuse</strong></p> 
<p><img src="https://images2.imgbox.com/71/d2/pLl91sPP_o.png" alt="在这里插入图片描述"></p> 
<p>通过权重修正达到k-Lipshitz约束会使得分辨器倾向于更简单的函数。为了证明这一点，通过权重裁剪来训练 WGAN分辨器，使其在几个玩具分布上达到最优，将生成器分布 Pg 固定在真实分布加上单位方差高斯噪声。在上图为分辨器的价值面。在分辨器中省略了批量归一化。在每种情况下，经过权重裁剪训练的分辨器都会忽略数据分布的更高矩，而是对最优函数进行非常简单的近似建模。</p> 
<p><strong>Exploding and vanishing gradients</strong></p> 
<p><img src="https://images2.imgbox.com/c2/f1/tLxUY25d_o.png" alt="在这里插入图片描述"></p> 
<p>不合适的阈值c很容易导致梯度爆炸或者消失。为了证明这一点，在 Swiss Roll 玩具数据集上训练 WGAN，改变 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         [ 
        
       
         1 
        
        
        
          0 
         
         
         
           − 
          
         
           1 
          
         
        
       
         , 
        
       
         1 
        
        
        
          0 
         
         
         
           − 
          
         
           2 
          
         
        
       
         , 
        
       
         1 
        
        
        
          0 
         
         
         
           − 
          
         
           3 
          
         
        
       
         ] 
        
       
      
        [10^{-1}, 10^{-2}, 10^{-3}] 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0641em; vertical-align: -0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">3</span></span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> 中的裁剪阈值 c，并绘制分辨损失相对于连续层的梯度范数的激活。生成器和分辨器都是没有批量归一化的 12 层 ReLU MLPs。上图显示，对于每个值，当网络中进一步向后移动时，梯度要么呈指数增长，要么呈指数衰减。</p> 
<p>上图左侧为分辨器层的梯度范数，而右上角为WGAN的生成分布，右下角为gradient penalty的生成分布。显然gradient penalty在充分利用网络容量的同时降低了梯度爆炸与消失发生的概率。</p> 
<h5><a id="432__226"></a>4.3.2 单一数据集上训练随机架构</h5> 
<p><img src="https://images2.imgbox.com/7f/cb/lGjHGKho_o.png" alt="在这里插入图片描述"></p> 
<p>通过实验证明了模型训练大量架构的能力。从 DCGAN 架构开始，将模型设置更改为上表中的随机对应值来定义一组架构变体。</p> 
<p><img src="https://images2.imgbox.com/1a/b4/EjxFGVcI_o.png" alt="在这里插入图片描述"></p> 
<p>从这个集合中，对 200 个架构进行了采样，并使用 WGAN-GP 和标准 GAN 目标在 32$\times$32 ImageNet 上对每个架构进行训练。上表列出了其中以下任一情况的实例数量：仅标准 GAN 成功、仅 WGAN-GP 成功、两者均成功或均失败，其中成功定义为初始分数 &gt; 最低分数。</p> 
<h5><a id="433_LSUN_236"></a>4.3.3 LSUN上训练多种框架</h5> 
<p>为了展示模型使用默认设置训练多种框架的能力，在LSUN数据集上训练了六种不同的GAN框架，此外，还训练了基础模型DCGAN。框架如下：</p> 
<ol><li>生成器中没有BN和恒定数量的滤波器</li><li>4层512维ReLU MLP生成器</li><li>分辨器或生成器中均不进行归一化</li><li>门控乘法非线性</li><li>tanh非线性</li><li>101ResNet生成器和分辨器</li></ol> 
<p>对于每种架构，使用四种不同的 GAN 方法训练模型：WGAN-GP、带权重裁剪的 WGAN、DCGAN 和最小二乘 GAN。对于每个目标，使用该工作中推荐的默认优化器超参数集（LSGAN 除外，在其中搜索学习率）。</p> 
<p>对于 WGAN-GP，用层归一化替换判别器中的任何批量归一化。对每个模型进行 20 万次迭代训练。使用 WGAN-GP 使用一组共享超参数训练每个架构。</p> 
<p>下图展示了训练效果</p> 
<p><img src="https://images2.imgbox.com/c0/5d/T5sTsidc_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="434__255"></a>4.3.4 改进权重裁剪的性能</h5> 
<p><img src="https://images2.imgbox.com/74/58/5r7Canob_o.png" alt="在这里插入图片描述"></p> 
<p>在CIFAR 10上使用权重裁剪和梯度惩罚训练WGAN，并在上图中绘制训练过程中的Inception分数。对于WGAN-GP，使用与WGAN相同的优化器（RMSProp）和学习率训练一个模型，并使用权重裁剪，另一个模型使用Adam和更高的学习率。在使用相同的优化器的情况下，文中方法也比权重裁剪收敛得更快，得分更高。使用Adam可以进一步提高性能。此外，还绘制了DCGAN的性能。该方法最终分数低于DCGAN，但收敛过程更稳定。</p> 
<p>上图左侧，横轴为生成器迭代次数，上图右侧，横轴为时间刻（以秒为单位）</p> 
<h5><a id="435_CIFAR10LSUN_263"></a>4.3.5 CIFAR-10和LSUN的样本质量</h5> 
<p><img src="https://images2.imgbox.com/c5/cb/NuEvkXNK_o.png" alt="在这里插入图片描述"></p> 
<p>对于等效架构，该方法实现了与标准 GAN 目标相当的样本质量。因为更高的稳定性，所以可以使用该方法训练更为复杂的模型。为了证明这一点，架构在无监督的 CIFAR-10 上建立了新的最先进的 Inception 分数。当添加标签信息时，相同的架构优于除 SGAN 之外的所有其他已发布模型。上表为CIFAR-10上使用监督学习模式以及无监督学习模式的各个框架的Inception分数</p> 
<p>此外，还<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         128 
        
       
         × 
        
       
         128 
        
       
      
        128\times 128 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">128</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">128</span></span></span></span></span>在LSUN上训练深度ResNet，样本如下图所示。</p> 
<p><img src="https://images2.imgbox.com/c7/37/uiidY2Zm_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="436__273"></a>4.3.6 使用连续的生成器对离散数据进行建模</h5> 
<p>使用GAN建模复杂离散分布的问题，GAN的生成器是在连续空间上定义的。在Google Billion Word数据集上训练字符集GAN语言模型。生成器和分辨器是一个简单的一维CNN，通过一维卷积确定性将潜在向量转换为32个one-hot字符向量的序列。输出使用softmax非线性输出，不适用采样步骤，直接将输出传递到分辨器。解码样本时，只取每个输出向量的argmax</p> 
<p>在该实验中，模型经常出现拼写错误（可能是因为它必须独立输出每个字符），但仍然设法学习了很多有关语言统计的知识。无法产生与标准 GAN 目标相当的结果。</p> 
<h4><a id="44__279"></a>4.4 结论</h4> 
<p>该文研究并展示了WGAN中的权重裁剪问题，并在分辨器损失中引入了新的惩罚项。在各种框架上展示了强大的建模性能和稳定性。在大规模图像数据集和与数据集上进行了实验，验证了该方法可以激励分辨器学习更平滑的决策边界来稳定训练。</p> 
<h2><a id="WGAN_283"></a>三、WGAN</h2> 
<p>在MNIST数据上训练WGAN网络，本文基于WGAN论文中的代码</p> 
<p>以下几点改进：</p> 
<ol><li>判别器最后一层去掉sigmoid。sigmoid函数容易出现梯度消失的情况。</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ol> 
<p>下图为下载数据集过程</p> 
<p><img src="https://images2.imgbox.com/96/ce/oLfV6wsr_o.png" alt="在这里插入图片描述"></p> 
<p>以下为上周使用GAN的训练结果</p> 
<p><img src="https://images2.imgbox.com/d0/79/7QWYPHbe_o.png" alt="在这里插入图片描述"></p> 
<p>以下为最后几个批次生成的图片</p> 
<p><img src="https://images2.imgbox.com/da/7d/VIgVunSG_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> argparse
<span class="token keyword">import</span> os
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> math
<span class="token keyword">import</span> sys

<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>utils <span class="token keyword">import</span> save_image

<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable

<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch

os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">"images"</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#方法是递归目录创建功能。如果exists_ok为False(默认值)，则如果目标目录已存在，则引发OSError错误，True则不会</span>

parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--n_epochs"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of epochs of training"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--batch_size"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"size of the batches"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--lr"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.00005</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"learning rate"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--n_cpu"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of cpu threads to use during batch generation"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--latent_dim"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"dimensionality of the latent space"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--img_size"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"size of each image dimension"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--channels"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of image channels"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--n_critic"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of training steps for discriminator per iter"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--clip_value"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"lower and upper clip value for disc. weights"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--sample_interval"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"interval betwen image samples"</span><span class="token punctuation">)</span>
opt <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>opt<span class="token punctuation">)</span>

img_shape <span class="token operator">=</span> <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>img_size<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>img_size<span class="token punctuation">)</span>

cuda <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token boolean">False</span>


<span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>
            <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>
                layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> layers

        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token operator">*</span>block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>
        img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>
        <span class="token keyword">return</span> img


<span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#np.prod(img_shape)连乘操作，长*宽*深度</span>
            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#改进1、判别器最后一层去掉sigmoid。sigmoid函数容易出现梯度消失的情况。</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>
        img_flat <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img_flat<span class="token punctuation">)</span>
        <span class="token keyword">return</span> validity


<span class="token comment"># Initialize generator and discriminator</span>
generator <span class="token operator">=</span> Generator<span class="token punctuation">(</span><span class="token punctuation">)</span>
discriminator <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> cuda<span class="token punctuation">:</span>
    generator<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    discriminator<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Configure data loader</span>
os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">"../../data/mnist"</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
    datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>
        <span class="token string">"../../data/mnist"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>opt<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># Optimizers</span>
optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">)</span><span class="token comment">#改进4、不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</span>
optimizer_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">)</span>

Tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>FloatTensor <span class="token keyword">if</span> cuda <span class="token keyword">else</span> torch<span class="token punctuation">.</span>FloatTensor

<span class="token comment"># ----------</span>
<span class="token comment">#  Training</span>
<span class="token comment"># ----------</span>

batches_done <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># Configure input</span>
        real_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># ---------------------</span>
        <span class="token comment">#  Train Discriminator</span>
        <span class="token comment"># ---------------------</span>

        optimizer_D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># Sample noise as generator input</span>
        z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># Generate a batch of images</span>
        fake_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#detach 的意思是，这个数据和生成它的计算图“脱钩”了，即梯度传到它那个地方就停了，不再继续往前传播</span>
        <span class="token comment">#要少计算一次 generator 的所有参数的梯度，同时，也不必刻意保存一次计算图，占用不必要的内存。</span>
        <span class="token comment"># Adversarial loss</span>
        loss_D <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>fake_imgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#改进2、生成器和判别器的loss不取log</span>

        loss_D<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#只更新discriminator的参数</span>

        <span class="token comment"># Clip weights of discriminator</span>
        <span class="token keyword">for</span> p <span class="token keyword">in</span> discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            p<span class="token punctuation">.</span>data<span class="token punctuation">.</span>clamp_<span class="token punctuation">(</span><span class="token operator">-</span>opt<span class="token punctuation">.</span>clip_value<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>clip_value<span class="token punctuation">)</span>

        <span class="token comment"># Train the generator every n_critic iterations</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> opt<span class="token punctuation">.</span>n_critic <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>

            <span class="token comment"># -----------------</span>
            <span class="token comment">#  Train Generator</span>
            <span class="token comment"># -----------------</span>

            optimizer_G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># Generate a batch of images</span>
            gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
            <span class="token comment"># Adversarial loss</span>
            loss_G <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span><span class="token punctuation">)</span>

            loss_G<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#只更新 generator 的参数</span>

            <span class="token keyword">print</span><span class="token punctuation">(</span>
                <span class="token string">"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"</span>
                <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">,</span> batches_done <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss_D<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loss_G<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>

        <span class="token keyword">if</span> batches_done <span class="token operator">%</span> opt<span class="token punctuation">.</span>sample_interval <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            save_image<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"images/%d.png"</span> <span class="token operator">%</span> batches_done<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        batches_done <span class="token operator">+=</span> <span class="token number">1</span>
</code></pre> 
<h3><a id="_479"></a>小结</h3> 
<p>本周继续学习了GAN并拓展阅读了相关文章，文章提出了WGAN，因此本文还介绍了Wassertain Distance。此外，还实现了wgan。<br> 下周计划继续学习GAN网络，侧重于训练方法以及评估权重方面，还会学习CGAN的基础理论。</p> 
<h3><a id="_483"></a>参考文献</h3> 
<p>[1] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville. 2017. Improved training of wasserstein GANs. In Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS’17). Curran Associates Inc., Red Hook, NY, USA, 5769–5779.</p> 
<p>[2] M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein gan. arXiv preprint arXiv:1701.07875,<br> 2017.</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b9c4484a7a078f5c5619eac15ea2802e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">手撕AVL_二叉平衡树(图文并茂)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7e466b5c463eb8f4eb4a1adfa655ab3c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Android权限管理--权限类型</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>