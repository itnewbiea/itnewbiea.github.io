<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【论文速览】根据人脑fMRI信号重建图像 Image Reconstruction from human brain activity - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【论文速览】根据人脑fMRI信号重建图像 Image Reconstruction from human brain activity" />
<meta property="og:description" content="文章目录 前言文章一研究背景主要方法部分实验结果总结与思考参考资料 文章二研究背景主要方法部分实验结果总结与思考 前言 人类的视觉神经系统对于真实世界的视觉刺激有着非凡的感知与理解能力，比如我们能够准确地识别物体距离和三维几何关系等，这是当前人工智能难以比拟的能力。在人类视觉感知系统中，外部视觉刺激会经过神经编码为神经信号，而神经解码就是根据神经信号得到相对应的视觉刺激，通过研究这个编解码过程能够帮助我们进一步去理解大脑不同区域的功能。
根据不同任务的复杂性和具体目标，这类研究可以分为刺激分类(stimuli classification)、刺激识别(stimuli recognition)和刺激重建(stimuli reconstruction)。比如刺激分类就是根据大脑活动信息去区分视觉刺激中包含的物体类别，刺激识别就是从一组已知的图像中识别特定的视觉刺激，而刺激重构就是直接生成图像。
这篇博文将介绍今年两个比较新的根据人脑活动信号直接生成视觉刺激图像的工作，具体地说，就是根据观测图像时生成的脑补fMRI信号去重建观测图像。
文章一 研究背景 本文要做的一个任务就是根据人脑活动重建视觉图像，更具体地说就是根据人脑的功能性磁共振成像(functional magnetic resonance imaging, fMRI)来重建其观测到的图像。如上图所示，第一行是现有的图像(观测者看到的图像)，第二行是模型根据其中一个观测者的fMRI重建得到的图像。
本文提出的方法主要基于Stable Diffusion模型，并且探讨了LDM(latent diffusion model)与人脑独特功能之间的联系，从神经科学的角度对LDM不同成分提供了一种的定量解释。
主要方法 Stable Diffusion
关于Stable Diffusion模型这里就不过多介绍了，感兴趣可以参考我这篇博客（一文速览扩散模型优化过程：从DDPM到条件生成模型Stable Diffusion），其模型结构大致如下所示：
其中z是原始图像输入编码器得到的潜在表征(latent representation)，c是输入文本信息表征，数学公式: $ z_c $是去噪后得到的表征，其会送入解码器得到最终的生成图像。
本文直接用的其开源的代码与预训练参数（version 1.4）.
解码过程：从fMRI重构图像
解码过程如下图所示，本论文主要要训练的只有两个线性模型(红色部分)，其负责将fMRI信号转换成对应的潜在表征(z和c)，而Stable Diffusion的其他参数不需要调整。
（i）首先第一步观测者早期视觉皮层(early visual cortex)对应的fMRI信号得到潜在表征z，然后送入解码器得到得到一个粗(coarse)解码图像 X z X_z Xz​；
（ii） X z X_z Xz​随后会被送入解码器，然后进行加噪过程（扩散模型的前向过程）；
（iii）将观测者高层视觉皮层(higher visual cortex)的fMRI信号编码称为潜在的文本表征c，然后与加噪后的表征 z T z_T zT​一起进行去噪过程（扩散模型的逆向过程）得到最终的生成图像 X z c X_{zc} Xzc​.
线性模型使用的是L2正则化的线性回归，针对不同的观测者单独训练.
编码过程：全脑体素建模
为了去解释LDM模型与人脑活动之间的联系，本文构造了一个全脑体素(whole-brain voxel-wise)编码模型，如下图所示。其通过线性模型来构造Stable Diffusion中潜在表征与人脑体素之间的对应关系，分别对比了不同噪声条件下、不同扩散阶段、不同U-Net层的特征与大脑部位的对应关系。
这一部分就不详细介绍了，感兴趣的可以参见原文，主要是从生物神经学的角度分析了LDM的内在机理。
部分实验结果 上图展示了同一名受试者根据不同潜在表征生成的图像，可以发现：① 仅使用z重建的图像与原图像视觉一致(visually consistent)，但语义内容不一致（个人认为这里的视觉一致指的就是整体的颜色与纹理结构）；② 仅使用c生成的图像具有高度的语义保真度但视觉不一致；③ 从 z c z_c zc​生成的图像同时具有高度语义保真度和视觉一致性。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/94de4da63165c7d4c17a521fba35e64e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-04T22:36:04+08:00" />
<meta property="article:modified_time" content="2023-06-04T22:36:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【论文速览】根据人脑fMRI信号重建图像 Image Reconstruction from human brain activity</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atelier-sulphurpool-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_1" rel="nofollow">前言</a></li><li><a href="#_8" rel="nofollow">文章一</a></li><li><ul><li><a href="#_10" rel="nofollow">研究背景</a></li><li><a href="#_17" rel="nofollow">主要方法</a></li><li><a href="#_37" rel="nofollow">部分实验结果</a></li><li><a href="#_44" rel="nofollow">总结与思考</a></li><li><a href="#_49" rel="nofollow">参考资料</a></li></ul> 
   </li><li><a href="#_53" rel="nofollow">文章二</a></li><li><ul><li><a href="#_55" rel="nofollow">研究背景</a></li><li><a href="#_65" rel="nofollow">主要方法</a></li><li><a href="#_74" rel="nofollow">部分实验结果</a></li><li><a href="#_85" rel="nofollow">总结与思考</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_1"></a>前言</h3> 
<p>人类的视觉神经系统对于真实世界的视觉刺激有着非凡的感知与理解能力，比如我们能够准确地识别物体距离和三维几何关系等，这是当前人工智能难以比拟的能力。在人类视觉感知系统中，外部视觉刺激会经过神经编码为神经信号，而神经解码就是根据神经信号得到相对应的视觉刺激，通过研究这个编解码过程能够帮助我们进一步去理解大脑不同区域的功能。</p> 
<p>根据不同任务的复杂性和具体目标，这类研究可以分为刺激分类(stimuli classification)、刺激识别(stimuli recognition)和刺激重建(stimuli reconstruction)。比如刺激分类就是根据大脑活动信息去区分视觉刺激中包含的物体类别，刺激识别就是从一组已知的图像中识别特定的视觉刺激，而刺激重构就是直接生成图像。</p> 
<p>这篇博文将介绍今年两个比较新的根据人脑活动信号直接生成视觉刺激图像的工作，具体地说，就是<strong>根据观测图像时生成的脑补fMRI信号去重建观测图像</strong>。</p> 
<h3><a id="_8"></a>文章一</h3> 
<p><img src="https://images2.imgbox.com/b6/e6/MDZHbOHa_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_10"></a>研究背景</h4> 
<p><img src="https://images2.imgbox.com/83/ad/VOQsLXXP_o.png" alt="在这里插入图片描述"><br> 本文要做的一个任务就是根据人脑活动重建视觉图像，更具体地说就是根据人脑的功能性磁共振成像(functional magnetic resonance imaging, fMRI)来重建其观测到的图像。如上图所示，第一行是现有的图像(观测者看到的图像)，第二行是模型根据其中一个观测者的fMRI重建得到的图像。</p> 
<p>本文提出的方法主要基于Stable Diffusion模型，并且探讨了LDM(latent diffusion model)与人脑独特功能之间的联系，从神经科学的角度对LDM不同成分提供了一种的定量解释。</p> 
<h4><a id="_17"></a>主要方法</h4> 
<p><strong>Stable Diffusion</strong><br> 关于Stable Diffusion模型这里就不过多介绍了，感兴趣可以参考我这篇博客（<a href="https://blog.csdn.net/qq_36560894/article/details/130851385?spm=1001.2014.3001.5501">一文速览扩散模型优化过程：从DDPM到条件生成模型Stable Diffusion</a>），其模型结构大致如下所示：<br> <img src="https://images2.imgbox.com/cf/69/Vw5qovfH_o.png" alt="在这里插入图片描述"><br> 其中z是原始图像输入编码器得到的潜在表征(latent representation)，c是输入文本信息表征，数学公式: $ z_c $是去噪后得到的表征，其会送入解码器得到最终的生成图像。</p> 
<blockquote> 
 <p>本文直接用的其开源的代码与预训练参数（version 1.4）.</p> 
</blockquote> 
<p><strong>解码过程：从fMRI重构图像</strong><br> 解码过程如下图所示，本论文主要要训练的只有两个线性模型(红色部分)，其负责将fMRI信号转换成对应的潜在表征(z和c)，而Stable Diffusion的其他参数不需要调整。<br> <img src="https://images2.imgbox.com/b3/d2/jli2kuGE_o.png" alt="在这里插入图片描述"><br> （i）首先第一步观测者早期视觉皮层(early visual cortex)对应的fMRI信号得到潜在表征z，然后送入解码器得到得到一个粗(coarse)解码图像<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
        
          z 
         
        
       
      
        X_z 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.044em;">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>；<br> （ii）<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
        
          z 
         
        
       
      
        X_z 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.044em;">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>随后会被送入解码器，然后进行加噪过程（扩散模型的前向过程）；<br> （iii）将观测者高层视觉皮层(higher visual cortex)的fMRI信号编码称为潜在的文本表征c，然后与加噪后的表征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          T 
         
        
       
      
        z_T 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>一起进行去噪过程（扩散模型的逆向过程）得到最终的生成图像<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
         
         
           z 
          
         
           c 
          
         
        
       
      
        X_{zc} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">zc</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>.</p> 
<blockquote> 
 <p>线性模型使用的是L2正则化的线性回归，针对不同的观测者单独训练.</p> 
</blockquote> 
<p><strong>编码过程：全脑体素建模</strong><br> 为了去解释LDM模型与人脑活动之间的联系，本文构造了一个全脑体素(whole-brain voxel-wise)编码模型，如下图所示。其通过线性模型来构造Stable Diffusion中潜在表征与人脑体素之间的对应关系，分别对比了不同噪声条件下、不同扩散阶段、不同U-Net层的特征与大脑部位的对应关系。<br> <img src="https://images2.imgbox.com/d0/80/SfzkZ3r6_o.png" alt="在这里插入图片描述"><br> 这一部分就不详细介绍了，感兴趣的可以参见原文，主要是从生物神经学的角度分析了LDM的内在机理。</p> 
<h4><a id="_37"></a>部分实验结果</h4> 
<p><img src="https://images2.imgbox.com/75/5a/o2zBh8VE_o.png" alt="在这里插入图片描述"><br> 上图展示了同一名受试者根据不同潜在表征生成的图像，可以发现：① 仅使用z重建的图像与原图像视觉一致(visually consistent)，但语义内容不一致（个人认为这里的视觉一致指的就是整体的颜色与纹理结构）；② 仅使用c生成的图像具有高度的语义保真度但视觉不一致；③ 从<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          c 
         
        
       
      
        z_c 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>生成的图像同时具有高度语义保真度和视觉一致性。</p> 
<p><img src="https://images2.imgbox.com/4c/bc/Zk2KsfWk_o.png" alt="在这里插入图片描述"><br> 上图展示了不同观测者对同一副图像的fMRI信号生成的重构图像，可以看到整体的重建质量还是可以的。（不同观测者重建出来的图像相互间有差距，可能是因为每个人关注的区域不一致导致激活有差异）。</p> 
<h4><a id="_44"></a>总结与思考</h4> 
<p>本文基于Stable Diffusion模型提出了一个可以从人脑fMRI信号重构图像的方法，它不需要对大模型进行重新训练，只需要学习fMRI到LDM潜在表征的线性映射即可。此外，模型从生物神经科学的角度探讨了LDM的内在机理。</p> 
<p>读完全文，可以发现本文的主要方法和思路都不难，并且从重建的效果上来看还不错，基本能够认出原始图像的特征，但整体细节还有待进一步加强。此外，方法需要针对不同观测者去构建线性映射模型，这里也值得优化。</p> 
<h4><a id="_49"></a>参考资料</h4> 
<p>[1] <a href="https://zhuanlan.zhihu.com/p/631955002" rel="nofollow">【AI论文学习笔记】大脑信号重建图像 High-resolution image reconstruction with LDM from human brain activity</a></p> 
<h3><a id="_53"></a>文章二</h3> 
<p><img src="https://images2.imgbox.com/bf/71/emXJAnfc_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_55"></a>研究背景</h4> 
<p>针对fMRI信号重建的任务，作者分析了目前工作存在的问题：首先是早期方法虽然能够顺利重建出原始图像的结构信息，比如轮廓、大小等，但其重建结果缺乏明显的语义信息导致难以辨认；而最近的方法采用预训练的生成模型进行重建，能生成语义相似的图像（比如上面那篇文章），但其生成结果在结构信息上是不可控的，比如位置、朝向等。</p> 
<p><img src="https://images2.imgbox.com/07/0f/2Tct0uH4_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>第一行图像展示了早期方法的重建结果，第二行展示了当前方法的生成结果，最后一行为本文提出MindDiffuser的生成结果</p> 
</blockquote> 
<p>为了去解决这两个问题，本文提出了一个两阶段的模型MindDiffuser，结合了“优化”和“生成”两种方法的思想，使得重构结果在语义上相似的同时结构也一致。</p> 
<h4><a id="_65"></a>主要方法</h4> 
<p>MindDiffuser的模型框架如上图所示，其包括两个阶段。首先MindDiffuser要构建三个不同的回归模型，去学习fMRI与图像图像潜层特征之间的映射，包括VQ-VAE编码特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Z 
        
       
      
        Z 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0715em;">Z</span></span></span></span></span>，CLIP提取的图像特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          Z 
         
         
         
           C 
          
         
           L 
          
         
           I 
          
         
           P 
          
         
        
       
      
        Z_{CLIP} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0715em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0715em;">C</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">I</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和文本特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         C 
        
       
      
        C 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0715em;">C</span></span></span></span></span>（这些都是在后面过程中要用到的）。在第一阶段(a)，会利用Z和C两个特征去进行图像生成，这和Stable Diffusion的过程一模一样。<br> <img src="https://images2.imgbox.com/0e/f8/BpzCRfn1_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>作者认为在第一阶段主要是嵌入了语义信息和细粒度细节信息，解决了"what is contained"</p> 
</blockquote> 
<p>在第二阶段，作者利用CLIP输出的视觉特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          Z 
         
         
         
           C 
          
         
           L 
          
         
           I 
          
         
           P 
          
         
        
       
      
        Z_{CLIP} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0715em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0715em;">C</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">I</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>来进一步对齐结构信息。具体地，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          Z 
         
         
         
           C 
          
         
           L 
          
         
           I 
          
         
           P 
          
         
        
       
      
        Z_{CLIP} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0715em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0715em;">C</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">I</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>包括了图像对应的一组浅层特征（浅层特征包含了视觉低层信息，如结构位置信息等），通过计算生成图与<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          Z 
         
         
         
           C 
          
         
           L 
          
         
           I 
          
         
           P 
          
         
        
       
      
        Z_{CLIP} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0715em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0715em;">C</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">I</span><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>之间的L2距离来反向优化生成图像，通过反向传播进行多次迭代来对齐结构信息，从而得到最终的生成结果。</p> 
<p><img src="https://images2.imgbox.com/2a/45/QAlIw8gZ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_74"></a>部分实验结果</h4> 
<p><img src="https://images2.imgbox.com/84/be/caLK2soR_o.png" alt="在这里插入图片描述"><br> 上图展示了MindDiffuser与当前不同主流方法之间的重构结果对比，可以看到MindDiffuser是能够较好地捕获到原始图像的语义和结构信息的。此外，第三行也证明了第二阶段的重要性（without control）。</p> 
<p><img src="https://images2.imgbox.com/d0/4a/nEBzwXZO_o.png" alt="在这里插入图片描述"><br> 此外，在定量指标的对比上，MindDiffuser也具有明显优势。</p> 
<p><img src="https://images2.imgbox.com/7a/98/VsdZ3wOP_o.png" alt="在这里插入图片描述"><br> 上图展示了MindDiffuser对于不同受试者fMRI的重建结果，需要注意的是，这里的结果都是由同一个模型生成，这说明MindDiffuser能够适应于不同个体。</p> 
<blockquote> 
 <p>文中还探讨了VQ-VAE特征z对于重构生成的重要性，更多实验参照原文.</p> 
</blockquote> 
<h4><a id="_85"></a>总结与思考</h4> 
<p>MindDiffuser第一阶段的过程与上面第一篇文章基本上一样，都是基于直接构造fMRI到不同特征空间的映射模型，然后通过Stable Diffusion来进行图像重构。但不同点在于它没有引入过多先验，即通过ROI定位不同脑部视觉皮层区域的fMRI信号，而是直接针对完整的fMRI信号进行学习，这有助于简化数据获取难度。此外，MindDiffuser可以直接针对多个受试者同时训练模型，这说明其针对个体差异的泛化能力更强。</p> 
<p>本论文的主要贡献就是利用CLIP的图像特征，额外引入了一个结构信息对齐功能。因为在StableDiffusion框架下的生成过程会引入一定程度的随机性，在前向和逆向过程中都有随机噪声的参与，所以在浅层特征上引入一致性损失会改善这种现象。</p> 
<p>对于这个任务，能达到这种效果其实还是比较惊艳了，如果要完全重构出完整图像应该是不可能的，因为不同的人在观测时会注意到不同的模块，大脑产生的信号也不同。随着人工智能技术的发展，脑机接口时代到临可能真的不远了。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/76c6e331578460884c897a90621aa37e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Android Studio学习笔记--Activity的创建与使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5838f8445c594e5a833f3eb06fdc9e19/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">javascript基础二十七：说说 JavaScript 数字精度丢失的问题，解决方案？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>