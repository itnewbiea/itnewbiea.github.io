<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习之卷积神经网络--CNN介绍 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习之卷积神经网络--CNN介绍" />
<meta property="og:description" content="卷积神经网络–CNN 1. 卷积神经网络介绍 卷积神经网络（Convolutional Neural Networks，CNN）是一种包
含卷积计算且具有深度结构的前馈神经网络，是深度学习的代表算法之一。
常见的CNN网络有LeNet-5、VGGNet、GoogleNet、ResNet、
DenseNet、MobileNet等。
CNN主要应用场景： 图像分类、图像分割 、 目标检测 、 自然语言处
理等领域。
2. 卷积神经网络基本结构及原理 卷积神经网络基本结构 CNN基本结构：INPUT -&gt; 卷积-&gt;激活 -&gt; 池化 -&gt; 全连接 -&gt;OUTPUT
卷积层 对输入的图像数据与卷积核做卷积运算提取图像的高阶特征
卷积过程的几个参数
1、深度（depth）：卷积核个数，也称神经元个数，决定输出的特征图的数量。
2、步长（stride）：卷积核滑动一次的大小，决定滑动多少步可以到达边缘。
3、填充值（padding）：在外围边缘补充0的层数。
卷积过程 卷积网络最主要的两个特征
1、局部感知
2、权值共享
激活层、Relu函数
池化层 下采样（downsamples），对输入的特征图进行压缩；
一方面使特征图变小，简化网络计算复杂度，有效控制过拟合；
另一方面进行特征压缩，提取主要特征。
池化，规模一般为 2＊2，操作一般有2种：
最大池化（Max Pooling）。取4个点的最大值。这是最常用的池化方法。均值池化（Mean Pooling）。取4个点的均值。 全连接层 连接所有的特征，将输出值送给分类器，实现分类。
3. pytorch中卷积的实现 卷积层 torch.nn.Conv2d（）
参数说明
in_channels：输入通道数（深度）
out_channels：输出通道数（深度）
kernel_size：滤波器（卷积核）大小
stride：表示滤波器滑动的步长
padding：是否进行零填充
bias：默认为 True，表示使用偏置
groups：控制分组卷积，默认不分组，为1组。
dilation：卷积对输入的空间间隔，默认为 True
激活层 torch.nn.ReLU（）
参数说明
inplace:是否在原数据进行操作，默认是False
池化层 torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/7f460304e213a1d6e589a4a876c7f0b3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-15T10:41:24+08:00" />
<meta property="article:modified_time" content="2022-06-15T10:41:24+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习之卷积神经网络--CNN介绍</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="CNN_0"></a>卷积神经网络–CNN</h2> 
<h2><a id="1__2"></a>1. 卷积神经网络介绍</h2> 
<p>卷积神经网络（Convolutional Neural Networks，CNN）是一种包<br> 含卷积计算且具有深度结构的前馈神经网络，是深度学习的代表算法之一。<br> 常见的CNN网络有LeNet-5、VGGNet、GoogleNet、ResNet、<br> DenseNet、MobileNet等。<br> CNN主要应用场景： 图像分类、图像分割 、 目标检测 、 自然语言处<br> 理等领域。</p> 
<h2><a id="2__11"></a>2. 卷积神经网络基本结构及原理</h2> 
<h3><a id="_13"></a>卷积神经网络基本结构</h3> 
<p><img src="https://images2.imgbox.com/40/f3/NrJhtC2M_o.png" alt="在这里插入图片描述"></p> 
<p>CNN基本结构：INPUT -&gt; 卷积-&gt;激活 -&gt; 池化 -&gt; 全连接 -&gt;OUTPUT</p> 
<h3><a id="_20"></a>卷积层</h3> 
<p>对输入的图像数据与卷积核做卷积运算提取图像的高阶特征<br> 卷积过程的几个参数<br> 1、深度（depth）：卷积核个数，也称神经元个数，决定输出的特征图的数量。<br> <img src="https://images2.imgbox.com/6c/47/ajRJ5YoK_o.png" alt="在这里插入图片描述"></p> 
<p>2、步长（stride）：卷积核滑动一次的大小，决定滑动多少步可以到达边缘。<br> <img src="https://images2.imgbox.com/14/5c/Yxf8UYfc_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/34/1c/0XtDw6xN_o.png" alt="在这里插入图片描述"></p> 
<p>3、填充值（padding）：在外围边缘补充0的层数。</p> 
<h3><a id="_34"></a>卷积过程</h3> 
<p><img src="https://images2.imgbox.com/de/8a/AOT3fBbD_o.png" alt="在这里插入图片描述"></p> 
<p>卷积网络最主要的两个特征<br> 1、局部感知<br> 2、权值共享<br> 激活层、Relu函数</p> 
<h3><a id="_43"></a>池化层</h3> 
<p>下采样（downsamples），对输入的特征图进行压缩；<br> 一方面使特征图变小，简化网络计算复杂度，有效控制过拟合；<br> 另一方面进行特征压缩，提取主要特征。<br> 池化，规模一般为 2＊2，操作一般有2种：</p> 
<ul><li>最大池化（Max Pooling）。取4个点的最大值。这是最常用的池化方法。</li><li>均值池化（Mean Pooling）。取4个点的均值。</li><li><img src="https://images2.imgbox.com/3a/38/Rf9JH7ZH_o.png" alt="在这里插入图片描述"></li><li></ul> 
<h3><a id="_54"></a>全连接层</h3> 
<p>连接所有的特征，将输出值送给分类器，实现分类。<br> <img src="https://images2.imgbox.com/8e/16/NQOt0ge8_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3_pytorch_59"></a>3. pytorch中卷积的实现</h2> 
<h3><a id="_61"></a>卷积层</h3> 
<p>torch.nn.Conv2d（）<br> 参数说明<br> in_channels：输入通道数（深度）<br> out_channels：输出通道数（深度）<br> kernel_size：滤波器（卷积核）大小<br> stride：表示滤波器滑动的步长<br> padding：是否进行零填充<br> bias：默认为 True，表示使用偏置<br> groups：控制分组卷积，默认不分组，为1组。<br> dilation：卷积对输入的空间间隔，默认为 True</p> 
<h3><a id="_74"></a>激活层</h3> 
<p>torch.nn.ReLU（）<br> 参数说明<br> inplace:是否在原数据进行操作，默认是False</p> 
<h3><a id="_79"></a>池化层</h3> 
<p>torch.nn.MaxPool2d（）<br> torch.nn.AvgPool2d（）<br> 参数说明<br> kernel_size :表示做最大池化的窗口大小<br> stride：步长<br> padding：是否进行零填充<br> dilation：卷积对输入的空间间隔，默认为 True</p> 
<h3><a id="_88"></a>全连接层</h3> 
<p>torch.nn.Linear（）<br> 参数说明<br> in_features :输入特征数；<br> out_features：输出特征数；<br> bias：默认为 True，表示使用偏置</p> 
<h2><a id="4__94"></a>4. 经典卷积神经网络介绍</h2> 
<h3><a id="Lenet5_96"></a>Lenet-5</h3> 
<p>LeNet5卷积神经网络源于Yann LeCun在1998年发表的论文：Gradient-<br> based Learning Applied to Document Recognition，是一种用于手写数字识别的<br> 卷积神经网络。<br> LeNet-5是CNN网络架构中最知名的网络模型，是卷积神经网络的开山之<br> 作。</p> 
<h3><a id="AlexNet_106"></a>AlexNet</h3> 
<p>2012 年， AlexNet 横空出世。AlexNet 使⽤卷积神经⽹络，并以很⼤的优<br> 势赢得了ImageNet 2012 图像识别挑战赛冠军。<br> Alexnet模型由5个卷积层和3个池化Pooling 层 ，其中还有3个全连接层构<br> 成。AlexNet 跟 LeNet 结构类似，但使⽤了更多的卷积层和更⼤的参数空间来拟<br> 合⼤规模数据集 ImageNet。它是浅层神经⽹络和深度神经⽹络的分界线。</p> 
<h3><a id="cifar10_114"></a>cifar10数据介绍</h3> 
<p>CIFAR-10 是由 Hinton 的学生 Alex Krizhevsky 和 Ilya Sutskever 整理的一<br> 个用于识别普适物体的小型数据集。一共包含 10 个类别的 RGB 彩色图 片：飞<br> 机（ a叩lane ）、汽车（ automobile ）、鸟类（ bird ）、猫（ cat ）、鹿<br> （ deer ）、狗（ dog ）、蛙类（ frog ）、马（ horse ）、船（ ship ）和卡车<br> （ truck ）。图片的尺寸为 32×32 ，数据集中一共有 50000 张训练圄片和<br> 10000 张测试图片<img src="https://images2.imgbox.com/10/ee/Bz6N0qMh_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="VGGNet_124"></a>VGGNet</h3> 
<p>VGGNet 是由牛津大学视觉几何小组（Visual Geometry Group, VGG）提<br> 出的一种深层卷积网络结构，他们以 7.32% 的错误率赢得了 2014 年 ILSVRC 分<br> 类任务的亚军。<br> VGGNet探索了卷积神经网络的深度与其性能之间的关系，成功地构筑了<br> 16~19层深的卷积神经网络，证明了增加网络的深度能够在一定程度上影响网络<br> 最终的性能，使错误率大幅下降，同时拓展性又很强，迁移到其它图片数据上的<br> 泛化性也非常好。到目前为止，VGG仍然被用来提取图像特征。<br> VGG可以看成是加深版本的AlexNet。都是conv layer + FC layer</p> 
<h3><a id="GoogleNet_136"></a>GoogleNet</h3> 
<p>GoogleNet是2014年Google团队提出的一种全新的深度学习结构,赢得了<br> 2014 年 ILSVRC 分类任务的冠军。<br> GoogLeNet是第一个使用并行网络结构的经典模型，这在深度学习的发展<br> 历程中是具有开创性意义的。<br> GoogLeNet最基本的网络块是Inception，它是一个并联网络块，经过不断<br> 的迭代优化，发展出了Inception-v1、Inception-v2、Inception-v3、Inception-v4、<br> Inception-ResNet共5个版本。<br> Inception家族的迭代逻辑是通过结构优化来提升模型泛化能力、降低模型<br> 参数。</p> 
<h3><a id="ResNet_149"></a>ResNet</h3> 
<p>ResNet(残差网络) 网络是在 2015年 由微软实验室中的何凯明等几位大神<br> 提出，斩获当年ImageNet竞赛中分类任务第一名，目标检测第一名。获得COCO<br> 数据集中目标检测第一名，图像分割第一名。<br> 它使用了一种连接方式叫做“shortcut connection”，顾名思义，shortcut就<br> 是“抄近道”的意思。<img src="https://images2.imgbox.com/50/35/wYYKwFAW_o.png" alt="在这里插入图片描述"><br> ResNet block有两种，一种两层结构，一种三层结构<img src="https://images2.imgbox.com/cf/70/OnR2UtjJ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="MobileNet_158"></a>MobileNet</h3> 
<p>MobileNet是谷歌在2017年提出，专注于移动端或者嵌入式设备中的轻量<br> 级CNN网络。<br> MobileNet的基本单元是深度可分离卷积，其可以分解为两个更小的操作：<br> depthwise convolution和pointwise convolution。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/14a492a2e92b5abc440e519dbc82c7a9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">西门子200PLC指令详解——位逻辑指令</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d59c3152cf20261d0fd6cafe32677269/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python一 —— Python的垃圾回收机制</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>