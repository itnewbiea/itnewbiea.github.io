<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>137.CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving 笔记 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="137.CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving 笔记" />
<meta property="og:description" content="137.CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving 用于自动驾驶中物体检测的真实世界道路角落案例数据集
ECCV2022
文章结构：
摘要
1.引言
2.相关工作
3.CODA属性
4.CODA的构造
4.1概述 4.2识别潜在的角落案例 4.3进一步检查 5.实验
5.1实验细节 5.2结果 6.讨论
7.结论
附录
1.针对什么问题（摘要） 当代用于自动驾驶的深度学习物体检测方法通常假定普通交通参与者的类别是固定的，如行人和汽车。
大多数现有的检测器无法检测到不常见的物体和角落的情况（例如，一只狗穿过街道），这在某些情况下可能会导致严重的事故，使得可靠的自动驾驶在现实世界的应用时间线不确定。
阻碍真正可靠的自动驾驶系统发展的一个主要原因是缺乏公共数据集来评估角落案例中物体检测器的性能。
个人理解：
问题：用于自动驾驶的现存检测方法通常假定交通参与者的类别是固定的，如行人和汽车。
不能识别不常见的物体和角落（如一只狗穿过街道、失控的轮胎、翻转的卡车），可能会导致交通事故。
原因：没有一个这样的数据集来评估角落案例中物体检测器的性能。
2.解决办法（摘要） 引入了一个名为CODA的数据集。
该数据集由1500个真实世界驾驶场景组成，每个场景平均包含四个物体级别的角落案例，横跨30多个物体类别。
2.1 引入CODA数据集的必要性（摘要、相关工作） （相关工作）：
以前的检测器大多是在封闭世界环境中训练的，它只能检测属于预先定义的语义类别集的物体。
为了建立一个真实世界的感知系统，开放世界检测引起了更多关注，它可以明确地检测出未见过类别的物体是未知的。
（摘要）：
在CODA上，在大规模自动驾驶数据集上训练的标准物体检测器的性能在mAR上显著下降到不超过12.8%。
用最先进的物体检测器也不能可靠地识别CODA中的物体。
希望CODA数据集能够促进对现实世界自动驾驶的可靠检测的进一步研究。
mAR:
在深度学习中，mAR通常指的是“移动平均准确率”（moving average accuracy）。这是一种评估模型性能的指标，在训练过程中使用。它是通过计算模型在一段时间内预测正确的样本数量的移动平均值来衡量模型的准确率。
移动平均准确率可以帮助我们观察模型在训练过程中的稳定性和趋势。通过跟踪模型的移动平均准确率，我们可以了解模型是否在逐渐改进，或者是否出现了过拟合或欠拟合的情况。
为了计算移动平均准确率，我们首先定义一个窗口大小（例如，最近100个批次）。然后，每当经过一个新的批次时，我们计算该批次的准确率，并将其添加到移动平均值中。随着新的批次不断到来，旧的批次会从移动平均中剔除，以保持固定大小的窗口。
通过观察移动平均准确率，我们可以更好地理解模型的整体表现，并对其进行调整和优化。
必要性个人理解：并且在CODA上训练的物体检测器性能显著下降；用最先进的物体检测器也不能可靠地识别CODA中的物体。
3.创新点/贡献点（引言） 提出了CODA，第一个真实世界的道路角落案例数据集，作为开发完全可靠的自动驾驶车辆的基准。
评估了各种最先进的物体检测器（Cascade R-CNN [5], Deformable DETR [49], and Sparse R-CNN [39]），表明真正可靠的自动驾驶系统可能还远远没有达到。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/82593f3ce645be6ede115f9e243e2fe1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-27T16:12:29+08:00" />
<meta property="article:modified_time" content="2023-07-27T16:12:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">137.CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving 笔记</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="137CODA_A_RealWorld_Road_Corner_Case_Dataset_for_Object_Detection_in_Autonomous_Driving_0"></a>137.CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving</h2> 
<p>用于自动驾驶中物体检测的真实世界道路角落案例数据集</p> 
<blockquote> 
 <p>ECCV2022<br> 文章结构：</p> 
 <ul><li class="task-list-item"> <p><input type="checkbox" class="task-list-item-checkbox" checked disabled> 摘要</p> </li><li class="task-list-item"> <p><input type="checkbox" class="task-list-item-checkbox" checked disabled> 1.引言</p> </li><li class="task-list-item"> <p><input type="checkbox" class="task-list-item-checkbox" checked disabled> 2.相关工作</p> </li><li class="task-list-item"> <p><input type="checkbox" class="task-list-item-checkbox" checked disabled> 3.CODA属性</p> </li><li class="task-list-item"> <p><input type="checkbox" class="task-list-item-checkbox" disabled> 4.CODA的构造</p> 
   <ul><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked disabled> 4.1概述</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> 4.2识别潜在的角落案例</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> 4.3进一步检查</li></ul> </li><li class="task-list-item"> <p><input type="checkbox" class="task-list-item-checkbox" disabled> 5.实验</p> 
   <ul><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> 5.1实验细节</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> 5.2结果</li></ul> </li><li class="task-list-item"> <p><input type="checkbox" class="task-list-item-checkbox" checked disabled> 6.讨论</p> </li><li class="task-list-item"> <p><input type="checkbox" class="task-list-item-checkbox" checked disabled> 7.结论</p> </li><li class="task-list-item"> <p><input type="checkbox" class="task-list-item-checkbox" disabled> 附录</p> </li></ul> 
</blockquote> 
<h3><a id="1_34"></a>1.针对什么问题（摘要）</h3> 
<p>当代用于自动驾驶的深度学习物体检测方法通常假定普通交通参与者的类别是固定的，如行人和汽车。</p> 
<p>大多数现有的检测器无法检测到不常见的物体和角落的情况（例如，一只狗穿过街道），这在某些情况下可能会导致严重的事故，使得可靠的自动驾驶在现实世界的应用时间线不确定。</p> 
<p>阻碍真正可靠的自动驾驶系统发展的一个主要原因是缺乏公共数据集来评估角落案例中物体检测器的性能。</p> 
<blockquote> 
 <p>个人理解：</p> 
 <p><strong>问题</strong>：用于自动驾驶的现存检测方法通常假定交通参与者的类别是固定的，如行人和汽车。</p> 
 <p>不能识别不常见的物体和角落（如一只狗穿过街道、失控的轮胎、翻转的卡车），可能会导致交通事故。</p> 
 <p><strong>原因</strong>：没有一个这样的数据集来评估角落案例中物体检测器的性能。</p> 
</blockquote> 
<h3><a id="2_50"></a>2.解决办法（摘要）</h3> 
<p>引入了一个名为<strong>CODA的数据集</strong>。</p> 
<p>该数据集由1500个真实世界驾驶场景组成，每个场景平均包含四个物体级别的角落案例，横跨30多个物体类别。</p> 
<h4><a id="21_CODA_56"></a>2.1 引入CODA数据集的必要性（摘要、相关工作）</h4> 
<p>（相关工作）：</p> 
<ol><li> <p><strong>以前的检测器</strong>大多是在<strong>封闭世界</strong>环境中<strong>训练</strong>的，它<strong>只能检测</strong>属于<strong>预先定义的语义类别集</strong>的物体。</p> <p>为了建立一个真实世界的感知系统，<strong>开放世界检测</strong>引起了更多关注，它可以<strong>明确地检测出未见过类别的物体是未知的。</strong></p> </li></ol> 
<p>（摘要）：</p> 
<ol start="2"><li> <p>在CODA上，在大规模自动驾驶数据集上训练的标准物体检测器的性能在<strong>mAR</strong>上显著下降到不超过12.8%。</p> <p><strong>用最先进的物体检测器也不能可靠地识别CODA中的物体</strong>。</p> <p>希望CODA数据集能够促进对现实世界自动驾驶的可靠检测的进一步研究。</p> </li></ol> 
<blockquote> 
 <p><strong>mAR</strong>:</p> 
 <p>在深度学习中，<strong>mAR</strong>通常指的是“<strong>移动平均准确率</strong>”（moving average accuracy）。这是一种评估模型性能的指标，在训练过程中使用。它是通过计算模型在一段时间内预测正确的样本数量的移动平均值来衡量模型的准确率。</p> 
 <p>移动平均准确率可以帮助我们观察模型在训练过程中的稳定性和趋势。通过跟踪模型的移动平均准确率，我们可以了解模型是否在逐渐改进，或者是否出现了过拟合或欠拟合的情况。</p> 
 <p>为了计算移动平均准确率，我们首先定义一个窗口大小（例如，最近100个批次）。然后，每当经过一个新的批次时，我们计算该批次的准确率，并将其添加到移动平均值中。随着新的批次不断到来，旧的批次会从移动平均中剔除，以保持固定大小的窗口。</p> 
 <p>通过观察移动平均准确率，我们可以更好地理解模型的整体表现，并对其进行调整和优化。</p> 
</blockquote> 
<blockquote> 
 <p>必要性个人理解：并且在CODA上训练的物体检测器性能显著下降；用最先进的物体检测器也不能可靠地识别CODA中的物体。</p> 
</blockquote> 
<h3><a id="3_84"></a>3.创新点/贡献点（引言）</h3> 
<ul><li> <p><strong>提出了CODA</strong>，第一个真实世界的道路角落案例数据集，作为开发完全可靠的自动驾驶车辆的基准。</p> </li><li> <p><strong>评估了各种最先进的物体检测器</strong>（Cascade R-CNN [5], Deformable DETR [49], and Sparse R-CNN [39]），表明真正可靠的自动驾驶系统可能还远远没有达到。</p> </li><li> <p><strong>介绍了COPG</strong>,一个用于开发角落案例的通用管道。</p> <p>【角落案例建议生成办法（corner-case proposal generation,COPG）】</p> </li></ul> 
<h3><a id="4_94"></a>4.用了什么方法（引言）</h3> 
<p><strong>CODA</strong>：</p> 
<ol><li>CODA是由自动驾驶的三个主要目标检测基准构建而成——<strong>KITTI、nuScenes 和ONCE</strong></li></ol> 
<blockquote> 
 <p>KITTI、nuScenes和ONCE都是与自动驾驶和计算机视觉相关的<strong>数据集或项目</strong>。</p> 
 <ul><li> <p><strong>KITTI</strong>：KITTI（Karlsruhe Institute of Technology and Toyota Technological Institute）是一个著名的自动驾驶和计算机视觉<strong>数据集</strong>。它提供了包括图像、激光雷达点云、地面真值标签等多种类型的数据，用于目标检测、语义分割、立体视觉等任务的训练和评估。</p> </li><li> <p><strong>nuScenes</strong>：nuScenes是由nuTonomy公司发布的一个大规模自动驾驶<strong>数据集</strong>和<strong>场景库</strong>。它收集了来自汽车传感器（如相机、激光雷达、雷达等）的数据，提供了高质量的2D和3D注释信息（如目标框、语义分割等），用于自动驾驶系统的开发和评估。</p> </li><li> <p><strong>ONCE</strong>：ONCE（Object Annotation for Computer Vision Evaluation）是由中科院自动化研究所开发的一套目标检测<strong>数据集</strong>和<strong>标注工具</strong>。该项目旨在提供高质量的目标检测数据集，同时为用户提供方便的标注工具，以支持计算机视觉算法的研究和评估。</p> </li></ul> 
 <p>这些数据集和项目在自动驾驶和计算机视觉领域广泛应用，用于训练和评估算法，并推动相关技术的发展。</p> 
</blockquote> 
<blockquote> 
 <p>个人理解：CODA数据集来自于目标检测领域用于自动驾驶的三个主要数据集：<strong>KITTI、nuScenes 和ONCE</strong></p> 
</blockquote> 
<ol start="2"><li> <p>CODA的构成：（3.CODA的属性Properties）</p> <p><strong>CODA</strong>从超过一百万个场景的组合数据集（上面三个数据集）中选择了<strong>1500个场景（图像）</strong>，（每个场景至少包含一个对自动驾驶车辆或周围的生命和资产有危害物体级角落案例），从而产生了近6000个高质量的带注释的道路拐角案例。</p> 
  <ul><li> <p>角落的情况可以归纳为<strong>7个超类</strong>，34个细粒度的类别。</p> <p>车辆、行人、骑自行车的人、动物、交通设施、障碍物和杂项。</p> 
    <ul><li> <p>这些类可以分为新的类和常见的类。</p> 
      <ul><li>常见的类：汽车、行人…</li><li>新的类：狗、婴儿车…</li></ul> </li><li> <p>tricycle, car, pedestrian,cyclist,truck,bus motorcycle,bicycle ,traffic_light,traffic_sign,barrier,basket,bollard,cart,chair,concrete_block,construction_vehicle,debris,dog,dustbin,machinery,misc,moped,phone_booth,recreational_vehicle,sentry_box,stroller,suitcase,traffic_box,traffic_cone,traffic_island,trailer,warning_sign,wheelchair</p> <p>三轮车、汽车、行人、骑自行车的人、卡车、公共汽车、摩托车、自行车、交通灯、交通标志、障碍物、篮子、系船柱、手推车、椅子、混凝土块、建筑车辆、碎片、狗、垃圾箱、机械、杂项、轻便摩托车、电话亭、休闲车、岗亭、婴儿车、手提箱、交通箱、交通锥、交通岛、拖车、警告标志、轮椅</p> </li></ul> </li></ul> <p>​ CODA中超过90% 的实例属于新的类别。</p> </li><li> <p>CODA数据多样性（3.CODA的属性Properties）</p> 
  <ul><li> <p>对象层面：包含<strong>广泛的对象类</strong>，大部分被现有的数据集忽略。<code>如图3</code></p> </li><li> <p>场景层面：CODA包含来自<strong>三个不同国家</strong>的场景，<code>如图2</code>.</p> 
    <ul><li>展示了不同的天气状况，75%晴朗，22%多云，4% 多雨</li><li>91%是白天场景，9%是夜晚场景</li></ul> </li><li> <p>与道路异常数据集比较，<code>如表1</code>，这些数据集也有对象级别的注释。</p> <p>这些数据集要么是合成的，要么是小规模的。</p> <p>现实世界中最大的一个道路异常数据集BDD-Anomaly，只包含两个对象类别，尽管它在数量上与CODA相当<br> <img src="https://images2.imgbox.com/d0/79/6727n65M_o.png" alt="在这里插入图片描述"><br> 图3<br> <img src="https://images2.imgbox.com/c8/b7/OXRcQp7X_o.png" alt="在这里插入图片描述"><br> 图2<br> <img src="https://images2.imgbox.com/54/fa/nbXhpj0b_o.png" alt="在这里插入图片描述"><br> 表1</p> </li></ul> </li><li> <p>CODA的选择过程包括<strong>两个阶段</strong>：（引言、4.1概述）</p> 
  <ul><li> <p>关于潜在角落案例的全自动提案的<strong>生成</strong>（从初始数据中识别潜在角落案例）</p> </li><li> <p>对提案的<strong>人工检查和修正</strong>（手动选择和标记过程，消除提案的假阳性，对剩余真阳性进行分类，同时调整边界框，使其更加精确）</p> 
    <blockquote> 
     <p>我们的<strong>角落案例建议生成办法</strong>（corner-case proposal generation**,COPG**）<code>如图5</code>：</p> 
     <ul><li>大大减少了第二阶段的人力劳动</li><li>是通过一个<strong>通用的管道</strong>，只需要<strong>相机</strong>和<strong>激光雷达传感器</strong>的原始数据，即二维图像和三维点云（也就是说，<strong>不需要注释</strong>），以识别任何给定数据集中的潜在角落情况。<br> <img src="https://images2.imgbox.com/ae/d3/r0WvIaOi_o.png" alt="在这里插入图片描述"><br> 图5</li></ul> 
    </blockquote> </li></ul> </li><li> <p>我们希望CODA可以作为一种有效的手段来评估及其感知在<strong>自动驾驶中的鲁棒性</strong>，并反过来促进真正可靠的自动驾驶系统的发展。</p> </li><li> <p>（4.CODA的构造）</p> <p><strong>判断一个物体是否是角落案例的标准</strong>：</p> 
  <ul><li> <p><strong>风险</strong>：物体<strong>阻挡或即将阻挡</strong>装有摄像头的自动驾驶车辆的潜在路径。</p> <p>不在道路上的静态物体，如树木和建筑物，不被认为会阻挡车辆。</p> <p><strong>表明该物体可能被车辆击中</strong></p> </li><li> <p><strong>新颖性</strong>：该对象不属于任何自动驾驶基准的通用类，或者它是通用类的<strong>新实例</strong>。</p> <p>为简单起见，我们将SODA10M [13]的类作为公共类</p> <p><strong>表明该物体很难检测到。</strong></p> </li></ul> 
  <blockquote> 
   <p>总结：</p> 
   <p>判断一个物体是否是角落案例的<strong>标准</strong>：<br> 1.该物体<strong>可能被车辆击中</strong><br> 2.该物体<strong>很难检测到</strong></p> 
   <p>满足这两点就是角落案例</p> 
  </blockquote> 
  <blockquote> 
   <ol><li> <p>封闭世界物体检测器：</p> <p>单阶段：Reti-naNet[22]</p> <p>双阶段：Faster R-CNN[34]、Cascade R-CNN[5]</p> </li><li> <p>开放世界物体检测器：</p> <p>最先进的ORE[19]</p> </li></ol> 
  </blockquote> </li></ol> 
<h3><a id="5_203"></a>5.结论</h3> 
<ul><li>​ 本文中，<strong>提出了CODA</strong>，一个用于自主驾驶中物体检测的真实世界道路角落案例数据集，由地面实况分类和自动的提案构成。</li><li>我们观察到，当部署在CDA上时，最先进的检测器的<strong>性能明显下降</strong>。</li><li>我们进一步对不同的方法进行了彻底的比较，并阐明了更强大的感知系统的<strong>潜在解决方案</strong>。</li><li>希望CODA能够<strong>激励人们</strong>进一步研究现实世界中自动驾驶的可靠性检测。</li></ul> 
<h3><a id="6_210"></a>6.局限性和未来工作</h3> 
<p>我们将继续通过探索<strong>扩大CODA</strong>。</p> 
<ul><li>在更多真实世界的道路场景中使用COPG（<strong>角落案例建议生成办法</strong>（corner-case proposal generation,COPG））</li><li>由于CODA是在现实世界中收集的，具有高质量的注释，我们可以按照[1,17]<strong>生成更多的合成图像</strong>，或者以半监督的方式挖掘大规模未标记的道路场景图像。</li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/77b31ac12eae3a84231bd3719ebc183c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">在 Vue3 中实现飘逸的元素拖拽</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9b8cc94d4d4d47d31290eb6e9af31579/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">windows/linux git安装</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>