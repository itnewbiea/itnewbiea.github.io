<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习毕业设计 CNN实现谣言检测系统 - python 机器学习 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习毕业设计 CNN实现谣言检测系统 - python 机器学习" />
<meta property="og:description" content="文章目录 1 前言1.1 背景 2 数据集3 实现过程4 CNN网络实现5 模型训练部分6 模型评估7 预测结果8 最后 1 前言 Hi，大家好，学长今天向大家介绍 一个深度学习项目
基于CNN实现谣言检测
1.1 背景 社交媒体的发展在加速信息传播的同时，也带来了虚假谣言信息的泛滥，往往会引发诸多不安定因素，并对经济和社会产生巨大的影响。
2 数据集 本项目所使用的数据是从新浪微博不实信息举报平台抓取的中文谣言数据，数据集中共包含1538条谣言和1849条非谣言。
如下图所示，每条数据均为json格式，其中text字段代表微博原文的文字内容。
每个文件夹里又有很多新闻文本。
每个文本又是json格式，具体内容如下：
3 实现过程 步骤入下：
*（1）解压数据，读取并解析数据，生成all_data.txt
*（2）生成数据字典，即dict.txt
*（3）生成数据列表，并进行训练集与验证集的划分，train_list.txt 、eval_list.txt
*（4）定义训练数据集提供器train_reader和验证数据集提供器eval_reader
import zipfile import os import io import random import json import matplotlib.pyplot as plt import numpy as np import paddle import paddle.fluid as fluid from paddle.fluid.dygraph.nn import Conv2D, Linear, Embedding from paddle.fluid.dygraph.base import to_variable #解压原始数据集，将Rumor_Dataset.zip解压至data目录下 src_path=&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/512f5602414fa12d1ceba55e7031bcd8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-09T11:00:03+08:00" />
<meta property="article:modified_time" content="2023-02-09T11:00:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习毕业设计 CNN实现谣言检测系统 - python 机器学习</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1__3" rel="nofollow">1 前言</a></li><li><ul><li><a href="#11__11" rel="nofollow">1.1 背景</a></li></ul> 
  </li><li><a href="#2___16" rel="nofollow">2 数据集</a></li><li><a href="#3__32" rel="nofollow">3 实现过程</a></li><li><a href="#4_CNN_254" rel="nofollow">4 CNN网络实现</a></li><li><a href="#5__350" rel="nofollow">5 模型训练部分</a></li><li><a href="#6__415" rel="nofollow">6 模型评估</a></li><li><a href="#7__460" rel="nofollow">7 预测结果</a></li><li><a href="#8__502" rel="nofollow">8 最后</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1__3"></a>1 前言</h2> 
<p>Hi，大家好，学长今天向大家介绍 一个深度学习项目</p> 
<p><strong>基于CNN实现谣言检测</strong></p> 
<h3><a id="11__11"></a>1.1 背景</h3> 
<p>社交媒体的发展在加速信息传播的同时，也带来了虚假谣言信息的泛滥，往往会引发诸多不安定因素，并对经济和社会产生巨大的影响。</p> 
<h2><a id="2___16"></a>2 数据集</h2> 
<p>本项目所使用的数据是从新浪微博不实信息举报平台抓取的中文谣言数据，数据集中共包含1538条谣言和1849条非谣言。</p> 
<p>如下图所示，每条数据均为json格式，其中text字段代表微博原文的文字内容。</p> 
<p><img src="https://images2.imgbox.com/06/33/8PDq2VSG_o.png" alt="在这里插入图片描述"></p> 
<p>每个文件夹里又有很多新闻文本。</p> 
<p><img src="https://images2.imgbox.com/7a/3d/lQclWgez_o.png" alt="在这里插入图片描述"><br> 每个文本又是json格式，具体内容如下：</p> 
<p><img src="https://images2.imgbox.com/ff/95/mlygj2fz_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3__32"></a>3 实现过程</h2> 
<p>步骤入下：</p> 
<p>*（1）解压数据，读取并解析数据，生成all_data.txt<br> *（2）生成数据字典，即dict.txt<br> *（3）生成数据列表，并进行训练集与验证集的划分，train_list.txt 、eval_list.txt<br> *（4）定义训练数据集提供器train_reader和验证数据集提供器eval_reader</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> zipfile
<span class="token keyword">import</span> os
<span class="token keyword">import</span> io
<span class="token keyword">import</span> random
<span class="token keyword">import</span> json
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> paddle
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid
<span class="token keyword">from</span> paddle<span class="token punctuation">.</span>fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2D<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Embedding
<span class="token keyword">from</span> paddle<span class="token punctuation">.</span>fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>base <span class="token keyword">import</span> to_variable

<span class="token comment">#解压原始数据集，将Rumor_Dataset.zip解压至data目录下</span>
src_path<span class="token operator">=</span><span class="token string">"/home/aistudio/data/data36807/Rumor_Dataset.zip"</span> <span class="token comment">#这里填写自己项目所在的数据集路径</span>
target_path<span class="token operator">=</span><span class="token string">"/home/aistudio/data/Chinese_Rumor_Dataset-master"</span>
<span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>target_path<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    z <span class="token operator">=</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span>src_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
    z<span class="token punctuation">.</span>extractall<span class="token punctuation">(</span>path<span class="token operator">=</span>target_path<span class="token punctuation">)</span>
    z<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#分别为谣言数据、非谣言数据、全部数据的文件路径</span>
rumor_class_dirs <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>target_path<span class="token operator">+</span><span class="token string">"非开源数据集"</span><span class="token punctuation">)</span> <span class="token comment"># 这里填写自己项目所在的数据集路径</span>
non_rumor_class_dirs <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>target_path<span class="token operator">+</span><span class="token string">"非开源数据集"</span><span class="token punctuation">)</span>
original_microblog <span class="token operator">=</span> target_path<span class="token operator">+</span><span class="token string">"非开源数据集"</span>
<span class="token comment">#谣言标签为0，非谣言标签为1</span>
rumor_label<span class="token operator">=</span><span class="token string">"0"</span>
non_rumor_label<span class="token operator">=</span><span class="token string">"1"</span>

<span class="token comment">#分别统计谣言数据与非谣言数据的总数</span>
rumor_num <span class="token operator">=</span> <span class="token number">0</span>
non_rumor_num <span class="token operator">=</span> <span class="token number">0</span>
all_rumor_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
all_non_rumor_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment">#解析谣言数据</span>
<span class="token keyword">for</span> rumor_class_dir <span class="token keyword">in</span> rumor_class_dirs<span class="token punctuation">:</span> 
    <span class="token keyword">if</span><span class="token punctuation">(</span>rumor_class_dir <span class="token operator">!=</span> <span class="token string">'.DS_Store'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#遍历谣言数据，并解析</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>original_microblog <span class="token operator">+</span> rumor_class_dir<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            rumor_content <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
        rumor_dict <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>rumor_content<span class="token punctuation">)</span>
        all_rumor_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>rumor_label<span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span>rumor_dict<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
        rumor_num <span class="token operator">+=</span><span class="token number">1</span>
<span class="token comment">#解析非谣言数据</span>
<span class="token keyword">for</span> non_rumor_class_dir <span class="token keyword">in</span> non_rumor_class_dirs<span class="token punctuation">:</span> 
    <span class="token keyword">if</span><span class="token punctuation">(</span>non_rumor_class_dir <span class="token operator">!=</span> <span class="token string">'.DS_Store'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>original_microblog <span class="token operator">+</span> non_rumor_class_dir<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f2<span class="token punctuation">:</span>
            non_rumor_content <span class="token operator">=</span> f2<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
        non_rumor_dict <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>non_rumor_content<span class="token punctuation">)</span>
        all_non_rumor_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>non_rumor_label<span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span>non_rumor_dict<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
        non_rumor_num <span class="token operator">+=</span><span class="token number">1</span>
        
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"谣言数据总量为："</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>rumor_num<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"非谣言数据总量为："</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>non_rumor_num<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#全部数据进行乱序后写入all_data.txt</span>
data_list_path<span class="token operator">=</span><span class="token string">"/home/aistudio/data/"</span>
all_data_path<span class="token operator">=</span>data_list_path <span class="token operator">+</span> <span class="token string">"all_data.txt"</span>
all_data_list <span class="token operator">=</span> all_rumor_list <span class="token operator">+</span> all_non_rumor_list

random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>all_data_list<span class="token punctuation">)</span>

<span class="token comment">#在生成all_data.txt之前，首先将其清空</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span> 
    
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>all_data_path<span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> all_data_list<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data<span class="token punctuation">)</span> 
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'all_data.txt已生成'</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/1b/01/Dcu4kQRT_o.png" alt="在这里插入图片描述"></p> 
<p><strong>接下来就是生成数据字典。</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 生成数据字典</span>
<span class="token keyword">def</span> <span class="token function">create_dict</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> dict_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        f<span class="token punctuation">.</span>truncate<span class="token punctuation">(</span><span class="token punctuation">)</span> 

    dict_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 读取全部数据</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 把数据生成一个元组</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        content <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> s <span class="token keyword">in</span> content<span class="token punctuation">:</span>
            dict_set<span class="token punctuation">.</span>add<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
    <span class="token comment"># 把元组转换成字典，一个字对应一个数字</span>
    dict_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> s <span class="token keyword">in</span> dict_set<span class="token punctuation">:</span>
        dict_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>s<span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        i <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token comment"># 添加未知字符</span>
    dict_txt <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>dict_list<span class="token punctuation">)</span>
    end_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"&lt;unk&gt;"</span><span class="token punctuation">:</span> i<span class="token punctuation">}</span>
    dict_txt<span class="token punctuation">.</span>update<span class="token punctuation">(</span>end_dict<span class="token punctuation">)</span>
    <span class="token comment"># 把这些字典保存到本地中</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dict_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"数据字典生成完成！"</span><span class="token punctuation">,</span><span class="token string">'\t'</span><span class="token punctuation">,</span><span class="token string">'字典长度为：'</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>dict_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>我们可以查看一下dict_txt的内容</p> 
<p><img src="https://images2.imgbox.com/80/42/oAoLFTcm_o.png" alt="在这里插入图片描述"></p> 
<p>接下来就是数据列表的生成</p> 
<pre><code class="prism language-python"><span class="token comment"># 创建序列化表示的数据,并按照一定比例划分训练数据与验证数据</span>
<span class="token keyword">def</span> <span class="token function">create_data_list</span><span class="token punctuation">(</span>data_list_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'dict.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        dict_txt <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'all_data.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'eval_list.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_eval<span class="token punctuation">,</span>\
    <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_list_path<span class="token punctuation">,</span> <span class="token string">'train_list.txt'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_train<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
            title <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>
            lab <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            t_ids <span class="token operator">=</span> <span class="token string">""</span>
            <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">8</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> s <span class="token keyword">in</span> title<span class="token punctuation">:</span>
                    temp <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span>
                    t_ids <span class="token operator">=</span> t_ids <span class="token operator">+</span> temp <span class="token operator">+</span> <span class="token string">','</span>
                t_ids <span class="token operator">=</span> t_ids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">'\t'</span> <span class="token operator">+</span> lab <span class="token operator">+</span> <span class="token string">'\n'</span>
                f_eval<span class="token punctuation">.</span>write<span class="token punctuation">(</span>t_ids<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> s <span class="token keyword">in</span> title<span class="token punctuation">:</span>
                    temp <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span>
                    t_ids <span class="token operator">=</span> t_ids <span class="token operator">+</span> temp <span class="token operator">+</span> <span class="token string">','</span>
                t_ids <span class="token operator">=</span> t_ids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">'\t'</span> <span class="token operator">+</span> lab <span class="token operator">+</span> <span class="token string">'\n'</span>
                f_train<span class="token punctuation">.</span>write<span class="token punctuation">(</span>t_ids<span class="token punctuation">)</span>
            i <span class="token operator">+=</span> <span class="token number">1</span>
        
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"数据列表生成完成！"</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>定义数据读取器</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">data_reader</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> phrase<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    all_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">with</span> io<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fin<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> fin<span class="token punctuation">:</span>
            cols <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>cols<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>cols<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            
            wids <span class="token operator">=</span> cols<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
            all_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>wids<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> shuffle<span class="token punctuation">:</span>
        <span class="token keyword">if</span> phrase <span class="token operator">==</span> <span class="token string">"train"</span><span class="token punctuation">:</span>
            random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>all_data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">reader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> doc<span class="token punctuation">,</span> label <span class="token keyword">in</span> all_data<span class="token punctuation">:</span>
            <span class="token keyword">yield</span> doc<span class="token punctuation">,</span> label
    <span class="token keyword">return</span> reader

<span class="token keyword">class</span> <span class="token class-name">SentaProcessor</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dir<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data_dir <span class="token operator">=</span> data_dir
        
    <span class="token keyword">def</span> <span class="token function">get_train_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dir<span class="token punctuation">,</span> shuffle<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> data_reader<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_dir <span class="token operator">+</span> <span class="token string">"train_list.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                            <span class="token string">"train"</span><span class="token punctuation">,</span> shuffle<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_eval_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dir<span class="token punctuation">,</span> shuffle<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> data_reader<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_dir <span class="token operator">+</span> <span class="token string">"eval_list.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                            <span class="token string">"eval"</span><span class="token punctuation">,</span> shuffle<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">data_generator</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> phase<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">"train"</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> paddle<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>get_train_data<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_dir<span class="token punctuation">,</span> shuffle<span class="token punctuation">)</span><span class="token punctuation">,</span>
                batch_size<span class="token punctuation">,</span>
                drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> phase <span class="token operator">==</span> <span class="token string">"eval"</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> paddle<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>get_eval_data<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_dir<span class="token punctuation">,</span> shuffle<span class="token punctuation">)</span><span class="token punctuation">,</span>
                batch_size<span class="token punctuation">,</span>
                drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                <span class="token string">"Unknown phase, which should be in ['train', 'eval']"</span><span class="token punctuation">)</span>
</code></pre> 
<p>总之在数据处理这一块需要我们注意的是一共生成以下的几个文件。</p> 
<p><img src="https://images2.imgbox.com/40/2d/u97mnMAb_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="4_CNN_254"></a>4 CNN网络实现</h2> 
<p>接下来就是构建以及配置卷积神经网络(Convolutional Neural Networks, CNN)，开篇也说了，其实这里有很多模型的选择，之所以选择CNN是因为让我们熟悉CNN的相关实现。 输入词向量序列，产生一个特征图（feature map），对特征图采用时间维度上的最大池化（max pooling over time）操作得到此卷积核对应的整句话的特征，最后，将所有卷积核得到的特征拼接起来即为文本的定长向量表示，对于文本分类问题，将其连接至softmax即构建出完整的模型。在实际应用中，我们会使用多个卷积核来处理句子，窗口大小相同的卷积核堆叠起来形成一个矩阵，这样可以更高效的完成运算。另外，我们也可使用窗口大小不同的卷积核来处理句子。具体的流程如下：</p> 
<p><img src="https://images2.imgbox.com/2a/70/rFsAFPQy_o.png" alt="在这里插入图片描述"><br> 首先我们构建单层CNN神经网络。</p> 
<pre><code class="prism language-python"><span class="token comment">#单层</span>
<span class="token keyword">class</span> <span class="token class-name">SimpleConvPool</span><span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 num_channels<span class="token punctuation">,</span> <span class="token comment"># 通道数</span>
                 num_filters<span class="token punctuation">,</span>  <span class="token comment"># 卷积核数量</span>
                 filter_size<span class="token punctuation">,</span>  <span class="token comment"># 卷积核大小</span>
                 batch_size<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 16</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SimpleConvPool<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size
        self<span class="token punctuation">.</span>_conv2d <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>num_channels <span class="token operator">=</span> num_channels<span class="token punctuation">,</span>
            num_filters <span class="token operator">=</span> num_filters<span class="token punctuation">,</span>
            filter_size <span class="token operator">=</span> filter_size<span class="token punctuation">,</span>
            act<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_pool2d <span class="token operator">=</span> fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>Pool2D<span class="token punctuation">(</span>
            pool_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">150</span> <span class="token operator">-</span> filter_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            pool_type <span class="token operator">=</span> <span class="token string">'max'</span><span class="token punctuation">,</span>
            pool_stride<span class="token operator">=</span><span class="token number">1</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print('SimpleConvPool_inputs数据纬度',inputs.shape) # [16, 1, 148, 128]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>_conv2d<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


<span class="token keyword">class</span> <span class="token class-name">CNN</span><span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>CNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dict_dim <span class="token operator">=</span> train_parameters<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>emb_dim <span class="token operator">=</span> <span class="token number">128</span>   <span class="token comment">#emb纬度</span>
        self<span class="token punctuation">.</span>hid_dim <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span>  <span class="token comment">#卷积核数量</span>
        self<span class="token punctuation">.</span>fc_hid_dim <span class="token operator">=</span> <span class="token number">96</span>  <span class="token comment">#fc参数纬度</span>
        self<span class="token punctuation">.</span>class_dim <span class="token operator">=</span> <span class="token number">2</span>    <span class="token comment">#分类数</span>
        self<span class="token punctuation">.</span>channels <span class="token operator">=</span> <span class="token number">1</span>     <span class="token comment">#输入通道数</span>
        self<span class="token punctuation">.</span>win_size <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">]</span>  <span class="token comment"># 卷积核尺寸</span>
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> train_parameters<span class="token punctuation">[</span><span class="token string">"batch_size"</span><span class="token punctuation">]</span> 
        self<span class="token punctuation">.</span>seq_len <span class="token operator">=</span> train_parameters<span class="token punctuation">[</span><span class="token string">"padding_size"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> Embedding<span class="token punctuation">(</span> 
            size<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>dict_dim <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>emb_dim<span class="token punctuation">]</span><span class="token punctuation">,</span>
            dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">,</span> 
            is_sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_simple_conv_pool_1 <span class="token operator">=</span> SimpleConvPool<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>channels<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>hid_dim<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>win_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            batch_size<span class="token operator">=</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_fc1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>input_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>hid_dim<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                            output_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_hid_dim<span class="token punctuation">,</span>
                            act<span class="token operator">=</span><span class="token string">"tanh"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_fc_prediction <span class="token operator">=</span> Linear<span class="token punctuation">(</span>input_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_hid_dim<span class="token punctuation">,</span>
                                    output_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>class_dim<span class="token punctuation">,</span>
                                    act<span class="token operator">=</span><span class="token string">"softmax"</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        emb <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span> <span class="token comment"># [2400, 128]</span>
        <span class="token comment"># print('CNN_emb',emb.shape)  </span>
        emb <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>   <span class="token comment"># [16, 1, 150, 128]</span>
            emb<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>channels <span class="token punctuation">,</span> self<span class="token punctuation">.</span>seq_len<span class="token punctuation">,</span> self<span class="token punctuation">.</span>emb_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># print('CNN_emb',emb.shape)</span>
        conv_3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_simple_conv_pool_1<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
        fc_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_fc1<span class="token punctuation">(</span>conv_3<span class="token punctuation">)</span>
        prediction <span class="token operator">=</span> self<span class="token punctuation">.</span>_fc_prediction<span class="token punctuation">(</span>fc_1<span class="token punctuation">)</span>
        <span class="token keyword">if</span> label <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            acc <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span>
            <span class="token keyword">return</span> prediction<span class="token punctuation">,</span> acc
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> prediction
</code></pre> 
<p>接下来就是参数的配置，不过为了在模型训练过程中更直观的查看我们训练的准确率，我们首先利用python的matplotlib.pyplt函数实现一个可视化图，具体的实现如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">draw_train_process</span><span class="token punctuation">(</span>iters<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> train_accs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    title<span class="token operator">=</span><span class="token string">"training loss/training accs"</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>title<span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"iter"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"loss/acc"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>iters<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'training loss'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>iters<span class="token punctuation">,</span> train_accs<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'green'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'training accs'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="5__350"></a>5 模型训练部分</h2> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>guard<span class="token punctuation">(</span>place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CUDAPlace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 因为要进行很大规模的训练，因此我们用的是GPU，如果没有安装GPU的可以使用下面一句，把这句代码注释掉即可</span>
    <span class="token comment"># with fluid.dygraph.guard(place = fluid.CPUPlace()):</span>

        processor <span class="token operator">=</span> SentaProcessor<span class="token punctuation">(</span> data_dir<span class="token operator">=</span><span class="token string">"data/"</span><span class="token punctuation">)</span>
    
        train_data_generator <span class="token operator">=</span> processor<span class="token punctuation">.</span>data_generator<span class="token punctuation">(</span>
            batch_size<span class="token operator">=</span>train_parameters<span class="token punctuation">[</span><span class="token string">"batch_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            phase<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span>
            shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            
        model <span class="token operator">=</span> CNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
        sgd_optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adagrad<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>train_parameters<span class="token punctuation">[</span><span class="token string">"adam"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>parameter_list<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        steps <span class="token operator">=</span> <span class="token number">0</span>
        Iters<span class="token punctuation">,</span>total_loss<span class="token punctuation">,</span> total_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> eop <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>train_parameters<span class="token punctuation">[</span><span class="token string">"epoch"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_data_generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                steps <span class="token operator">+=</span> <span class="token number">1</span>
                <span class="token comment">#转换为 variable 类型</span>
                doc <span class="token operator">=</span> to_variable<span class="token punctuation">(</span>
                    np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
                        np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>train_parameters<span class="token punctuation">[</span><span class="token string">"padding_size"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment">#对句子进行padding，全部填补为定长150</span>
                              <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> train_parameters<span class="token punctuation">[</span><span class="token string">"padding_size"</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>train_parameters<span class="token punctuation">[</span><span class="token string">"padding_size"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                               <span class="token string">'constant'</span><span class="token punctuation">,</span>
                              constant_values<span class="token operator">=</span><span class="token punctuation">(</span>train_parameters<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 用 &lt;unk&gt; 的id 进行填补</span>
                        <span class="token keyword">for</span> x <span class="token keyword">in</span> data
                    <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'int64'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment">#转换为 variable 类型</span>
                label <span class="token operator">=</span> to_variable<span class="token punctuation">(</span>
                    np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> data<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'int64'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>
                        train_parameters<span class="token punctuation">[</span><span class="token string">"batch_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

                model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#使用训练模式</span>
                prediction<span class="token punctuation">,</span> acc <span class="token operator">=</span> model<span class="token punctuation">(</span>doc<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
                avg_loss <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
                avg_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
                sgd_optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>avg_loss<span class="token punctuation">)</span>
                model<span class="token punctuation">.</span>clear_gradients<span class="token punctuation">(</span><span class="token punctuation">)</span>
                
                <span class="token keyword">if</span> steps <span class="token operator">%</span> train_parameters<span class="token punctuation">[</span><span class="token string">"skip_steps"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    Iters<span class="token punctuation">.</span>append<span class="token punctuation">(</span>steps<span class="token punctuation">)</span>
                    total_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>avg_loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                    total_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"eop: %d, step: %d, ave loss: %f, ave acc: %f"</span> <span class="token operator">%</span>
                         <span class="token punctuation">(</span>eop<span class="token punctuation">,</span> steps<span class="token punctuation">,</span>avg_loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>acc<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> steps <span class="token operator">%</span> train_parameters<span class="token punctuation">[</span><span class="token string">"save_steps"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    save_path <span class="token operator">=</span> train_parameters<span class="token punctuation">[</span><span class="token string">"checkpoints"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"/"</span><span class="token operator">+</span><span class="token string">"save_dir_"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>steps<span class="token punctuation">)</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'save model to: '</span> <span class="token operator">+</span> save_path<span class="token punctuation">)</span>
                    fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>save_dygraph<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                   save_path<span class="token punctuation">)</span>
                <span class="token comment"># break</span>
    draw_train_process<span class="token punctuation">(</span>Iters<span class="token punctuation">,</span> total_loss<span class="token punctuation">,</span> total_acc<span class="token punctuation">)</span>
</code></pre> 
<p>训练的过程以及训练的结果如下：</p> 
<p><img src="https://images2.imgbox.com/19/4b/rRzZVZ1V_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="6__415"></a>6 模型评估</h2> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">to_eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>guard<span class="token punctuation">(</span>place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CUDAPlace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        processor <span class="token operator">=</span> SentaProcessor<span class="token punctuation">(</span>data_dir<span class="token operator">=</span><span class="token string">"data/"</span><span class="token punctuation">)</span> <span class="token comment">#写自己的路径</span>

        eval_data_generator <span class="token operator">=</span> processor<span class="token punctuation">.</span>data_generator<span class="token punctuation">(</span>
                batch_size<span class="token operator">=</span>train_parameters<span class="token punctuation">[</span><span class="token string">"batch_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                phase<span class="token operator">=</span><span class="token string">'eval'</span><span class="token punctuation">,</span>
                shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        model_eval <span class="token operator">=</span> CNN<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#示例化模型</span>
        model<span class="token punctuation">,</span> _ <span class="token operator">=</span> fluid<span class="token punctuation">.</span>load_dygraph<span class="token punctuation">(</span><span class="token string">"data//save_dir_180.pdparams"</span><span class="token punctuation">)</span> <span class="token comment">#写自己的路径</span>
        model_eval<span class="token punctuation">.</span>load_dict<span class="token punctuation">(</span>model<span class="token punctuation">)</span>

        model_eval<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 切换为eval模式</span>
        total_eval_cost<span class="token punctuation">,</span> total_eval_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> eval_batch_id<span class="token punctuation">,</span> eval_data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>eval_data_generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            eval_np_doc <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>train_parameters<span class="token punctuation">[</span><span class="token string">"padding_size"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> train_parameters<span class="token punctuation">[</span><span class="token string">"padding_size"</span><span class="token punctuation">]</span> <span class="token operator">-</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>train_parameters<span class="token punctuation">[</span><span class="token string">"padding_size"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                    <span class="token string">'constant'</span><span class="token punctuation">,</span>
                                    constant_values<span class="token operator">=</span><span class="token punctuation">(</span>train_parameters<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                            <span class="token keyword">for</span> x <span class="token keyword">in</span> eval_data
                            <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'int64'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            eval_label <span class="token operator">=</span> to_variable<span class="token punctuation">(</span>
                                    np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> eval_data<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>
                                    <span class="token string">'int64'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>train_parameters<span class="token punctuation">[</span><span class="token string">"batch_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            eval_doc <span class="token operator">=</span> to_variable<span class="token punctuation">(</span>eval_np_doc<span class="token punctuation">)</span>
            eval_prediction<span class="token punctuation">,</span> eval_acc <span class="token operator">=</span> model_eval<span class="token punctuation">(</span>eval_doc<span class="token punctuation">,</span> eval_label<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>eval_prediction<span class="token punctuation">,</span> eval_label<span class="token punctuation">)</span>
            avg_loss <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
            total_eval_cost<span class="token punctuation">.</span>append<span class="token punctuation">(</span>avg_loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            total_eval_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>eval_acc<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Final validation result: ave loss: %f, ave acc: %f"</span> <span class="token operator">%</span>
        <span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>total_eval_cost<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>total_eval_acc<span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>   
</code></pre> 
<p>评估准确率如下：</p> 
<p><img src="https://images2.imgbox.com/ab/73/oiFcj9nK_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="7__460"></a>7 预测结果</h2> 
<pre><code class="prism language-python"><span class="token comment"># 获取数据</span>
<span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 读取数据字典</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data/dict.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_data<span class="token punctuation">:</span>
        dict_txt <span class="token operator">=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>f_data<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    dict_txt <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">)</span>
    <span class="token comment"># 把字符串数据转换成列表数据</span>
    keys <span class="token operator">=</span> dict_txt<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> s <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>
        <span class="token comment"># 判断是否存在未知字符</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> s <span class="token keyword">in</span> keys<span class="token punctuation">:</span>
            s <span class="token operator">=</span> <span class="token string">'&lt;unk&gt;'</span>
        data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>dict_txt<span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> data

train_parameters<span class="token punctuation">[</span><span class="token string">"batch_size"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
lab <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token string">'谣言'</span><span class="token punctuation">,</span> <span class="token string">'非谣言'</span><span class="token punctuation">]</span>
 
<span class="token keyword">with</span> fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>guard<span class="token punctuation">(</span>place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CUDAPlace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    data <span class="token operator">=</span> load_data<span class="token punctuation">(</span><span class="token string">'兴仁县今天抢小孩没抢走，把孩子母亲捅了一刀，看见这车的注意了，真事，车牌号辽HFM055！！！！！赶紧散播！ 都别带孩子出去瞎转悠了 尤其别让老人自己带孩子出去 太危险了 注意了！！！！辽HFM055北京现代朗动，在各学校门口抢小孩！！！110已经 证实！！全市通缉！！'</span><span class="token punctuation">)</span>
    data_np <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    data_np <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>data_np<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">150</span><span class="token operator">-</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_np<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"constant"</span><span class="token punctuation">,</span>constant_values <span class="token operator">=</span>train_parameters<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'int64'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    infer_np_doc <span class="token operator">=</span> to_variable<span class="token punctuation">(</span>data_np<span class="token punctuation">)</span>
   
    model_infer <span class="token operator">=</span> CNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model<span class="token punctuation">,</span> _ <span class="token operator">=</span> fluid<span class="token punctuation">.</span>load_dygraph<span class="token punctuation">(</span><span class="token string">"data/save_dir_900.pdparams"</span><span class="token punctuation">)</span>
    model_infer<span class="token punctuation">.</span>load_dict<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    model_infer<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    result <span class="token operator">=</span> model_infer<span class="token punctuation">(</span>infer_np_doc<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预测结果为：'</span><span class="token punctuation">,</span> lab<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>result<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/58/88/BOA5b2Rv_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="8__502"></a>8 最后</h2>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a7aa961f06dab069ca6d4bcfef8f4062/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ingess报错</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7bc2dd3e9521b58bbdbd3774d3bcca6d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">深度学习通用训练步骤</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>