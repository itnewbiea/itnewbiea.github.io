<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python使用Redis实现IP代理池 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python使用Redis实现IP代理池" />
<meta property="og:description" content="可以使用快代理，芝麻代理，蘑菇代理 ，讯代理等代理商提供API代理IP或者免费代理建立自己IP代理池
#使用apscheduler库定时爬取ip，定时检测ip删除ip，做了2层检测，第一层爬取后放入redis——db0进行检测，成功的放入redis——db1再次进行检测，确保获取的代理ip的可用性 import requests, redis import pandas import random from apscheduler.schedulers.blocking import BlockingScheduler import datetime import logging db_conn = redis.ConnectionPool(host=&#34;*.*.*.*&#34;, port=6379, password=&#34;123456&#34;) redis_conn_0 = redis.Redis(connection_pool=db_conn, max_connections=10,db=0) redis_conn_1 = redis.Redis(connection_pool=db_conn, max_connections=10,db=1) # 删除redis数据库里的ip def remove_ip(ip,redis_conn): redis_conn.zrem(&#34;IP&#34;, ip) print(&#34;已删除 %s...&#34; % ip) # 获取redis数据库里一共有多少ip def get_ip_num(redis_conn): num = redis_conn.zcard(&#34;IP&#34;) return num # 获取ip的端口 def get_port(ip,redis_conn): port = redis_conn.zscore(&#34;IP&#34;, ip) port = str(port).replace(&#34;.0&#34;, &#34;&#34;) return port # 添加ip和端口到数据库里 def add_ip(ip, port,redis_conn): # nx: 不要更新已有的元素。总是添加新的元素,只有True，False redis_conn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/665b2a85a654dba684be0c3051df4039/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-02-25T23:31:50+08:00" />
<meta property="article:modified_time" content="2020-02-25T23:31:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python使用Redis实现IP代理池</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>可以使用快代理，芝麻代理，蘑菇代理 ，讯代理等代理商提供API代理IP或者免费代理建立自己IP代理池</p> 
<pre><code class="language-python">#使用apscheduler库定时爬取ip，定时检测ip删除ip，做了2层检测，第一层爬取后放入redis——db0进行检测，成功的放入redis——db1再次进行检测，确保获取的代理ip的可用性

import requests, redis
import pandas
import random

from apscheduler.schedulers.blocking import BlockingScheduler
import datetime
import logging

db_conn = redis.ConnectionPool(host="*.*.*.*", port=6379, password="123456")
redis_conn_0 = redis.Redis(connection_pool=db_conn, max_connections=10,db=0)
redis_conn_1 = redis.Redis(connection_pool=db_conn, max_connections=10,db=1)


# 删除redis数据库里的ip
def remove_ip(ip,redis_conn):
    redis_conn.zrem("IP", ip)
    print("已删除 %s..." % ip)


# 获取redis数据库里一共有多少ip
def get_ip_num(redis_conn):
    num = redis_conn.zcard("IP")
    return num


# 获取ip的端口
def get_port(ip,redis_conn):
    port = redis_conn.zscore("IP", ip)
    port = str(port).replace(".0", "")
    return port


# 添加ip和端口到数据库里
def add_ip(ip, port,redis_conn):
    # nx: 不要更新已有的元素。总是添加新的元素,只有True，False
    redis_conn.zadd("IP", {ip: port}, nx=55)
    print("已添加 %s %s...ok" % (ip, port))


# 列出所有的ip
def get_all_ip(redis_conn):
    all_ip = redis_conn.zrange("IP", 0, -1)
    return all_ip


# 随机获取一个ip
def get_random_ip(redis_conn):
    end_num = get_ip_num(redis_conn)
    num = random.randint(0, end_num)
    random_ip = redis_conn.zrange("IP", num, num)
    if not random_ip:
        return "",""
    random_ip = str(random_ip[0]).replace("b", '').replace("'", "")
    port = get_port(random_ip,redis_conn)
    return random_ip, port


# 获取代理ip
def spider_ip(x,redis_conn):
    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), x)
    for p in range(1, 20):
        res = pandas.read_html("http://www.89ip.cn/index_{}.html".format(p))
        # print(res)
        # print(type(res[0]))
        for i in range(len(res[0])):
            ip = res[0].iloc[i, 0]
            port = res[0].iloc[i, 1]
            print("ip", ip)
            print("port", port)
            add_ip(str(ip), str(port),redis_conn)


logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S',
                    filename='log1.txt',
                    filemode='a')


def aps_detection_ip(x,redis_conn):
    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), x)
    res=get_random_ip(redis_conn)
    ip=res[0]
    port=res[1]
    try:
        requests.get("http://www.baidu.com",proxies={'https':'{ip}:{port}'.format(ip=ip,port=port)})
        print("可用",ip,port,res)
        if redis_conn!=redis_conn_1:
            add_ip(str(ip), str(port), redis_conn_1)
    except Exception:
        # ip错误失效就删除
        remove_ip(ip,redis_conn)


scheduler = BlockingScheduler()
scheduler.add_job(func=aps_detection_ip, args=('检测循环任务0',redis_conn_0), trigger='interval', seconds=3, id='aps_detection_ip_task0',max_instances=10)
scheduler.add_job(func=spider_ip, args=('获取循环任务0',redis_conn_0), trigger='interval', seconds=60*60*2, id='spider_ip_task0',max_instances=10)

scheduler.add_job(func=aps_detection_ip, args=('检测循环任务1',redis_conn_1), trigger='interval', seconds=3, id='aps_detection_ip_task1',max_instances=10)

scheduler._logger = logging

# scheduler.start()
if __name__ == '__main__':
    # print(get_ip_num())
    # spider_ip("获取循环任务")
    scheduler.start()
    # aps_detection_ip("检测循环任务")</code></pre> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e7f809b7d5171c23f684ac290e704957/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">运行python代码import cv2时报错的解决方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/df1c85b5e0c93e61d8fc2974ee030aa6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">stm32cube 串口空闲中断接收（非DMA方式）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>