<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>cora数据集示例项目学习图神经网络 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="cora数据集示例项目学习图神经网络" />
<meta property="og:description" content="下面所有博客是个人对EEG脑电的探索，项目代码是早期版本不完整，需要完整项目代码和资料请私聊。
数据集
1、脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED
相关论文阅读分析：
1、EEG-SEED数据集作者的—基线论文阅读和分析
2、图神经网络EEG论文阅读和分析：《EEG-Based Emotion Recognition Using Regularized Graph Neural Networks》
3、EEG-GNN论文阅读和分析：《EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks》
4、论文阅读和分析:Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification
5、论文阅读和分析：《DeepGCNs: Can GCNs Go as Deep as CNNs?》
6、论文阅读和分析： “How Attentive are Graph Attention Networks?”
7、论文阅读和分析：Simplifying Graph Convolutional Networks
8、论文阅读和分析：LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation
9、图神经网络汇总和总结
相关实验和代码实现：
1、用于图神经网络的脑电数据处理实现_图神经网络 脑电
2、使用GCN训练和测试EEG的公开SEED数据集
3、使用GAT训练和测试EEG公开的SEED数据集
4、使用SGC训练和测试SEED数据集
5、使用Transformer训练和测试EEG的公开SEED数据集_eeg transformer" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/5d6f5b5ed88d20e11881d95ded82b22f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-05T12:28:31+08:00" />
<meta property="article:modified_time" content="2023-04-05T12:28:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">cora数据集示例项目学习图神经网络</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p><strong><font size="3" face="Courier New">下面所有博客是个人对EEG脑电的探索，项目代码是早期版本不完整，需要完整项目代码和资料请私聊。</font></strong><br> <br><br> <strong><font size="3" face="Courier New">数据集</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128589175?spm=1001.2014.3001.5501">脑电项目探索和实现(EEG) (上)：研究数据集选取和介绍SEED</a><br> <strong><font size="3" face="Courier New">相关论文阅读分析：</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128607350?spm=1001.2014.3001.5501">EEG-SEED数据集作者的—基线论文阅读和分析</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/128637894?spm=1001.2014.3001.5501">图神经网络EEG论文阅读和分析：《EEG-Based Emotion Recognition Using Regularized Graph Neural Networks》</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/128679724?spm=1001.2014.3001.5501">EEG-GNN论文阅读和分析：《EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks》</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/128882363?spm=1001.2014.3001.5501">论文阅读和分析:Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/128892103?spm=1001.2014.3001.5501">论文阅读和分析：《DeepGCNs: Can GCNs Go as Deep as CNNs?》</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/128911280?spm=1001.2014.3001.5501">论文阅读和分析： “How Attentive are Graph Attention Networks?”</a><br> 7、<a href="https://blog.csdn.net/KPer_Yang/article/details/128927668?spm=1001.2014.3001.5501">论文阅读和分析：Simplifying Graph Convolutional Networks</a><br> 8、<a href="https://blog.csdn.net/KPer_Yang/article/details/128945159?spm=1001.2014.3001.5501">论文阅读和分析：LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</a><br> 9、<a href="https://blog.csdn.net/KPer_Yang/article/details/129968785?spm=1001.2014.3001.5502">图神经网络汇总和总结</a><br> <strong><font size="3" face="Courier New">相关实验和代码实现：</font></strong><br> <font size="3" face="Courier New">1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128740968?spm=1001.2014.3001.5501">用于图神经网络的脑电数据处理实现_图神经网络 脑电</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/129034169?spm=1001.2014.3001.5501">使用GCN训练和测试EEG的公开SEED数据集</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/129074872?spm=1001.2014.3001.5501">使用GAT训练和测试EEG公开的SEED数据集</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/129094901?spm=1001.2014.3001.5501">使用SGC训练和测试SEED数据集</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/129095088?spm=1001.2014.3001.5501">使用Transformer训练和测试EEG的公开SEED数据集_eeg transformer</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/129133439?spm=1001.2014.3001.5501">使用RGNN训练和测试EEG公开的SEED数据集</a><br> <strong><font size="3" face="Courier New">辅助学习资料：</font></strong><br> 1、<a href="https://blog.csdn.net/KPer_Yang/article/details/128808874?spm=1001.2014.3001.5501">官网三个简单Graph示例说明三种层次的应用_graph 简单示例</a><br> 2、<a href="https://blog.csdn.net/KPer_Yang/article/details/128810698?spm=1001.2014.3001.5501">PPI数据集示例项目学习图神经网络</a><br> 3、<a href="https://blog.csdn.net/KPer_Yang/article/details/128859245?spm=1001.2014.3001.5501">geometric库的数据处理详解</a><br> 4、<a href="https://blog.csdn.net/KPer_Yang/article/details/128880391?spm=1001.2014.3001.5501">NetworkX的dicts of dicts以及解决Seven Bridges of Königsberg问题</a><br> 5、<a href="https://blog.csdn.net/KPer_Yang/article/details/128889737?spm=1001.2014.3001.5501">geometric源码阅读和分析：MessagePassin类详解和使用</a><br> 6、<a href="https://blog.csdn.net/KPer_Yang/article/details/129095501?spm=1001.2014.3001.5501">cora数据集示例项目学习图神经网络</a><br> 7、<a href="https://blog.csdn.net/KPer_Yang/article/details/129102055?spm=1001.2014.3001.5501">Graph 聚合</a><br> 8、<a href="https://blog.csdn.net/KPer_Yang/article/details/129105477?spm=1001.2014.3001.5501">QM9数据集示例项目学习图神经网络</a><br> 9、<a href="https://blog.csdn.net/KPer_Yang/article/details/129105010?spm=1001.2014.3001.5501">处理图的开源库</a></font></font></font></p> 
</blockquote> 
<p><strong>部分代码如下:</strong></p> 
<h3><a id="cora_35"></a>cora数据集：</h3> 
<p>Cora数据集包含2708篇科学出版物， 5429条边，总共7种类别。数据集中的每个出版物都由一个 0/1 值的词向量描述，表示字典中相应词的缺失/存在。 该词典由 1433 个独特的词组成。意思就是说每一个出版物都由1433个特征构成，每个特征仅由0/1表示。</p> 
<p>数据集组成：</p> 
<ul><li>ind.cora.x : 训练集节点特征向量，保存对象为：scipy.sparse.csr.csr_matrix，实际展开后大小为： (140, 1433)</li><li>ind.cora.tx : 测试集节点特征向量，保存对象为：scipy.sparse.csr.csr_matrix，实际展开后大小为： (1000, 1433)</li><li>ind.cora.allx : 包含有标签和无标签的训练节点特征向量，保存对象为：scipy.sparse.csr.csr_matrix，实际展开后大小为：(1708, 1433)，可以理解为除测试集以外的其他节点特征集合，训练集是它的子集</li><li>ind.cora.y : one-hot表示的训练节点的标签，保存对象为：numpy.ndarray</li><li>ind.cora.ty : one-hot表示的测试节点的标签，保存对象为：numpy.ndarray</li><li>ind.cora.ally : one-hot表示的ind.cora.allx对应的标签，保存对象为：numpy.ndarray</li><li>ind.cora.graph : 保存节点之间边的信息，保存格式为：{ index : [ index_of_neighbor_nodes ] }</li><li>ind.cora.test.index : 保存测试集节点的索引，保存对象为：List，用于后面的归纳学习设置。</li></ul> 
<h3><a id="_50"></a>读开源代码实现：</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> argparse
<span class="token keyword">import</span> os<span class="token punctuation">.</span>path <span class="token keyword">as</span> osp

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">import</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Planetoid
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>logging <span class="token keyword">import</span> init_wandb<span class="token punctuation">,</span> log
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GATConv

parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--dataset'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'Cora'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--hidden_channels'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--heads'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--lr'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.005</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--epochs'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--wandb'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Track experiment'</span><span class="token punctuation">)</span>
args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
init_wandb<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f'GAT-</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> heads<span class="token operator">=</span>args<span class="token punctuation">.</span>heads<span class="token punctuation">,</span> epochs<span class="token operator">=</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span>
           hidden_channels<span class="token operator">=</span>args<span class="token punctuation">.</span>hidden_channels<span class="token punctuation">,</span> lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>

path <span class="token operator">=</span> osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>realpath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'Planetoid'</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span>path<span class="token punctuation">,</span> args<span class="token punctuation">.</span>dataset<span class="token punctuation">,</span> transform<span class="token operator">=</span>T<span class="token punctuation">.</span>NormalizeFeatures<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">GAT</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> heads<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GATConv<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> heads<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span><span class="token comment"># out==8*8</span>
        <span class="token comment"># On the Pubmed dataset, use `heads` output heads in `conv2`.</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GATConv<span class="token punctuation">(</span>hidden_channels <span class="token operator">*</span> heads<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> heads<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                             concat<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span><span class="token comment">#(2708, 1433)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>elu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#(2708, 64) 64=8*8，8是因为 head==8注意力；</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span><span class="token comment">#(2708, 64)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token comment">#(2708, 7) 总共7类；</span>
        <span class="token keyword">return</span> x


model <span class="token operator">=</span> GAT<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> args<span class="token punctuation">.</span>hidden_channels<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">,</span>
            args<span class="token punctuation">.</span>heads<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.005</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">5e-4</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>out<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>


<span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> mask <span class="token keyword">in</span> <span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">,</span> data<span class="token punctuation">.</span>val_mask<span class="token punctuation">,</span> data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span><span class="token punctuation">:</span>
        accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>pred<span class="token punctuation">[</span>mask<span class="token punctuation">]</span> <span class="token operator">==</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">int</span><span class="token punctuation">(</span>mask<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> accs


best_val_acc <span class="token operator">=</span> final_test_acc <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    train_acc<span class="token punctuation">,</span> val_acc<span class="token punctuation">,</span> tmp_test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> val_acc <span class="token operator">&gt;</span> best_val_acc<span class="token punctuation">:</span>
        best_val_acc <span class="token operator">=</span> val_acc
        test_acc <span class="token operator">=</span> tmp_test_acc
    log<span class="token punctuation">(</span>Epoch<span class="token operator">=</span>epoch<span class="token punctuation">,</span> Loss<span class="token operator">=</span>loss<span class="token punctuation">,</span> Train<span class="token operator">=</span>train_acc<span class="token punctuation">,</span> Val<span class="token operator">=</span>val_acc<span class="token punctuation">,</span> Test<span class="token operator">=</span>test_acc<span class="token punctuation">)</span>

</code></pre> 
<p>参考：</p> 
<p><a href="https://blog.csdn.net/zfhsfdhdfajhsr/article/details/116137598">【数据集介绍】Cora数据集介绍_一穷二白到年薪百万的博客-CSDN博客_cora数据集</a></p> 
<p><a href="https://github.com/pyg-team/pytorch_geometric">GitHub - pyg-team/pytorch_geometric: Graph Neural Network Library for PyTorch</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/361037ec02c48f7ae153b63bacd98823/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">PPI数据集示例项目学习图神经网络</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b2ca3073ce516aa2e04182843bb08ba4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">QM9数据集示例项目学习图神经网络</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>