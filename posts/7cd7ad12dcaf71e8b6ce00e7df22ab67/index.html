<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DataX与DataX web入门 - IT学习者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="DataX与DataX web入门" />
<meta property="og:description" content="1.DataX3.0简介
DataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。
设计理念
为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。当前使用现状
DataX在阿里巴巴集团内被广泛使用，承担了所有大数据的离线同步业务，并已持续稳定运行了6年之久。目前每天完成同步8w多道作业，每日传输数据量超过300TB。 2.DataX3.0框架设计
DataX本身作为离线数据同步框架，采用Framework &#43; plugin架构构建。将数据源读取和写入抽象成为Reader/Writer插件，纳入到整个同步框架中。
Reader：Reader为数据采集模块，负责采集数据源的数据，将数据发送给Framework。Writer： Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。 详情可参照官方文档说明：
https://github.com/alibaba/DataX/blob/master/introduction.md
3.dataX安装部署文档
推荐环境：
Linux
JDK(1.8以上，推荐1.8)
Python(推荐Python2.6.X)
Apache Maven 3.x (Compile DataX)
部署
方式1：直接下载DataX工具包
http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz
方式2：下载DataX源码，自己编译
https://github.com/alibaba/DataX
下载DataX源码：
$ git clone git@github.com:alibaba/DataX.git 通过maven打包： $ cd {DataX_source_code_home} $ mvn -U clean package assembly:assembly -Dmaven.test.skip=true 打包成功后的DataX包位于 {DataX_source_code_home}/target/datax/datax/ 4.dataX示例
reader–MySQL
writer–HIVE
准备MySQL数据源表信息hive中创建表结构构建json文件，用于数据抽取 { &#34;job&#34;: { &#34;content&#34;: [ { &#34;reader&#34;: { &#34;name&#34;: &#34;mysqlreader&#34;, &#34;parameter&#34;: { &#34;column&#34;: [ &#34;*&#34; ], &#34;connection&#34;: [ { &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itnewbiea.github.io/posts/7cd7ad12dcaf71e8b6ce00e7df22ab67/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-07-21T11:29:41+08:00" />
<meta property="article:modified_time" content="2020-07-21T11:29:41+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="IT学习者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">IT学习者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">DataX与DataX web入门</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><em><strong>1.DataX3.0简介</strong></em><br> DataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。<br> <img src="https://images2.imgbox.com/dd/24/Xjt1rRGm_o.png" alt="在这里插入图片描述"></p> 
<ul><li>设计理念<br> 为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。</li><li>当前使用现状<br> DataX在阿里巴巴集团内被广泛使用，承担了所有大数据的离线同步业务，并已持续稳定运行了6年之久。目前每天完成同步8w多道作业，每日传输数据量超过300TB。</li></ul> 
<p><em><strong>2.DataX3.0框架设计</strong></em><br> DataX本身作为离线数据同步框架，采用Framework + plugin架构构建。将数据源读取和写入抽象成为Reader/Writer插件，纳入到整个同步框架中。</p> 
<ul><li>Reader：Reader为数据采集模块，负责采集数据源的数据，将数据发送给Framework。</li><li>Writer： Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。</li><li>Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。</li></ul> 
<p>详情可参照官方文档说明：<br> https://github.com/alibaba/DataX/blob/master/introduction.md</p> 
<p><em><strong>3.dataX安装部署文档</strong></em></p> 
<ul><li> <p>推荐环境：<br> Linux<br> JDK(1.8以上，推荐1.8)<br> Python(推荐Python2.6.X)<br> Apache Maven 3.x (Compile DataX)</p> </li><li> <p>部署<br> 方式1：直接下载DataX工具包<br> http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz</p> <p>方式2：下载DataX源码，自己编译<br> https://github.com/alibaba/DataX<br> 下载DataX源码：</p> </li></ul> 
<pre><code class="prism language-bash">$ <span class="token function">git</span> clone git@github.com:alibaba/DataX.git
通过maven打包：
$ <span class="token function">cd</span>  <span class="token punctuation">{<!-- --></span>DataX_source_code_home<span class="token punctuation">}</span>
$ mvn -U clean package assembly:assembly -Dmaven.test.skip<span class="token operator">=</span>true
打包成功后的DataX包位于 <span class="token punctuation">{<!-- --></span>DataX_source_code_home<span class="token punctuation">}</span>/target/datax/datax/ 
</code></pre> 
<p><em><strong>4.dataX示例</strong></em><br> reader–MySQL<br> writer–HIVE</p> 
<ul><li>准备MySQL数据源表信息</li><li>hive中创建表结构</li><li>构建json文件，用于数据抽取</li></ul> 
<pre><code class="prism language-bash"><span class="token punctuation">{<!-- --></span>
    <span class="token string">"job"</span><span class="token keyword">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"content"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{<!-- --></span>
                <span class="token string">"reader"</span><span class="token keyword">:</span> <span class="token punctuation">{<!-- --></span>
                    <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"mysqlreader"</span>,
                    <span class="token string">"parameter"</span><span class="token keyword">:</span> <span class="token punctuation">{<!-- --></span>
                        <span class="token string">"column"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>
                            <span class="token string">"*"</span>
                        <span class="token punctuation">]</span>,
                        <span class="token string">"connection"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>
                            <span class="token punctuation">{<!-- --></span>
                                <span class="token string">"jdbcUrl"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>
                                    <span class="token string">"jdbc:mysql://100.73.13.37:3306/test"</span>
                                <span class="token punctuation">]</span>,
                                <span class="token string">"table"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>
                                    <span class="token string">"datax"</span>
                                <span class="token punctuation">]</span>
                            <span class="token punctuation">}</span>
                        <span class="token punctuation">]</span>,
                        <span class="token string">"password"</span><span class="token keyword">:</span> <span class="token string">"datax"</span>,
                        <span class="token string">"username"</span><span class="token keyword">:</span> <span class="token string">"datax"</span>
                    <span class="token punctuation">}</span>
                <span class="token punctuation">}</span>,
                <span class="token string">"writer"</span><span class="token keyword">:</span> <span class="token punctuation">{<!-- --></span>
                    <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"hdfswriter"</span>,
                    <span class="token string">"parameter"</span><span class="token keyword">:</span> <span class="token punctuation">{<!-- --></span>
                        <span class="token string">"column"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>
                            <span class="token punctuation">{<!-- --></span>
                                <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"id"</span>,
                                <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"BIGINT"</span>
                            <span class="token punctuation">}</span>,
                            <span class="token punctuation">{<!-- --></span>
                                <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"test1"</span>,
                                <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"VARCHAR"</span>
                            <span class="token punctuation">}</span>,
                            <span class="token punctuation">{<!-- --></span>
                                <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"test2"</span>,
                                <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"INT"</span>
                            <span class="token punctuation">}</span>,
                            <span class="token punctuation">{<!-- --></span>
                                <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"test3"</span>,
                                <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"INT"</span>
                            <span class="token punctuation">}</span>
                        <span class="token punctuation">]</span>,
                        <span class="token string">"compress"</span><span class="token keyword">:</span> <span class="token string">"gzip"</span>,
                        <span class="token string">"defaultFS"</span><span class="token keyword">:</span> <span class="token string">"hdfs://jxq-100-73-13-31:8020"</span>,
                        <span class="token string">"fieldDelimiter"</span><span class="token keyword">:</span> <span class="token string">"\t"</span>,
                        <span class="token string">"fileName"</span><span class="token keyword">:</span> <span class="token string">"dataxtest"</span>,
                        <span class="token string">"fileType"</span><span class="token keyword">:</span> <span class="token string">"text"</span>,
                        <span class="token string">"path"</span><span class="token keyword">:</span> <span class="token string">"/user/hive/warehouse/datax"</span>,
                        <span class="token string">"writeMode"</span><span class="token keyword">:</span> <span class="token string">"append"</span>
                    <span class="token punctuation">}</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">]</span>,
        <span class="token string">"setting"</span><span class="token keyword">:</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"speed"</span><span class="token keyword">:</span> <span class="token punctuation">{<!-- --></span>
                <span class="token string">"channel"</span><span class="token keyword">:</span> <span class="token string">"2"</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<pre><code class="prism language-bash"><span class="token variable">$python</span> /datax/bin/datax.py hdfs.json 

执行脚本输出：
DataX <span class="token punctuation">(</span>DATAX-OPENSOURCE-3.0<span class="token punctuation">)</span>, From Alibaba <span class="token operator">!</span>
Copyright <span class="token punctuation">(</span>C<span class="token punctuation">)</span> 2010-2017, Alibaba Group. All Rights Reserved.


2020-07-21 10:57:07.856 <span class="token punctuation">[</span>main<span class="token punctuation">]</span> INFO  VMInfo - VMInfo<span class="token comment"># operatingSystem class =&gt; sun.management.OperatingSystemImpl</span>
2020-07-21 10:57:07.864 <span class="token punctuation">[</span>main<span class="token punctuation">]</span> INFO  Engine - the machine info  <span class="token operator">=</span><span class="token operator">&gt;</span> 

        osInfo: Oracle Corporation 1.8 25.141-b15
        jvmInfo:        Linux amd64 3.10.0-693.5.2.el7.x86_64
        cpu num:        4

        totalPhysicalMemory:    -0.00G
        freePhysicalMemory:     -0.00G
        maxFileDescriptorCount: -1
        currentOpenFileDescriptorCount: -1

        GC Names        <span class="token punctuation">[</span>PS MarkSweep, PS Scavenge<span class="token punctuation">]</span>

        MEMORY_NAME                    <span class="token operator">|</span> allocation_size                <span class="token operator">|</span> init_size                      
        PS Eden Space                  <span class="token operator">|</span> 256.00MB                       <span class="token operator">|</span> 256.00MB                       
        Code Cache                     <span class="token operator">|</span> 240.00MB                       <span class="token operator">|</span> 2.44MB                         
        Compressed Class Space         <span class="token operator">|</span> 1,024.00MB                     <span class="token operator">|</span> 0.00MB                         
        PS Survivor Space              <span class="token operator">|</span> 42.50MB                        <span class="token operator">|</span> 42.50MB                        
        PS Old Gen                     <span class="token operator">|</span> 683.00MB                       <span class="token operator">|</span> 683.00MB                       
        Metaspace                      <span class="token operator">|</span> -0.00MB                        <span class="token operator">|</span> 0.00MB                         


2020-07-21 10:57:07.880 <span class="token punctuation">[</span>main<span class="token punctuation">]</span> INFO  Engine - 
<span class="token punctuation">{<!-- --></span><span class="token punctuation">..</span>.
<span class="token punctuation">}</span>

2020-07-21 10:57:07.901 <span class="token punctuation">[</span>main<span class="token punctuation">]</span> WARN  Engine - prioriy <span class="token keyword">set</span> to 0, because NumberFormatException, the value is: null
2020-07-21 10:57:07.903 <span class="token punctuation">[</span>main<span class="token punctuation">]</span> INFO  PerfTrace - PerfTrace traceId<span class="token operator">=</span>job_-1, isEnable<span class="token operator">=</span>false, priority<span class="token operator">=</span>0
2020-07-21 10:57:07.903 <span class="token punctuation">[</span>main<span class="token punctuation">]</span> INFO  JobContainer - DataX jobContainer starts job.
2020-07-21 10:57:07.904 <span class="token punctuation">[</span>main<span class="token punctuation">]</span> INFO  JobContainer - Set jobId <span class="token operator">=</span> 0
2020-07-21 10:57:08.237 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://100.73.13.37:3306/test?yearIsDateType<span class="token operator">=</span>false<span class="token operator">&amp;</span>zeroDateTimeBehavior<span class="token operator">=</span>convertToNull<span class="token operator">&amp;</span>tinyInt1isBit<span class="token operator">=</span>false<span class="token operator">&amp;</span>rewriteBatchedStatements<span class="token operator">=</span>true.
2020-07-21 10:57:08.239 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> WARN  OriginalConfPretreatmentUtil - 您的配置文件中的列配置存在一定的风险. 因为您未配置读取数据库表的列，当您的表字段个数、类型有变动时，可能影响任务正确性甚至会运行出错。请检查您的配置并作出修改.
Jul 21, 2020 10:57:08 AM org.apache.hadoop.util.NativeCodeLoader <span class="token operator">&lt;</span>clinit<span class="token operator">&gt;</span>
WARNING: Unable to load native-hadoop library <span class="token keyword">for</span> your platform<span class="token punctuation">..</span>. using builtin-java classes where applicable
2020-07-21 10:57:09.225 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - jobContainer starts to <span class="token keyword">do</span> prepare <span class="token punctuation">..</span>.
2020-07-21 10:57:09.226 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - DataX Reader.Job <span class="token punctuation">[</span>mysqlreader<span class="token punctuation">]</span> <span class="token keyword">do</span> prepare work <span class="token keyword">.</span>
2020-07-21 10:57:09.226 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - DataX Writer.Job <span class="token punctuation">[</span>hdfswriter<span class="token punctuation">]</span> <span class="token keyword">do</span> prepare work <span class="token keyword">.</span>
2020-07-21 10:57:09.321 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Job</span> - 由于您配置了writeMode append, 写入前不做清理工作, <span class="token punctuation">[</span>/user/hive/warehouse/datax<span class="token punctuation">]</span> 目录下写入相应文件名前缀  <span class="token punctuation">[</span>dataxtest<span class="token punctuation">]</span> 的文件
2020-07-21 10:57:09.321 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - jobContainer starts to <span class="token keyword">do</span> <span class="token function">split</span> <span class="token punctuation">..</span>.
2020-07-21 10:57:09.321 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - Job <span class="token keyword">set</span> Channel-Number to 2 channels.
2020-07-21 10:57:09.326 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - DataX Reader.Job <span class="token punctuation">[</span>mysqlreader<span class="token punctuation">]</span> splits to <span class="token punctuation">[</span>1<span class="token punctuation">]</span> tasks.
2020-07-21 10:57:09.328 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Job</span> - begin <span class="token keyword">do</span> split<span class="token punctuation">..</span>.
2020-07-21 10:57:09.331 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Job</span> - splited <span class="token function">write</span> <span class="token function">file</span> name:<span class="token punctuation">[</span>hdfs://jxq-100-73-13-31:8020/user/hive/warehouse/datax__3ee8db03_9653_4f5f_bdba_82e1459a7865/dataxtest__8813b2e1_2cd2_45fa_a81d_a3f762cb2b77<span class="token punctuation">]</span>
2020-07-21 10:57:09.331 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Job</span> - end <span class="token keyword">do</span> split.
2020-07-21 10:57:09.331 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - DataX Writer.Job <span class="token punctuation">[</span>hdfswriter<span class="token punctuation">]</span> splits to <span class="token punctuation">[</span>1<span class="token punctuation">]</span> tasks.
2020-07-21 10:57:09.345 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - jobContainer starts to <span class="token keyword">do</span> schedule <span class="token punctuation">..</span>.
2020-07-21 10:57:09.347 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - Scheduler starts <span class="token punctuation">[</span>1<span class="token punctuation">]</span> taskGroups.
2020-07-21 10:57:09.349 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - Running by standalone Mode.
2020-07-21 10:57:09.355 <span class="token punctuation">[</span>taskGroup-0<span class="token punctuation">]</span> INFO  TaskGroupContainer - taskGroupId<span class="token operator">=</span><span class="token punctuation">[</span>0<span class="token punctuation">]</span> start <span class="token punctuation">[</span>1<span class="token punctuation">]</span> channels <span class="token keyword">for</span> <span class="token punctuation">[</span>1<span class="token punctuation">]</span> tasks.
2020-07-21 10:57:09.368 <span class="token punctuation">[</span>taskGroup-0<span class="token punctuation">]</span> INFO  Channel - Channel <span class="token keyword">set</span> byte_speed_limit to -1, No bps activated.
2020-07-21 10:57:09.368 <span class="token punctuation">[</span>taskGroup-0<span class="token punctuation">]</span> INFO  Channel - Channel <span class="token keyword">set</span> record_speed_limit to -1, No tps activated.
2020-07-21 10:57:09.375 <span class="token punctuation">[</span>taskGroup-0<span class="token punctuation">]</span> INFO  TaskGroupContainer - taskGroup<span class="token punctuation">[</span>0<span class="token punctuation">]</span> taskId<span class="token punctuation">[</span>0<span class="token punctuation">]</span> attemptCount<span class="token punctuation">[</span>1<span class="token punctuation">]</span> is started
2020-07-21 10:57:09.379 <span class="token punctuation">[</span>0-0-0-reader<span class="token punctuation">]</span> INFO  CommonRdbmsReader<span class="token variable">$Task</span> - Begin to <span class="token function">read</span> record by Sql: <span class="token punctuation">[</span>select * from datax 
<span class="token punctuation">]</span> jdbcUrl:<span class="token punctuation">[</span>jdbc:mysql://100.73.13.37:3306/test?yearIsDateType<span class="token operator">=</span>false<span class="token operator">&amp;</span>zeroDateTimeBehavior<span class="token operator">=</span>convertToNull<span class="token operator">&amp;</span>tinyInt1isBit<span class="token operator">=</span>false<span class="token operator">&amp;</span>rewriteBatchedStatements<span class="token operator">=</span>true<span class="token punctuation">]</span>.
2020-07-21 10:57:09.403 <span class="token punctuation">[</span>0-0-0-writer<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Task</span> - begin <span class="token keyword">do</span> write<span class="token punctuation">..</span>.
2020-07-21 10:57:09.403 <span class="token punctuation">[</span>0-0-0-writer<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Task</span> - <span class="token function">write</span> to <span class="token function">file</span> <span class="token keyword">:</span> <span class="token punctuation">[</span>hdfs://jxq-100-73-13-31:8020/user/hive/warehouse/datax__3ee8db03_9653_4f5f_bdba_82e1459a7865/dataxtest__8813b2e1_2cd2_45fa_a81d_a3f762cb2b77<span class="token punctuation">]</span>
2020-07-21 10:57:09.413 <span class="token punctuation">[</span>0-0-0-reader<span class="token punctuation">]</span> INFO  CommonRdbmsReader<span class="token variable">$Task</span> - Finished <span class="token function">read</span> record by Sql: <span class="token punctuation">[</span>select * from datax 
<span class="token punctuation">]</span> jdbcUrl:<span class="token punctuation">[</span>jdbc:mysql://100.73.13.37:3306/test?yearIsDateType<span class="token operator">=</span>false<span class="token operator">&amp;</span>zeroDateTimeBehavior<span class="token operator">=</span>convertToNull<span class="token operator">&amp;</span>tinyInt1isBit<span class="token operator">=</span>false<span class="token operator">&amp;</span>rewriteBatchedStatements<span class="token operator">=</span>true<span class="token punctuation">]</span>.
2020-07-21 10:57:09.745 <span class="token punctuation">[</span>0-0-0-writer<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Task</span> - end <span class="token keyword">do</span> <span class="token function">write</span>
2020-07-21 10:57:09.776 <span class="token punctuation">[</span>taskGroup-0<span class="token punctuation">]</span> INFO  TaskGroupContainer - taskGroup<span class="token punctuation">[</span>0<span class="token punctuation">]</span> taskId<span class="token punctuation">[</span>0<span class="token punctuation">]</span> is successed, used<span class="token punctuation">[</span>402<span class="token punctuation">]</span>ms
2020-07-21 10:57:09.777 <span class="token punctuation">[</span>taskGroup-0<span class="token punctuation">]</span> INFO  TaskGroupContainer - taskGroup<span class="token punctuation">[</span>0<span class="token punctuation">]</span> completed it's tasks.
2020-07-21 10:57:19.364 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  StandAloneJobContainerCommunicator - Total 6 records, 50 bytes <span class="token operator">|</span> Speed 5B/s, 0 records/s <span class="token operator">|</span> Error 0 records, 0 bytes <span class="token operator">|</span>  All Task WaitWriterTime 0.000s <span class="token operator">|</span>  All Task WaitReaderTime 0.000s <span class="token operator">|</span> Percentage 100.00%
2020-07-21 10:57:19.365 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  AbstractScheduler - Scheduler accomplished all tasks.
2020-07-21 10:57:19.365 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - DataX Writer.Job <span class="token punctuation">[</span>hdfswriter<span class="token punctuation">]</span> <span class="token keyword">do</span> post work.
2020-07-21 10:57:19.365 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Job</span> - start <span class="token function">rename</span> <span class="token function">file</span> <span class="token punctuation">[</span>hdfs://jxq-100-73-13-31:8020/user/hive/warehouse/datax__3ee8db03_9653_4f5f_bdba_82e1459a7865/dataxtest__8813b2e1_2cd2_45fa_a81d_a3f762cb2b77.gz<span class="token punctuation">]</span> to <span class="token function">file</span> <span class="token punctuation">[</span>hdfs://jxq-100-73-13-31:8020/user/hive/warehouse/datax/dataxtest__8813b2e1_2cd2_45fa_a81d_a3f762cb2b77.gz<span class="token punctuation">]</span>.
2020-07-21 10:57:19.372 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Job</span> - finish <span class="token function">rename</span> <span class="token function">file</span> <span class="token punctuation">[</span>hdfs://jxq-100-73-13-31:8020/user/hive/warehouse/datax__3ee8db03_9653_4f5f_bdba_82e1459a7865/dataxtest__8813b2e1_2cd2_45fa_a81d_a3f762cb2b77.gz<span class="token punctuation">]</span> to <span class="token function">file</span> <span class="token punctuation">[</span>hdfs://jxq-100-73-13-31:8020/user/hive/warehouse/datax/dataxtest__8813b2e1_2cd2_45fa_a81d_a3f762cb2b77.gz<span class="token punctuation">]</span>.
2020-07-21 10:57:19.373 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Job</span> - start delete tmp <span class="token function">dir</span> <span class="token punctuation">[</span>hdfs://jxq-100-73-13-31:8020/user/hive/warehouse/datax__3ee8db03_9653_4f5f_bdba_82e1459a7865<span class="token punctuation">]</span> <span class="token keyword">.</span>
2020-07-21 10:57:19.389 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  HdfsWriter<span class="token variable">$Job</span> - finish delete tmp <span class="token function">dir</span> <span class="token punctuation">[</span>hdfs://jxq-100-73-13-31:8020/user/hive/warehouse/datax__3ee8db03_9653_4f5f_bdba_82e1459a7865<span class="token punctuation">]</span> <span class="token keyword">.</span>
2020-07-21 10:57:19.390 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - DataX Reader.Job <span class="token punctuation">[</span>mysqlreader<span class="token punctuation">]</span> <span class="token keyword">do</span> post work.
2020-07-21 10:57:19.390 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - DataX jobId <span class="token punctuation">[</span>0<span class="token punctuation">]</span> completed successfully.
2020-07-21 10:57:19.391 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  HookInvoker - No hook invoked, because base <span class="token function">dir</span> not exists or is a file: /data/lilin/datax/hook
2020-07-21 10:57:19.393 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - 
         <span class="token punctuation">[</span>total cpu info<span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> 
                averageCpu                     <span class="token operator">|</span> maxDeltaCpu                    <span class="token operator">|</span> minDeltaCpu                    
                -1.00%                         <span class="token operator">|</span> -1.00%                         <span class="token operator">|</span> -1.00%
                        

         <span class="token punctuation">[</span>total gc info<span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> 
                 NAME                 <span class="token operator">|</span> totalGCCount       <span class="token operator">|</span> maxDeltaGCCount    <span class="token operator">|</span> minDeltaGCCount    <span class="token operator">|</span> totalGCTime        <span class="token operator">|</span> maxDeltaGCTime     <span class="token operator">|</span> minDeltaGCTime     
                 PS MarkSweep         <span class="token operator">|</span> 1                  <span class="token operator">|</span> 1                  <span class="token operator">|</span> 1                  <span class="token operator">|</span> 0.029s             <span class="token operator">|</span> 0.029s             <span class="token operator">|</span> 0.029s             
                 PS Scavenge          <span class="token operator">|</span> 1                  <span class="token operator">|</span> 1                  <span class="token operator">|</span> 1                  <span class="token operator">|</span> 0.018s             <span class="token operator">|</span> 0.018s             <span class="token operator">|</span> 0.018s             

2020-07-21 10:57:19.393 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - PerfTrace not enable<span class="token operator">!</span>
2020-07-21 10:57:19.394 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  StandAloneJobContainerCommunicator - Total 6 records, 50 bytes <span class="token operator">|</span> Speed 5B/s, 0 records/s <span class="token operator">|</span> Error 0 records, 0 bytes <span class="token operator">|</span>  All Task WaitWriterTime 0.000s <span class="token operator">|</span>  All Task WaitReaderTime 0.000s <span class="token operator">|</span> Percentage 100.00%
2020-07-21 10:57:19.394 <span class="token punctuation">[</span>job-0<span class="token punctuation">]</span> INFO  JobContainer - 
任务启动时刻                    <span class="token keyword">:</span> 2020-07-21 10:57:07
任务结束时刻                    <span class="token keyword">:</span> 2020-07-21 10:57:19
任务总计耗时                    <span class="token keyword">:</span>                 11s
任务平均流量                    <span class="token keyword">:</span>                5B/s
记录写入速度                    <span class="token keyword">:</span>              0rec/s
读出记录总数                    <span class="token keyword">:</span>                   6
读写失败总数                    <span class="token keyword">:</span>                   0

</code></pre> 
<pre><code class="prism language-bash">hive<span class="token operator">&gt;</span> <span class="token keyword">select</span> * from datax<span class="token punctuation">;</span>
OK
1       你好    11      111
2       he      22      222
3       li      33      333
4       xu      44      444
5       xiao    55      555
6       xu      66      666
</code></pre> 
<p><em><strong>5.dataX web 单机安装部署</strong></em></p> 
<ul><li> <p>安装包准备：<br> 方式1：下载官方提供的tar安装包<br> https://pan.baidu.com/s/13yoqhGpD00I82K4lOYtQhg<br> 提取码：cpsk<br> 方式2：编译打包，具体要求可参考官方文档：https://github.com/WeiYe-Jing/datax-web/blob/master/doc/datax-web/datax-web-deploy.md</p> </li><li> <p>部署：<br> 解压后，执行一建安装脚本</p> </li></ul> 
<pre><code class="prism language-bash"><span class="token function">tar</span> -zxvf datax-web-2.1.2.tar.gz
<span class="token function">cd</span> datax-web-2.1.2/bin
sh install.sh --force
</code></pre> 
<ul><li>数据库安装，此步可参考MySQL安装方案</li></ul> 
<pre><code class="prism language-bash">mysql<span class="token operator">&gt;</span> create database datax<span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> use datax_web
mysql<span class="token operator">&gt;</span> <span class="token function">source</span> <span class="token variable">$PATH</span>/datax-web-2.1.2/bin/db/datax_web.sql
mysql<span class="token operator">&gt;</span> use datax_web
Reading table information <span class="token keyword">for</span> completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql<span class="token operator">&gt;</span> show tables<span class="token punctuation">;</span>
+---------------------+
<span class="token operator">|</span> Tables_in_datax_web <span class="token operator">|</span>
+---------------------+
<span class="token operator">|</span> job_group           <span class="token operator">|</span>
<span class="token operator">|</span> job_info            <span class="token operator">|</span>
<span class="token operator">|</span> job_jdbc_datasource <span class="token operator">|</span>
<span class="token operator">|</span> job_lock            <span class="token operator">|</span>
<span class="token operator">|</span> job_log             <span class="token operator">|</span>
<span class="token operator">|</span> job_log_report      <span class="token operator">|</span>
<span class="token operator">|</span> job_logglue         <span class="token operator">|</span>
<span class="token operator">|</span> job_permission      <span class="token operator">|</span>
<span class="token operator">|</span> job_project         <span class="token operator">|</span>
<span class="token operator">|</span> job_registry        <span class="token operator">|</span>
<span class="token operator">|</span> job_template        <span class="token operator">|</span>
<span class="token operator">|</span> job_user            <span class="token operator">|</span>
+---------------------+
12 rows <span class="token keyword">in</span> <span class="token keyword">set</span> <span class="token punctuation">(</span>0.00 sec<span class="token punctuation">)</span>
</code></pre> 
<ul><li>修改配置文件<br> ./modules/datax-admin/conf/application.yml</li></ul> 
<pre><code class="prism language-bash">server:
  port: 8080
  <span class="token comment">#port: ${server.port}</span>
spring:
  <span class="token comment">#数据源</span>
  datasource:
    username: datax
    password: datax
    url: jdbc:mysql://localhost:3306/datax_web?serverTimezone<span class="token operator">=</span>Asia/Shanghai<span class="token operator">&amp;</span>useLegacyDatetimeCode<span class="token operator">=</span>false<span class="token operator">&amp;</span>useSSL<span class="token operator">=</span>false<span class="token operator">&amp;</span>nullNamePatternMatchesAll<span class="token operator">=</span>true<span class="token operator">&amp;</span>useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF-8
    driver-class-name: com.mysql.jdbc.Driver

或者修改:
bootstrap.properties 配置文件
</code></pre> 
<ul><li>修改./modules/datax-executor/conf/application.yml配置文件</li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># web port</span>
server:
  port: <span class="token variable">${server.port}</span>
  <span class="token comment">#port: 8081</span>

<span class="token comment"># log config</span>
logging:
  config: classpath:logback.xml
  path: <span class="token variable">${data.path}</span>/applogs/executor/jobhandler
  <span class="token comment">#path: ./data/applogs/executor/jobhandler</span>

datax:
  job:
    admin:
      <span class="token comment">### datax admin address list, such as "http://address" or "http://address01,http://address02"</span>
      <span class="token comment">#addresses: http://127.0.0.1:8080</span>
      addresses: http://127.0.0.1:<span class="token variable">${datax.admin.port}</span>
    executor:
      appname: datax-executor
      ip:
      port: 9999
      <span class="token comment">#port: ${executor.port:9999}</span>
      <span class="token comment">### job log path</span>
      logpath: ./data/applogs/executor/jobhandler
      <span class="token comment">#logpath: ${data.path}/applogs/executor/jobhandler</span>
      <span class="token comment">### job log retention days</span>
      logretentiondays: 30
    <span class="token comment">### job, access token</span>
    accessToken:

  executor:
    <span class="token comment">#jsonpath: D:\\temp\\executor\\json\\</span>
    jsonpath: /data/lilin/datax/bin

  <span class="token comment">#pypath: F:\tools\datax\bin\datax.py</span>
  pypath: /data/lilin/datax/bin/datax.py
</code></pre> 
<ul><li>执行启动脚本：</li></ul> 
<pre><code class="prism language-bash"><span class="token function">cd</span> ./datax-web-2.1.2/bin
sh start-all.sh
<span class="token punctuation">[</span>root@jxq-100-73-13-3 bin<span class="token punctuation">]</span><span class="token comment"># jps</span>
7428 DataXAdminApplication
7704 DataXExecutorApplication
</code></pre> 
<p>启动成功后，出现DataXAdminApplication和DataXExecutorApplication进程；如启动失败，请检查日志：modules/datax-admin/bin/console.out或者modules/datax-executor/bin/console.out</p> 
<p><em><strong>6.运行</strong></em></p> 
<pre><code class="prism language-bash">http://<span class="token variable">$IP</span>:9527/index.html
输入用户名 admin 密码 123456 就可以直接访问系统
</code></pre> 
<p><em><strong>参考链接：</strong></em><br> dataX官方安装文档:<br> https://github.com/alibaba/DataX/blob/master/userGuid.md<br> dataX web官方安装文档：<br> https://github.com/WeiYe-Jing/datax-web/blob/master/doc/datax-web/datax-web-deploy.md<br> dataX 3.0官方介绍文档：<br> https://github.com/alibaba/DataX/blob/master/introduction.md<br> 其他童鞋贡献的文档:<br> https://segmentfault.com/a/1190000022182167?utm_source=tag-newest<br> https://www.oschina.net/search?scope=blog&amp;q=datax</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/35fbf272f870ba455d45a28a2965bb9f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">geoserver图层样式</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9ee4e34056f2b7089e52fdffe57f4d8e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">js使用split()方法处理截取以逗号分隔的字符串</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 IT学习者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://itnewbiea.github.io/js/foot.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>